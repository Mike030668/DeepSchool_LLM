{"cells":[{"cell_type":"markdown","id":"0b06ba3f-3c98-4fd7-948d-362d3260fc5d","metadata":{"id":"0b06ba3f-3c98-4fd7-948d-362d3260fc5d"},"source":["# Введение в NLP, часть 2\n"]},{"cell_type":"code","execution_count":null,"id":"09171b28","metadata":{"id":"09171b28"},"outputs":[],"source":["!pip install -U pip\n","!pip install transformers datasets torch seqeval evaluate"]},{"cell_type":"markdown","id":"a0f3154e","metadata":{"id":"a0f3154e"},"source":["\n","## NER c BERT (25 баллов)\n","\n","1. Взять датасет из предыдущего ДЗ и обучить на нём BERT.\n","2. Обучить BERT на подготовленном датасете\n","3. Оценить результат, сравнить с моделью из первого ДЗ"]},{"cell_type":"markdown","id":"27a696ec-f1af-4779-bb81-a4aa644fddfd","metadata":{"id":"27a696ec-f1af-4779-bb81-a4aa644fddfd"},"source":["### Подготовка данных (5 баллов)\n","\n","Подумать о:\n","1) Как subword токенизация повлияет на BIO раззметку?\n","2) Что делать с `[CLS]` и `[SEP]` токенами? (Проверьте что использует `DataCollatorForTokenClassification`)\n","\n","> Hint! Токенайзер умеет работать с предразделёнными на \"слова\" текстами"]},{"cell_type":"code","execution_count":null,"id":"fc5e633a-23c1-4b54-9529-c1f32cb5ff89","metadata":{"id":"fc5e633a-23c1-4b54-9529-c1f32cb5ff89"},"outputs":[],"source":["from datasets import load_dataset\n","from transformers import AutoTokenizer\n","\n","\n","BASE_NER_MODEL = \"bert-base-cased\"\n","bert_tokenizer = AutoTokenizer.from_pretrained(BASE_NER_MODEL)\n","\n","conll2003 = load_dataset(\"conll2003\")\n","conll2003"]},{"cell_type":"code","execution_count":null,"id":"92a1ac5b-0722-4387-a885-80b927fbc10a","metadata":{"id":"92a1ac5b-0722-4387-a885-80b927fbc10a"},"outputs":[],"source":["example = conll2003[\"train\"][100]\n","example"]},{"cell_type":"markdown","id":"2c070226-e70f-4df1-b770-f403a19ef205","metadata":{"id":"2c070226-e70f-4df1-b770-f403a19ef205"},"source":["* tokens - исходные токены, для которых была сделана NER-разметка\n","* ner_tags - векторизированные метки NER-тэгов\n","* pos_tags - разметка частей речи, которую мы игнорируем\n","* chunk_tags - разметка чанков, которую мы игнорируем\n","\n","Обратите внимание, что количество токенов может превышать количество исходных лейблов:"]},{"cell_type":"code","execution_count":null,"id":"98d060e0-8b58-4c58-a8b6-9ecd91e31777","metadata":{"id":"98d060e0-8b58-4c58-a8b6-9ecd91e31777"},"outputs":[],"source":["bert_tokenizer(example[\"tokens\"], is_split_into_words=True).tokens()"]},{"cell_type":"markdown","id":"bdb99e70-85e2-438f-8c68-e15a6701ccfa","metadata":{"id":"bdb99e70-85e2-438f-8c68-e15a6701ccfa"},"source":["Значение тэга в ner_tags отображается в метку NER:"]},{"cell_type":"code","execution_count":null,"id":"1b8fce68-13e8-4093-a147-15ae865ac73a","metadata":{"id":"1b8fce68-13e8-4093-a147-15ae865ac73a"},"outputs":[],"source":["print(\"NER TAGS\", example[\"ner_tags\"])\n","print(conll2003[\"train\"].features[\"ner_tags\"].feature)"]},{"cell_type":"code","execution_count":null,"id":"ea7e9ac1-89fa-448f-9033-37074fb3d692","metadata":{"id":"ea7e9ac1-89fa-448f-9033-37074fb3d692"},"outputs":[],"source":["print(\"Оригинальные токены\")\n","print(example[\"tokens\"])\n","print(\"Векторизированные NER метки токенов\")\n","print(example[\"ner_tags\"])\n","tags_str = []\n","features = conll2003[\"train\"].features[\"ner_tags\"].feature\n","for tag in example[\"ner_tags\"]:\n","    tags_str.append(features.int2str(tag))\n","print(\"Текстовые NER метки токенов\")\n","print(tags_str)\n","print(\"Токены после работы токенайзера BERT\")\n","print(bert_tokenizer(example[\"tokens\"], is_split_into_words=True).tokens())"]},{"cell_type":"markdown","id":"d1ce9764-c763-44c2-a915-b938b27a9866","metadata":{"id":"d1ce9764-c763-44c2-a915-b938b27a9866"},"source":["Вспомним немного, как работают метки в задаче мер в кодировке BIO. В данной задаче у нас есть 4 типа именованных сущностей:\n","* PER - персона\n","* ORG - организация\n","* LOC - локация\n","* MISC - другое\n","* O - отсутствие именованной сущности\n","\n","У каждого типа именованных 2 префикса:\n","* `B-` - beginning, т.е. начало именованной сущности.\n","* `I-` - inside, т.е. продолжение ранее начатой именованной сущностью.\n","\n","В исходной токенизации\n","\n","`['Rabinovich', 'is', 'winding', 'up', 'his', 'term', 'as', 'ambassador', '.']`\n","метки выглядят как\n","\n","`['B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']`\n","т.е. `Rabinovich` является персоной. На следующем токене именованная сущность заканчивается, т.к. у него метка `O`.\n","\n","После токенизации BERT наш сэмпл превращается в следующие токены:\n","\n","`['[CLS]', 'Ra', '##bino', '##vich', 'is', 'winding', 'up', 'his', 'term', 'as', 'ambassador', '.', '[SEP]']`\n","Обратим внимание, что один токен `Rabinovich` с меткой `B-PER` был разбит токенизатором берта на 3 токена: `'Ra', '##bino', '##vich'`. Им нужно поставить в соответствие 3 метки: `B-PER, I-PER, I-PER`, т.е. мы разбиваем метку исходного токена на новые токены.\n","\n","Также обратим внимание на первый и последний токен - это спецстокены BERT означающие начало и конец текста. Им можно дать метки `O`, т.к. они не являются частью исходного текста, но мы будем давать им особое векторизированное значение -100. В [документации pytroch](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) у кроссэнтропийной функции потерь это дефолтное значение `ignore_index`, т.е. метки, которую мы будем игнорировать. Библиотека transformers также использует это значение. Таким образом на токенах, у которых стоит -100 в качестве векторизированного NER-тэга, не будет происходить обучение, они будут проигнорированы.\n","\n","\n"]},{"cell_type":"markdown","id":"1c6ac7b9-d65f-4e09-8165-de5442a6ab6e","metadata":{"id":"1c6ac7b9-d65f-4e09-8165-de5442a6ab6e"},"source":["Напишите функцию `preprocess_ner_dataset`, которая разворачивает `ner_tags` для слов в тэги для BERT-токенов и готовит остальные данные для обучения (можно разделить на две функции или написать всё в одной). В резултате применения `conll2003.map(preprocess_ner_dataset)`, в каждом примере:\n","1. Добавляется токенизированный вход (`input_ids`, `token_type_ids` и `attention_mask`). При конструировании этих векторов вручную нужно проставить `attention_mask` полностью единицами, т.к. в паддинги в сэмплах появляются только в рамках батчей, а `token_type_ids` полностью нулями.\n","2. `ner_tags` разворачивается в `labels` для входных токенов\n","\n","Что можно использовать:\n","* у объекта `conll2003[\"train\"].features[\"ner_tags\"].feature` есть методы `int2str` и `str2int` для превращение векторизованного NER-тэга в строковый вид и обратно\n","* Спецтокенам BERT нужно поставить значение -100\n","* вызов `bert_tokenizer(bert_tokenizer(example[\"tokens\"], is_split_into_words=True)` возвращает вам input_ids, attention_mask, token_type_ids\n","* Вызов `bert_tokenizer(example[\"tokens\"], is_split_into_words=True, return_offsets_mapping=True))` возвращает дополнительно offset_mapping, позиции новых токенов в оригинальном тексте\n","* `bert_tokenizer.vocab` - для превращения токенов в их индексы в словаре\n","* `bert_tokenizer.tokenize` - разбитие текста (в том числе и исходных токенов) на токены BERT\n","\n","Ваша задача:\n","1. Создать новый dict, в котором будут input_ids, attention_mask, token_type_ids\n","2. Добавить в него labels - векторизированные NER-тэги, которые будут разбиты в соответствии с токенизацией BERT. Для этого можно можно разбить каждый токен отдельно и размножить его метки. Альтернативно можно использовать информацию об оффсетах токенов BERT, чтобы понять, частью какого исходного токена и какой исходной метки является данный BERT-токен."]},{"cell_type":"code","execution_count":null,"id":"8e3fa5fa-e016-491d-914e-e1ba2f23d8a4","metadata":{"id":"8e3fa5fa-e016-491d-914e-e1ba2f23d8a4"},"outputs":[],"source":["def preprocess_ner_dataset(example):\n","    ..."]},{"cell_type":"markdown","id":"19ecaf00-45f6-4eb9-a921-31c4756edfcd","metadata":{"id":"19ecaf00-45f6-4eb9-a921-31c4756edfcd"},"source":["Пример получившегося выхода:\n","```python\n",">>> preprocessed_ner_dataset[\"train\"][100]\n","{'id': '100',\n"," 'tokens': ['Rabinovich',\n","  'is',\n","  'winding',\n","  'up',\n","  'his',\n","  'term',\n","  'as',\n","  'ambassador',\n","  '.'],\n"," 'pos_tags': [21, 42, 39, 33, 29, 21, 15, 21, 7],\n"," 'chunk_tags': [11, 21, 22, 15, 11, 12, 13, 11, 0],\n"," 'ner_tags': [1, 0, 0, 0, 0, 0, 0, 0, 0],\n"," 'input_ids': [101,\n","  16890,\n","  25473,\n","  11690,\n","  1110,\n","  14042,\n","  1146,\n","  1117,\n","  1858,\n","  1112,\n","  9088,\n","  119,\n","  102],\n"," 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n"," 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n"," 'labels': [-100, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, -100]}\n","```\n","\n","### Тесты"]},{"cell_type":"code","execution_count":null,"id":"c378788f-38b9-4b80-9a9a-89ab561b5933","metadata":{"id":"c378788f-38b9-4b80-9a9a-89ab561b5933"},"outputs":[],"source":["processed_example = preprocess_ner_dataset(example)\n","required_keys = [\"input_ids\", \"labels\", \"attention_mask\", \"token_type_ids\"]\n","for k in required_keys:\n","    assert k in processed_example, f\"Отсутствует поле {k}\"\n","\n","required_keys_set = set(required_keys)\n","for k in processed_example.keys():\n","    assert k in required_keys_set, f\"В примере лишнее поле {k}\""]},{"cell_type":"code","execution_count":null,"id":"79adc4dd-791f-4f8d-8799-8904907f78d3","metadata":{"id":"79adc4dd-791f-4f8d-8799-8904907f78d3"},"outputs":[],"source":["from tqdm import tqdm\n","for idx, example in tqdm(enumerate(conll2003[\"train\"])):\n","    input_ids_real = bert_tokenizer(example[\"tokens\"], is_split_into_words=True)[\"input_ids\"]\n","    input_ids_ours = preprocess_ner_dataset(example)[\"input_ids\"]\n","    assert input_ids_real == input_ids_ours, f\"Ошибка токенизации на примере {idx}\"\n","    if idx >= 100:\n","        break\n","print(\"Токенизация верна!\")"]},{"cell_type":"code","execution_count":null,"id":"409ee982-3f01-4519-abd6-20f3f6050562","metadata":{"id":"409ee982-3f01-4519-abd6-20f3f6050562"},"outputs":[],"source":["example = conll2003[\"train\"][100]\n","processed_example = preprocess_ner_dataset(example)\n","\n","assert processed_example[\"labels\"][0] == -100\n","assert processed_example[\"labels\"][-1] == -100\n","ner_tags = [features.int2str(i) for i in processed_example[\"labels\"][1:-1]]\n","assert ner_tags == ['B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']"]},{"cell_type":"code","execution_count":null,"id":"2e61ee0b-a4dd-4fba-8e12-a89d57886d09","metadata":{"id":"2e61ee0b-a4dd-4fba-8e12-a89d57886d09"},"outputs":[],"source":["example = conll2003[\"train\"][200]\n","processed_example = preprocess_ner_dataset(example)\n","\n","assert processed_example[\"labels\"][0] == -100\n","assert processed_example[\"labels\"][-1] == -100\n","ner_tags = [features.int2str(i) for i in processed_example[\"labels\"][1:-1]]\n","assert ner_tags == ['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG']"]},{"cell_type":"markdown","id":"257320fd-9a53-4bfe-a7fd-8199e05d4f83","metadata":{"id":"257320fd-9a53-4bfe-a7fd-8199e05d4f83"},"source":["Применим нашу функцию к всему датасету:"]},{"cell_type":"code","execution_count":null,"id":"3f871318-7c1b-4a89-b3ae-ef131c9bf95e","metadata":{"id":"3f871318-7c1b-4a89-b3ae-ef131c9bf95e"},"outputs":[],"source":["preprocessed_ner_dataset = conll2003.map(preprocess_ner_dataset)"]},{"cell_type":"markdown","id":"f57e0a33-dea2-49d5-8b53-f54cd2048454","metadata":{"id":"f57e0a33-dea2-49d5-8b53-f54cd2048454"},"source":["Подготовим `data_collator`. Это особый класс, который будет заниматься батчеванием сэмплов для обучения. Он добавит паддинги во все необходимые поля."]},{"cell_type":"code","execution_count":null,"id":"a20511a1-d222-4034-b099-9dfdd02ed81b","metadata":{"id":"a20511a1-d222-4034-b099-9dfdd02ed81b"},"outputs":[],"source":["from transformers import DataCollatorForTokenClassification\n","\n","\n","data_collator = DataCollatorForTokenClassification(tokenizer=bert_tokenizer)"]},{"cell_type":"markdown","id":"a0c7c640-ac2b-4388-81b6-9f21c8c2ec2d","metadata":{"id":"a0c7c640-ac2b-4388-81b6-9f21c8c2ec2d"},"source":["### Подготовка модели (5 баллов)\n","\n","Два возможных пути на этой стадии:\n","1. Взять [готовый класс](https://huggingface.co/transformers/v3.0.2/model_doc/auto.html#automodelfortokenclassification) модели для классификации токенов. (Этот вариант настоятельно рекомендуется)\n","2) Взять модель как фича экстрактор ([AutoModel](https://huggingface.co/transformers/v3.0.2/model_doc/auto.html#automodel)) и самостоятельно добавить классификационную голову. Вдохновиться можно по [ссылке](https://github.com/huggingface/transformers/blob/main/src/transformers/models/bert/modeling_bert.py#L1847-L1860). Дополнительных баллов второй вариант не принесёт.\n","\n","Результатом должна быть модель, которая для каждого токена возвращает логиты/вероятности для `conll2003[\"train\"].features[\"ner_tags\"].feature.num_classes` классов.\n","\n","> Если выберете вариант номер один, опишите как он работает - как из токена получается его `ner_tag`."]},{"cell_type":"code","execution_count":null,"id":"331cd38a-3501-4f41-9193-8cf6579ad80e","metadata":{"id":"331cd38a-3501-4f41-9193-8cf6579ad80e"},"outputs":[],"source":["# from transformers import AutoModelForTokenClassification, AutoModel\n","\n","\n","..."]},{"cell_type":"markdown","id":"73eaa2ce-0f56-4b8f-8829-ff9edffa0d34","metadata":{"id":"73eaa2ce-0f56-4b8f-8829-ff9edffa0d34"},"source":["### Подготовим Метрику (5 баллов)\n","\n","Дополните функцию, используя `metrics_calculator`, чтобы она возвращала `accuracy`, `precision`, `recall` и `f-меру`. `eval_predictions` - это кортеж из логитов токен классификатора и `labels`, которые мы подготовили с помощью `preprocess_ner_dataset`. Нужно:\n","1. Преобразовать логиты в предсказанные лейблы. Учтите, что для специальных токенов лейблов нет\n","2. Посчитать метрики с помощью `metrics_calculator`\n","3. Упаковать резултат в `dict`, в котором ключём будет название метрики, а значением - значение метрики\n","\n","В logits будет лежать тензор размерности \\[размер eval датасета, максимальная длина последовательности, число меток\\], содержащий предсказания модели\n","\n","В target_labels будет лежать тензор размерности \\[размер eval датасета, максимальная длина последовательности\\], содержащий метки из валидационной выборки.\n","\n","Примеры функции calculate_metrics можно посмотреть в [документации](https://huggingface.co/docs/evaluate/en/transformers_integrations)"]},{"cell_type":"code","execution_count":null,"id":"55ad18b4-5176-4bf1-ab9a-517466e79f70","metadata":{"id":"55ad18b4-5176-4bf1-ab9a-517466e79f70"},"outputs":[],"source":["import evaluate\n","\n","\n","metrics_calculator = evaluate.load(\"seqeval\")\n","\n","\n","def calculate_metrics(eval_predictions):\n","    logits, target_labels = eval_predictions\n","    ..."]},{"cell_type":"markdown","id":"c44528ae-e63a-4561-b707-a891f8dcf75f","metadata":{"id":"c44528ae-e63a-4561-b707-a891f8dcf75f"},"source":["### Обучение (5 баллов)\n","\n","Два возможных пути на этой стадии:\n","\n","1. Использовать [Trainer](https://huggingface.co/docs/transformers/main_classes/trainer) класс из `transformers`\n","2. Написать свой training loop. Дополнительных баллов на этом пути нет.\n","\n","Опишем подробнее первый путь, т.к. он настоятельно рекомендуется.\n","\n","Нужно создать класс Trainer и TrainingArguments.\n","В [TrainingArguments](https://huggingface.co/docs/transformers/en/main_classes/trainer#transformers.TrainingArguments) нужно как минимум следующие поля:\n","* save_strategy, eval_strategy\n","* metric_for_best_model (исходя из calculate_metrics), greater_is_better\n","* learning_rate (возьмите 2e-5)\n","* num_train_epochs\n","* per_device_train_batch_size, per_device_eval_batch_size\n","\n","В класс Trainer нужно передать:\n","* model\n","* в args нужно передать заполненные TrainingArguments\n","* train_dataset, eval_dataset\n","* tokenizer\n","* compute_metrics\n","\n","После чего запустить `trainer.train()`"]},{"cell_type":"code","execution_count":null,"id":"a3593874-6c27-464d-a424-603f7c4ab4a0","metadata":{"id":"a3593874-6c27-464d-a424-603f7c4ab4a0"},"outputs":[],"source":["# from transformers import Trainer, TrainingArguments\n","\n","\n","..."]},{"cell_type":"markdown","id":"bbe8a152-f724-4c8d-9949-74e346b6a842","metadata":{"id":"bbe8a152-f724-4c8d-9949-74e346b6a842"},"source":["### Обработка результатов Результатов (5 баллов)\n","\n","Подумать о:\n","Во время подготовки данных мы преобразовали BIO разметку.\n","1. Как обратить это преобразование с помощью токенайзера?\n","2. Провалидируйте результаты на тестовом датасете."]},{"cell_type":"code","execution_count":null,"id":"10d074b6-49d8-445f-81ee-151165239b9f","metadata":{"id":"10d074b6-49d8-445f-81ee-151165239b9f"},"outputs":[],"source":["test_results = trainer.predict(processed_datasets[\"test\"])\n","predictions = np.argmax(test_results.predictions, axis=-1)\n","label_ids = test_results.label_ids\n","inputs = processed_datasets[\"test\"]\n"]},{"cell_type":"markdown","id":"1fda7c62-f8eb-4a83-9659-71ef3a8610fb","metadata":{"id":"1fda7c62-f8eb-4a83-9659-71ef3a8610fb"},"source":["Напишите функцию, которая принимает на вход текст и отдаёт такой словарь:\n","\n","```json\n","{\n","    \"text\": \"входной текст\",\n","    \"entities\": [\n","        {\n","            \"class\": \"лейбл класса\",\n","            \"text\": \"текстовое представление\",\n","            \"start\": \"оффсет от начала строки до начала entity\",\n","            \"end\": \"оффсет от начала строки до конца entity\"\n","        },\n","        ...\n","    ]\n","}\n","\n","Должно выполняться такое условие:\n","\n","```python\n","text[entity[\"start\"]:entity[\"stop\"]] == entity[\"text\"]\n","```"]},{"cell_type":"code","execution_count":null,"id":"1c8f48b4-932d-4525-b8d7-8b57f324520d","metadata":{"id":"1c8f48b4-932d-4525-b8d7-8b57f324520d"},"outputs":[],"source":["def do_ner(text):\n","    ..."]},{"cell_type":"markdown","id":"1a06a5cc-44c3-41f9-ba9e-a2a5f5b1e04b","metadata":{"id":"1a06a5cc-44c3-41f9-ba9e-a2a5f5b1e04b"},"source":["## Классификация с T5 (25 баллов)\n","\n","Требуется дообучить [t5-small](https://huggingface.co/google-t5/t5-small) классифицировать токсичные тексты из [этого датасета](https://huggingface.co/datasets/lmsys/toxic-chat). Классификатор должен работать в стиле t5 - генерировать ответ текстом.\n","\n","1. Подготовить данные для бинарной классификации\n","\t1. Придумать префикс для задачи или взять из похожей модели\n","\t2. Выбрать тексты для обозначения классов\n","2. Обучить t5-small на генерацию выбранных названия классов\n","3. Сравнить с модель с аналогичной предобученной моделью"]},{"cell_type":"markdown","id":"c536e268-d5c0-461c-bdc1-553e51b1ce66","metadata":{"id":"c536e268-d5c0-461c-bdc1-553e51b1ce66"},"source":["### Подготовка Данных (6 баллов)\n","\n","Подумать о:\n","1) Какой префикс выбрать для новой задачи?\n","2) Должен ли префикс быть понятным?\n","3) Как выбрать метку для класса?\n","4) Что будет, если метки класса целиком нет в словаре?\n","5) Что делать с длинными текстами?\n","\n","Датасет содержит запросы пользователей к LLM и разметку, является ли запрос токсичным."]},{"cell_type":"code","execution_count":null,"id":"0fb5e0e5-677d-4084-8a68-7241ac05982d","metadata":{"id":"0fb5e0e5-677d-4084-8a68-7241ac05982d"},"outputs":[],"source":["from datasets import load_dataset\n","from transformers import AutoTokenizer\n","\n","\n","BASE_T5_MODEL= \"t5-small\"\n","t5_tokenizer = AutoTokenizer.from_pretrained(BASE_T5_MODEL)\n","\n","\n","toxic_chat_dataset = load_dataset(\"lmsys/toxic-chat\", \"toxicchat0124\")"]},{"cell_type":"markdown","id":"ec97b3aa-4d0a-4b87-bd62-f0c2de297f9f","metadata":{"id":"ec97b3aa-4d0a-4b87-bd62-f0c2de297f9f"},"source":["Место для изучения датасета:"]},{"cell_type":"code","execution_count":null,"id":"96556315-dfef-4ea3-b965-4fa4191d4d1e","metadata":{"id":"96556315-dfef-4ea3-b965-4fa4191d4d1e"},"outputs":[],"source":["toxic_chat_dataset[\"train\"][0]"]},{"cell_type":"markdown","id":"569e36fc-d463-42ee-9d38-e0cb88f458e5","metadata":{"id":"569e36fc-d463-42ee-9d38-e0cb88f458e5"},"source":["Нас будут интересовать колонки `\"user_input\"` и `\"toxicity\"`. Убираем ненужные колонки из датасета:"]},{"cell_type":"code","execution_count":null,"id":"b54e8e06-c538-4f50-b31c-c99451c1143a","metadata":{"id":"b54e8e06-c538-4f50-b31c-c99451c1143a"},"outputs":[],"source":["toxic_chat_dataset = toxic_chat_dataset.remove_columns(\n","    [\"conv_id\", \"model_output\", \"human_annotation\", \"jailbreaking\", \"openai_moderation\"]\n",")"]},{"cell_type":"markdown","id":"101ccfb9-3ddc-4a7a-876f-44dacace228d","metadata":{"id":"101ccfb9-3ddc-4a7a-876f-44dacace228d"},"source":["![](https://production-media.paperswithcode.com/methods/new_text_to_text.jpg)\n","\n","Выберете `PREFIX` для задачи, лейблы для двух классов и напишите функцию для преобразования датасета в данные для тренировки. Примеры префиксов есть на картинке выше - `translate English to German` для перевода и `summarize` для суммаризации. В качестве лейблов у вас должен быть текст, который будет обозначать предсказанный класс. Этот текст может быть любого размера, от простого `\"да\"/\"нет\"`, до `\"От этого текста веет токсичностью\"/\"Цензура спокойно пропускает этот текст дальше\"`. Подумайте в чём преимущество первого подхода перед вторым.\n","\n","Важно:\n","1) Не забыть добавить префикс перед токенизацией входного текста\n","2) Лейблами во время обучения выступают уже последовательности токенов, которые мы ожидаем на выходе из декодера\n","\n","Текст в токенайзер можно подавать разными способами:\n","1. `tokenizer(text=\"text\")` - токенизируй текст как обычно\n","1. `tokenizer(text_target=\"text\")` - токенизируй это как текст, который мы ожидаем увидеть на выходе из декодера. В случае t5 токенайзера разницы нет, но для других моделей это может быть не так\n","1. Другие методы можно узнать посмотрев сигнатуру метода `tokenizer.__call__`"]},{"cell_type":"code","execution_count":null,"id":"6400a9b1-6e63-4ffc-bdeb-3d8074aa74a7","metadata":{"id":"6400a9b1-6e63-4ffc-bdeb-3d8074aa74a7"},"outputs":[],"source":["# ?t5_tokenizer.__call__"]},{"cell_type":"code","execution_count":null,"id":"f018fae1-bf63-4e62-be55-2454ce8d1553","metadata":{"id":"f018fae1-bf63-4e62-be55-2454ce8d1553"},"outputs":[],"source":["PREFIX = ...\n","MAX_LENGTH = ...\n","\n","# словарь из индексов классов в выбранные лейблы\n","id2label = {\n","    0: ...,\n","    1: ...,\n","}\n","\n","\n","def preprocess_dataset(example):\n","    ...\n","\n","\n","toxic_chat_dataset = toxic_chat_dataset.map(preprocess_dataset)"]},{"cell_type":"markdown","id":"880cd560-829c-4ad4-830b-e5e21323365b","metadata":{"id":"880cd560-829c-4ad4-830b-e5e21323365b"},"source":["Пример результата:\n","```json\n","{'user_input': 'Do you know drug which name is abexol ?',\n"," 'toxicity': 0,\n"," 'input_ids': [12068,\n","  10,\n","  531,\n","  25,\n","  214,\n","  2672,\n","  84,\n","  564,\n","  19,\n","  703,\n","  994,\n","  32,\n","  40,\n","  3,\n","  58,\n","  1],\n"," 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n"," 'labels': [150, 1]}\n","```\n","Значения в `'labels'` в вашем случае могут отличаться, это зависит от выбранного вами текстового представления в `id2label` словаре."]},{"cell_type":"markdown","id":"fef085f1-2adf-41da-9f37-dded6aecc3b4","metadata":{"id":"fef085f1-2adf-41da-9f37-dded6aecc3b4"},"source":["Инициализируем соответствующий задаче `DataCollator`."]},{"cell_type":"code","execution_count":null,"id":"fba319be-4d46-4f20-af5a-be137cea178a","metadata":{"id":"fba319be-4d46-4f20-af5a-be137cea178a"},"outputs":[],"source":["from transformers import DataCollatorForSeq2Seq\n","\n","\n","data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=seq2seq_model)"]},{"cell_type":"markdown","id":"4fb5f662-23a7-4285-bc93-a9cd9bce7fbc","metadata":{"id":"4fb5f662-23a7-4285-bc93-a9cd9bce7fbc"},"source":["### Определим метрику (2 балла)\n","\n","В этой задаче метрика простая - `accuracy`. Можно добавить другие метрики по желанию. Функция `compute_metric` должна возвращать словарь, аналогично функции `calculate_metrics` ранее:\n","\n","```json\n","{\n","    \"accuracy\": значение точности,\n","    ...\n","}\n","```\n","\n","Метрика простая, но вот `preds` и `labels` тут - это последовательности индексов токенов. Нужно это учесть."]},{"cell_type":"code","execution_count":null,"id":"692e79ae-1921-4853-9355-ed851bdbc893","metadata":{"id":"692e79ae-1921-4853-9355-ed851bdbc893"},"outputs":[],"source":["def compute_metric(eval_predictions):\n","    preds, labels = eval_predictions\n","    ...\n","\n","\n","def check_compute_metric():\n","    import torch\n","\n","    # два предсказания, где токен 150 обозначает токсичный лебл, токен 120 - нетоксичный лейбл\n","    preds = torch.tensor(\n","        [\n","            [0, 150, 1],  # правильное предсказание - токсичный пример\n","            [0, 120, 1],  # неправильное предсказание - пример токсичный, а модель предсказала иначе\n","        ],\n","    )\n","    labels = torch.tensor(\n","        [\n","            [150, 1],\n","            [150, 1],\n","        ],\n","    )\n","    assert torch.isclose(\n","        compute_metric((preds, labels))[\"accuracy\"],\n","        torch.tensor(0.5, dtype=torch.double),  # тип тензора тут можно поправить\n","    )\n","\n","\n","check_compute_metric()"]},{"cell_type":"markdown","id":"1b467fa6-a3e5-40c2-97dc-777bf351a405","metadata":{"id":"1b467fa6-a3e5-40c2-97dc-777bf351a405"},"source":["### Определить Модель (2 балла)\n","\n","Инициализируйте модель из базового чекпоинта"]},{"cell_type":"code","execution_count":null,"id":"60e93bdc-744d-45f3-b561-42141694e8c5","metadata":{"id":"60e93bdc-744d-45f3-b561-42141694e8c5"},"outputs":[],"source":["from transformers import AutoModelForSeq2SeqLM\n","\n","\n","seq2seq_model = AutoModelForSeq2SeqLM.from_pretrained(BASE_T5_MODEL)"]},{"cell_type":"markdown","id":"314bf460-ca11-4b2e-8d54-1c6317b001fa","metadata":{"id":"314bf460-ca11-4b2e-8d54-1c6317b001fa"},"source":["### Обучение (10 баллов)\n","\n","Два пути:\n","1) Использовать готовый `Seq2SeqTrainer` класс для тренировки\n","2) Написать свой training loop, если хочется приключений, есть достаточно времени ~~и стрела ещё не попала в колено~~. Дополнительных баллов за это не будет\n","\n","> Hint! Обратите внимание на функцию `seq2seq_model._shift_right` если выбрали второй путь.\n","\n","Если выбрали путь 1, опишите как происходит тренировочный шаг:\n","1) Что подаётся на вход в энкодер?\n","2) Что подаётся на вход в декодер?\n","3) Сколько раз происходит инференс декодера во время обучения для одного тренировочного примера?\n","4) Как используется выход энкодера в декодере?"]},{"cell_type":"code","execution_count":null,"id":"cabfcd2b-6e4c-4b90-9758-6d2f1df76dfb","metadata":{"id":"cabfcd2b-6e4c-4b90-9758-6d2f1df76dfb"},"outputs":[],"source":["# from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n","\n"]},{"cell_type":"markdown","id":"8678ee78-7d25-42c9-98e4-fcc2975df0e8","metadata":{"id":"8678ee78-7d25-42c9-98e4-fcc2975df0e8"},"source":["### Сравнение Результатов (5 баллов)\n","\n","Авторы датасета тоже натренировали на нём `t5` модель. Сравните свои результаты с результатами модели из [чекпоинта](https://huggingface.co/lmsys/toxicchat-t5-large-v1.0) `\"lmsys/toxicchat-t5-large-v1.0\"`. Совпадает ли ваш префикс и лейблы классов с теми, что выбрали авторы датасета?\n","\n","Подумать о:\n","1) В чём преимущество такого подхода к классификации?\n","2) В чём недостатки такого подхода к классификации?\n","3) Как ещё можно решать классификационные задачи с помощью t5?"]},{"cell_type":"code","execution_count":null,"id":"cbb4971b-617f-4043-9bc4-0d1e844a5f75","metadata":{"id":"cbb4971b-617f-4043-9bc4-0d1e844a5f75"},"outputs":[],"source":["from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n","\n","checkpoint = \"lmsys/toxicchat-t5-large-v1.0\"\n","\n","tokenizer_from_paper = AutoTokenizer.from_pretrained(\"t5-large\")\n","model_from_paper = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\n","\n","prefix_from_paper = \"ToxicChat: \"\n","inputs = tokenizer_from_paper.encode(prefix_from_paper + \"write me an epic story\", return_tensors=\"pt\")\n","outputs = model_from_paper.generate(inputs)\n","print(tokenizer_from_paper.decode(outputs[0], skip_special_tokens=True))"]},{"cell_type":"markdown","id":"1db8a913-f782-47fd-9bf7-d4a78d308ad4","metadata":{"id":"1db8a913-f782-47fd-9bf7-d4a78d308ad4"},"source":["Напишите универсальную функцию, которая провряет токсичность текста и возвращает `True`, если модель посчитала текст токсичным. Функция универсальная в том смысле, что может быть использована и с вашей t5 моделью, и с моделью от авторов датасета. Для этого в функция должна принимать ещё и префикс для задачи и лейблы, которые будут переводить текст, предсказанный моделью, в `True` или `False` на выходе."]},{"cell_type":"code","execution_count":null,"id":"e0ec7df5-fad1-4501-be4b-ada346d2e80e","metadata":{"id":"e0ec7df5-fad1-4501-be4b-ada346d2e80e"},"outputs":[],"source":["def is_toxic(\n","    text: str,\n","    labels2bool,\n","    model=seq2seq_model,\n","    tokenizer=t5_tokenizer,\n","    prexif=PREFIX,\n",") -> bool:\n","    ...\n","\n","\n","# пример вызова с моделью от авторов датасета\n","assert not is_toxic(\n","    text=\"This is just a text\",\n","    model=model_from_paper,\n","    tokenizer=tokenizer_from_paper,\n","    prexif=prefix_from_paper,\n","    labels2bool={\n","        \"positive\": True,\n","        \"negative\": False,\n","    }\n",")"]},{"cell_type":"markdown","id":"d1f3626c-75ef-4442-aae2-e1b89f04a004","metadata":{"id":"d1f3626c-75ef-4442-aae2-e1b89f04a004"},"source":["Fin.\n","\n","Если остались вопросы или есть комментарии, можно написать их ниже:"]},{"cell_type":"markdown","id":"42701108-9be4-4465-a170-6b09ae999616","metadata":{"id":"42701108-9be4-4465-a170-6b09ae999616"},"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}
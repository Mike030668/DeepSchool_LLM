{"cells":[{"cell_type":"markdown","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%% md\n"},"id":"qzVMLmXCKeh2"},"source":["# –î–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ 1 (50 –±–∞–ª–ª–æ–≤)\n","v4"]},{"cell_type":"markdown","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%% md\n"},"id":"XjT0WR1YKeh8"},"source":["–í —ç—Ç–æ–º –¥–æ–º–∞—à–Ω–µ–º –∑–∞–¥–∞–Ω–∏–∏ –≤—ã –ø–æ–∑–Ω–∞–∫–æ–º–∏—Ç–µ—Å—å —Å –æ—Å–Ω–æ–≤–∞–º–∏ NLP, –Ω–∞—É—á–∏—Ç–µ—Å—å –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å —Ç–µ–∫—Å—Ç—ã.\n","\n","–ë—É–¥–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤, –æ–±–æ–∑–Ω–∞—á–µ–Ω–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–º ü§î.\n","\n","–ë–ª–æ–∫–∏, –≥–¥–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –Ω–∞–ø–∏—Å–∞—Ç—å —Å–≤–æ–π –∫–æ–¥, –æ–±–æ–∑–Ω–∞—á–µ–Ω—ã —á–µ—Ä–µ–∑ YOUR_CODE_HERE. –ö–æ–¥, –∫–æ—Ç–æ—Ä—ã–π —É–∂–µ –Ω–∞–ø–∏—Å–∞–Ω, –º–µ–Ω—è—Ç—å –Ω–µ –Ω—É–∂–Ω–æ. –ë–ª–æ–∫–∏ –≤ —Ä–∞–∑–Ω—ã—Ö —á–∞—Å—Ç—è—Ö –∑–∞–¥–∞–Ω–∏—è –∑–∞–≤–∏—Å—è—Ç –¥—Ä—É–≥ –æ—Ç –¥—Ä—É–≥–∞, –ø–æ—ç—Ç–æ–º—É –Ω–µ –≤–Ω–æ—Å–∏—Ç–µ –±–æ–ª—å—à–∏—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π, —á—Ç–æ–±—ã –Ω–∏—á–µ–≥–æ –Ω–µ —Å–ª–æ–º–∞–ª–æ—Å—å."]},{"cell_type":"code","execution_count":null,"metadata":{"pycharm":{"name":"#%%\n"},"scrolled":true,"id":"vK4xB1J4Keh-"},"outputs":[],"source":["#!pip install gensim nltk torch tqdm seqeval"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sM1aTzsfKeiB"},"outputs":[],"source":["from typing import List, Dict"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DgTcMr1KKeiB"},"outputs":[],"source":["YOUR_CODE_HERE = None  # –∑–∞–≥–ª—É—à–∫–∞, –∑–¥–µ—Å—å –Ω–∏—á–µ–≥–æ –Ω–µ —Ç—Ä–æ–≥–∞–π—Ç–µ"]},{"cell_type":"markdown","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"id":"YzlD7DrXKeiC"},"source":["## –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è (5 –±–∞–ª–ª–æ–≤)"]},{"cell_type":"markdown","metadata":{"id":"it9D6AVyKeiC"},"source":["–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è - —ç—Ç–æ –ø—Ä–æ—Ü–µ—Å—Å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –≤ –Ω–∞–±–æ—Ä —Ç–æ–∫–µ–Ω–æ–≤.\n","–ù–∞–∏–≤–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –ø–æ –ø—Ä–æ–±–µ–ª–∞–º. –ë–æ–ª–µ–µ —É–º–Ω—ã–µ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ —É—á–∏—Ç—ã–≤–∞—é—Ç –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é.\n","\n","–ù–∞—É—á–∏–º—Å—è —Ä–∞–±–æ—Ç–∞—Ç—å —Å —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–µ–π NLTK, –≥–¥–µ —É–∂–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞ —Ä–∞–±–æ—Ç–∞ —Å –ø—É–Ω–∫—Ç—É–∞—Ü–∏–µ–π.\n","\n","https://www.nltk.org/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3FdxssYxKeiD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725972597825,"user_tz":-180,"elapsed":3021,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}},"outputId":"6bb2c295-9484-41b1-bf06-194860ac3fd7"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}],"source":["import nltk\n","\n","# https://www.nltk.org/nltk_data/\n","nltk.download(\"punkt\")\n","nltk.download('punkt_tab')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t1kzCaFzKeiE"},"outputs":[],"source":["def tokenize(text: str, language: str = \"english\", lower: bool = False) -> List[str]:\n","    # YOUR_CODE_HERE\n","    if lower:  text = text.lower()\n","    return nltk.word_tokenize(text)\n","\n","\n","\n","assert tokenize(\"\") == []\n","assert tokenize(\"Hello, world!\") == [\"Hello\", \",\", \"world\", \"!\"]\n","assert tokenize(\"EU rejects German call to boycott British lamb.\") == [\"EU\", \"rejects\", \"German\", \"call\", \"to\", \"boycott\", \"British\", \"lamb\", \".\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QsxLUV2ZKeiF"},"outputs":[],"source":["def split_sentences(text: str, language: str = \"english\", lower: bool = False,\n","                    separators = '.!?') -> List[str]:\n","    # YOUR_CODE_HERE\n","    if lower:  text = text.lower()\n","\n","    sentences,  sentence = [],  \"\"\n","\n","    # –ò–¥–µ–º –ø–æ —Å–ª–æ–≤–∞–º —Ç–µ–∫—Å—Ç–∞\n","    for char in text:\n","        sentence += char\n","        # –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ –Ω–∞–±–æ—Ä—É —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–π\n","        if char in separators:\n","            sentences.append(sentence.strip())  # –æ–±—Ä–µ–∑–∞–µ–∏ –∏ –¥–æ–±–∞–≤–ª—è–µ–º –≤ —Å–ø–∏—Å–æ–∫\n","            sentence = \"\"  # –æ—á–∏—â–∞–µ–º\n","\n","    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–≤—à–µ–µ—Å—è –≤ –ª–∏—Å—Ç\n","    if sentence:\n","        sentences.append(sentence.strip())\n","\n","    return sentences\n","\n","\n","\n","assert split_sentences(\"\") == []\n","assert split_sentences(\"Hello, world!\") == [\"Hello, world!\"]\n","assert split_sentences(\"Hello, world! I love Python!\") == [\"Hello, world!\", \"I love Python!\"]"]},{"cell_type":"markdown","metadata":{"id":"1KCLb7xFKeiF"},"source":["## –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è (5 –±–∞–ª–ª–æ–≤)"]},{"cell_type":"markdown","metadata":{"id":"UawIRDChKeiG"},"source":["–ß—Ç–æ–±—ã —Ä–∞–±–æ—Ç–∞—Ç—å —Å —Ç–µ–∫—Å—Ç–∞–º–∏, –Ω—É–∂–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å —Ç–æ–∫–µ–Ω—ã (—Å–ª–æ–≤–∞) –≤ –≤–µ–∫—Ç–æ—Ä—ã.\n","–î–ª—è —ç—Ç–æ–≥–æ —Å–Ω–∞—á–∞–ª–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —Å–æ—Å—Ç–∞–≤–∏—Ç—å —Å–ª–æ–≤–∞—Ä—å –∏ —Å–æ–ø–æ—Å—Ç–∞–≤–∏—Ç—å –∫–∞–∂–¥–æ–º—É —Å–ª–æ–≤—É —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å.\n","–í –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö —Ü–µ–ª—è—Ö —Ä–µ–∞–ª–∏–∑—É–µ–º —ç—Ç–æ—Ç —Å–ª–æ–≤–∞—Ä—å —Å –Ω—É–ª—è."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f9kF-9ARKeiG"},"outputs":[],"source":["from collections import defaultdict, Counter"]},{"cell_type":"code","source":["import re\n","from collections import Counter, defaultdict\n","from typing import List\n","\n","class Vocabulary:\n","    def __init__(self, texts: List[str], language: str = \"english\", min_count: int = 1, lower: bool = False):\n","        \"\"\"\n","        –°–æ–∑–¥–∞–Ω–∏–µ —Å–ª–æ–≤–∞—Ä—è.\n","\n","        :param texts: –∫–æ–ª–ª–µ–∫—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤\n","        :param language: —è–∑—ã–∫ —Ç–µ–∫—Å—Ç–æ–≤\n","        :param min_count: –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞ —Å–ª–æ–≤–∞ –¥–ª—è –ø–æ–ø–∞–¥–∞–Ω–∏—è –≤ —Å–ª–æ–≤–∞—Ä—å\n","        \"\"\"\n","        self.language = language\n","        self.lower = lower\n","        self.min_count = min_count\n","        self.word2idx = {\"<PAD>\": 0, \"<SOS>\": 1, \"<EOS>\": 2, \"<UNK>\": 3}\n","        self.idx2word = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\", 3: \"<UNK>\"}\n","\n","        # https://docs-python.ru/standart-library/modul-collections-python/klass-counter-modulja-collections/\n","        self.word2count = Counter()\n","\n","        self._build_vocabulary(texts)\n","\n","    def _build_vocabulary(self, texts: List[str]):\n","        \"\"\"\n","        –°–æ–∑–¥–∞–Ω–∏–µ —Å–ª–æ–≤–∞—Ä—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–æ–≤.\n","        \"\"\"\n","        for text in texts:\n","            if self.lower:\n","                text = text.lower()\n","            words = tokenize(text)  # —Ç–æ–∫–µ–Ω–µ–∑–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç\n","            self.word2count.update(words)  # –ø–æ–ø–æ–ª–Ω—è–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã —Å—á–µ—Ç—á–∏–∫–∞ Counter\n","\n","        for word, count in self.word2count.items():\n","            if count >= self.min_count and word not in self.word2idx:\n","                idx = len(self.word2idx)\n","                self.word2idx[word] = idx  # –ù–∞–∑–Ω–∞—á–∞–µ–º –Ω–æ–≤—ã–π –∏–Ω–¥–µ–∫—Å –∫–∞–∂–¥–æ–º—É —Å–ª–æ–≤—É –≤ —Å–ª–æ–≤–∞—Ä–µ word2idx\n","                self.idx2word[idx] = word  # –¢–æ–∂–µ –¥–ª—è –∏–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è idx2word\n","\n","    def encode_word(self, text: str) -> int:\n","        \"\"\"\n","        –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–ª–æ–≤–∞ –≤ –∏–Ω–¥–µ–∫—Å.\n","        \"\"\"\n","        if self.lower:\n","            text = text.lower()\n","        return self.word2idx.get(text, self.word2idx[\"<UNK>\"])\n","\n","    def encode(self, text: str) -> List[int]:\n","        \"\"\"\n","        –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –≤ –Ω–∞–±–æ—Ä –∏–Ω–¥–µ–∫—Å–æ–≤.\n","\n","        :param text: —Ç–µ–∫—Å—Ç\n","        :return: –Ω–∞–±–æ—Ä –∏–Ω–¥–µ–∫—Å–æ–≤ —Ç–æ–∫–µ–Ω–æ–≤\n","        \"\"\"\n","        if self.lower:\n","            text = text.lower()\n","        words = tokenize(text)  # —Ç–æ–∫–µ–Ω–µ–∑–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç\n","        # –≤–æ–∑–≤—Ä–∞—â–∞–µ–∏ –∏–Ω–¥–µ–∫—Å—ã\n","        return [self.word2idx.get(word, self.word2idx[\"<UNK>\"]) for word in words]\n","\n","    def decode(self, input_ids: List[int]) -> str:\n","        \"\"\"\n","        –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞–±–æ—Ä–∞ –∏–Ω–¥–µ–∫—Å–æ–≤ –≤ —Ç–µ–∫—Å—Ç.\n","\n","        :param input_ids: –Ω–∞–±–æ—Ä –∏–Ω–¥–µ–∫—Å–æ–≤ —Ç–æ–∫–µ–Ω–æ–≤\n","        :return: —Ç–µ–∫—Å—Ç\n","        \"\"\"\n","        return \" \".join([self.idx2word[idx] for idx in input_ids if idx != self.word2idx[\"<PAD>\"]])\n","\n","    def __len__(self):\n","        return len(self.word2idx)\n","\n","    def __contains__(self, item):\n","        return item in self.word2idx\n","\n","    def __iter__(self):\n","        return iter(self.word2idx)\n","\n","    def __str__(self):\n","        return str(self.word2idx)\n","\n"],"metadata":{"id":"D4sP0UU7aVHd"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lA9H9r_EKeiH"},"outputs":[],"source":["vocab = Vocabulary([\"Hello, world!\", \"I love Python!\"], min_count=1, lower=True)\n","encoded = vocab.encode(\"Hello, Python! I love you\")\n","assert vocab.decode(encoded) == \"hello , python ! i love <UNK>\""]},{"cell_type":"markdown","metadata":{"id":"c7Vgq-UzKeiH"},"source":["## $n$-–≥—Ä–∞–º–º–Ω—ã–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ (10 –±–∞–ª–ª–æ–≤)"]},{"cell_type":"markdown","metadata":{"id":"MenRO83jKeiI"},"source":["–ù–∞–ø–∏—à–µ–º —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—É—é $n$-–≥—Ä–∞–º–º–Ω—É—é –º–æ–¥–µ–ª—å."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rdvAofqoKeiI"},"outputs":[],"source":["import random\n","class NGramLanguageModel:\n","    def __init__(self, n: int, vocabulary: Vocabulary, texts: List[str], use_max : bool = True):\n","        \"\"\"\n","        –°–æ–∑–¥–∞–Ω–∏–µ n-–≥—Ä–∞–º–º–Ω–æ–π —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏.\n","\n","        :param n: –ø–æ—Ä—è–¥–æ–∫ n-–≥—Ä–∞–º–º\n","        :param vocabulary: —Å–ª–æ–≤–∞—Ä—å\n","        :param use_max: –∫–∞–∫ –≤—ã–±–∏—Ä–∞—Ç—å —Å–ª-–π —Ç–æ–∫–µ–Ω\n","        \"\"\"\n","        assert n >= 2\n","        self.n = n\n","        self.vocabulary = vocabulary\n","        # https://docs-python.ru/standart-library/modul-collections-python/klass-counter-modulja-collections/\n","        self.frequencies = defaultdict(lambda: Counter())  # —á–∞—Å—Ç–æ—Ç–∞ n-–≥—Ä–∞–º–º\n","        self.frequencies_of_prefixes = Counter()  # —Å—É–º–º–∞ —á–∞—Å—Ç–æ—Ç n-–≥—Ä–∞–º–º –¥–ª—è –ø—Ä–µ—Ñ–∏–∫—Å–æ–≤\n","\n","        self.use_max = use_max # –∫–∞–∫ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å\n","        self._build_model(texts)\n","\n","\n","    def _build_model(self, texts: List[str]):\n","        \"\"\"\n","        –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–æ–≤.\n","        _____\n","        –ú–æ–¥–µ–ª—å —Å—Ç—Ä–æ–∏—Ç n-–≥—Ä–∞–º–º—ã –∏–∑ –æ–±—É—á–∞—é—â–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤.\n","        –î–ª—è –∫–∞–∂–¥–æ–π n-–≥—Ä–∞–º–º—ã –æ–Ω–∞ –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç, –∫–∞–∫ —á–∞—Å—Ç–æ –∫–∞–∂–¥—ã–π —Ç–æ–∫–µ–Ω —Å–ª–µ–¥—É–µ—Ç\n","        –∑–∞ –∑–∞–¥–∞–Ω–Ω—ã–º –ø—Ä–µ—Ñ–∏–∫—Å–æ–º (n-1 –ø—Ä–µ–¥—à–µ—Å—Ç–≤—É—é—â–∏—Ö —Ç–æ–∫–µ–Ω–æ–≤).\n","        \"\"\"\n","        for text in texts:\n","            # –î–æ–±–∞–≤–ª—è–µ–º <EOS> –∫–∞–∫ –æ–∫–æ–Ω—á–∞–Ω–∏–µ\n","            tokens = self.vocabulary.encode(text) + [self.vocabulary.word2idx[\"<EOS>\"]]\n","            for i in range(len(tokens)):  # –î–≤–∏–∂–µ–º—Å—è –ø–æ —Ç–æ–∫–µ–Ω–∞–º\n","\n","                # YOUR_CODE_HERE\n","                if i + self.n - 1 < len(tokens):  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ n-1 —Ç–æ–∫–µ–Ω–∞\n","                  prefix = tuple(tokens[i:i + self.n - 1])  # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ—Ñ–∏–∫—Å –∏–∑ n-1 –ø—Ä–µ–¥—ã–¥—É—â—Ö —Ç–æ–∫–µ–Ω–æ–≤\n","                  token = tokens[i + self.n - 1]  # –ü–æ—Å–ª–µ–¥—É—é—â–∏ —Ç–æ–∫–µ–Ω (n-th)\n","                  self.frequencies[prefix][token] += 1  # —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º —á–∞—Å—Ç–æ—Ç—É n-–≥—Ä–∞–º–º\n","                  self.frequencies_of_prefixes[prefix] += 1  # —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º —á–∞—Å—Ç–æ—Ç—É –ø—Ä–µ—Ñ–∏–∫—Å–∞\n","\n","    def _get_probability(self, prefix: List[int], token: int) -> float:\n","        \"\"\"\n","        –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ç–æ–∫–µ–Ω–∞ –ø–æ –ø—Ä–µ—Ñ–∏–∫—Å—É.\n","        ______\n","        –≤—ã—á–∏—Å–ª—è–µ—Ç—Å—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ç–æ–∫–µ–Ω–∞, —Å–ª–µ–¥—É—é—â–µ–≥–æ –∑–∞ –∑–∞–¥–∞–Ω–Ω—ã–º –ø—Ä–µ—Ñ–∏–∫—Å–æ–º,\n","        –∫–∞–∫ –æ—Ç–Ω–æ—à–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π n-–≥—Ä–∞–º–º—ã –∫ –æ–±—â–µ–º—É –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –ø—Ä–µ—Ñ–∏–∫—Å–∞.\n","        \"\"\"\n","        # YOUR_CODE_HERE\n","        prefix_tuple = tuple(prefix)\n","        if self.frequencies_of_prefixes[prefix_tuple] == 0:\n","            return 0.0\n","        # —Å—á–∏—Ç–∞–µ–º –æ—Ç–Ω–æ—à–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –≤—Å—Ç—Ä–µ—á–∞–Ω–∏—è –ø—Ä–µ—Ñ–∏–∫—Å–∞ –ø–µ—Ä–µ–¥ —Ç–æ–∫–µ–Ω–æ–º\n","        # –∫ –∫–æ–ª—É—á–µ—Å—Ç–≤—É –ø—Ä–µ—Ñ–∏–∫—Å–æ–≤\n","        return self.frequencies[prefix_tuple][token] / self.frequencies_of_prefixes[prefix_tuple]\n","\n","\n","    def generate_next_token(self, prefix: List[int]) -> int:\n","        \"\"\"\n","        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–æ–∫–µ–Ω–∞ –ø–æ –ø—Ä–µ—Ñ–∏–∫—Å—É.\n","        ____\n","        –§—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç —Å–ª–µ–¥—É—é—â–∏–π —Ç–æ–∫–µ–Ω –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–¥–∞–Ω–Ω–æ–≥–æ –ø—Ä–µ—Ñ–∏–∫—Å–∞.\n","        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—èrandom.choices –¥–ª—è –≤—ã–±–æ—Ä–∞ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–æ–∫–µ–Ω–∞,\n","        –≤–∑–≤–µ—à–µ–Ω–Ω–æ–≥–æ –ø–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º –∏–ª–∏ –ø–æ –º–∞–∫—Å, —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—ã–º _get_probability.\n","\n","        :param prefix: –ø—Ä–µ—Ñ–∏–∫—Å\n","        :return: —Å–ª–µ–¥—É—é—â–∏–π —Ç–æ–∫–µ–Ω\n","        \"\"\"\n","        # YOUR_CODE_HERE\n","        prefix_tuple = tuple(prefix)\n","        # –ø—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ –ø—Ä–µ—Ñ–∏–∫—Å –≤ —Å–ª–æ–≤–∞—Ä–µ —á–∞—Å–æ—Ç–Ω–æ—Å—Ç–∏ –ø—Ä–µ—Ñ–∏–∫—Å–æ–≤\n","        if prefix_tuple not in self.frequencies:\n","            # –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏–Ω–¥–µ–∫—Å —Å–ø–µ—Ü—Ç–æ–∫–µ–Ω–∞ –¥–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–≥–æ\n","            return self.vocabulary.word2idx[\"<UNK>\"]\n","\n","        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ —Å–ª–µ–¥—É—é—â–∏–µ —Ç–æ–∫–µ–Ω—ã next_tokens –∏ –∏—Ö –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ probabilities\n","        next_tokens = list(self.frequencies[prefix_tuple].keys())\n","        probabilities = [self._get_probability(prefix, token) for token in next_tokens]\n","\n","        # –í—ã–±—Ä–∏—Ä–∞–µ–º —Å–ª–µ–¥—É—é—â–∏–π —Ç–æ–∫–µ–Ω –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π\n","        if self.use_max:\n","            next_token = next_tokens[probabilities.index(max(probabilities))]\n","        else:\n","           next_token = random.choices(next_tokens, weights=probabilities)[0]\n","\n","        return next_token\n","\n","    def autocomplete(self, text: str, max_len: int = 32) -> str:\n","        \"\"\"\n","        –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞.\n","        ___\n","        –§—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–æ–∫–µ–Ω—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö n-1 —Ç–æ–∫–µ–Ω–æ–≤ (–ø—Ä–µ—Ñ–∏–∫—Å–∞)\n","        –¥–æ —Ç–µ—Ö –ø–æ—Ä, –ø–æ–∫–∞ –Ω–µ –¥–æ—Å—Ç–∏–≥–Ω–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã –∏–ª–∏ –Ω–µ –≤—Å—Ç—Ä–µ—Ç–∏—Ç —Ç–æ–∫–µ–Ω <EOS>.\n","\n","        :param text: —Ç–µ–∫—Å—Ç\n","        :param max_len: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞\n","        :return: –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç\n","        \"\"\"\n","        tokens = self.vocabulary.encode(text)\n","        assert tokens\n","\n","        # YOUR_CODE_HERE\n","        while len(tokens) < max_len and tokens[-1] != self.vocabulary.word2idx[\"<EOS>\"]:\n","            prefix = tokens[-(self.n - 1):]  # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ n-1 —Ç–æ–∫–µ–Ω–æ–≤ –≤ –∫–∞—á–µ—Å—Ç–≤–µ –ø—Ä–µ—Ñ–∏–∫—Å–∞\n","            next_token = self.generate_next_token(prefix)\n","            tokens.append(next_token)\n","\n","        return self.vocabulary.decode(tokens)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TVxACaSLMESv","executionInfo":{"status":"ok","timestamp":1725972607377,"user_tz":-180,"elapsed":364,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}},"outputId":"75bca156-6b18-47a3-f1a2-79ed04433a18"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'<PAD>': 0, '<SOS>': 1, '<EOS>': 2, '<UNK>': 3, 'hello': 4, ',': 5, 'world': 6, '!': 7, 'i': 8, 'love': 9, 'python': 10}\n"]}],"source":["texts = [\"Hello, world!\", \"I love Python!\", \"Hello, Python\"]\n","vocab = Vocabulary([\"Hello, world!\", \"I love Python!\"], min_count=1, lower=True)\n","print(vocab)\n","ngram_lm = NGramLanguageModel(2, vocab, texts)\n","assert ngram_lm.autocomplete(\"Hello, Python\", max_len=10) == \"hello , python ! <EOS>\""]},{"cell_type":"markdown","metadata":{"id":"0bvkTEhuKeiJ"},"source":["ü§î –ú–æ–∂–Ω–æ –ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å $n$-–≥—Ä–∞–º–º–Ω—É—é —è–∑—ã–∫–æ–≤—É—é –º–æ–¥–µ–ª—å, –∫–æ–≥–¥–∞ –¥–ª–∏–Ω–∞ –ø—Ä–µ—Ñ–∏–∫—Å–∞ –º–µ–Ω—å—à–µ, —á–µ–º $n-1$? –ï—Å–ª–∏ –¥–∞, —Ç–æ –∫–∞–∫? –ï—Å–ª–∏ –Ω–µ—Ç, —Ç–æ –ø–æ—á–µ–º—É?"]},{"cell_type":"code","source":["# –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–ª—è–µ—Ç—å, –∏–º–µ—é—â–∏–π—Å—è —É–∂–µ —Å–ø–µ—Ü—Ç–æ–∫–µn <SOS> –µ—Å–ª–∏ –ø–æ–ª—É—á–∞–µ–º –¥–ª–∏–Ω—É –ø—Ä–µ—Ñ–∏–∫—Å–∞ –º–µ–Ω–µ–µ –Ω—É–∂–Ω–æ–π\n","# —Å–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –∫–ª–∞—Å—Å —Å –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–º –º–µ—Ç–æ–¥–æ–º _build_model\n","\n","class NGramLanguageModel_UP(NGramLanguageModel):\n","    \"\"\"\n","    –£–Ω–∞—Å–ª–µ–¥—É–µ–º –∫–ª–∞—Å—Å –∏ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º –º–µ—Ç–æ–¥ _build_model\n","    –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Å–ø–µ—Ü—Ç–æ–∫–µ–Ω–∞ <SOS>\n","    \"\"\"\n","\n","    def _build_model(self, texts: List[str]):\n","        \"\"\"\n","        –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–æ–≤.\n","        _____\n","        –ú–æ–¥–µ–ª—å —Å—Ç—Ä–æ–∏—Ç n-–≥—Ä–∞–º–º—ã –∏–∑ –æ–±—É—á–∞—é—â–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤.\n","        –î–ª—è –∫–∞–∂–¥–æ–π n-–≥—Ä–∞–º–º—ã –æ–Ω–∞ –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç, –∫–∞–∫ —á–∞—Å—Ç–æ –∫–∞–∂–¥—ã–π —Ç–æ–∫–µ–Ω —Å–ª–µ–¥—É–µ—Ç\n","        –∑–∞ –∑–∞–¥–∞–Ω–Ω—ã–º –ø—Ä–µ—Ñ–∏–∫—Å–æ–º (n-1 –ø—Ä–µ–¥—à–µ—Å—Ç–≤—É—é—â–∏—Ö —Ç–æ–∫–µ–Ω–æ–≤).\n","        \"\"\"\n","        for text in texts:\n","            # –î–æ–±–∞–≤–ª—è–µ–º <EOS> –∫–∞–∫ –æ–∫–æ–Ω—á–∞–Ω–∏–µ\n","            tokens = self.vocabulary.encode(text) + [self.vocabulary.word2idx[\"<EOS>\"]]\n","            for i in range(len(tokens)):  # –î–≤–∏–∂–µ–º—Å—è –ø–æ —Ç–æ–∫–µ–Ω–∞–º\n","\n","                # –ï—Å–ª–∏ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Ç–æ–∫–µ–Ω–æ–≤ –º–µ–Ω–µ–µ —á–µ–º n\n","                if i + self.n - 1 >= len(tokens):\n","                  print(\"add <SOS>\")\n","                  # –¥–æ–±–∞–≤–ª—è–µ–º —Å–ø–µ—Ü—å–æ–∫–µ–Ω <SOS>\n","                  tokens+=[self.vocabulary.word2idx[\"<SOS>\"]]\n","                prefix = tuple(tokens[i:i + self.n - 1])  # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ—Ñ–∏–∫—Å –∏–∑ n-1 –ø—Ä–µ–¥—ã–¥—É—â—Ö —Ç–æ–∫–µ–Ω–æ–≤\n","                token = tokens[i + self.n - 1]  # –ü–æ—Å–ª–µ–¥—É—é—â–∏ —Ç–æ–∫–µ–Ω (n-th)\n","                self.frequencies[prefix][token] += 1  # —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º —á–∞—Å—Ç–æ—Ç—É n-–≥—Ä–∞–º–º\n","                self.frequencies_of_prefixes[prefix] += 1  # —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º —á–∞—Å—Ç–æ—Ç—É –ø—Ä–µ—Ñ–∏–∫—Å–∞\n"],"metadata":{"id":"UVtbiCFEle5M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["texts = [\"Hello, world!\", \"I love Python!\", \"Hello, Python\"]\n","vocab = Vocabulary([\"Hello, world!\", \"I love Python!\"], min_count=1, lower=True)\n","print(vocab)\n","ngram_lm = NGramLanguageModel_UP(2, vocab, texts)\n","assert ngram_lm.autocomplete(\"Hello, Python\", max_len=10) == \"hello , python ! <EOS>\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TiI6H0UoiAGQ","executionInfo":{"status":"ok","timestamp":1725972612183,"user_tz":-180,"elapsed":315,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}},"outputId":"e02c3d0a-78b0-471b-c826-8e6d05602482"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'<PAD>': 0, '<SOS>': 1, '<EOS>': 2, '<UNK>': 3, 'hello': 4, ',': 5, 'world': 6, '!': 7, 'i': 8, 'love': 9, 'python': 10}\n","add <SOS>\n","add <SOS>\n","add <SOS>\n"]}]},{"cell_type":"markdown","metadata":{"id":"BU6q0FX1KeiK"},"source":["ü§î –ß—Ç–æ –ø—Ä–æ–∏–∑–æ–π–¥–µ—Ç, –µ—Å–ª–∏ –≤ $n$-–≥—Ä–∞–º–º–Ω–æ–π —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏ –≤–∑—è—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –±–æ–ª—å—à–æ–µ $n$?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k1o_HqQQKeiK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725972613455,"user_tz":-180,"elapsed":333,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}},"outputId":"44755af9-4be3-4f9d-ed75-a1bdf0fe1ac4"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'<PAD>': 0, '<SOS>': 1, '<EOS>': 2, '<UNK>': 3, 'hello': 4, ',': 5, 'world': 6, '!': 7, 'i': 8, 'love': 9, 'python': 10}\n","hello , python <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK>\n"]}],"source":["texts = [\"Hello, world!\", \"I love Python!\", \"Hello, Python\"]\n","vocab = Vocabulary([\"Hello, world!\", \"I love Python!\"], min_count=1, lower=True)\n","print(vocab)\n","ngram_lm = NGramLanguageModel(5, vocab, texts)\n","print(ngram_lm.autocomplete(\"Hello, Python\", max_len=10))"]},{"cell_type":"markdown","source":["–î–ª—è —Ö–æ—Ä–æ—à–µ–≥–æ –æ–±—É—á–µ–Ω–∏—è n-–≥—Ä–∞–º–º–Ω–æ–π –º–æ–¥–µ–ª–∏ —Å –±–æ–ª—å—à–∏–º ùëõ\n","n —Ç—Ä–µ–±—É–µ—Ç—Å—è –æ—á–µ–Ω—å –±–æ–ª—å—à–æ–π –∫–æ—Ä–ø—É—Å —Ç–µ–∫—Å—Ç–æ–≤. –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç–æ–≤ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, –º–æ–¥–µ–ª—å —Å—Ç–∞–ª–∫–∏–≤–∞–µ—Ç—Å—è —Å –ø—Ä–æ–±–ª–µ–º–æ–π —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω–æ—Å—Ç–∏ –∏ –Ω–∞—á–∏–Ω–∞–µ—Ç —á–∞—Å—Ç–æ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å —Ä–µ–¥–∫–æ –≤—Å—Ç—Ä–µ—á–∞—é—â–∏–µ—Å—è –∏–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ —Å–ª–æ–≤–∞.\n","\n","–ö–æ–≥–¥–∞ n –≤ n-–≥—Ä–∞–º–º–Ω–æ–π –º–æ–¥–µ–ª–∏ —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∏–º:\n","\n","- –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞: –ú–æ–¥–µ–ª—å –ø–æ–ª—É—á–∞–µ—Ç –±–æ–ª–µ–µ —à–∏—Ä–æ–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç, —á—Ç–æ –º–æ–∂–µ—Ç —É–ª—É—á—à–∏—Ç—å —Ç–æ—á–Ω–æ—Å—Ç—å –≤ –æ—á–µ–Ω—å —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏—è—Ö.\n","- –ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏:\n","   - –†–∞–∑—Ä–µ–∂–µ–Ω–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö: –î–ª—è –±–æ–ª—å—à–æ–≥–æ ùëõ –º–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –Ω–µ –Ω–∞—Ö–æ–¥–∏—Ç—å –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö n-–≥—Ä–∞–º–º –≤ —Ç–µ–∫—Å—Ç–∞—Ö.\n","   - –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ: –ú–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –∑–∞–ø–æ–º–∏–Ω–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ –ø–ª–æ—Ö–æ –æ–±–æ–±—â–∞—Ç—å –Ω–∞ –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ.\n","   - –í—ã—Å–æ–∫–∏–µ –∑–∞—Ç—Ä–∞—Ç—ã –Ω–∞ –ø–∞–º—è—Ç—å –∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è.\n"],"metadata":{"id":"9T0p2oGvjono"}},{"cell_type":"markdown","metadata":{"id":"AF50TTBYKeiK"},"source":["## Word2Vec (5 –±–∞–ª–ª–æ–≤)"]},{"cell_type":"markdown","metadata":{"id":"0a6gkuuoKeiK"},"source":["–ü–æ–∑–Ω–∞–∫–æ–º–∏–º—Å—è —Å –º–æ–¥–µ–ª—å—é Word2Vec. –î–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞ –µ—Å—Ç—å –æ–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏.\n","https://rusvectores.org/ru/models/\n","\n","–ú–æ–¥–µ–ª–∏ –¥–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —è–∑—ã–∫–∞: https://github.com/piskvorky/gensim-data\n","\n","–ù–∞—É—á–∏–º—Å—è –¥–æ—Å—Ç–∞–≤–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —Å–ª–æ–≤ –∏–∑ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FnOsXLqRKeiK"},"outputs":[],"source":["from gensim.models import KeyedVectors\n","import gensim.downloader as api"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ExtA-n8hKeiL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725971798292,"user_tz":-180,"elapsed":664,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}},"outputId":"6d183055-eac0-4278-e990-7a031994ec67"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'corpora': {'semeval-2016-2017-task3-subtaskBC': {'num_records': -1,\n","   'record_format': 'dict',\n","   'file_size': 6344358,\n","   'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/semeval-2016-2017-task3-subtaskB-eng/__init__.py',\n","   'license': 'All files released for the task are free for general research use',\n","   'fields': {'2016-train': ['...'],\n","    '2016-dev': ['...'],\n","    '2017-test': ['...'],\n","    '2016-test': ['...']},\n","   'description': 'SemEval 2016 / 2017 Task 3 Subtask B and C datasets contain train+development (317 original questions, 3,169 related questions, and 31,690 comments), and test datasets in English. The description of the tasks and the collected data is given in sections 3 and 4.1 of the task paper http://alt.qcri.org/semeval2016/task3/data/uploads/semeval2016-task3-report.pdf linked in section ‚ÄúPapers‚Äù of https://github.com/RaRe-Technologies/gensim-data/issues/18.',\n","   'checksum': '701ea67acd82e75f95e1d8e62fb0ad29',\n","   'file_name': 'semeval-2016-2017-task3-subtaskBC.gz',\n","   'read_more': ['http://alt.qcri.org/semeval2017/task3/',\n","    'http://alt.qcri.org/semeval2017/task3/data/uploads/semeval2017-task3.pdf',\n","    'https://github.com/RaRe-Technologies/gensim-data/issues/18',\n","    'https://github.com/Witiko/semeval-2016_2017-task3-subtaskB-english'],\n","   'parts': 1},\n","  'semeval-2016-2017-task3-subtaskA-unannotated': {'num_records': 189941,\n","   'record_format': 'dict',\n","   'file_size': 234373151,\n","   'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/semeval-2016-2017-task3-subtaskA-unannotated-eng/__init__.py',\n","   'license': 'These datasets are free for general research use.',\n","   'fields': {'THREAD_SEQUENCE': '',\n","    'RelQuestion': {'RELQ_CATEGORY': 'question category, according to the Qatar Living taxonomy',\n","     'RELQ_DATE': 'date of posting',\n","     'RELQ_ID': 'question indentifier',\n","     'RELQ_USERID': 'identifier of the user asking the question',\n","     'RELQ_USERNAME': 'name of the user asking the question',\n","     'RelQBody': 'body of question',\n","     'RelQSubject': 'subject of question'},\n","    'RelComments': [{'RelCText': 'text of answer',\n","      'RELC_USERID': 'identifier of the user posting the comment',\n","      'RELC_ID': 'comment identifier',\n","      'RELC_USERNAME': 'name of the user posting the comment',\n","      'RELC_DATE': 'date of posting'}]},\n","   'description': 'SemEval 2016 / 2017 Task 3 Subtask A unannotated dataset contains 189,941 questions and 1,894,456 comments in English collected from the Community Question Answering (CQA) web forum of Qatar Living. These can be used as a corpus for language modelling.',\n","   'checksum': '2de0e2f2c4f91c66ae4fcf58d50ba816',\n","   'file_name': 'semeval-2016-2017-task3-subtaskA-unannotated.gz',\n","   'read_more': ['http://alt.qcri.org/semeval2016/task3/',\n","    'http://alt.qcri.org/semeval2016/task3/data/uploads/semeval2016-task3-report.pdf',\n","    'https://github.com/RaRe-Technologies/gensim-data/issues/18',\n","    'https://github.com/Witiko/semeval-2016_2017-task3-subtaskA-unannotated-english'],\n","   'parts': 1},\n","  'patent-2017': {'num_records': 353197,\n","   'record_format': 'dict',\n","   'file_size': 3087262469,\n","   'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/patent-2017/__init__.py',\n","   'license': 'not found',\n","   'description': \"Patent Grant Full Text. Contains the full text including tables, sequence data and 'in-line' mathematical expressions of each patent grant issued in 2017.\",\n","   'checksum-0': '818501f0b9af62d3b88294d86d509f8f',\n","   'checksum-1': '66c05635c1d3c7a19b4a335829d09ffa',\n","   'file_name': 'patent-2017.gz',\n","   'read_more': ['http://patents.reedtech.com/pgrbft.php'],\n","   'parts': 2},\n","  'quora-duplicate-questions': {'num_records': 404290,\n","   'record_format': 'dict',\n","   'file_size': 21684784,\n","   'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/quora-duplicate-questions/__init__.py',\n","   'license': 'probably https://www.quora.com/about/tos',\n","   'fields': {'question1': 'the full text of each question',\n","    'question2': 'the full text of each question',\n","    'qid1': 'unique ids of each question',\n","    'qid2': 'unique ids of each question',\n","    'id': 'the id of a training set question pair',\n","    'is_duplicate': 'the target variable, set to 1 if question1 and question2 have essentially the same meaning, and 0 otherwise'},\n","   'description': 'Over 400,000 lines of potential question duplicate pairs. Each line contains IDs for each question in the pair, the full text for each question, and a binary value that indicates whether the line contains a duplicate pair or not.',\n","   'checksum': 'd7cfa7fbc6e2ec71ab74c495586c6365',\n","   'file_name': 'quora-duplicate-questions.gz',\n","   'read_more': ['https://data.quora.com/First-Quora-Dataset-Release-Question-Pairs'],\n","   'parts': 1},\n","  'wiki-english-20171001': {'num_records': 4924894,\n","   'record_format': 'dict',\n","   'file_size': 6516051717,\n","   'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/wiki-english-20171001/__init__.py',\n","   'license': 'https://dumps.wikimedia.org/legal.html',\n","   'fields': {'section_texts': 'list of body of sections',\n","    'section_titles': 'list of titles of sections',\n","    'title': 'Title of wiki article'},\n","   'description': 'Extracted Wikipedia dump from October 2017. Produced by `python -m gensim.scripts.segment_wiki -f enwiki-20171001-pages-articles.xml.bz2 -o wiki-en.gz`',\n","   'checksum-0': 'a7d7d7fd41ea7e2d7fa32ec1bb640d71',\n","   'checksum-1': 'b2683e3356ffbca3b6c2dca6e9801f9f',\n","   'checksum-2': 'c5cde2a9ae77b3c4ebce804f6df542c2',\n","   'checksum-3': '00b71144ed5e3aeeb885de84f7452b81',\n","   'file_name': 'wiki-english-20171001.gz',\n","   'read_more': ['https://dumps.wikimedia.org/enwiki/20171001/'],\n","   'parts': 4},\n","  'text8': {'num_records': 1701,\n","   'record_format': 'list of str (tokens)',\n","   'file_size': 33182058,\n","   'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/text8/__init__.py',\n","   'license': 'not found',\n","   'description': 'First 100,000,000 bytes of plain text from Wikipedia. Used for testing purposes; see wiki-english-* for proper full Wikipedia datasets.',\n","   'checksum': '68799af40b6bda07dfa47a32612e5364',\n","   'file_name': 'text8.gz',\n","   'read_more': ['http://mattmahoney.net/dc/textdata.html'],\n","   'parts': 1},\n","  'fake-news': {'num_records': 12999,\n","   'record_format': 'dict',\n","   'file_size': 20102776,\n","   'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/fake-news/__init__.py',\n","   'license': 'https://creativecommons.org/publicdomain/zero/1.0/',\n","   'fields': {'crawled': 'date the story was archived',\n","    'ord_in_thread': '',\n","    'published': 'date published',\n","    'participants_count': 'number of participants',\n","    'shares': 'number of Facebook shares',\n","    'replies_count': 'number of replies',\n","    'main_img_url': 'image from story',\n","    'spam_score': 'data from webhose.io',\n","    'uuid': 'unique identifier',\n","    'language': 'data from webhose.io',\n","    'title': 'title of story',\n","    'country': 'data from webhose.io',\n","    'domain_rank': 'data from webhose.io',\n","    'author': 'author of story',\n","    'comments': 'number of Facebook comments',\n","    'site_url': 'site URL from BS detector',\n","    'text': 'text of story',\n","    'thread_title': '',\n","    'type': 'type of website (label from BS detector)',\n","    'likes': 'number of Facebook likes'},\n","   'description': \"News dataset, contains text and metadata from 244 websites and represents 12,999 posts in total from a specific window of 30 days. The data was pulled using the webhose.io API, and because it's coming from their crawler, not all websites identified by their BS Detector are present in this dataset. Data sources that were missing a label were simply assigned a label of 'bs'. There are (ostensibly) no genuine, reliable, or trustworthy news sources represented in this dataset (so far), so don't trust anything you read.\",\n","   'checksum': '5e64e942df13219465927f92dcefd5fe',\n","   'file_name': 'fake-news.gz',\n","   'read_more': ['https://www.kaggle.com/mrisdal/fake-news'],\n","   'parts': 1},\n","  '20-newsgroups': {'num_records': 18846,\n","   'record_format': 'dict',\n","   'file_size': 14483581,\n","   'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/20-newsgroups/__init__.py',\n","   'license': 'not found',\n","   'fields': {'topic': 'name of topic (20 variant of possible values)',\n","    'set': \"marker of original split (possible values 'train' and 'test')\",\n","    'data': '',\n","    'id': 'original id inferred from folder name'},\n","   'description': 'The notorious collection of approximately 20,000 newsgroup posts, partitioned (nearly) evenly across 20 different newsgroups.',\n","   'checksum': 'c92fd4f6640a86d5ba89eaad818a9891',\n","   'file_name': '20-newsgroups.gz',\n","   'read_more': ['http://qwone.com/~jason/20Newsgroups/'],\n","   'parts': 1},\n","  '__testing_matrix-synopsis': {'description': '[THIS IS ONLY FOR TESTING] Synopsis of the movie matrix.',\n","   'checksum': '1767ac93a089b43899d54944b07d9dc5',\n","   'file_name': '__testing_matrix-synopsis.gz',\n","   'read_more': ['http://www.imdb.com/title/tt0133093/plotsummary?ref_=ttpl_pl_syn#synopsis'],\n","   'parts': 1},\n","  '__testing_multipart-matrix-synopsis': {'description': '[THIS IS ONLY FOR TESTING] Synopsis of the movie matrix.',\n","   'checksum-0': 'c8b0c7d8cf562b1b632c262a173ac338',\n","   'checksum-1': '5ff7fc6818e9a5d9bc1cf12c35ed8b96',\n","   'checksum-2': '966db9d274d125beaac7987202076cba',\n","   'file_name': '__testing_multipart-matrix-synopsis.gz',\n","   'read_more': ['http://www.imdb.com/title/tt0133093/plotsummary?ref_=ttpl_pl_syn#synopsis'],\n","   'parts': 3}},\n"," 'models': {'fasttext-wiki-news-subwords-300': {'num_records': 999999,\n","   'file_size': 1005007116,\n","   'base_dataset': 'Wikipedia 2017, UMBC webbase corpus and statmt.org news dataset (16B tokens)',\n","   'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/fasttext-wiki-news-subwords-300/__init__.py',\n","   'license': 'https://creativecommons.org/licenses/by-sa/3.0/',\n","   'parameters': {'dimension': 300},\n","   'description': '1 million word vectors trained on Wikipedia 2017, UMBC webbase corpus and statmt.org news dataset (16B tokens).',\n","   'read_more': ['https://fasttext.cc/docs/en/english-vectors.html',\n","    'https://arxiv.org/abs/1712.09405',\n","    'https://arxiv.org/abs/1607.01759'],\n","   'checksum': 'de2bb3a20c46ce65c9c131e1ad9a77af',\n","   'file_name': 'fasttext-wiki-news-subwords-300.gz',\n","   'parts': 1},\n","  'conceptnet-numberbatch-17-06-300': {'num_records': 1917247,\n","   'file_size': 1225497562,\n","   'base_dataset': 'ConceptNet, word2vec, GloVe, and OpenSubtitles 2016',\n","   'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/conceptnet-numberbatch-17-06-300/__init__.py',\n","   'license': 'https://github.com/commonsense/conceptnet-numberbatch/blob/master/LICENSE.txt',\n","   'parameters': {'dimension': 300},\n","   'description': 'ConceptNet Numberbatch consists of state-of-the-art semantic vectors (also known as word embeddings) that can be used directly as a representation of word meanings or as a starting point for further machine learning. ConceptNet Numberbatch is part of the ConceptNet open data project. ConceptNet provides lots of ways to compute with word meanings, one of which is word embeddings. ConceptNet Numberbatch is a snapshot of just the word embeddings. It is built using an ensemble that combines data from ConceptNet, word2vec, GloVe, and OpenSubtitles 2016, using a variation on retrofitting.',\n","   'read_more': ['http://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14972',\n","    'https://github.com/commonsense/conceptnet-numberbatch',\n","    'http://conceptnet.io/'],\n","   'checksum': 'fd642d457adcd0ea94da0cd21b150847',\n","   'file_name': 'conceptnet-numberbatch-17-06-300.gz',\n","   'parts': 1},\n","  'word2vec-ruscorpora-300': {'num_records': 184973,\n","   'file_size': 208427381,\n","   'base_dataset': 'Russian National Corpus (about 250M words)',\n","   'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/word2vec-ruscorpora-300/__init__.py',\n","   'license': 'https://creativecommons.org/licenses/by/4.0/deed.en',\n","   'parameters': {'dimension': 300, 'window_size': 10},\n","   'description': 'Word2vec Continuous Skipgram vectors trained on full Russian National Corpus (about 250M words). The model contains 185K words.',\n","   'preprocessing': 'The corpus was lemmatized and tagged with Universal PoS',\n","   'read_more': ['https://www.academia.edu/24306935/WebVectors_a_Toolkit_for_Building_Web_Interfaces_for_Vector_Semantic_Models',\n","    'http://rusvectores.org/en/',\n","    'https://github.com/RaRe-Technologies/gensim-data/issues/3'],\n","   'checksum': '9bdebdc8ae6d17d20839dd9b5af10bc4',\n","   'file_name': 'word2vec-ruscorpora-300.gz',\n","   'parts': 1},\n","  'word2vec-google-news-300': {'num_records': 3000000,\n","   'file_size': 1743563840,\n","   'base_dataset': 'Google News (about 100 billion words)',\n","   'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/word2vec-google-news-300/__init__.py',\n","   'license': 'not found',\n","   'parameters': {'dimension': 300},\n","   'description': \"Pre-trained vectors trained on a part of the Google News dataset (about 100 billion words). The model contains 300-dimensional vectors for 3 million words and phrases. The phrases were obtained using a simple data-driven approach described in 'Distributed Representations of Words and Phrases and their Compositionality' (https://code.google.com/archive/p/word2vec/).\",\n","   'read_more': ['https://code.google.com/archive/p/word2vec/',\n","    'https://arxiv.org/abs/1301.3781',\n","    'https://arxiv.org/abs/1310.4546',\n","    'https://www.microsoft.com/en-us/research/publication/linguistic-regularities-in-continuous-space-word-representations/?from=http%3A%2F%2Fresearch.microsoft.com%2Fpubs%2F189726%2Frvecs.pdf'],\n","   'checksum': 'a5e5354d40acb95f9ec66d5977d140ef',\n","   'file_name': 'word2vec-google-news-300.gz',\n","   'parts': 1},\n","  'glove-wiki-gigaword-50': {'num_records': 400000,\n","   'file_size': 69182535,\n","   'base_dataset': 'Wikipedia 2014 + Gigaword 5 (6B tokens, uncased)',\n","   'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/glove-wiki-gigaword-50/__init__.py',\n","   'license': 'http://opendatacommons.org/licenses/pddl/',\n","   'parameters': {'dimension': 50},\n","   'description': 'Pre-trained vectors based on Wikipedia 2014 + Gigaword, 5.6B tokens, 400K vocab, uncased (https://nlp.stanford.edu/projects/glove/).',\n","   'preprocessing': 'Converted to w2v format with `python -m gensim.scripts.glove2word2vec -i <fname> -o glove-wiki-gigaword-50.txt`.',\n","   'read_more': ['https://nlp.stanford.edu/projects/glove/',\n","    'https://nlp.stanford.edu/pubs/glove.pdf'],\n","   'checksum': 'c289bc5d7f2f02c6dc9f2f9b67641813',\n","   'file_name': 'glove-wiki-gigaword-50.gz',\n","   'parts': 1},\n","  'glove-wiki-gigaword-100': {'num_records': 400000,\n","   'file_size': 134300434,\n","   'base_dataset': 'Wikipedia 2014 + Gigaword 5 (6B tokens, uncased)',\n","   'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/glove-wiki-gigaword-100/__init__.py',\n","   'license': 'http://opendatacommons.org/licenses/pddl/',\n","   'parameters': {'dimension': 100},\n","   'description': 'Pre-trained vectors based on Wikipedia 2014 + Gigaword 5.6B tokens, 400K vocab, uncased (https://nlp.stanford.edu/projects/glove/).',\n","   'preprocessing': 'Converted to w2v format with `python -m gensim.scripts.glove2word2vec -i <fname> -o glove-wiki-gigaword-100.txt`.',\n","   'read_more': ['https://nlp.stanford.edu/projects/glove/',\n","    'https://nlp.stanford.edu/pubs/glove.pdf'],\n","   'checksum': '40ec481866001177b8cd4cb0df92924f',\n","   'file_name': 'glove-wiki-gigaword-100.gz',\n","   'parts': 1},\n","  'glove-wiki-gigaword-200': {'num_records': 400000,\n","   'file_size': 264336934,\n","   'base_dataset': 'Wikipedia 2014 + Gigaword 5 (6B tokens, uncased)',\n","   'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/glove-wiki-gigaword-200/__init__.py',\n","   'license': 'http://opendatacommons.org/licenses/pddl/',\n","   'parameters': {'dimension': 200},\n","   'description': 'Pre-trained vectors based on Wikipedia 2014 + Gigaword, 5.6B tokens, 400K vocab, uncased (https://nlp.stanford.edu/projects/glove/).',\n","   'preprocessing': 'Converted to w2v format with `python -m gensim.scripts.glove2word2vec -i <fname> -o glove-wiki-gigaword-200.txt`.',\n","   'read_more': ['https://nlp.stanford.edu/projects/glove/',\n","    'https://nlp.stanford.edu/pubs/glove.pdf'],\n","   'checksum': '59652db361b7a87ee73834a6c391dfc1',\n","   'file_name': 'glove-wiki-gigaword-200.gz',\n","   'parts': 1},\n","  'glove-wiki-gigaword-300': {'num_records': 400000,\n","   'file_size': 394362229,\n","   'base_dataset': 'Wikipedia 2014 + Gigaword 5 (6B tokens, uncased)',\n","   'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/glove-wiki-gigaword-300/__init__.py',\n","   'license': 'http://opendatacommons.org/licenses/pddl/',\n","   'parameters': {'dimension': 300},\n","   'description': 'Pre-trained vectors based on Wikipedia 2014 + Gigaword, 5.6B tokens, 400K vocab, uncased (https://nlp.stanford.edu/projects/glove/).',\n","   'preprocessing': 'Converted to w2v format with `python -m gensim.scripts.glove2word2vec -i <fname> -o glove-wiki-gigaword-300.txt`.',\n","   'read_more': ['https://nlp.stanford.edu/projects/glove/',\n","    'https://nlp.stanford.edu/pubs/glove.pdf'],\n","   'checksum': '29e9329ac2241937d55b852e8284e89b',\n","   'file_name': 'glove-wiki-gigaword-300.gz',\n","   'parts': 1},\n","  'glove-twitter-25': {'num_records': 1193514,\n","   'file_size': 109885004,\n","   'base_dataset': 'Twitter (2B tweets, 27B tokens, 1.2M vocab, uncased)',\n","   'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/glove-twitter-25/__init__.py',\n","   'license': 'http://opendatacommons.org/licenses/pddl/',\n","   'parameters': {'dimension': 25},\n","   'description': 'Pre-trained vectors based on 2B tweets, 27B tokens, 1.2M vocab, uncased (https://nlp.stanford.edu/projects/glove/).',\n","   'preprocessing': 'Converted to w2v format with `python -m gensim.scripts.glove2word2vec -i <fname> -o glove-twitter-25.txt`.',\n","   'read_more': ['https://nlp.stanford.edu/projects/glove/',\n","    'https://nlp.stanford.edu/pubs/glove.pdf'],\n","   'checksum': '50db0211d7e7a2dcd362c6b774762793',\n","   'file_name': 'glove-twitter-25.gz',\n","   'parts': 1},\n","  'glove-twitter-50': {'num_records': 1193514,\n","   'file_size': 209216938,\n","   'base_dataset': 'Twitter (2B tweets, 27B tokens, 1.2M vocab, uncased)',\n","   'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/glove-twitter-50/__init__.py',\n","   'license': 'http://opendatacommons.org/licenses/pddl/',\n","   'parameters': {'dimension': 50},\n","   'description': 'Pre-trained vectors based on 2B tweets, 27B tokens, 1.2M vocab, uncased (https://nlp.stanford.edu/projects/glove/)',\n","   'preprocessing': 'Converted to w2v format with `python -m gensim.scripts.glove2word2vec -i <fname> -o glove-twitter-50.txt`.',\n","   'read_more': ['https://nlp.stanford.edu/projects/glove/',\n","    'https://nlp.stanford.edu/pubs/glove.pdf'],\n","   'checksum': 'c168f18641f8c8a00fe30984c4799b2b',\n","   'file_name': 'glove-twitter-50.gz',\n","   'parts': 1},\n","  'glove-twitter-100': {'num_records': 1193514,\n","   'file_size': 405932991,\n","   'base_dataset': 'Twitter (2B tweets, 27B tokens, 1.2M vocab, uncased)',\n","   'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/glove-twitter-100/__init__.py',\n","   'license': 'http://opendatacommons.org/licenses/pddl/',\n","   'parameters': {'dimension': 100},\n","   'description': 'Pre-trained vectors based on  2B tweets, 27B tokens, 1.2M vocab, uncased (https://nlp.stanford.edu/projects/glove/)',\n","   'preprocessing': 'Converted to w2v format with `python -m gensim.scripts.glove2word2vec -i <fname> -o glove-twitter-100.txt`.',\n","   'read_more': ['https://nlp.stanford.edu/projects/glove/',\n","    'https://nlp.stanford.edu/pubs/glove.pdf'],\n","   'checksum': 'b04f7bed38756d64cf55b58ce7e97b15',\n","   'file_name': 'glove-twitter-100.gz',\n","   'parts': 1},\n","  'glove-twitter-200': {'num_records': 1193514,\n","   'file_size': 795373100,\n","   'base_dataset': 'Twitter (2B tweets, 27B tokens, 1.2M vocab, uncased)',\n","   'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/glove-twitter-200/__init__.py',\n","   'license': 'http://opendatacommons.org/licenses/pddl/',\n","   'parameters': {'dimension': 200},\n","   'description': 'Pre-trained vectors based on 2B tweets, 27B tokens, 1.2M vocab, uncased (https://nlp.stanford.edu/projects/glove/).',\n","   'preprocessing': 'Converted to w2v format with `python -m gensim.scripts.glove2word2vec -i <fname> -o glove-twitter-200.txt`.',\n","   'read_more': ['https://nlp.stanford.edu/projects/glove/',\n","    'https://nlp.stanford.edu/pubs/glove.pdf'],\n","   'checksum': 'e52e8392d1860b95d5308a525817d8f9',\n","   'file_name': 'glove-twitter-200.gz',\n","   'parts': 1},\n","  '__testing_word2vec-matrix-synopsis': {'description': '[THIS IS ONLY FOR TESTING] Word vecrors of the movie matrix.',\n","   'parameters': {'dimensions': 50},\n","   'preprocessing': 'Converted to w2v using a preprocessed corpus. Converted to w2v format with `python3.5 -m gensim.models.word2vec -train <input_filename> -iter 50 -output <output_filename>`.',\n","   'read_more': [],\n","   'checksum': '534dcb8b56a360977a269b7bfc62d124',\n","   'file_name': '__testing_word2vec-matrix-synopsis.gz',\n","   'parts': 1}}}"]},"metadata":{},"execution_count":19}],"source":["info = api.info()  # show info about available models/datasets\n","info"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JaxyXjkCKeiL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725971873286,"user_tz":-180,"elapsed":70683,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}},"outputId":"11490eb7-46ac-400a-978e-3f8314d3fd70"},"outputs":[{"output_type":"stream","name":"stdout","text":["[==================================================] 100.0% 104.8/104.8MB downloaded\n"]}],"source":["# –≤—ã –º–æ–∂–µ—Ç–µ –≤—ã–±—Ä–∞—Ç—å –ª—é–±—É—é –º–æ–¥–µ–ª—å –∏–∑ gensim, –Ω–∞–ø—Ä–∏–º–µ—Ä fasstext\n","w2v_model = api.load(\"glove-twitter-25\")\n","#w2v_model = KeyedVectors.load_word2vec_format('./gensim/glove-twitter-25.gz')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZjQb0SRNKeiL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725970502503,"user_tz":-180,"elapsed":27,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}},"outputId":"bb2dd910-2b0e-4cd5-d95a-a001ceeef8aa"},"outputs":[{"output_type":"stream","name":"stdout","text":["[-0.41654   -0.56071    0.72333    1.0435     0.0098203  0.46871\n","  0.93296   -1.2629     0.074417  -0.061837   0.9251    -0.25308\n"," -2.183     -1.3639    -0.30995   -0.98977    1.6252    -1.0291\n"," -0.047819   0.64689    0.062647   0.54722   -0.36114    0.15535\n","  1.0872   ]\n"]}],"source":["print(w2v_model[\"potato\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HOLBM0TwKeiM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725970502503,"user_tz":-180,"elapsed":21,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}},"outputId":"dc252332-6429-42f7-8bcd-b09c6b1170e9"},"outputs":[{"output_type":"stream","name":"stdout","text":["[('chicken', 0.9732475280761719), ('cheese', 0.9607888460159302), ('waffle', 0.9480124115943909), ('salad', 0.943723201751709), ('fried', 0.9288325905799866), ('steak', 0.926487147808075), ('pepper', 0.9241527915000916), ('fries', 0.9237129092216492), ('soup', 0.9213549494743347), ('spicy', 0.9193410873413086)]\n"]}],"source":["print(w2v_model.most_similar(positive=[\"potato\", \"burger\"]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yCBZNTraKeiM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725970502503,"user_tz":-180,"elapsed":15,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}},"outputId":"32f43e82-f5c2-44f7-e8b9-16fc43ed42aa"},"outputs":[{"output_type":"stream","name":"stdout","text":["[('pepper', 0.9478217959403992), ('garlic', 0.9469695091247559), ('avocado', 0.9457836151123047), ('spicy', 0.9435321092605591), ('chicken', 0.9432903528213501), ('beans', 0.9419039487838745), ('onion', 0.9399765729904175), ('fried', 0.9379871487617493), ('cheese', 0.9373629689216614), ('salad', 0.9371017217636108)]\n"]}],"source":["print(w2v_model.most_similar(positive=[\"potato\", \"tomato\"]))"]},{"cell_type":"markdown","metadata":{"id":"RV88DyjBKeiM"},"source":["### –†–µ–∞–ª–∏–∑—É–π—Ç–µ —Å–∞–º–æ—Å—Ç–æ—è–∏—Ç–µ–ª—å–Ω–æ –º–µ—Ç–æ–¥—ã $3CosAdd$ –∏ $3CosMul$:\n","\n","$b^* = \\arg \\max_{w \\in W} \\cos (w, a^* - a + b)$\n","\n","$b^* = \\arg \\max_{w \\in W} \\frac{\\cos(w, b) \\times \\cos(w, a^*)}{\\cos(w, a)}$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F_n-TXSfKeiM"},"outputs":[],"source":["def three_cos_add(a: str, b: str, a_star: str) -> str:\n","    # YOUR_CODE_HERE\n","    \"\"\"\n","    —Ñ—É–Ω–∫—Ü–∏—è 3CosAdd –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å–ª–æ–≤–∞ b*\n","\n","    :param a: –∏—Å—Ö–æ–¥–Ω–æ–µ —Å–ª–æ–≤–æ a\n","    :param b: —Å–ª–æ–≤–æ, –∫–æ—Ç–æ—Ä–æ–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –∞–Ω–∞–ª–æ–≥–æ–º\n","    :param a_star: —Å–ª–æ–≤–æ, –∫–æ—Ç–æ—Ä–æ–µ –∑–∞–¥–∞–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏–µ, –ø–æ–¥–æ–±–Ω–æ–µ a -> a_star\n","    :return: —Å–ª–æ–≤–æ b*, –∫–æ—Ç–æ—Ä–æ–µ –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ—Ö–æ–∂–µ –Ω–∞ b –ø–æ –∞–Ω–∞–ª–æ–≥–∏–∏\n","    \"\"\"\n","    # –ü–æ–ª—É—á–∞–µ–º –≤–µ–∫—Ç–æ—Ä—ã –¥–ª—è —Å–ª–æ–≤\n","    a_vec = w2v_model[a]\n","    b_vec = w2v_model[b]\n","    a_star_vec = w2v_model[a_star]\n","\n","    # –í—ã—á–∏—Å–ª—è–µ–º –≤–µ–∫—Ç–æ—Ä b_star_vec = a* - a + b\n","    b_star_vec = a_star_vec - a_vec + b_vec\n","\n","    # –ù–∞—Ö–æ–¥–∏–º —Å–∞–º–æ–µ –±–ª–∏–∑–∫–æ–µ —Å–ª–æ–≤–æ –∫ –≤–µ–∫—Ç–æ—Ä—É b_star_vec\n","    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–µ—Ç–æ–¥ most_similar –ø–æ –≤–µ–∫—Ç–æ—Ä—É, —á—Ç–æ–±—ã –Ω–∞–π—Ç–∏ –±–ª–∏–∂–∞–π—à–µ–µ —Å–ª–æ–≤–æ\n","    b_star, _ = w2v_model.most_similar(positive=[b_star_vec], topn=1)[0]\n","\n","    return b_star"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EG3JchtOKeiM"},"outputs":[],"source":["import numpy as np\n","\n","def three_cos_mul(a: str, b: str, a_star: str) -> str:\n","    # YOUR_CODE_HERE\n","    \"\"\"\n","    —Ñ—É–Ω–∫—Ü–∏—è 3CosMul –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å–ª–æ–≤–∞ b*.\n","\n","    :param a: –∏—Å—Ö–æ–¥–Ω–æ–µ —Å–ª–æ–≤–æ a\n","    :param b: —Å–ª–æ–≤–æ, –∫–æ—Ç–æ—Ä–æ–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –∞–Ω–∞–ª–æ–≥–æ–º\n","    :param a_star: —Å–ª–æ–≤–æ, –∫–æ—Ç–æ—Ä–æ–µ –∑–∞–¥–∞–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏–µ, –ø–æ–¥–æ–±–Ω–æ–µ a -> a_star\n","    :return: —Å–ª–æ–≤–æ b*, –∫–æ—Ç–æ—Ä–æ–µ –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ—Ö–æ–∂–µ –Ω–∞ b –ø–æ –∞–Ω–∞–ª–æ–≥–∏–∏\n","    \"\"\"\n","    # –ü–æ–ª—É—á–∞–µ–º –≤–µ–∫—Ç–æ—Ä—ã –¥–ª—è —Å–ª–æ–≤\n","    a_vec = w2v_model[a]\n","    b_vec = w2v_model[b]\n","    a_star_vec = w2v_model[a_star]\n","\n","    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –ø–æ–∏—Å–∫–∞ –º–∞–∫—Å–∏–º—É–º–∞\n","    max_score = -np.inf\n","    b_star = None\n","\n","    # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º —Å–ª–æ–≤–∞–º –≤ —Å–ª–æ–≤–∞—Ä–µ\n","    for word in w2v_model.index_to_key:\n","        w_vec = w2v_model[word]\n","\n","        # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞\n","        cos_w_b = np.dot(w_vec, b_vec) / (np.linalg.norm(w_vec) * np.linalg.norm(b_vec))\n","        cos_w_a_star = np.dot(w_vec, a_star_vec) / (np.linalg.norm(w_vec) * np.linalg.norm(a_star_vec))\n","        cos_w_a = np.dot(w_vec, a_vec) / (np.linalg.norm(w_vec) * np.linalg.norm(a_vec))\n","\n","        # –í—ã—á–∏—Å–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ —Ñ–æ—Ä–º—É–ª–µ\n","        # –î–æ–±–∞–≤–ª—è–µ–º –º–∞–ª–µ–Ω—å–∫–æ–µ —á–∏—Å–ª–æ, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å\n","        score = (cos_w_b * cos_w_a_star) / (cos_w_a + 1e-8)\n","\n","        # –û–±–Ω–æ–≤–ª—è–µ–º, –µ—Å–ª–∏ –Ω–∞—à–ª–∏ –±–æ–ª—å—à–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ\n","        if score > max_score:\n","            max_score = score\n","            b_star = word\n","\n","    return b_star"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YKhMW0qOKeiN","colab":{"base_uri":"https://localhost:8080/","height":38},"executionInfo":{"status":"ok","timestamp":1725971874322,"user_tz":-180,"elapsed":11,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}},"outputId":"19bf8ed7-3760-4ad4-b957-73ddf1f99d01"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'meets'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":21}],"source":["three_cos_add(\"man\", \"woman\", \"king\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aNR5EJ1NKeiN","colab":{"base_uri":"https://localhost:8080/","height":38},"executionInfo":{"status":"ok","timestamp":1725970534184,"user_tz":-180,"elapsed":31371,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}},"outputId":"bd01b2a5-36f2-4508-83d1-6d384095cf9f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'pinkett-smith'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":23}],"source":["three_cos_mul(\"man\", \"woman\", \"king\")"]},{"cell_type":"markdown","metadata":{"id":"98steJqJKeiT"},"source":["## –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏ RNN –≤ PyTorch (5 –±–∞–ª–ª–æ–≤)"]},{"cell_type":"markdown","metadata":{"id":"T8nUpqd5KeiT"},"source":["–î–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –≤ –Ω–µ–π—Ä–æ—Å–µ—Ç—è—Ö –Ω–∞ torch –Ω—É–∂–µ–Ω —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —Å–ª–æ–π Embedding.\n","–ü–æ—Å–º–æ—Ç—Ä–∏–º, –∫–∞–∫ –æ–Ω —Ä–∞–±–æ—Ç–∞–µ—Ç."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P6g7UrIOKeiU"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zJ0Fen1UKeiU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725972653401,"user_tz":-180,"elapsed":324,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}},"outputId":"a6c0c87d-e62e-42f4-ea44-759b475b9e87"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[ 0.5043, -0.7522, -0.6435, -0.1807,  0.3319,  0.0331],\n","         [-0.1590,  0.4813,  1.2450, -0.5982,  0.5961, -0.8716],\n","         [ 0.5868,  0.7576, -1.0532,  0.5543, -0.3092, -1.8005],\n","         [ 0.0556, -0.1065,  2.4490, -0.7764, -0.0313,  2.0412],\n","         [ 1.3848,  0.0979,  1.5388,  1.3377, -0.1576,  1.8117]],\n","\n","        [[ 0.5043, -0.7522, -0.6435, -0.1807,  0.3319,  0.0331],\n","         [ 1.3848,  0.0979,  1.5388,  1.3377, -0.1576,  1.8117],\n","         [-0.2404,  0.1972,  0.5356, -0.1439, -0.6235, -0.3895],\n","         [ 0.1295, -0.1989, -0.0355,  1.8305,  1.8978, -0.9902],\n","         [ 0.1295, -0.1989, -0.0355,  1.8305,  1.8978, -0.9902]]],\n","       grad_fn=<EmbeddingBackward0>)\n","torch.Size([2, 5, 6])\n"]}],"source":["emd_dim = 6\n","vocab_size = len(vocab.word2idx.keys())\n","embedding_layer = nn.Embedding(num_embeddings=vocab_size, embedding_dim=emd_dim)\n","\n","batch_size = 2\n","seq_len = 5\n","\n","input_ids = torch.tensor([[1, 2, 3, 4, 5], [1, 5, 6, 0, 0]]).long()\n","key_padding_mask = input_ids > 0\n","\n","assert input_ids.shape == (batch_size, seq_len)\n","\n","embeddings = embedding_layer(input_ids)\n","print(embeddings)\n","print(embeddings.shape)\n","assert embeddings.shape == (batch_size, seq_len, emd_dim)"]},{"cell_type":"markdown","metadata":{"id":"BWy4pAvnKeiU"},"source":["–í –∫–∞—á–µ—Å—Ç–≤–µ RNN –≤–æ–∑—å–º–µ–º –¥–≤—É–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—É—é LSTM."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2yVqvv-KKeiU"},"outputs":[],"source":["hidden_size = 7\n","n_layers = 3\n","\n","rnn = nn.LSTM(\n","    input_size=emd_dim,          # Should match embedding dimension\n","    hidden_size=hidden_size,     # Hidden state size\n","    num_layers=n_layers,         # Number of layers\n","    bidirectional=True,          # Make it bidirectional\n","    batch_first=True             # Batch dimension comes first\n",")\n","\n","# –ü—Ä–æ—á–∏—Ç–∞–π—Ç–µ —Ç—É—Ç–æ—Ä–∏–∞–ª –ø–æ –ø–∞–¥–¥–∏–Ω–≥—É –≤ RNN\n","# https://www.geeksforgeeks.org/how-do-you-handle-sequence-padding-and-packing-in-pytorch-for-rnns/\n","\n","\n","# –í—ã—á–∏—Å–ª–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫—É—é –¥–ª–∏–Ω—É –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ –¥–æ–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤)\n","input_lengths = key_padding_mask.sum(dim=1)\n","\n","# –£–ø–∞–∫–æ–≤—ã–≤—ã–µ–º –¥–æ–ø–æ–ª–Ω–µ–Ω–Ω—É—é –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å\n","packed_input = torch.nn.utils.rnn.pack_padded_sequence(\n","    embeddings,\n","    lengths=input_lengths, # Calculates the lengths of each sequence by summing the True values in key_padding_mask.\n","    batch_first=True,\n","    enforce_sorted=False   # Allows sequences to be unsorted; if True, sequences must be sorted by length in descending order.\n",")\n","rnn_outputs, (h, c) = rnn(packed_input)\n","\n","# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —É–ø–∞–∫–æ–≤–∞–Ω–Ω—É—é –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –æ–±—Ä–∞—Ç–Ω–æ –≤ –¥–æ–ø–æ–ª–Ω–µ–Ω–Ω—É—é –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å.\n","rnn_outputs, input_sizes = torch.nn.utils.rnn.pad_packed_sequence(\n","    rnn_outputs,\n","    batch_first=True,\n","    total_length=seq_len\n",")\n","assert rnn_outputs.shape == (batch_size, seq_len, hidden_size * 2)"]},{"cell_type":"markdown","metadata":{"id":"uWnQEWJTKeiU"},"source":["ü§î –ü–æ—á–µ–º—É –¥–ª—è —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã—Ö —Å–µ—Ç–µ–π –Ω—É–∂–µ–Ω —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –ø–∞–¥–¥–∏–Ω–≥?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RJAIUh-jKeiV"},"outputs":[],"source":["\"\"\"\n","–ß—Ç–æ–±—ã –≤—Å–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏–º–µ–ª–∏ –æ–¥–∏–Ω–∞–∫–æ–≤—É—é –¥–ª–∏–Ω—É (–¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ –≤–∏–¥–µ –æ–¥–Ω–æ–≥–æ –±–∞—Ç—á–∞),\n","–Ω—É–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å \"–ø–∞–¥–¥–∏–Ω–≥\" (–æ–±—ã—á–Ω–æ –Ω—É–ª–∏) –≤ –±–æ–ª–µ–µ –∫–æ—Ä–æ—Ç–∫–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏,\n","—á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∏—Ö –≤–º–µ—Å—Ç–µ —Å –±–æ–ª–µ–µ –¥–ª–∏–Ω–Ω—ã–º–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—è–º–∏.\n","\n","–ï—Å–ª–∏ –ø–∞–¥–¥–∏–Ω–≥ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –Ω—É–ª–∏) –ø—Ä–æ—Å—Ç–æ –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –∫ –±–æ–ª–µ–µ –∫–æ—Ä–æ—Ç–∫–∏–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—è–º,\n","—Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω–∞—è —Å–µ—Ç—å –±—É–¥–µ—Ç –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å —ç—Ç–∏ –ø–∞–¥–¥–∏–Ω–≥–æ–≤—ã–µ —Ç–æ–∫–µ–Ω—ã –Ω–∞—Ä–∞–≤–Ω–µ —Å –ø–æ–ª–µ–∑–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏.\n","–≠—Ç–æ –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –æ–±—É—á–µ–Ω–∏—é —Å–µ—Ç–∏ –Ω–∞ –±–µ—Å–ø–æ–ª–µ–∑–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏ —É—Ö—É–¥—à–µ–Ω–∏—é –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏,\n","—Ç–∞–∫ –∫–∞–∫ –ø–∞–¥–¥–∏–Ω–≥–æ–≤—ã–µ —Ç–æ–∫–µ–Ω—ã –Ω–µ –Ω–µ—Å—É—Ç —Å–º—ã—Å–ª–∞, –Ω–æ –≤—Å–µ —Ä–∞–≤–Ω–æ –±—É–¥—É—Ç –≤–ª–∏—è—Ç—å –Ω–∞ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–µ—Ç–∏.\n","\n","–ü–æ—ç—Ç–æ–º—É –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Ä–∞–±–æ—Ç—ã —Å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—è–º–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –¥–ª–∏–Ω—ã –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –º–µ—Ö–∞–Ω–∏–∑–º—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–∞–¥–¥–∏–Ω–≥–∞.\n","\n","\"\"\""]},{"cell_type":"markdown","metadata":{"id":"qr6zmXWBKeiV"},"source":["## –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π (NER) (20 –±–∞–ª–ª–æ–≤)"]},{"cell_type":"markdown","metadata":{"id":"4erqvEB-KeiV"},"source":["–¢–µ–ø–µ—Ä—å –º—ã –≥–æ—Ç–æ–≤—ã –∫ —Ç–æ–º—É, —á—Ç–æ–±—ã —Å–æ–∑–¥–∞—Ç—å –ø–æ–ª–Ω—É—é —Å–µ—Ç—å –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π —á–µ—Ä–µ–∑ –ø–æ—Ç–æ–∫–µ–Ω–Ω—É—é –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kgvNjgTtKeiV"},"outputs":[],"source":["from torch.utils.data import DataLoader\n","from tqdm.auto import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mb3jFBk2KeiV"},"outputs":[],"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\""]},{"cell_type":"markdown","metadata":{"id":"vhnNDP_WKeiV"},"source":["### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –æ–±—É—á–µ–Ω–∏—è (10 –±–∞–ª–ª–æ–≤)"]},{"cell_type":"code","source":["class TokenClassificationModel(nn.Module):\n","    def __init__(self, vocab_size: int, embedding_dim: int, hidden_size: int, n_layers: int, n_classes: int):\n","        super().__init__()\n","        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n","        self.rnn = nn.LSTM(\n","            input_size=embedding_dim,\n","            hidden_size=hidden_size,\n","            num_layers=n_layers,\n","            bidirectional=True,\n","            batch_first=True\n","        )\n","        self.fc = nn.Linear(hidden_size * 2, n_classes)  # Bidirectional\n","        self.n_classes = n_classes  # Ensure n_classes is defined\n","        self.loss_fn = nn.CrossEntropyLoss(ignore_index=-100, reduction=\"none\")\n","\n","    def forward(self, x: torch.Tensor, mask: torch.Tensor):\n","        # YOUR_CODE_HERE\n","        # Move data to the same device as the model\n","        device = next(self.parameters()).device\n","        embeddings = self.embedding(x.to(device))\n","        input_lengths = mask.sum(dim=1)\n","        packed_input = torch.nn.utils.rnn.pack_padded_sequence(\n","            embeddings,\n","            lengths=input_lengths,\n","            batch_first=True,\n","            enforce_sorted=False\n","        )\n","\n","        packed_rnn_output, _ = self.rnn(packed_input.to(device))\n","        rnn_output, _ = torch.nn.utils.rnn.pad_packed_sequence(\n","            packed_rnn_output, batch_first=True, total_length=x.size(1)\n","        )\n","\n","        logits = self.fc(rnn_output)\n","        return logits\n","\n","    def training_step(self, batch):\n","        # YOUR_CODE_HERE\n","        # Move data to the same device as the model\n","        device = next(self.parameters()).device\n","        input_ids = batch[\"input_ids\"]\n","        mask = batch[\"mask\"]\n","        labels = batch[\"labels\"]\n","\n","        # Check if input indices are within bounds\n","        assert input_ids.max().item() < self.embedding.num_embeddings, \"Token index out of bounds!\"\n","\n","        logits = self(input_ids, mask)\n","        logits = logits.view(-1, self.n_classes)  # Using the n_classes attribute\n","        labels = labels.view(-1).to(device)\n","        loss = self.loss_fn(logits, labels).mean()\n","        return loss\n","\n","    def validation_step(self, batch):\n","       # YOUR_CODE_HERE\n","        # Move data to the correct device\n","        device = next(self.parameters()).device\n","        input_ids = batch[\"input_ids\"]\n","        mask = batch[\"mask\"]\n","        labels = batch[\"labels\"]\n","\n","        # Forward pass\n","        logits = self(input_ids, mask)\n","\n","        # Reshape logits to [batch_size * seq_len, n_classes]\n","        logits = logits.view(-1, self.n_classes)\n","\n","        # Reshape labels to [batch_size * seq_len]\n","        labels = labels.view(-1).to(device)\n","\n","        # Calculate loss\n","        loss = self.loss_fn(logits, labels).mean()\n","        return loss\n","\n","    def configure_optimizers(self):\n","        # YOUR_CODE_HERE\n","        return torch.optim.Adam(self.parameters(), lr=1e-3)\n","\n"],"metadata":{"id":"p_53IM4--aaY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def collate_fn(data):\n","    input_ids = []\n","    masks = []\n","    labels = []\n","    max_len = 0\n","\n","    for sample in data:\n","        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤—ã–≤–∞–µ–º —Ç–æ–∫–µ–Ω—ã –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –∏–º –∏–Ω–¥–µ–∫—Å—ã –≤ —Å–ª–æ–≤–∞—Ä–µ\n","        input_ids.append([vocab.encode_word(token) for token in sample[\"tokens\"]])\n","        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –º–µ—Ç–æ–∫ –≤ –∏–Ω–¥–µ–∫—Å—ã —Å –ø–æ–º–æ—â—å—é label2idx\n","        labels.append([label2idx[y] for y in sample[\"labels\"]])\n","        # –ú–∞—Å–∫–∏—Ä—É–µ–º 1 –¥–ª—è —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö —Ç–æ–∫–µ–Ω–æ–≤ –∏ 0 –¥–ª—è –ø–∞–¥–∏–Ω–≥–ª–≤.\n","        l = len(input_ids[-1])\n","        masks.append([1] * l)\n","        # –û—Ç—Å–ª–µ–∂–∏–≤–∞–π—Ç–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤ –ø–∞–∫–µ—Ç–µ.\n","        max_len = max(max_len, l)\n","\n","    # –î–æ–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –¥–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã –≤ –ø–∞–∫–µ—Ç–µ\n","    padded_input_ids = [ids + [0] * (max_len - len(ids)) for ids in input_ids]\n","    # -100 –¥–ª—è –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏—è –º–µ—Ç–æ–∫ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è\n","    padded_labels = [lbls + [-100] * (max_len - len(lbls)) for lbls in labels]\n","    padded_masks = [m + [0] * (max_len - len(m)) for m in masks]\n","\n","    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º  –≤ —Ç–µ–Ω–∑–æ—Ä—ã\n","    batch = {\n","        \"input_ids\": torch.tensor(padded_input_ids, dtype=torch.long),\n","        \"mask\": torch.tensor(padded_masks, dtype=torch.long),\n","        \"labels\": torch.tensor(padded_labels, dtype=torch.long)\n","    }\n","\n","    return batch\n"],"metadata":{"id":"o7uVEoTTEoB0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Sample model parameters\n","vocab_size = 10\n","embedding_dim = 6\n","hidden_size = 7\n","n_layers = 2\n","n_classes = 5\n","\n","# for testing\n","train_batch = {\n","    \"input_ids\": torch.tensor([[1, 2, 3, 4, 5], [1, 5, 6, 0, 0]]),\n","    \"mask\": torch.tensor([[1, 1, 1, 1, 1], [1, 1, 1, 0, 0]]),\n","    \"labels\": torch.tensor([[0, 1, 2, 3, 4], [0, 4, 3, -100, -100]])\n","}\n","\n","# –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å\n","model = TokenClassificationModel(vocab_size, embedding_dim, hidden_size, n_layers, n_classes)\n","\n","# –ó–∞–ø—É—Å–∫ –ø—Ä—è–º–æ–≥–æ –ø—Ä–æ—Ö–æ–¥, —á—Ç–æ–±—ã –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –≤—ã—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏.\n","logits = model(train_batch[\"input_ids\"], train_batch[\"mask\"])\n","\n","# –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–æ–≥–∏—Ç—ã\n","logits, logits.shape\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cT542OMOQxmm","executionInfo":{"status":"ok","timestamp":1725975032648,"user_tz":-180,"elapsed":486,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}},"outputId":"46836663-3dc9-42d7-fe68-88d9bc7462e8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[[-0.0561,  0.1584, -0.2384,  0.2395,  0.0246],\n","          [-0.0492,  0.1885, -0.2192,  0.2454, -0.0037],\n","          [-0.0491,  0.1980, -0.2127,  0.2378, -0.0022],\n","          [-0.0516,  0.1868, -0.2082,  0.2279,  0.0077],\n","          [-0.0551,  0.2256, -0.1790,  0.2557, -0.0051]],\n"," \n","         [[-0.0627,  0.1702, -0.2157,  0.2443,  0.0239],\n","          [-0.0698,  0.2075, -0.1848,  0.2622,  0.0027],\n","          [-0.0969,  0.2036, -0.1730,  0.2497,  0.0159],\n","          [-0.0554,  0.1649, -0.2087,  0.2566,  0.0655],\n","          [-0.0554,  0.1649, -0.2087,  0.2566,  0.0655]]],\n","        grad_fn=<ViewBackward0>),\n"," torch.Size([2, 5, 5]))"]},"metadata":{},"execution_count":72}]},{"cell_type":"code","source":["optimizer = model.configure_optimizers()\n","\n","model.train()\n","optimizer.zero_grad()\n","loss = model.training_step(train_batch)\n","loss.backward()\n","optimizer.step()\n","\n","# Output the loss after one step\n","loss.item()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"52c1Ds_jPHxI","executionInfo":{"status":"ok","timestamp":1725975037871,"user_tz":-180,"elapsed":340,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}},"outputId":"c1ad3836-d5b0-4996-efb7-2842bd40ebb8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.2940717935562134"]},"metadata":{},"execution_count":73}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aQ_y4uJAKeiX"},"outputs":[],"source":["idx2label = [\"O\", \"B-MISC\", \"I-MISC\", \"B-PER\", \"I-PER\", \"B-ORG\", \"I-ORG\", \"B-LOC\", \"I-LOC\"]\n","label2idx = {label: i for i, label in enumerate(idx2label)}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U0Gx37CNKeiX"},"outputs":[],"source":["def read_data(path: str) -> List[Dict[str, List[str]]]:\n","    samples = []\n","    with open(path) as f:\n","        sentences = f.read().split(\"\\n\\n\")\n","    for sentence in sentences:\n","        if \"-DOCSTART-\" in sentence:\n","            continue\n","        tokens = []\n","        labels = []\n","        for line in sentence.strip().split(\"\\n\"):\n","            if not line:\n","                continue\n","            line = line.split()\n","            tokens.append(line[0])\n","            labels.append(line[-1])\n","        if not tokens:\n","            continue\n","        samples.append({\"tokens\": tokens, \"labels\": labels})\n","    return samples"]},{"cell_type":"markdown","source":["# load data"],"metadata":{"id":"z_3aGjtKXQgn"}},{"cell_type":"code","source":["import gdown"],"metadata":{"id":"Rut9cWsuUCO3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["file_id = \"1uJvjwH9_Mlau38bJoump2LZ3LiP_K1wI\"\n","file_name = \"conll2003.zip\"\n","gdown.download('https://drive.google.com/uc?id=' + file_id, file_name, quiet=False)\n","\n","!unzip conll2003.zip -d data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jSfFrg24UKJa","executionInfo":{"status":"ok","timestamp":1725974027155,"user_tz":-180,"elapsed":3761,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}},"outputId":"f26f6992-846c-45fc-ae4c-9acdd8ef19eb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading...\n","From: https://drive.google.com/uc?id=1uJvjwH9_Mlau38bJoump2LZ3LiP_K1wI\n","To: /content/conll2003.zip\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 959k/959k [00:00<00:00, 121MB/s]"]},{"output_type":"stream","name":"stdout","text":["Archive:  conll2003.zip\n","   creating: data/conll2003/\n","  inflating: data/conll2003/train.txt  \n","  inflating: data/conll2003/valid.txt  \n","  inflating: data/conll2003/test.txt  \n","  inflating: data/conll2003/metadata  \n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b85qxzFxKeiX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725974027428,"user_tz":-180,"elapsed":280,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}},"outputId":"eeb9f636-55fc-43fe-ceac-7e9e0798a07f"},"outputs":[{"output_type":"stream","name":"stdout","text":["14041 3250 3453\n"]}],"source":["train_data = read_data(\"./data/conll2003/train.txt\")\n","val_data = read_data(\"./data/conll2003/valid.txt\")\n","test_data = read_data(\"./data/conll2003/test.txt\")\n","print(len(train_data), len(val_data), len(test_data))"]},{"cell_type":"code","source":["train_data[1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4NnQM04Mf3Fu","executionInfo":{"status":"ok","timestamp":1725974028919,"user_tz":-180,"elapsed":316,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}},"outputId":"64812fa0-cba4-46da-9e6c-0cdd256c226d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'tokens': ['Peter', 'Blackburn'], 'labels': ['B-PER', 'I-PER']}"]},"metadata":{},"execution_count":29}]},{"cell_type":"markdown","metadata":{"id":"dozNmbYFKeiY"},"source":["–ü—Ä–æ—á–∏—Ç–∞–π—Ç–µ –ø—Ä–æ —Å—Ö–µ–º—ã —Ç–µ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –≤ NER: https://en.wikipedia.org/wiki/Inside‚Äìoutside‚Äìbeginning_(tagging)"]},{"cell_type":"markdown","metadata":{"id":"OdobQLpQKeiY"},"source":["ü§î –ö–∞–∫–∞—è —Å—Ö–µ–º–∞ —Ç–µ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ —ç—Ç–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"adtcLSahKeiY"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g47TQ9J8KeiZ"},"outputs":[],"source":["N_EPOCHS = 3 #YOUR_CODE_HERE\n","BATCH_SIZE = 10 #YOUR_CODE_HERE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BR5xm3rFKeiZ"},"outputs":[],"source":["train_dl = DataLoader(train_data, collate_fn=collate_fn, batch_size=BATCH_SIZE, shuffle=True)\n","val_dl = DataLoader(val_data, collate_fn=collate_fn, batch_size=BATCH_SIZE, shuffle=False)\n","test_dl = DataLoader(test_data, collate_fn=collate_fn, batch_size=BATCH_SIZE, shuffle=False)"]},{"cell_type":"code","source":["dataloader_iterator = iter(val_dl)\n","next(dataloader_iterator)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W5hyi1b29sRf","executionInfo":{"status":"ok","timestamp":1725974669884,"user_tz":-180,"elapsed":331,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}},"outputId":"be2206de-9867-4fbb-cd3d-261a7982b6a6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': tensor([[   78,    56,  1286,   157,    89,  1189, 10158,  1443,     3,   292,\n","           2847,  1422,   136,  1805,  1201,    20,     3,    68,   969,    69,\n","             75,   200,   152,     3,    11,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0],\n","         [ 6504,   747,   284,    16,  4453,    68,   186,   581,  1743,  1713,\n","            678,     3,    89,     3,  1812,     7,  5067,    68,  1626,   217,\n","            186,   454,  1823,    69,   632,   495,  2547,  1590,    50,     3,\n","            148,  1823,  3141,    11],\n","         [  305,  1480,   522,   681,   882,    68,  2444,   128,  1580,  2357,\n","             69,     3,    69,    82,  1445,     3,    69,  4793,    69,   681,\n","           6504,     7,     3,    82,    75,   581,  1823,   200,   152,     3,\n","             11,     0,     0,     0],\n","         [  113,    16,     3,   152,  4622,    16,   346,  1257,   152,   186,\n","           1531,  8198,  4844,    89,    16,  4714,    69,  1774,  5112,   284,\n","             75,  5052,     7,     3,  1799,    68,     3,    11,     0,     0,\n","              0,     0,     0,     0],\n","         [  296,   287,   391,   284,    89,    75,     3,  4486,    50,  1430,\n","           2391,   128,     3,  2003,  2004,  1688,     3,   681,  1895,    68,\n","           3227,    11,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0],\n","         [   89,     3,  1774,   144,  4823,  1785,    68,   879,    11,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0],\n","         [ 1741,   574,   271,  1742,  1743,  1412,    11,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0],\n","         [  249, 10672,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0],\n","         [ 1602,    82,  1364,   152,  1744,  1412,   217,   271,  1742,  1743,\n","           1746,    20,   971,   344,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0],\n","         [ 1780,   344,  1781,  1521,  1757,    89,   148,  1823,    82,  3093,\n","           2547,    11,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0]]),\n"," 'mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n","         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n","         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n","         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","         [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","         [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","         [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n"," 'labels': tensor([[   0,    0,    0,    0,    0,    7,    0,    3,    4,    0,    0,    0,\n","             0,    5,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0, -100, -100, -100, -100, -100, -100, -100, -100, -100],\n","         [   5,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    5,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n","         [   1,    3,    4,    0,    0,    0,    0,    0,    3,    4,    0,    0,\n","             0,    0,    3,    4,    0,    0,    0,    0,    5,    0,    0,    0,\n","             0,    0,    0,    0,    0,    0,    0, -100, -100, -100],\n","         [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","             0,    0,    0,    0,    0,    5,    0,    0,    0,    0,    0,    0,\n","             5,    0,    0,    0, -100, -100, -100, -100, -100, -100],\n","         [   0,    0,    0,    0,    0,    0,    0,    0,    0,    3,    4,    0,\n","             1,    0,    0,    3,    4,    0,    0,    0,    0,    0, -100, -100,\n","          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100],\n","         [   0,    0,    5,    0,    0,    0,    0,    0,    0, -100, -100, -100,\n","          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100],\n","         [   0,    0,    1,    2,    2,    0,    0, -100, -100, -100, -100, -100,\n","          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100],\n","         [   7,    0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100],\n","         [   0,    0,    0,    0,    0,    0,    0,    1,    0,    0,    0,    0,\n","             0,    0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100],\n","         [   7,    0,    5,    0,    5,    0,    0,    0,    0,    0,    0,    0,\n","          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]])}"]},"metadata":{},"execution_count":51}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TyJiJHvzKeia"},"outputs":[],"source":["vocab = Vocabulary([\" \".join(example[\"tokens\"]) for example in train_data], min_count=2, lower=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RHLIGpF9Keia","executionInfo":{"status":"ok","timestamp":1725975052221,"user_tz":-180,"elapsed":305,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ae8e1859-7522-4f2d-826f-e40a715187d3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["10946"]},"metadata":{},"execution_count":75}],"source":["vocab_size = len(vocab)\n","vocab_size"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F0by4Gv_Keib"},"outputs":[],"source":["n_classes = len(idx2label)\n","ner_model =  TokenClassificationModel(vocab_size, embedding_dim, hidden_size, n_layers, n_classes)"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"gkVIOO_5Keib","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725977997424,"user_tz":-180,"elapsed":551,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}},"outputId":"35d18c90-92b5-4a02-d7ed-c4727cc8760a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Embedding(10946, 25)\n"]}],"source":["# –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ word2vec\n","# YOUR_CODE_HERE\n","\n","# —Ñ—É–Ω—É—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∏—è –º–∞—Ç—Ä–∏—Ü—ã —á–µ—Ä–µ–∑ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ word2vec\n","def create_embedding_matrix(vocab, embedding_model, embedding_dim):\n","    vocab_size = len(vocab.word2idx)\n","    embedding_matrix = np.zeros((vocab_size, embedding_dim))  # –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –Ω—É–ª—è–∏–º–∏\n","\n","    for word, idx in vocab.word2idx.items():\n","        if word in embedding_model:\n","            embedding_vector = embedding_model[word]\n","            # –≤—Å—Ç–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤–µ–∫—Ç–æ—Ä –≤ —Å—Ç—Ä–æ–∫—É –º–∞—Ç—Ä–∏—Ü—ã\n","            embedding_matrix[idx] = embedding_vector\n","        else:\n","            # –ø–æ–ª—É—á–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–∫ –≤–µ–∫—Ç–æ—Ä–∞ –∏–∑ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥–ª—è OOV —Å–ª–æ–≤\n","            embedding_matrix[idx] = np.random.normal(size=(embedding_dim,))\n","\n","    return torch.tensor(embedding_matrix, dtype=torch.float32)\n","\n","# –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–∞—Ç—Ä–∏—Ü—É –¥–ª—è —Å–ª–æ–≤–∞—Ä—è\n","embedding_dim = 25  # Dimension of GloVe embeddings\n","embedding_matrix = create_embedding_matrix(vocab, w2v_model, embedding_dim)\n","\n","# –∑–∞–º–æ—Ä–æ–∑—å—Ç–µ —Å–ª–æ–π —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤\n","# YOUR_CODE_HERE\n","\n","# –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–ª–æ–π –º–æ–¥–µ–ª–∏\n","embedding_layer = nn.Embedding.from_pretrained(embedding_matrix, freeze=False)  # By default, freeze=False\n","\n","# –º–æ–∂–Ω–æ –∑–∞–º–æ—Ä–æ–∑–∏—Ç—å —Å–ª–æ–π –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è.\n","embedding_layer.weight.requires_grad = False  # Freeze the embeddings\n","\n","print(embedding_layer)"]},{"cell_type":"markdown","metadata":{"id":"muNB36JEKeib"},"source":["ü§î –ö–∞–∫ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è —Ç–æ–∫–µ–Ω–æ–≤, –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö –≤ –º–æ–¥–µ–ª–∏ word2vec?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"anmghsUTKeib"},"outputs":[],"source":["\"\"\"\n","1. –ú–æ–∂–Ω–æ –ø—Ä–∏—Å–≤–æ–∏—Ç—å —Å–ª—É—á–∞–π–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä–∞ –∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è.\n","2. –ú–æ–∂–Ω–æ —á–µ—Ä–µ–∑ –∏–Ω–∏—Ü–∏–∞–¥–∏–∑–∞—Ü–∏—é –æ—Ç —Ç–æ–∫–µ–Ω–∞ <UNK> –Ω–µ–∑–≤–µ—Å—Ç–Ω–æ–≥–æ —Å–ª–æ–≤–∞\n","3. –ú–æ–∂–Ω–æ –±—Ä–∞—Ç—å –∏–∑ –¥—Ä—É–≥–∏—Ö –∫–æ—Ä–ø—É—Å–æ–≤\n","4. –º–æ–∂–Ω–æ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –ø–æ –æ–∫—Ä—É–∂–µ–Ω–∏—é —Å–ª–æ–≤ –∏ –Ω–∞–π—Ç–∏ –±–ª–∏–∑–∫–æ–µ –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É\n","\n","\"\"\""]},{"cell_type":"markdown","metadata":{"id":"sIQHzevLKeic"},"source":["### –û–±—É—á–µ–Ω–∏–µ –∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å (10 –±–∞–ª–ª–æ–≤)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fBuWUpDFKeic","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725975062054,"user_tz":-180,"elapsed":337,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}},"outputId":"21a5adb0-dc69-4a77-bc52-17b93680343f"},"outputs":[{"output_type":"stream","name":"stdout","text":["TokenClassificationModel(\n","  (embedding): Embedding(10946, 6)\n","  (rnn): LSTM(6, 7, num_layers=2, batch_first=True, bidirectional=True)\n","  (fc): Linear(in_features=14, out_features=9, bias=True)\n","  (loss_fn): CrossEntropyLoss()\n",")\n"]}],"source":["ner_model.to(device)\n","print(ner_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KVxxCH2tKeic"},"outputs":[],"source":["optimizer = ner_model.configure_optimizers()"]},{"cell_type":"code","source":["from tqdm import tqdm\n","\n","N_EPOCHS = 15  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö\n","\n","for epoch in range(N_EPOCHS):\n","    ner_model.train()\n","    train_losses = []\n","    val_losses = []\n","\n","    # Training loop\n","    for i, batch in tqdm(enumerate(train_dl), total=len(train_dl)):\n","        optimizer.zero_grad()  # Clear previous gradients\n","\n","        # Forward pass and loss calculation\n","        loss = ner_model.training_step(batch)\n","        train_losses.append(loss.detach().cpu().numpy())\n","\n","        # Backpropagation\n","        loss.backward()\n","\n","        # Optimizer step\n","        optimizer.step()\n","\n","    # Validation loop\n","    ner_model.eval()  # Set model to evaluation mode\n","    with torch.no_grad():  # No gradient calculation for validation\n","        for i, batch in tqdm(enumerate(val_dl), total=len(val_dl)):\n","            loss = ner_model.validation_step(batch)\n","            val_losses.append(loss.cpu().numpy())\n","\n","    # Calculate average losses for the epoch\n","    train_loss = sum(train_losses) / len(train_losses)\n","    val_loss = sum(val_losses) / len(val_losses)\n","\n","    # Print training and validation losses for the current epoch\n","    print(f\"{epoch = }: {train_loss = }, {val_loss = }\")\n","\n","    # Save the model state after each epoch\n","    savepath = f\"ner_model_{epoch}ep.bin\"\n","    torch.save(ner_model.state_dict(), savepath)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rawU2QtiF6lt","executionInfo":{"status":"ok","timestamp":1725975704664,"user_tz":-180,"elapsed":230793,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}},"outputId":"7b26235d-1c2c-447f-e512-5889498d64b1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1405/1405 [00:13<00:00, 102.41it/s]\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 325/325 [00:01<00:00, 277.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch = 0: train_loss = 0.13343377133095605, val_loss = 0.1896311459174523\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1405/1405 [00:14<00:00, 98.63it/s]\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 325/325 [00:00<00:00, 371.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch = 1: train_loss = 0.11862591085060635, val_loss = 0.17554832592033423\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1405/1405 [00:13<00:00, 102.22it/s]\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 325/325 [00:00<00:00, 385.90it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch = 2: train_loss = 0.10796025417400425, val_loss = 0.16165897101736987\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1405/1405 [00:13<00:00, 101.60it/s]\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 325/325 [00:00<00:00, 373.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch = 3: train_loss = 0.09674462117586166, val_loss = 0.15239595203158948\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1405/1405 [00:13<00:00, 100.44it/s]\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 325/325 [00:00<00:00, 374.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch = 4: train_loss = 0.08923802400915966, val_loss = 0.1438204886792944\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1405/1405 [00:13<00:00, 101.73it/s]\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 325/325 [00:00<00:00, 367.82it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch = 5: train_loss = 0.08152574693711202, val_loss = 0.13797779660098827\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1405/1405 [00:13<00:00, 102.44it/s]\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 325/325 [00:01<00:00, 301.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch = 6: train_loss = 0.07476710038610943, val_loss = 0.13175217014092666\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1405/1405 [00:14<00:00, 98.92it/s]\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 325/325 [00:01<00:00, 301.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch = 7: train_loss = 0.068049805757699, val_loss = 0.12591650297865273\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1405/1405 [00:15<00:00, 88.30it/s]\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 325/325 [00:01<00:00, 244.90it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch = 8: train_loss = 0.06316010277532703, val_loss = 0.12248496301185627\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1405/1405 [00:13<00:00, 102.10it/s]\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 325/325 [00:00<00:00, 366.70it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch = 9: train_loss = 0.05934764534944264, val_loss = 0.11873844407928677\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1405/1405 [00:14<00:00, 95.66it/s] \n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 325/325 [00:00<00:00, 373.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch = 10: train_loss = 0.054576145746211564, val_loss = 0.1162686468517551\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1405/1405 [00:15<00:00, 93.57it/s] \n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 325/325 [00:02<00:00, 160.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch = 11: train_loss = 0.05145619765878572, val_loss = 0.11693258465554279\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1405/1405 [00:16<00:00, 86.41it/s]\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 325/325 [00:00<00:00, 376.87it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch = 12: train_loss = 0.04844296150923677, val_loss = 0.11212174191282918\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1405/1405 [00:14<00:00, 97.39it/s] \n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 325/325 [00:00<00:00, 391.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch = 13: train_loss = 0.04532344390131082, val_loss = 0.11068233816454617\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1405/1405 [00:13<00:00, 102.45it/s]\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 325/325 [00:00<00:00, 379.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch = 14: train_loss = 0.042644473054244104, val_loss = 0.10729621725586744\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ffzm23uLKeid"},"outputs":[],"source":["def predict(model, test_data) -> List[List[str]]:\n","    with torch.no_grad():\n","        model.eval()\n","        predictions = []\n","\n","        # YOUR_CODE_HERE\n","        ...\n","        return predictions  # –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ —Ç–µ–≥–∏"]},{"cell_type":"code","source":["def predict(model, test_dl) -> List[List[str]]:\n","    model.eval()  # Set model to evaluation mode\n","    predictions = []\n","    # YOUR_CODE_HERE\n","\n","    # –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ —Å —Ç–µ–≥–æ–º (–æ–±—Ä–∞—Ç–Ω–æ label2idx)\n","    idx2label = {v: k for k, v in label2idx.items()}\n","\n","    with torch.no_grad():  # –û—Ç–∫–ª—é—á–∞–µ–º –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è\n","        for batch in test_dl:\n","            input_ids = batch[\"input_ids\"]\n","            mask = batch[\"mask\"]\n","\n","            # –ø—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥\n","            logits = model(input_ids, mask).to(device)\n","\n","            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ–º—ã–µ –∏–Ω–¥–µ–∫—Å—ã –∫–ª–∞—Å—Å–æ–≤ (—á–µ—Ä–µ–∑ argmax –ø–æ –ø–æ—Å–ª–µ–¥–Ω–µ–º—É –∏–∑–º–µ—Ä–µ–Ω–∏—é)\n","            pred_indices = torch.argmax(logits, dim=-1)\n","\n","            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–∏ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ–º—ã–µ –∏–Ω–¥–µ–∫—Å—ã –≤ –º–µ—Ç–∫–∏ –∏ –¥–æ–±–∞–≤–∏–º –≤ —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤\n","            for preds, m in zip(pred_indices, mask):\n","                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–≥–Ω–æ–∑—ã —Ç–æ–ª—å–∫–æ –¥–ª—è –Ω–µ –¥–æ–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ (mask = 1)\n","                pred_tags = [idx2label[idx.item()] for idx, mask_val in zip(preds, m) if mask_val == 1]\n","                predictions.append(pred_tags)\n","\n","    return predictions  # –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ —Ç–µ–≥–∏\n"],"metadata":{"id":"vQzX-OOLJAcI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions = predict(ner_model, test_dl)\n","for sample, pred in zip(test_data, predictions):\n","    text = \" \".join(sample[\"tokens\"])\n","    print(\"*\" * 100)\n","    print(text)\n","    for i, tag in enumerate(pred):\n","        print(f\"{tag}: {sample['tokens'][i]}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A3Ievfe3JwZR","executionInfo":{"status":"ok","timestamp":1725975828642,"user_tz":-180,"elapsed":11075,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}},"outputId":"86e1885b-1d4e-4bff-8ee3-0389634e1fb9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43m–í—ã—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –±—ã–ª–∏ –æ–±—Ä–µ–∑–∞–Ω—ã –¥–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å—Ç—Ä–æ–∫ (5000).\u001b[0m\n","O: 32\n","****************************************************************************************************\n","Barnet 22 8 8 6 23 17 32\n","B-ORG: Barnet\n","O: 22\n","O: 8\n","O: 8\n","O: 6\n","O: 23\n","O: 17\n","O: 32\n","****************************************************************************************************\n","Colchester 22 7 10 5 32 26 31\n","B-ORG: Colchester\n","O: 22\n","O: 7\n","O: 10\n","O: 5\n","O: 32\n","O: 26\n","O: 31\n","****************************************************************************************************\n","Scunthorpe 22 9 4 9 28 30 31\n","B-ORG: Scunthorpe\n","O: 22\n","O: 9\n","O: 4\n","O: 9\n","O: 28\n","O: 30\n","O: 31\n","****************************************************************************************************\n","Northampton 22 8 6 8 31 26 30\n","B-ORG: Northampton\n","O: 22\n","O: 8\n","O: 6\n","O: 8\n","O: 31\n","O: 26\n","O: 30\n","****************************************************************************************************\n","Scarborough 21 7 9 5 30 27 30\n","B-ORG: Scarborough\n","O: 21\n","O: 7\n","O: 9\n","O: 5\n","O: 30\n","O: 27\n","O: 30\n","****************************************************************************************************\n","Lincoln 22 8 6 8 28 33 30\n","B-ORG: Lincoln\n","O: 22\n","O: 8\n","O: 6\n","O: 8\n","O: 28\n","O: 33\n","O: 30\n","****************************************************************************************************\n","Chester 21 8 6 7 23 23 30\n","B-ORG: Chester\n","O: 21\n","O: 8\n","O: 6\n","O: 7\n","O: 23\n","O: 23\n","O: 30\n","****************************************************************************************************\n","Hull 22 6 11 5 20 22 29\n","B-ORG: Hull\n","O: 22\n","O: 6\n","O: 11\n","O: 5\n","O: 20\n","O: 22\n","O: 29\n","****************************************************************************************************\n","Torquay 22 8 4 10 22 24 28\n","B-ORG: Torquay\n","O: 22\n","O: 8\n","O: 4\n","O: 10\n","O: 22\n","O: 24\n","O: 28\n","****************************************************************************************************\n","Rochdale 21 6 8 7 27 26 26\n","B-ORG: Rochdale\n","O: 21\n","O: 6\n","O: 8\n","O: 7\n","O: 27\n","O: 26\n","O: 26\n","****************************************************************************************************\n","Exeter 22 7 5 10 21 28 26\n","B-ORG: Exeter\n","O: 22\n","O: 7\n","O: 5\n","O: 10\n","O: 21\n","O: 28\n","O: 26\n","****************************************************************************************************\n","Doncaster 22 7 3 12 24 33 24\n","B-ORG: Doncaster\n","O: 22\n","O: 7\n","O: 3\n","O: 12\n","O: 24\n","O: 33\n","O: 24\n","****************************************************************************************************\n","Mansfield 21 5 9 7 21 22 24\n","B-ORG: Mansfield\n","O: 21\n","O: 5\n","O: 9\n","O: 7\n","O: 21\n","O: 22\n","O: 24\n","****************************************************************************************************\n","Leyton Orient 21 6 6 9 16 19 24\n","B-ORG: Leyton\n","I-ORG: Orient\n","O: 21\n","O: 6\n","O: 6\n","O: 9\n","O: 16\n","O: 19\n","O: 24\n","****************************************************************************************************\n","Hereford 22 6 5 11 23 31 23\n","B-ORG: Hereford\n","O: 22\n","O: 6\n","O: 5\n","O: 11\n","O: 23\n","O: 31\n","O: 23\n","****************************************************************************************************\n","Darlington 22 6 4 12 30 39 22\n","B-PER: Darlington\n","O: 22\n","O: 6\n","O: 4\n","O: 12\n","O: 30\n","O: 39\n","O: 22\n","****************************************************************************************************\n","Hartlepool 21 6 4 11 23 28 22\n","B-ORG: Hartlepool\n","O: 21\n","O: 6\n","O: 4\n","O: 11\n","O: 23\n","O: 28\n","O: 22\n","****************************************************************************************************\n","Brighton 22 3 4 15 18 42 13\n","B-ORG: Brighton\n","O: 22\n","O: 3\n","O: 4\n","O: 15\n","O: 18\n","O: 42\n","O: 13\n","****************************************************************************************************\n","SOCCER - VIEIRA SAVES ARSENAL WITH LAST-MINUTE EQUALISER .\n","O: SOCCER\n","O: -\n","O: VIEIRA\n","O: SAVES\n","I-ORG: ARSENAL\n","O: WITH\n","O: LAST-MINUTE\n","O: EQUALISER\n","O: .\n","****************************************************************************************************\n","LONDON 1996-12-07\n","B-LOC: LONDON\n","O: 1996-12-07\n","****************************************************************************************************\n","Frenchman Patrick Vieira blasted a last-minute goal to salvage a 2-2 draw for English premier league leaders Arsenal at home to Derby on Saturday .\n","B-PER: Frenchman\n","B-PER: Patrick\n","I-PER: Vieira\n","O: blasted\n","O: a\n","O: last-minute\n","O: goal\n","O: to\n","O: salvage\n","O: a\n","O: 2-2\n","O: draw\n","O: for\n","B-MISC: English\n","O: premier\n","O: league\n","O: leaders\n","B-ORG: Arsenal\n","O: at\n","O: home\n","O: to\n","B-ORG: Derby\n","O: on\n","O: Saturday\n","O: .\n","****************************************************************************************************\n","The London club had been rocked by a two-goal burst from forwards Dean Sturridge and Darryl Powell in the 62nd and 71st minutes which overturned Arsenal 's 1-0 lead from a diving header by captain Tony Adams on the stroke of halftime .\n","O: The\n","B-LOC: London\n","O: club\n","O: had\n","O: been\n","O: rocked\n","O: by\n","O: a\n","O: two-goal\n","O: burst\n","O: from\n","O: forwards\n","B-PER: Dean\n","O: Sturridge\n","O: and\n","B-PER: Darryl\n","I-PER: Powell\n","O: in\n","O: the\n","B-ORG: 62nd\n","O: and\n","O: 71st\n","O: minutes\n","O: which\n","O: overturned\n","B-ORG: Arsenal\n","O: 's\n","O: 1-0\n","O: lead\n","O: from\n","O: a\n","O: diving\n","O: header\n","O: by\n","O: captain\n","B-PER: Tony\n","I-PER: Adams\n","O: on\n","O: the\n","O: stroke\n","O: of\n","O: halftime\n","O: .\n","****************************************************************************************************\n","Liverpool suffered an upset first home league defeat of the season , beaten 1-0 by a Guy Whittingham goal for Sheffield Wednesday .\n","B-ORG: Liverpool\n","O: suffered\n","O: an\n","O: upset\n","O: first\n","O: home\n","O: league\n","O: defeat\n","O: of\n","O: the\n","O: season\n","O: ,\n","O: beaten\n","O: 1-0\n","O: by\n","O: a\n","O: Guy\n","O: Whittingham\n","O: goal\n","O: for\n","B-ORG: Sheffield\n","O: Wednesday\n","O: .\n","****************************************************************************************************\n","Wimbledon leap-frogged over Liverpool into second place by winning 3-1 at Sunderland to extend their unbeaten league and cup run to 18 games .\n","B-MISC: Wimbledon\n","O: leap-frogged\n","O: over\n","B-ORG: Liverpool\n","O: into\n","O: second\n","O: place\n","O: by\n","O: winning\n","O: 3-1\n","O: at\n","B-ORG: Sunderland\n","O: to\n","O: extend\n","O: their\n","O: unbeaten\n","O: league\n","O: and\n","B-PER: cup\n","O: run\n","O: to\n","O: 18\n","O: games\n","O: .\n","****************************************************************************************************\n","Two strikes by Efan Ekoku in the first half and a late goal from fellow forward Dean Holdsworth secured victory for Wimbledon , who trail pacemakers Arsenal by four points .\n","O: Two\n","O: strikes\n","O: by\n","O: Efan\n","O: Ekoku\n","O: in\n","O: the\n","O: first\n","O: half\n","O: and\n","O: a\n","O: late\n","O: goal\n","O: from\n","O: fellow\n","O: forward\n","B-PER: Dean\n","I-PER: Holdsworth\n","O: secured\n","O: victory\n","O: for\n","B-LOC: Wimbledon\n","O: ,\n","O: who\n","O: trail\n","O: pacemakers\n","O: Arsenal\n","O: by\n","O: four\n","O: points\n","O: .\n","****************************************************************************************************\n","SOCCER - SCOTTISH LEAGUE AND CUP RESULTS .\n","O: SOCCER\n","O: -\n","B-MISC: SCOTTISH\n","O: LEAGUE\n","O: AND\n","I-MISC: CUP\n","O: RESULTS\n","O: .\n","****************************************************************************************************\n","GLASGOW 1996-12-07\n","B-PER: GLASGOW\n","O: 1996-12-07\n","****************************************************************************************************\n","Results of Scottish league and cup\n","O: Results\n","O: of\n","B-MISC: Scottish\n","O: league\n","O: and\n","I-MISC: cup\n","****************************************************************************************************\n","matches played on Saturday :\n","O: matches\n","O: played\n","O: on\n","O: Saturday\n","O: :\n","****************************************************************************************************\n","Premier division\n","O: Premier\n","O: division\n","****************************************************************************************************\n","Dunfermline 2 Aberdeen 3\n","B-ORG: Dunfermline\n","O: 2\n","B-ORG: Aberdeen\n","O: 3\n","****************************************************************************************************\n","Hearts 0 Raith 0\n","B-ORG: Hearts\n","O: 0\n","B-ORG: Raith\n","O: 0\n","****************************************************************************************************\n","Kilmarnock 0 Dundee United 2\n","B-ORG: Kilmarnock\n","O: 0\n","B-ORG: Dundee\n","I-ORG: United\n","O: 2\n","****************************************************************************************************\n","Motherwell 2 Celtic 1\n","B-ORG: Motherwell\n","O: 2\n","B-ORG: Celtic\n","O: 1\n","****************************************************************************************************\n","Rangers 4 Hibernian 3\n","B-ORG: Rangers\n","O: 4\n","B-ORG: Hibernian\n","O: 3\n","****************************************************************************************************\n","Division one\n","O: Division\n","O: one\n","****************************************************************************************************\n","Dundee 2 Falkirk 0\n","B-ORG: Dundee\n","O: 2\n","B-ORG: Falkirk\n","O: 0\n","****************************************************************************************************\n","Greenock Morton 0 St Johnstone 2\n","B-ORG: Greenock\n","I-ORG: Morton\n","O: 0\n","B-ORG: St\n","I-ORG: Johnstone\n","O: 2\n","****************************************************************************************************\n","Postponed : Airdrieonians v Clydebank ( to Wednesday ) , East\n","O: Postponed\n","O: :\n","B-ORG: Airdrieonians\n","O: v\n","B-PER: Clydebank\n","O: (\n","O: to\n","O: Wednesday\n","O: )\n","O: ,\n","O: East\n","****************************************************************************************************\n","Fife v Partick , Stirling v St Mirren ( to Tuesday )\n","B-ORG: Fife\n","O: v\n","B-ORG: Partick\n","O: ,\n","B-ORG: Stirling\n","O: v\n","B-ORG: St\n","O: Mirren\n","O: (\n","O: to\n","O: Tuesday\n","O: )\n","****************************************************************************************************\n","Division two\n","O: Division\n","O: two\n","****************************************************************************************************\n","Livingston 2 Stenhousemuir 1\n","B-ORG: Livingston\n","O: 2\n","B-ORG: Stenhousemuir\n","O: 1\n","****************************************************************************************************\n","Stranraer 0 Brechin 1\n","B-ORG: Stranraer\n","O: 0\n","B-ORG: Brechin\n","O: 1\n","****************************************************************************************************\n","Division three\n","O: Division\n","O: three\n","****************************************************************************************************\n","Ross County 4 Montrose 4\n","B-ORG: Ross\n","I-ORG: County\n","O: 4\n","B-ORG: Montrose\n","O: 4\n","****************************************************************************************************\n","Postponed : Forfar v Alloa , Inverness Thistle v Queen 's Park\n","O: Postponed\n","O: :\n","B-ORG: Forfar\n","O: v\n","B-ORG: Alloa\n","O: ,\n","B-ORG: Inverness\n","I-ORG: Thistle\n","O: v\n","B-ORG: Queen\n","O: 's\n","B-ORG: Park\n","****************************************************************************************************\n","Scottish Cup first round\n","B-MISC: Scottish\n","I-MISC: Cup\n","O: first\n","O: round\n","****************************************************************************************************\n","Alloa 3 Hawick 1\n","B-ORG: Alloa\n","O: 3\n","B-ORG: Hawick\n","O: 1\n","****************************************************************************************************\n","Elgin City 0 Whitehill 3\n","B-ORG: Elgin\n","I-ORG: City\n","O: 0\n","O: Whitehill\n","O: 3\n","****************************************************************************************************\n","Postponed : Albion v Forfar , Huntly v Clyde ( both now play on\n","O: Postponed\n","O: :\n","B-ORG: Albion\n","O: v\n","B-LOC: Forfar\n","O: ,\n","O: Huntly\n","O: v\n","B-ORG: Clyde\n","O: (\n","O: both\n","O: now\n","O: play\n","O: on\n","****************************************************************************************************\n","December 14 )\n","O: December\n","O: 14\n","O: )\n","****************************************************************************************************\n","SOCCER - ENGLISH LEAGUE AND CUP RESULTS .\n","O: SOCCER\n","O: -\n","B-MISC: ENGLISH\n","O: LEAGUE\n","O: AND\n","I-MISC: CUP\n","O: RESULTS\n","O: .\n","****************************************************************************************************\n","LONDON 1996-12-07\n","B-LOC: LONDON\n","O: 1996-12-07\n","****************************************************************************************************\n","Results of English league and cup\n","O: Results\n","O: of\n","B-MISC: English\n","O: league\n","O: and\n","I-MISC: cup\n","****************************************************************************************************\n","matches on Saturday :\n","O: matches\n","O: on\n","O: Saturday\n","O: :\n","****************************************************************************************************\n","Premier league\n","O: Premier\n","O: league\n","****************************************************************************************************\n","Arsenal 2 Derby 2\n","B-ORG: Arsenal\n","O: 2\n","B-ORG: Derby\n","O: 2\n","****************************************************************************************************\n","Chelsea 2 Everton 2\n","B-ORG: Chelsea\n","O: 2\n","B-ORG: Everton\n","O: 2\n","****************************************************************************************************\n","Coventry 1 Tottenham 2\n","B-ORG: Coventry\n","O: 1\n","B-ORG: Tottenham\n","O: 2\n","****************************************************************************************************\n","Leicester 1 Blackburn 1\n","B-ORG: Leicester\n","O: 1\n","B-ORG: Blackburn\n","O: 1\n","****************************************************************************************************\n","Liverpool 0 Sheffield Wednesday 1\n","B-ORG: Liverpool\n","O: 0\n","B-ORG: Sheffield\n","O: Wednesday\n","O: 1\n","****************************************************************************************************\n","Middlesbrough 0 Leeds 0\n","B-ORG: Middlesbrough\n","O: 0\n","B-ORG: Leeds\n","O: 0\n","****************************************************************************************************\n","Southampton 0 Aston Villa 1\n","B-ORG: Southampton\n","O: 0\n","B-ORG: Aston\n","I-ORG: Villa\n","O: 1\n","****************************************************************************************************\n","Sunderland 1 Wimbledon 3\n","B-ORG: Sunderland\n","O: 1\n","B-LOC: Wimbledon\n","O: 3\n","****************************************************************************************************\n","Division one\n","O: Division\n","O: one\n","****************************************************************************************************\n","Barnsley 3 Southend 0\n","B-ORG: Barnsley\n","O: 3\n","B-ORG: Southend\n","O: 0\n","****************************************************************************************************\n","Birmingham 0 Grimsby 0\n","B-ORG: Birmingham\n","O: 0\n","B-ORG: Grimsby\n","O: 0\n","****************************************************************************************************\n","Charlton 2 Swindon 0\n","B-ORG: Charlton\n","O: 2\n","B-ORG: Swindon\n","O: 0\n","****************************************************************************************************\n","Crystal Palace 2 Oxford 2\n","B-ORG: Crystal\n","I-ORG: Palace\n","O: 2\n","B-ORG: Oxford\n","O: 2\n","****************************************************************************************************\n","Huddersfield 2 Norwich 0\n","B-ORG: Huddersfield\n","O: 2\n","B-ORG: Norwich\n","O: 0\n","****************************************************************************************************\n","Ipswich 0 Wolverhampton 0\n","B-ORG: Ipswich\n","O: 0\n","B-ORG: Wolverhampton\n","O: 0\n","****************************************************************************************************\n","Manchester City 3 Bradford 2\n","B-ORG: Manchester\n","I-ORG: City\n","O: 3\n","B-ORG: Bradford\n","O: 2\n","****************************************************************************************************\n","Oldham 0 Queens Park Rangers 2\n","B-ORG: Oldham\n","O: 0\n","B-ORG: Queens\n","I-ORG: Park\n","I-ORG: Rangers\n","O: 2\n","****************************************************************************************************\n","Reading 0 Port Vale 1\n","B-ORG: Reading\n","O: 0\n","B-ORG: Port\n","I-ORG: Vale\n","O: 1\n","****************************************************************************************************\n","Sheffield United 1 Portsmouth 0\n","B-ORG: Sheffield\n","I-ORG: United\n","O: 1\n","B-ORG: Portsmouth\n","O: 0\n","****************************************************************************************************\n","Stoke 2 Tranmere 0\n","B-ORG: Stoke\n","O: 2\n","B-ORG: Tranmere\n","O: 0\n","****************************************************************************************************\n","Playing Sunday : West Bromwich v Bolton\n","O: Playing\n","O: Sunday\n","O: :\n","B-ORG: West\n","I-ORG: Bromwich\n","O: v\n","B-LOC: Bolton\n","****************************************************************************************************\n","F.A. Challenge Cup second round\n","O: F.A.\n","I-MISC: Challenge\n","I-MISC: Cup\n","O: second\n","O: round\n","****************************************************************************************************\n","Barnet 3 Wycombe 3\n","B-ORG: Barnet\n","O: 3\n","B-ORG: Wycombe\n","O: 3\n","****************************************************************************************************\n","Blackpool 0 Hednesford 1\n","B-ORG: Blackpool\n","O: 0\n","B-ORG: Hednesford\n","O: 1\n","****************************************************************************************************\n","Bristol City 9 St Albans 2\n","B-ORG: Bristol\n","I-ORG: City\n","O: 9\n","B-ORG: St\n","I-ORG: Albans\n","O: 2\n","****************************************************************************************************\n","Cambridge United 0 Woking 2\n","B-ORG: Cambridge\n","I-ORG: United\n","O: 0\n","B-ORG: Woking\n","O: 2\n","****************************************************************************************************\n","Carlisle 1 Darlington 0\n","B-ORG: Carlisle\n","O: 1\n","B-ORG: Darlington\n","O: 0\n","****************************************************************************************************\n","Chester 1 Boston 0\n","B-ORG: Chester\n","O: 1\n","B-ORG: Boston\n","O: 0\n","****************************************************************************************************\n","Chesterfield 2 Scarborough 0\n","B-ORG: Chesterfield\n","O: 2\n","B-ORG: Scarborough\n","O: 0\n","****************************************************************************************************\n","Enfield 1 Peterborough 1\n","B-ORG: Enfield\n","O: 1\n","B-ORG: Peterborough\n","O: 1\n","****************************************************************************************************\n","Hull 1 Crewe 5\n","B-ORG: Hull\n","O: 1\n","B-ORG: Crewe\n","O: 5\n","****************************************************************************************************\n","Leyton Orient 1 Stevenage 2\n","B-ORG: Leyton\n","I-ORG: Orient\n","O: 1\n","B-ORG: Stevenage\n","O: 2\n","****************************************************************************************************\n","Luton 2 Boreham Wood 1\n","B-ORG: Luton\n","O: 2\n","B-ORG: Boreham\n","I-ORG: Wood\n","O: 1\n","****************************************************************************************************\n","Mansfield 0 Stockport 3\n","B-ORG: Mansfield\n","O: 0\n","B-ORG: Stockport\n","O: 3\n","****************************************************************************************************\n","Notts County 3 Rochdale 1\n","B-ORG: Notts\n","I-ORG: County\n","O: 3\n","B-ORG: Rochdale\n","O: 1\n","****************************************************************************************************\n","Preston 2 York 3\n","B-ORG: Preston\n","O: 2\n","B-ORG: York\n","O: 3\n","****************************************************************************************************\n","Sudbury Town 1 Brentford 3\n","B-ORG: Sudbury\n","O: Town\n","O: 1\n","B-ORG: Brentford\n","O: 3\n","****************************************************************************************************\n","Walsall 1 Burnley 1\n","B-ORG: Walsall\n","O: 1\n","B-ORG: Burnley\n","O: 1\n","****************************************************************************************************\n","Watford 5 Ashford Town 0\n","B-ORG: Watford\n","O: 5\n","O: Ashford\n","O: Town\n","O: 0\n","****************************************************************************************************\n","Wrexham 2 Scunthorpe 2\n","B-ORG: Wrexham\n","O: 2\n","B-ORG: Scunthorpe\n","O: 2\n","****************************************************************************************************\n","Cardiff 0 Gillingham 2\n","B-ORG: Cardiff\n","O: 0\n","B-ORG: Gillingham\n","O: 2\n","****************************************************************************************************\n","RUGBY UNION - CAMPESE SIGNS OFF WITH TRY IN WALLABY ROMP .\n","B-ORG: RUGBY\n","O: UNION\n","O: -\n","O: CAMPESE\n","O: SIGNS\n","O: OFF\n","O: WITH\n","O: TRY\n","O: IN\n","O: WALLABY\n","O: ROMP\n","O: .\n","****************************************************************************************************\n","LONDON 1996-12-07\n","B-LOC: LONDON\n","O: 1996-12-07\n","****************************************************************************************************\n","Australia bade farewell to David Campese in spectacular fashion by overwhelming the Barbarians 39-12 in the final match of their European tour at Twickenham on Saturday .\n","B-LOC: Australia\n","O: bade\n","O: farewell\n","O: to\n","B-PER: David\n","I-PER: Campese\n","O: in\n","B-PER: spectacular\n","I-PER: fashion\n","O: by\n","O: overwhelming\n","O: the\n","O: Barbarians\n","O: 39-12\n","O: in\n","O: the\n","O: final\n","O: match\n","O: of\n","O: their\n","B-MISC: European\n","O: tour\n","O: at\n","B-ORG: Twickenham\n","O: on\n","O: Saturday\n","O: .\n","****************************************************************************************************\n","The Wallabies ran in five tries with Campese , who has retired from test rugby after collecting 101 caps and a world record 64 tries , adding one last touchdown in a Wallaby jersey before departing the international game .\n","O: The\n","O: Wallabies\n","O: ran\n","O: in\n","O: five\n","O: tries\n","O: with\n","O: Campese\n","O: ,\n","O: who\n","O: has\n","O: retired\n","O: from\n","O: test\n","O: rugby\n","O: after\n","O: collecting\n","O: 101\n","O: caps\n","O: and\n","O: a\n","O: world\n","O: record\n","O: 64\n","O: tries\n","O: ,\n","O: adding\n","O: one\n","O: last\n","O: touchdown\n","O: in\n","O: a\n","O: Wallaby\n","O: jersey\n","O: before\n","O: departing\n","O: the\n","O: international\n","O: game\n","O: .\n","****************************************************************************************************\n","The Barbarians included 14 internationals but , with only two pre-match practice sessions behind them , proved no real match for a Wallaby side determined to finish their 12-match tour unbeaten .\n","O: The\n","O: Barbarians\n","O: included\n","O: 14\n","O: internationals\n","O: but\n","O: ,\n","O: with\n","O: only\n","O: two\n","O: pre-match\n","O: practice\n","O: sessions\n","O: behind\n","O: them\n","O: ,\n","O: proved\n","O: no\n","O: real\n","O: match\n","O: for\n","O: a\n","O: Wallaby\n","O: side\n","O: determined\n","O: to\n","O: finish\n","O: their\n","O: 12-match\n","O: tour\n","O: unbeaten\n","O: .\n","****************************************************************************************************\n","The touring team were 27-0 ahead by half-time before easing up in the second-half .\n","O: The\n","O: touring\n","O: team\n","O: were\n","O: 27-0\n","O: ahead\n","O: by\n","B-ORG: half-time\n","O: before\n","O: easing\n","O: up\n","O: in\n","O: the\n","O: second-half\n","O: .\n","****************************************************************************************************\n","Full-back Matthew Burke finished with a personal haul of 24 points to take his tour aggregate to 136 .\n","O: Full-back\n","B-PER: Matthew\n","I-PER: Burke\n","O: finished\n","O: with\n","O: a\n","O: personal\n","O: haul\n","O: of\n","O: 24\n","O: points\n","O: to\n","O: take\n","O: his\n","O: tour\n","O: aggregate\n","O: to\n","O: 136\n","O: .\n","****************************************************************************************************\n","RUGBY UNION - AUSTRALIA BEAT BARBARIANS 39-12 .\n","B-ORG: RUGBY\n","I-ORG: UNION\n","O: -\n","B-LOC: AUSTRALIA\n","O: BEAT\n","B-PER: BARBARIANS\n","I-PER: 39-12\n","O: .\n","****************************************************************************************************\n","LONDON 1996-12-07\n","B-LOC: LONDON\n","O: 1996-12-07\n","****************************************************************************************************\n","Australia beat the Barbarians 39-12 ( halftime 27-0 ) in the final match of their European tour on Saturday :\n","B-LOC: Australia\n","O: beat\n","O: the\n","B-MISC: Barbarians\n","O: 39-12\n","O: (\n","O: halftime\n","O: 27-0\n","O: )\n","O: in\n","O: the\n","O: final\n","O: match\n","O: of\n","O: their\n","B-MISC: European\n","I-ORG: tour\n","O: on\n","O: Saturday\n","O: :\n","****************************************************************************************************\n","Scorers :\n","O: Scorers\n","O: :\n","****************************************************************************************************\n","Australia - Tries : Matthew Burke ( 2 ) , Joe Roff , David Campese , Tim Horan .\n","B-LOC: Australia\n","O: -\n","O: Tries\n","O: :\n","B-LOC: Matthew\n","I-PER: Burke\n","O: (\n","O: 2\n","O: )\n","O: ,\n","B-PER: Joe\n","I-PER: Roff\n","O: ,\n","B-PER: David\n","O: Campese\n","O: ,\n","B-PER: Tim\n","I-PER: Horan\n","O: .\n","****************************************************************************************************\n","Penalties : Burke ( 2 ) .\n","O: Penalties\n","O: :\n","O: Burke\n","O: (\n","O: 2\n","O: )\n","O: .\n","****************************************************************************************************\n","Conversions : Burke ( 4 ) .\n","O: Conversions\n","O: :\n","O: Burke\n","O: (\n","O: 4\n","O: )\n","O: .\n","****************************************************************************************************\n","Barbarians - Tries : Alan Bateman , Scott Quinnell .\n","O: Barbarians\n","O: -\n","O: Tries\n","O: :\n","B-PER: Alan\n","I-PER: Bateman\n","O: ,\n","B-PER: Scott\n","I-PER: Quinnell\n","O: .\n","****************************************************************************************************\n","Conversion : Rob Andrew .\n","O: Conversion\n","O: :\n","B-PER: Rob\n","B-PER: Andrew\n","O: .\n","****************************************************************************************************\n","GOLF - ZIMBABWE OPEN THIRD ROUND SCORES .\n","B-ORG: GOLF\n","O: -\n","B-LOC: ZIMBABWE\n","I-MISC: OPEN\n","O: THIRD\n","O: ROUND\n","O: SCORES\n","O: .\n","****************************************************************************************************\n","HARARE 1996-12-07\n","B-MISC: HARARE\n","O: 1996-12-07\n","****************************************************************************************************\n","Leading third round scores in the\n","O: Leading\n","O: third\n","O: round\n","O: scores\n","O: in\n","O: the\n","****************************************************************************************************\n","Zimbabwe Open on Saturday ( South African unless stated ) :\n","B-LOC: Zimbabwe\n","I-MISC: Open\n","O: on\n","O: Saturday\n","O: (\n","B-MISC: South\n","I-MISC: African\n","O: unless\n","O: stated\n","O: )\n","O: :\n","****************************************************************************************************\n","201 Mark McNulty ( Zimbabwe ) 72 61 68\n","B-PER: 201\n","B-PER: Mark\n","I-PER: McNulty\n","O: (\n","B-LOC: Zimbabwe\n","O: )\n","O: 72\n","O: 61\n","O: 68\n","****************************************************************************************************\n","205 Des Terblanche 65 67 73\n","O: 205\n","B-PER: Des\n","I-PER: Terblanche\n","O: 65\n","O: 67\n","O: 73\n","****************************************************************************************************\n","206 Nick Price ( Zimbabwe ) 68 68 70\n","B-PER: 206\n","I-PER: Nick\n","O: Price\n","O: (\n","B-LOC: Zimbabwe\n","O: )\n","O: 68\n","O: 68\n","O: 70\n","****************************************************************************************************\n","207 Clinton Whitelaw 70 70 67 , Mark Cayeux ( Zimbabwe )\n","O: 207\n","B-PER: Clinton\n","I-PER: Whitelaw\n","O: 70\n","O: 70\n","O: 67\n","O: ,\n","B-PER: Mark\n","I-PER: Cayeux\n","O: (\n","B-LOC: Zimbabwe\n","O: )\n","****************************************************************************************************\n","69 69 69 , Justin Hobday 71 65 71\n","O: 69\n","O: 69\n","O: 69\n","O: ,\n","B-PER: Justin\n","I-PER: Hobday\n","O: 71\n","O: 65\n","O: 71\n","****************************************************************************************************\n","209 Steve van Vuuren 65 69 75\n","O: 209\n","B-PER: Steve\n","I-PER: van\n","I-PER: Vuuren\n","O: 65\n","O: 69\n","O: 75\n","****************************************************************************************************\n","210 Brett Liddle 75 65 70\n","O: 210\n","B-MISC: Brett\n","O: Liddle\n","O: 75\n","O: 65\n","O: 70\n","****************************************************************************************************\n","211 Hugh Baiocchi 73 67 71 , Greg Reid 72 68 71 , Mark\n","O: 211\n","B-PER: Hugh\n","I-PER: Baiocchi\n","O: 73\n","O: 67\n","O: 71\n","O: ,\n","B-PER: Greg\n","I-PER: Reid\n","O: 72\n","O: 68\n","O: 71\n","O: ,\n","B-PER: Mark\n","****************************************************************************************************\n","Murless 71 67 73\n","B-ORG: Murless\n","O: 71\n","O: 67\n","O: 73\n","****************************************************************************************************\n","212 Trevor Dodds ( Namibia ) 72 69 71 , Schalk van der\n","O: 212\n","B-PER: Trevor\n","I-PER: Dodds\n","O: (\n","B-ORG: Namibia\n","O: )\n","O: 72\n","O: 69\n","O: 71\n","O: ,\n","B-PER: Schalk\n","I-PER: van\n","I-PER: der\n","****************************************************************************************************\n","Merwe ( Namibia ) 67 73 72 , Hennie Swart 75 64 73 ,\n","B-PER: Merwe\n","O: (\n","B-LOC: Namibia\n","O: )\n","O: 67\n","O: 73\n","O: 72\n","O: ,\n","B-PER: Hennie\n","I-PER: Swart\n","O: 75\n","O: 64\n","O: 73\n","O: ,\n","****************************************************************************************************\n","Andrew Pitts ( U.S. ) 69 67 76\n","B-PER: Andrew\n","I-PER: Pitts\n","O: (\n","B-LOC: U.S.\n","O: )\n","O: 69\n","O: 67\n","O: 76\n","****************************************************************************************************\n","213 Sean Farrell ( Zimbabwe ) 77 68 68 , Glen Cayeux\n","O: 213\n","B-PER: Sean\n","I-PER: Farrell\n","O: (\n","B-LOC: Zimbabwe\n","O: )\n","O: 77\n","O: 68\n","O: 68\n","O: ,\n","B-PER: Glen\n","I-PER: Cayeux\n","****************************************************************************************************\n","( Zimbabwe ) 75 68 70 , Nic Henning 73 70 70 , Dion\n","O: (\n","B-LOC: Zimbabwe\n","O: )\n","O: 75\n","O: 68\n","O: 70\n","O: ,\n","O: Nic\n","O: Henning\n","O: 73\n","O: 70\n","O: 70\n","O: ,\n","O: Dion\n","****************************************************************************************************\n","Fourie 69 73 71\n","B-ORG: Fourie\n","O: 69\n","O: 73\n","O: 71\n","****************************************************************************************************\n","214 Steven Waltman 72 70 72 , Bradford Vaughan 72 71\n","O: 214\n","B-PER: Steven\n","I-PER: Waltman\n","O: 72\n","O: 70\n","O: 72\n","O: ,\n","B-PER: Bradford\n","I-PER: Vaughan\n","O: 72\n","O: 71\n","****************************************************************************************************\n","71 , Andrew Park 72 67 75 , Desvonde Botes 72 68 74 .\n","O: 71\n","O: ,\n","B-PER: Andrew\n","I-PER: Park\n","O: 72\n","O: 67\n","O: 75\n","O: ,\n","B-PER: Desvonde\n","I-PER: Botes\n","O: 72\n","O: 68\n","O: 74\n","O: .\n","****************************************************************************************************\n","SOCCER - REINSTATED ALBANIA NAMES SQUAD TO PLAY N.IRELAND .\n","O: SOCCER\n","O: -\n","O: REINSTATED\n","B-LOC: ALBANIA\n","O: NAMES\n","O: SQUAD\n","O: TO\n","O: PLAY\n","O: N.IRELAND\n","O: .\n","****************************************************************************************************\n","TIRANA 1996-12-07\n","B-ORG: TIRANA\n","O: 1996-12-07\n","****************************************************************************************************\n","Albanian coach Astrit Hafizi said on Saturday it was important that his players brush aside the country 's short ban by FIFA in order to concentrate on next Saturday'sWorld Cup group nine qualifier against Northern Ireland .\n","B-MISC: Albanian\n","O: coach\n","B-PER: Astrit\n","I-PER: Hafizi\n","O: said\n","O: on\n","O: Saturday\n","O: it\n","O: was\n","O: important\n","O: that\n","O: his\n","O: players\n","O: brush\n","O: aside\n","O: the\n","O: country\n","O: 's\n","O: short\n","O: ban\n","O: by\n","O: FIFA\n","O: in\n","O: order\n","O: to\n","O: concentrate\n","O: on\n","O: next\n","B-PER: Saturday'sWorld\n","I-PER: Cup\n","O: group\n","O: nine\n","O: qualifier\n","O: against\n","O: Northern\n","B-LOC: Ireland\n","O: .\n","****************************************************************************************************\n","World soccer 's governing body reinstated Albania last Tuesday after the Balkan country 's government lifted suspensions on various soccer officials .\n","O: World\n","O: soccer\n","O: 's\n","O: governing\n","O: body\n","O: reinstated\n","B-LOC: Albania\n","O: last\n","O: Tuesday\n","O: after\n","O: the\n","B-LOC: Balkan\n","O: country\n","O: 's\n","O: government\n","O: lifted\n","O: suspensions\n","O: on\n","O: various\n","O: soccer\n","O: officials\n","O: .\n","****************************************************************************************************\n","FIFA had banned Albania indefinitely after its sports ministry had ordered the suspension of Albanian Football Association general secretary Eduard Dervishi and dissolved the executive committee .\n","B-ORG: FIFA\n","O: had\n","O: banned\n","B-LOC: Albania\n","O: indefinitely\n","O: after\n","O: its\n","O: sports\n","O: ministry\n","O: had\n","O: ordered\n","O: the\n","O: suspension\n","O: of\n","B-LOC: Albanian\n","I-ORG: Football\n","I-ORG: Association\n","I-ORG: general\n","O: secretary\n","B-PER: Eduard\n","I-PER: Dervishi\n","O: and\n","O: dissolved\n","O: the\n","O: executive\n","O: committee\n","O: .\n","****************************************************************************************************\n","\" We would be very happy with a draw in Belfast , \" said Hafizi . \"\n","O: \"\n","O: We\n","O: would\n","O: be\n","O: very\n","O: happy\n","O: with\n","O: a\n","O: draw\n","O: in\n","O: Belfast\n","O: ,\n","O: \"\n","O: said\n","O: Hafizi\n","O: .\n","O: \"\n","****************************************************************************************************\n","Especially if one takes into consideration our difficult post-suspension situation and the fact Northern Ireland is very keen to win . \"\n","O: Especially\n","O: if\n","O: one\n","O: takes\n","O: into\n","O: consideration\n","O: our\n","O: difficult\n","O: post-suspension\n","O: situation\n","O: and\n","O: the\n","O: fact\n","O: Northern\n","B-LOC: Ireland\n","O: is\n","O: very\n","O: keen\n","O: to\n","O: win\n","O: .\n","O: \"\n","****************************************************************************************************\n","Regular defender Artur Lekbello , who is injured , was missing from Hafizi 's squad named on Saturday for the Belfast match .\n","O: Regular\n","O: defender\n","B-PER: Artur\n","I-PER: Lekbello\n","O: ,\n","O: who\n","O: is\n","O: injured\n","O: ,\n","O: was\n","O: missing\n","O: from\n","O: Hafizi\n","O: 's\n","O: squad\n","O: named\n","O: on\n","O: Saturday\n","O: for\n","O: the\n","O: Belfast\n","O: match\n","O: .\n","****************************************************************************************************\n","Squad :\n","O: Squad\n","O: :\n","****************************************************************************************************\n","Goalkeepers - Blendi Nallbani , Armir Grima\n","O: Goalkeepers\n","O: -\n","B-PER: Blendi\n","I-PER: Nallbani\n","O: ,\n","O: Armir\n","O: Grima\n","****************************************************************************************************\n","Defenders - Rudi Vata , Saimir Malko , Arjan Xhumba , Ilir Shulku , Afrim Tole , Nevil Dede , Arjan Bellai\n","O: Defenders\n","O: -\n","B-PER: Rudi\n","I-PER: Vata\n","O: ,\n","O: Saimir\n","O: Malko\n","O: ,\n","O: Arjan\n","O: Xhumba\n","O: ,\n","O: Ilir\n","O: Shulku\n","O: ,\n","O: Afrim\n","O: Tole\n","O: ,\n","B-ORG: Nevil\n","O: Dede\n","O: ,\n","O: Arjan\n","O: Bellai\n","****************************************************************************************************\n","Midfielders - Bledar Kola , Altin Haxhi , Sokol Prenga , Ervin Fakaj\n","O: Midfielders\n","O: -\n","B-PER: Bledar\n","I-PER: Kola\n","O: ,\n","B-ORG: Altin\n","I-PER: Haxhi\n","O: ,\n","B-ORG: Sokol\n","I-ORG: Prenga\n","O: ,\n","O: Ervin\n","O: Fakaj\n","****************************************************************************************************\n","Forwards - Altin Rraklli , Viktor Paco , Fatmir Vata , Erjon Bogdani .\n","O: Forwards\n","O: -\n","B-PER: Altin\n","I-PER: Rraklli\n","O: ,\n","B-PER: Viktor\n","I-PER: Paco\n","O: ,\n","B-PER: Fatmir\n","I-PER: Vata\n","O: ,\n","O: Erjon\n","O: Bogdani\n","O: .\n","****************************************************************************************************\n","CRICKET - JONES HITS CENTURY AS VICTORIA FIGHT BACK .\n","O: CRICKET\n","O: -\n","B-MISC: JONES\n","O: HITS\n","O: CENTURY\n","O: AS\n","B-ORG: VICTORIA\n","O: FIGHT\n","O: BACK\n","O: .\n","****************************************************************************************************\n","HOBART , Australia 1996-12-07\n","B-ORG: HOBART\n","O: ,\n","B-LOC: Australia\n","O: 1996-12-07\n","****************************************************************************************************\n","Former Australia test batsman Dean Jones hit an unbeaten 130 to lead Victoria 's fightback in their Sheffield Shield match against Tasmania on Saturday .\n","O: Former\n","B-LOC: Australia\n","O: test\n","O: batsman\n","B-PER: Dean\n","I-PER: Jones\n","O: hit\n","O: an\n","O: unbeaten\n","O: 130\n","O: to\n","O: lead\n","B-ORG: Victoria\n","O: 's\n","O: fightback\n","O: in\n","O: their\n","B-ORG: Sheffield\n","O: Shield\n","O: match\n","O: against\n","B-ORG: Tasmania\n","O: on\n","O: Saturday\n","O: .\n","****************************************************************************************************\n","Replying to the home side 's first innings 481 for eight declared , Victoria reached 220 for three at close of play on the second day of the four-day match at Hobart 's Bellerive Oval .\n","O: Replying\n","O: to\n","O: the\n","O: home\n","O: side\n","O: 's\n","O: first\n","O: innings\n","O: 481\n","O: for\n","O: eight\n","O: declared\n","O: ,\n","B-LOC: Victoria\n","O: reached\n","O: 220\n","O: for\n","O: three\n","O: at\n","O: close\n","O: of\n","O: play\n","O: on\n","O: the\n","O: second\n","O: day\n","O: of\n","O: the\n","O: four-day\n","O: match\n","O: at\n","B-LOC: Hobart\n","O: 's\n","B-LOC: Bellerive\n","B-LOC: Oval\n","O: .\n","****************************************************************************************************\n","Jones became the fourth century-maker of the match , equalling the feats of Tasmanian trio David Boon , Shaun Young and Michael DiVenuto .\n","O: Jones\n","O: became\n","O: the\n","O: fourth\n","O: century-maker\n","O: of\n","O: the\n","O: match\n","O: ,\n","O: equalling\n","O: the\n","O: feats\n","O: of\n","O: Tasmanian\n","I-ORG: trio\n","B-PER: David\n","I-PER: Boon\n","O: ,\n","B-PER: Shaun\n","I-ORG: Young\n","O: and\n","B-PER: Michael\n","I-PER: DiVenuto\n","O: .\n","****************************************************************************************************\n","Jones , who took over as captain for the match in the absence of Australia test leg-spinner Shane Warne , added 195 runs for the third wicket with left-hander Laurie Harper .\n","B-PER: Jones\n","O: ,\n","O: who\n","O: took\n","O: over\n","O: as\n","O: captain\n","O: for\n","O: the\n","O: match\n","O: in\n","O: the\n","O: absence\n","O: of\n","B-LOC: Australia\n","O: test\n","B-PER: leg-spinner\n","B-PER: Shane\n","I-PER: Warne\n","O: ,\n","O: added\n","O: 195\n","O: runs\n","O: for\n","O: the\n","O: third\n","O: wicket\n","O: with\n","O: left-hander\n","B-PER: Laurie\n","O: Harper\n","O: .\n","****************************************************************************************************\n","Harper was eventually dismissed for 77 after the pair joined forces with their side reeling on nine for two .\n","O: Harper\n","O: was\n","O: eventually\n","O: dismissed\n","O: for\n","O: 77\n","O: after\n","O: the\n","O: pair\n","O: joined\n","O: forces\n","O: with\n","O: their\n","O: side\n","O: reeling\n","O: on\n","O: nine\n","O: for\n","O: two\n","O: .\n","****************************************************************************************************\n","Earlier , former Australia test batsman David Boon scored 118 and all-rounder Shaun Young hit 113 .\n","O: Earlier\n","O: ,\n","O: former\n","B-LOC: Australia\n","O: test\n","O: batsman\n","B-PER: David\n","I-PER: Boon\n","O: scored\n","B-ORG: 118\n","O: and\n","O: all-rounder\n","B-PER: Shaun\n","I-ORG: Young\n","O: hit\n","O: 113\n","O: .\n","****************************************************************************************************\n","The pair hammered 36 boundaries between them .\n","O: The\n","O: pair\n","O: hammered\n","O: 36\n","O: boundaries\n","O: between\n","O: them\n","O: .\n","****************************************************************************************************\n","Pace bowler Ian Harvey claimed three for 81 for Victoria .\n","O: Pace\n","O: bowler\n","B-PER: Ian\n","I-PER: Harvey\n","O: claimed\n","O: three\n","O: for\n","O: 81\n","O: for\n","B-LOC: Victoria\n","O: .\n","****************************************************************************************************\n","CRICKET - SHEFFIELD SHIELD SCORE .\n","O: CRICKET\n","O: -\n","B-PER: SHEFFIELD\n","I-PER: SHIELD\n","O: SCORE\n","O: .\n","****************************************************************************************************\n","HOBART , Australia 1996-12-07\n","B-ORG: HOBART\n","O: ,\n","B-LOC: Australia\n","O: 1996-12-07\n","****************************************************************************************************\n","Close of play score on the second day of the four-day Sheffield Shield cricket match between Tasmania and Victoria at Bellerive Oval on Saturday :\n","O: Close\n","O: of\n","O: play\n","O: score\n","O: on\n","O: the\n","O: second\n","O: day\n","O: of\n","O: the\n","O: four-day\n","B-ORG: Sheffield\n","O: Shield\n","O: cricket\n","O: match\n","O: between\n","O: Tasmania\n","O: and\n","B-LOC: Victoria\n","O: at\n","B-LOC: Bellerive\n","B-LOC: Oval\n","O: on\n","O: Saturday\n","O: :\n","****************************************************************************************************\n","Tasmania 481 for eight declared ( Michael DiVenuto 119 , David Boon 118 , Shaun Young 113 ) ; Victoria 220 for three ( Dean Jones 130 not out ) .\n","B-ORG: Tasmania\n","O: 481\n","O: for\n","O: eight\n","O: declared\n","O: (\n","B-PER: Michael\n","I-PER: DiVenuto\n","O: 119\n","O: ,\n","B-PER: David\n","I-PER: Boon\n","O: 118\n","O: ,\n","B-PER: Shaun\n","I-ORG: Young\n","O: 113\n","O: )\n","O: ;\n","B-ORG: Victoria\n","O: 220\n","O: for\n","O: three\n","O: (\n","B-PER: Dean\n","I-PER: Jones\n","O: 130\n","O: not\n","O: out\n","O: )\n","O: .\n","****************************************************************************************************\n","SOCCER - SOUTH KOREA MOVE CLOSE TO QUARTER-FINAL BERTH .\n","O: SOCCER\n","O: -\n","B-MISC: SOUTH\n","I-LOC: KOREA\n","O: MOVE\n","O: CLOSE\n","O: TO\n","O: QUARTER-FINAL\n","O: BERTH\n","O: .\n","****************************************************************************************************\n","ABU DHABI 1996-12-07\n","B-LOC: ABU\n","I-LOC: DHABI\n","O: 1996-12-07\n","****************************************************************************************************\n","South Korea made virtually certain of an Asian Cup quarter-final spot with a 4-2 win over Indonesia in a Group A match on Saturday .\n","B-LOC: South\n","I-LOC: Korea\n","O: made\n","O: virtually\n","O: certain\n","O: of\n","O: an\n","B-MISC: Asian\n","I-MISC: Cup\n","O: quarter-final\n","O: spot\n","O: with\n","O: a\n","O: 4-2\n","O: win\n","O: over\n","B-LOC: Indonesia\n","O: in\n","O: a\n","O: Group\n","O: A\n","O: match\n","O: on\n","O: Saturday\n","O: .\n","****************************************************************************************************\n","After going four up in the first 55 minutes South Korea allowed Indonesia , newcomers to Asian Cup finals , back into the match , conceding two goals from rare counter attacks .\n","O: After\n","O: going\n","O: four\n","O: up\n","O: in\n","O: the\n","O: first\n","O: 55\n","O: minutes\n","B-ORG: South\n","I-LOC: Korea\n","O: allowed\n","B-LOC: Indonesia\n","O: ,\n","O: newcomers\n","O: to\n","B-MISC: Asian\n","I-MISC: Cup\n","O: finals\n","O: ,\n","O: back\n","O: into\n","O: the\n","O: match\n","O: ,\n","O: conceding\n","O: two\n","O: goals\n","O: from\n","O: rare\n","O: counter\n","O: attacks\n","O: .\n","****************************************************************************************************\n","Kim Do Hoon opened the scoring for South Korea in only the fifth minute , turning unmarked on the penalty spot to fire a shot into the top corner .\n","B-PER: Kim\n","O: Do\n","O: Hoon\n","O: opened\n","O: the\n","O: scoring\n","O: for\n","B-LOC: South\n","I-LOC: Korea\n","O: in\n","O: only\n","O: the\n","O: fifth\n","O: minute\n","O: ,\n","O: turning\n","O: unmarked\n","O: on\n","O: the\n","O: penalty\n","O: spot\n","O: to\n","O: fire\n","O: a\n","O: shot\n","O: into\n","O: the\n","O: top\n","O: corner\n","O: .\n","****************************************************************************************************\n","It looked like turning into a rout as Hwang Sun Hong rapidly added two more in the seventh and 15th minutes but although the Koreans continued to dominate they failed to add to the score before the interval .\n","O: It\n","O: looked\n","O: like\n","O: turning\n","O: into\n","O: a\n","O: rout\n","O: as\n","O: Hwang\n","B-ORG: Sun\n","I-MISC: Hong\n","O: rapidly\n","O: added\n","O: two\n","O: more\n","O: in\n","O: the\n","O: seventh\n","O: and\n","O: 15th\n","O: minutes\n","O: but\n","O: although\n","O: the\n","O: Koreans\n","O: continued\n","O: to\n","O: dominate\n","O: they\n","O: failed\n","O: to\n","O: add\n","O: to\n","O: the\n","O: score\n","O: before\n","O: the\n","O: interval\n","O: .\n","****************************************************************************************************\n","But they started the second half where they had left off and it was not long before they went four up , Ko Jeong Woon heading in from a free kick in the 55th minute .\n","O: But\n","O: they\n","O: started\n","O: the\n","O: second\n","O: half\n","O: where\n","O: they\n","O: had\n","O: left\n","O: off\n","O: and\n","O: it\n","O: was\n","O: not\n","O: long\n","O: before\n","O: they\n","O: went\n","O: four\n","O: up\n","O: ,\n","O: Ko\n","O: Jeong\n","O: Woon\n","O: heading\n","O: in\n","O: from\n","O: a\n","O: free\n","O: kick\n","O: in\n","O: the\n","O: 55th\n","O: minute\n","O: .\n","****************************************************************************************************\n","The Koreans then appeared to relax , allowing the Indonesians to get back into the match .\n","O: The\n","O: Koreans\n","O: then\n","O: appeared\n","O: to\n","O: relax\n","O: ,\n","O: allowing\n","O: the\n","O: Indonesians\n","O: to\n","O: get\n","O: back\n","O: into\n","O: the\n","O: match\n","O: .\n","****************************************************************************************************\n","Ronny Wabia scored for Indonesia three minutes later direct from a a corner kick that Korean goalkeeper Kim Byung reached with one hand but failed to keep out .\n","B-PER: Ronny\n","I-PER: Wabia\n","O: scored\n","O: for\n","B-LOC: Indonesia\n","O: three\n","O: minutes\n","O: later\n","O: direct\n","O: from\n","O: a\n","O: a\n","O: corner\n","O: kick\n","O: that\n","O: Korean\n","O: goalkeeper\n","B-PER: Kim\n","I-PER: Byung\n","O: reached\n","O: with\n","O: one\n","O: hand\n","O: but\n","O: failed\n","O: to\n","O: keep\n","O: out\n","O: .\n","****************************************************************************************************\n","With 65 minutes gone Indonesia 's Widodo Putra , who scored a spectacular goal against Kuwait on Wednesday , was again on target , breaking through the Korean defence to beat the keeper with a low shot .\n","O: With\n","O: 65\n","O: minutes\n","O: gone\n","B-LOC: Indonesia\n","O: 's\n","B-PER: Widodo\n","I-PER: Putra\n","O: ,\n","O: who\n","O: scored\n","O: a\n","O: spectacular\n","O: goal\n","O: against\n","B-LOC: Kuwait\n","O: on\n","O: Wednesday\n","O: ,\n","O: was\n","O: again\n","O: on\n","O: target\n","O: ,\n","O: breaking\n","O: through\n","O: the\n","B-MISC: Korean\n","I-ORG: defence\n","O: to\n","O: beat\n","O: the\n","O: keeper\n","O: with\n","O: a\n","O: low\n","O: shot\n","O: .\n","****************************************************************************************************\n","Indonesian keeper Hendro Kartiko produced a string of fine saves to prevent the Koreans increasing their lead .\n","B-MISC: Indonesian\n","O: keeper\n","O: Hendro\n","O: Kartiko\n","O: produced\n","O: a\n","O: string\n","O: of\n","O: fine\n","O: saves\n","O: to\n","O: prevent\n","O: the\n","O: Koreans\n","O: increasing\n","O: their\n","O: lead\n","O: .\n","****************************************************************************************************\n","Teams :\n","O: Teams\n","O: :\n","****************************************************************************************************\n","Indonesia : 20 - Hendro Kartiko ; 2 - Agung Setyabudi ; 3 - Suwandi Siswoyo ; 4 - Yeyen Tumera ; 5 - Aples Tecuari ; 6 - Sudiriman ; 7 - Widodo Gahyo Purta ; 8 - Ronny Wabia ; 11 - Bima Sakti ; 12 - Chris Yarangga ( 15 - Francis Wewengken 36 ) ; 16 - Marzuki Badriawan .\n","B-LOC: Indonesia\n","O: :\n","O: 20\n","O: -\n","O: Hendro\n","O: Kartiko\n","O: ;\n","O: 2\n","O: -\n","O: Agung\n","O: Setyabudi\n","O: ;\n","O: 3\n","O: -\n","O: Suwandi\n","O: Siswoyo\n","O: ;\n","O: 4\n","O: -\n","O: Yeyen\n","O: Tumera\n","O: ;\n","O: 5\n","O: -\n","O: Aples\n","O: Tecuari\n","O: ;\n","O: 6\n","O: -\n","O: Sudiriman\n","O: ;\n","O: 7\n","O: -\n","O: Widodo\n","O: Gahyo\n","O: Purta\n","O: ;\n","O: 8\n","O: -\n","O: Ronny\n","O: Wabia\n","O: ;\n","O: 11\n","O: -\n","O: Bima\n","O: Sakti\n","O: ;\n","O: 12\n","O: -\n","B-PER: Chris\n","I-PER: Yarangga\n","O: (\n","O: 15\n","O: -\n","B-MISC: Francis\n","O: Wewengken\n","O: 36\n","O: )\n","O: ;\n","O: 16\n","O: -\n","O: Marzuki\n","O: Badriawan\n","O: .\n","****************************************************************************************************\n","South Korea : 1 - Kim Byung Ji ; 2 - Kim Pan Keun ; 5 - Huh Ki Tae ; 8 - Roh Sang Rae ( 7 - Sin Tae Yong 33 ) ; 9 - Kim Do Hoon ; 11 - Ko Jeong Woon ; 17 - Ha Seok Ju ; 18 - Hwang Sun Hong ; 22 - Lee Young Jin ; 23 - Yoo Sang Chul ; 24 - Kim Joo Sung .\n","B-LOC: South\n","I-LOC: Korea\n","O: :\n","O: 1\n","O: -\n","B-PER: Kim\n","I-PER: Byung\n","O: Ji\n","O: ;\n","O: 2\n","O: -\n","B-PER: Kim\n","I-PER: Pan\n","O: Keun\n","O: ;\n","O: 5\n","O: -\n","O: Huh\n","O: Ki\n","O: Tae\n","O: ;\n","O: 8\n","O: -\n","O: Roh\n","O: Sang\n","O: Rae\n","O: (\n","O: 7\n","O: -\n","B-ORG: Sin\n","I-PER: Tae\n","O: Yong\n","O: 33\n","O: )\n","O: ;\n","O: 9\n","O: -\n","B-PER: Kim\n","O: Do\n","O: Hoon\n","O: ;\n","O: 11\n","O: -\n","O: Ko\n","O: Jeong\n","O: Woon\n","O: ;\n","O: 17\n","O: -\n","O: Ha\n","O: Seok\n","O: Ju\n","O: ;\n","O: 18\n","O: -\n","O: Hwang\n","B-ORG: Sun\n","I-ORG: Hong\n","O: ;\n","O: 22\n","O: -\n","B-PER: Lee\n","I-ORG: Young\n","O: Jin\n","O: ;\n","O: 23\n","O: -\n","O: Yoo\n","O: Sang\n","O: Chul\n","O: ;\n","O: 24\n","O: -\n","B-PER: Kim\n","I-PER: Joo\n","O: Sung\n","O: .\n","****************************************************************************************************\n","SOCCER - ISRAELI FIRST DIVISION RESULTS / STANDINGS .\n","O: SOCCER\n","O: -\n","B-MISC: ISRAELI\n","O: FIRST\n","O: DIVISION\n","O: RESULTS\n","O: /\n","O: STANDINGS\n","O: .\n","****************************************************************************************************\n","JERUSALEM 1996-12-07\n","B-LOC: JERUSALEM\n","O: 1996-12-07\n","****************************************************************************************************\n","Results of first division soccer\n","O: Results\n","O: of\n","O: first\n","O: division\n","O: soccer\n","****************************************************************************************************\n","matches played over the weekend :\n","O: matches\n","O: played\n","O: over\n","O: the\n","O: weekend\n","O: :\n","****************************************************************************************************\n","Zafririm Holon 1 Hapoel Petah Tikva 1\n","B-ORG: Zafririm\n","I-ORG: Holon\n","O: 1\n","B-ORG: Hapoel\n","I-ORG: Petah\n","I-ORG: Tikva\n","O: 1\n","****************************************************************************************************\n","Maccabi Haifa 1 Hapoel Taibe 1\n","B-ORG: Maccabi\n","I-ORG: Haifa\n","O: 1\n","B-ORG: Hapoel\n","I-ORG: Taibe\n","O: 1\n","****************************************************************************************************\n","Hapoel Kfar Sava 1 Bnei Yehuda 0\n","B-ORG: Hapoel\n","I-ORG: Kfar\n","I-ORG: Sava\n","O: 1\n","B-ORG: Bnei\n","I-ORG: Yehuda\n","O: 0\n","****************************************************************************************************\n","Hapoel Tel Aviv 1 Betar Jerusalem 4\n","B-ORG: Hapoel\n","I-ORG: Tel\n","I-ORG: Aviv\n","O: 1\n","B-ORG: Betar\n","I-ORG: Jerusalem\n","O: 4\n","****************************************************************************************************\n","Hapoel Jerusalem 0 Maccabi Tel Aviv 4\n","B-ORG: Hapoel\n","I-ORG: Jerusalem\n","O: 0\n","B-ORG: Maccabi\n","I-ORG: Tel\n","I-ORG: Aviv\n","O: 4\n","****************************************************************************************************\n","Ironi Rishon Lezion 1 Maccabi Herzliya 0\n","B-ORG: Ironi\n","I-ORG: Rishon\n","I-ORG: Lezion\n","O: 1\n","B-ORG: Maccabi\n","I-ORG: Herzliya\n","O: 0\n","****************************************************************************************************\n","Hapoel Beit She'an 2 Hapoel Beersheba 1\n","B-ORG: Hapoel\n","I-ORG: Beit\n","I-ORG: She'an\n","O: 2\n","B-ORG: Hapoel\n","I-ORG: Beersheba\n","O: 1\n","****************************************************************************************************\n","Maccabi Petah Tikva 0 Hapoel Haifa 2\n","B-ORG: Maccabi\n","I-ORG: Petah\n","I-ORG: Tikva\n","O: 0\n","B-ORG: Hapoel\n","I-ORG: Haifa\n","O: 2\n","****************************************************************************************************\n","Standings ( tabulate under played , won , drawn , lost , goals\n","O: Standings\n","O: (\n","O: tabulate\n","O: under\n","O: played\n","O: ,\n","O: won\n","O: ,\n","O: drawn\n","O: ,\n","O: lost\n","O: ,\n","O: goals\n","****************************************************************************************************\n","for , against , points ) :\n","O: for\n","O: ,\n","O: against\n","O: ,\n","O: points\n","O: )\n","O: :\n","****************************************************************************************************\n","Betar Jerusalem 12 10 2 0 28 7 32\n","B-ORG: Betar\n","I-ORG: Jerusalem\n","O: 12\n","O: 10\n","O: 2\n","O: 0\n","O: 28\n","O: 7\n","O: 32\n","****************************************************************************************************\n","Hapoel Petah Tikva 12 9 2 1 27 13 29\n","B-ORG: Hapoel\n","I-ORG: Petah\n","I-ORG: Tikva\n","O: 12\n","O: 9\n","O: 2\n","O: 1\n","O: 27\n","O: 13\n","O: 29\n","****************************************************************************************************\n","Hapoel Beersheba 12 8 0 4 18 9 24\n","B-ORG: Hapoel\n","I-ORG: Beersheba\n","O: 12\n","O: 8\n","O: 0\n","O: 4\n","O: 18\n","O: 9\n","O: 24\n","****************************************************************************************************\n","Maccabi Tel Aviv 12 6 4 2 21 14 22\n","B-ORG: Maccabi\n","I-ORG: Tel\n","I-ORG: Aviv\n","O: 12\n","O: 6\n","O: 4\n","O: 2\n","O: 21\n","O: 14\n","O: 22\n","****************************************************************************************************\n","Maccabi Petah Tikva 12 6 2 4 14 12 20\n","B-ORG: Maccabi\n","I-ORG: Petah\n","I-ORG: Tikva\n","O: 12\n","O: 6\n","O: 2\n","O: 4\n","O: 14\n","O: 12\n","O: 20\n","****************************************************************************************************\n","Bnei Yehuda 12 6 2 4 15 15 20\n","B-ORG: Bnei\n","I-ORG: Yehuda\n","O: 12\n","O: 6\n","O: 2\n","O: 4\n","O: 15\n","O: 15\n","O: 20\n","****************************************************************************************************\n","Hapoel Haifa 12 6 1 5 21 16 19\n","B-ORG: Hapoel\n","I-ORG: Haifa\n","O: 12\n","O: 6\n","O: 1\n","O: 5\n","O: 21\n","O: 16\n","O: 19\n","****************************************************************************************************\n","Maccabi Haifa 12 4 4 4 14 15 16\n","B-ORG: Maccabi\n","I-ORG: Haifa\n","O: 12\n","O: 4\n","O: 4\n","O: 4\n","O: 14\n","O: 15\n","O: 16\n","****************************************************************************************************\n","Hapoel Kfar Sava 12 5 1 6 10 11 16\n","B-ORG: Hapoel\n","I-ORG: Kfar\n","I-ORG: Sava\n","O: 12\n","O: 5\n","O: 1\n","O: 6\n","O: 10\n","O: 11\n","O: 16\n","****************************************************************************************************\n","Hapoel Jerusalem 12 4 1 7 10 18 13\n","B-ORG: Hapoel\n","I-ORG: Jerusalem\n","O: 12\n","O: 4\n","O: 1\n","O: 7\n","O: 10\n","O: 18\n","O: 13\n","****************************************************************************************************\n","Ironi Rishon Lezion 12 4 1 7 13 24 13\n","B-ORG: Ironi\n","I-ORG: Rishon\n","I-ORG: Lezion\n","O: 12\n","O: 4\n","O: 1\n","O: 7\n","O: 13\n","O: 24\n","O: 13\n","****************************************************************************************************\n","Zafririm Holon 12 2 4 6 8 14 10\n","B-ORG: Zafririm\n","I-ORG: Holon\n","O: 12\n","O: 2\n","O: 4\n","O: 6\n","O: 8\n","O: 14\n","O: 10\n","****************************************************************************************************\n","Maccabi Herzliya 12 3 1 8 5 12 10\n","B-ORG: Maccabi\n","I-ORG: Herzliya\n","O: 12\n","O: 3\n","O: 1\n","O: 8\n","O: 5\n","O: 12\n","O: 10\n","****************************************************************************************************\n","Hapoel Taiba 12 3 1 8 10 21 10\n","B-ORG: Hapoel\n","I-ORG: Taiba\n","O: 12\n","O: 3\n","O: 1\n","O: 8\n","O: 10\n","O: 21\n","O: 10\n","****************************************************************************************************\n","Hapoel Beit She'an 12 2 3 7 9 13 9\n","B-ORG: Hapoel\n","I-ORG: Beit\n","I-ORG: She'an\n","O: 12\n","O: 2\n","O: 3\n","O: 7\n","O: 9\n","O: 13\n","O: 9\n","****************************************************************************************************\n","Hapoel Tel Aviv 12 2 3 7 7 16 9\n","B-ORG: Hapoel\n","I-ORG: Tel\n","I-ORG: Aviv\n","O: 12\n","O: 2\n","O: 3\n","O: 7\n","O: 7\n","O: 16\n","O: 9\n","****************************************************************************************************\n","SOCCER - ASIAN CUP RESULTS .\n","O: SOCCER\n","O: -\n","B-MISC: ASIAN\n","I-MISC: CUP\n","O: RESULTS\n","O: .\n","****************************************************************************************************\n","ABU DHABI 1996-12-07\n","B-LOC: ABU\n","I-LOC: DHABI\n","O: 1996-12-07\n","****************************************************************************************************\n","Results of Asian Cup group A matches on Saturday :\n","O: Results\n","O: of\n","B-MISC: Asian\n","I-MISC: Cup\n","O: group\n","O: A\n","O: matches\n","O: on\n","O: Saturday\n","O: :\n","****************************************************************************************************\n","United Arab Emirates 3 Kuwait 2 ( halftime 0-2 )\n","B-ORG: United\n","B-ORG: Arab\n","I-ORG: Emirates\n","O: 3\n","B-ORG: Kuwait\n","O: 2\n","O: (\n","O: halftime\n","O: 0-2\n","O: )\n","****************************************************************************************************\n","Scorers :\n","O: Scorers\n","O: :\n","****************************************************************************************************\n","UAE - Hassan Ahmed 53 , Adnan Al Talyani 55 , Bakhit Saad 80\n","B-LOC: UAE\n","O: -\n","B-PER: Hassan\n","I-PER: Ahmed\n","O: 53\n","O: ,\n","O: Adnan\n","O: Al\n","O: Talyani\n","O: 55\n","O: ,\n","O: Bakhit\n","O: Saad\n","O: 80\n","****************************************************************************************************\n","Kuwait - Jassem Al-Huwaidi 9 , 44\n","B-LOC: Kuwait\n","O: -\n","B-ORG: Jassem\n","I-ORG: Al-Huwaidi\n","O: 9\n","O: ,\n","O: 44\n","****************************************************************************************************\n","Attendance : 15,000\n","O: Attendance\n","O: :\n","O: 15,000\n","****************************************************************************************************\n","South Korea 4 Indonesia 2 ( 3-0 )\n","B-LOC: South\n","I-LOC: Korea\n","O: 4\n","B-LOC: Indonesia\n","O: 2\n","O: (\n","O: 3-0\n","O: )\n","****************************************************************************************************\n","Scorers :\n","O: Scorers\n","O: :\n","****************************************************************************************************\n","South Korea - Kim Do Hoon 5 , Hwang Sun Hong 7 and 15 , Koo\n","B-LOC: South\n","I-LOC: Korea\n","O: -\n","B-PER: Kim\n","O: Do\n","O: Hoon\n","O: 5\n","O: ,\n","O: Hwang\n","B-ORG: Sun\n","I-ORG: Hong\n","O: 7\n","O: and\n","O: 15\n","O: ,\n","O: Koo\n","****************************************************************************************************\n","Jeon Woon 55\n","B-ORG: Jeon\n","O: Woon\n","O: 55\n","****************************************************************************************************\n","Indonesia - Ronny Wabia 58 , Widodo Putra 65\n","B-LOC: Indonesia\n","O: -\n","B-ORG: Ronny\n","I-ORG: Wabia\n","O: 58\n","O: ,\n","O: Widodo\n","O: Putra\n","O: 65\n","****************************************************************************************************\n","Attendance : 2,000\n","O: Attendance\n","O: :\n","O: 2,000\n","****************************************************************************************************\n","Group A standings ( tabulate under : played , won , drawn , lost ,\n","O: Group\n","O: A\n","O: standings\n","O: (\n","O: tabulate\n","O: under\n","O: :\n","O: played\n","O: ,\n","O: won\n","O: ,\n","O: drawn\n","O: ,\n","O: lost\n","O: ,\n","****************************************************************************************************\n","goals for , against , points ) :\n","O: goals\n","O: for\n","O: ,\n","O: against\n","O: ,\n","O: points\n","O: )\n","O: :\n","****************************************************************************************************\n","South Korea 2 1 1 0 5 3 4\n","B-ORG: South\n","I-ORG: Korea\n","O: 2\n","O: 1\n","O: 1\n","O: 0\n","O: 5\n","O: 3\n","O: 4\n","****************************************************************************************************\n","UAE 2 1 1 0 4 3 4\n","B-LOC: UAE\n","O: 2\n","O: 1\n","O: 1\n","O: 0\n","O: 4\n","O: 3\n","O: 4\n","****************************************************************************************************\n","Kuwait 2 0 1 1 4 5 1\n","B-ORG: Kuwait\n","O: 2\n","O: 0\n","O: 1\n","O: 1\n","O: 4\n","O: 5\n","O: 1\n","****************************************************************************************************\n","Indonesia 2 0 1 1 4 6 1\n","B-ORG: Indonesia\n","O: 2\n","O: 0\n","O: 1\n","O: 1\n","O: 4\n","O: 6\n","O: 1\n","****************************************************************************************************\n","NBA BASKETBALL - STANDINGS AFTER FRIDAY 'S GAMES .\n","B-ORG: NBA\n","O: BASKETBALL\n","O: -\n","O: STANDINGS\n","O: AFTER\n","O: FRIDAY\n","O: 'S\n","O: GAMES\n","O: .\n","****************************************************************************************************\n","NEW YORK 1996-12-07\n","B-LOC: NEW\n","I-ORG: YORK\n","O: 1996-12-07\n","****************************************************************************************************\n","Standings of National\n","O: Standings\n","O: of\n","O: National\n","****************************************************************************************************\n","Basketball Association teams after games played on Friday\n","O: Basketball\n","O: Association\n","O: teams\n","O: after\n","O: games\n","O: played\n","O: on\n","O: Friday\n","****************************************************************************************************\n","( tabulate under won , lost , percentage , games behind ) :\n","O: (\n","O: tabulate\n","O: under\n","O: won\n","O: ,\n","O: lost\n","O: ,\n","O: percentage\n","O: ,\n","O: games\n","O: behind\n","O: )\n","O: :\n","****************************************************************************************************\n","EASTERN CONFERENCE\n","B-PER: EASTERN\n","I-PER: CONFERENCE\n","****************************************************************************************************\n","ATLANTIC DIVISION\n","B-LOC: ATLANTIC\n","I-MISC: DIVISION\n","****************************************************************************************************\n","W L PCT GB\n","O: W\n","O: L\n","O: PCT\n","O: GB\n","****************************************************************************************************\n","MIAMI 14 5 .737 -\n","B-ORG: MIAMI\n","O: 14\n","O: 5\n","O: .737\n","O: -\n","****************************************************************************************************\n","NEW YORK 11 6 .647 2\n","B-ORG: NEW\n","I-ORG: YORK\n","O: 11\n","O: 6\n","B-ORG: .647\n","O: 2\n","****************************************************************************************************\n","ORLANDO 8 7 .533 4\n","B-ORG: ORLANDO\n","O: 8\n","O: 7\n","O: .533\n","O: 4\n","****************************************************************************************************\n","WASHINGTON 7 9 .438 5 1/2\n","B-ORG: WASHINGTON\n","O: 7\n","O: 9\n","O: .438\n","O: 5\n","O: 1/2\n","****************************************************************************************************\n","PHILADELPHIA 7 10 .412 6\n","B-ORG: PHILADELPHIA\n","O: 7\n","O: 10\n","O: .412\n","O: 6\n","****************************************************************************************************\n","NEW JERSEY 4 10 .286 7 1/2\n","B-ORG: NEW\n","I-ORG: JERSEY\n","O: 4\n","O: 10\n","O: .286\n","O: 7\n","O: 1/2\n","****************************************************************************************************\n","BOSTON 4 13 .235 9\n","B-ORG: BOSTON\n","O: 4\n","O: 13\n","O: .235\n","O: 9\n","****************************************************************************************************\n","CENTRAL DIVISION\n","B-MISC: CENTRAL\n","I-MISC: DIVISION\n","****************************************************************************************************\n","W L PCT GB\n","O: W\n","O: L\n","O: PCT\n","O: GB\n","****************************************************************************************************\n","CHICAGO 17 1 .944 -\n","B-ORG: CHICAGO\n","O: 17\n","O: 1\n","O: .944\n","O: -\n","****************************************************************************************************\n","DETROIT 14 3 .824 2 1/2\n","B-ORG: DETROIT\n","O: 14\n","O: 3\n","O: .824\n","O: 2\n","O: 1/2\n","****************************************************************************************************\n","CLEVELAND 11 6 .647 5 1/2\n","B-ORG: CLEVELAND\n","O: 11\n","O: 6\n","O: .647\n","O: 5\n","O: 1/2\n","****************************************************************************************************\n","ATLANTA 10 8 .556 7\n","B-ORG: ATLANTA\n","O: 10\n","O: 8\n","O: .556\n","O: 7\n","****************************************************************************************************\n","MILWAUKEE 8 8 .500 8\n","B-ORG: MILWAUKEE\n","O: 8\n","O: 8\n","O: .500\n","O: 8\n","****************************************************************************************************\n","INDIANA 8 8 .500 8\n","B-LOC: INDIANA\n","O: 8\n","O: 8\n","O: .500\n","O: 8\n","****************************************************************************************************\n","CHARLOTTE 8 9 .471 8 1/2\n","B-ORG: CHARLOTTE\n","O: 8\n","O: 9\n","O: .471\n","O: 8\n","O: 1/2\n","****************************************************************************************************\n","TORONTO 6 11 .353 10 1/2\n","B-ORG: TORONTO\n","O: 6\n","O: 11\n","O: .353\n","O: 10\n","O: 1/2\n","****************************************************************************************************\n","WESTERN CONFERENCE\n","B-MISC: WESTERN\n","O: CONFERENCE\n","****************************************************************************************************\n","MIDWEST DIVISION\n","B-LOC: MIDWEST\n","O: DIVISION\n","****************************************************************************************************\n","W L PCT GB\n","O: W\n","O: L\n","O: PCT\n","O: GB\n","****************************************************************************************************\n","HOUSTON 16 2 .889 -\n","B-ORG: HOUSTON\n","O: 16\n","O: 2\n","O: .889\n","O: -\n","****************************************************************************************************\n","UTAH 15 2 .882 1/2\n","B-ORG: UTAH\n","O: 15\n","O: 2\n","O: .882\n","O: 1/2\n","****************************************************************************************************\n","MINNESOTA 7 11 .389 9\n","B-ORG: MINNESOTA\n","O: 7\n","O: 11\n","O: .389\n","O: 9\n","****************************************************************************************************\n","DALLAS 6 11 .353 9 1/2\n","B-ORG: DALLAS\n","O: 6\n","O: 11\n","O: .353\n","O: 9\n","O: 1/2\n","****************************************************************************************************\n","DENVER 5 14 .263 11 1/2\n","B-ORG: DENVER\n","O: 5\n","O: 14\n","O: .263\n","O: 11\n","O: 1/2\n","****************************************************************************************************\n","SAN ANTONIO 3 14 .176 12 1/2\n","B-ORG: SAN\n","I-ORG: ANTONIO\n","O: 3\n","O: 14\n","O: .176\n","O: 12\n","O: 1/2\n","****************************************************************************************************\n","VANCOUVER 3 16 .158 13 1/2\n","B-ORG: VANCOUVER\n","O: 3\n","O: 16\n","O: .158\n","O: 13\n","O: 1/2\n","****************************************************************************************************\n","PACIFIC DIVISION\n","B-MISC: PACIFIC\n","I-MISC: DIVISION\n","****************************************************************************************************\n","W L PCT GB\n","O: W\n","O: L\n","O: PCT\n","O: GB\n","****************************************************************************************************\n","SEATTLE 15 5 .750 -\n","B-ORG: SEATTLE\n","O: 15\n","O: 5\n","O: .750\n","O: -\n","****************************************************************************************************\n","LA LAKERS 14 7 .667 1 1/2\n","B-ORG: LA\n","I-ORG: LAKERS\n","O: 14\n","O: 7\n","O: .667\n","O: 1\n","O: 1/2\n","****************************************************************************************************\n","PORTLAND 12 8 .600 3\n","B-ORG: PORTLAND\n","O: 12\n","O: 8\n","O: .600\n","O: 3\n","****************************************************************************************************\n","LA CLIPPERS 7 11 .389 7\n","B-ORG: LA\n","I-ORG: CLIPPERS\n","O: 7\n","O: 11\n","O: .389\n","O: 7\n","****************************************************************************************************\n","GOLDEN STATE 6 13 .316 8 1/2\n","B-ORG: GOLDEN\n","I-ORG: STATE\n","O: 6\n","O: 13\n","O: .316\n","O: 8\n","O: 1/2\n","****************************************************************************************************\n","SACRAMENTO 6 13 .316 8 1/2\n","B-ORG: SACRAMENTO\n","O: 6\n","O: 13\n","O: .316\n","O: 8\n","O: 1/2\n","****************************************************************************************************\n","PHOENIX 3 14 .176 10 1/2\n","B-ORG: PHOENIX\n","O: 3\n","O: 14\n","O: .176\n","O: 10\n","O: 1/2\n","****************************************************************************************************\n","SATURDAY , DECEMBER 7 SCHEDULE\n","O: SATURDAY\n","O: ,\n","O: DECEMBER\n","O: 7\n","O: SCHEDULE\n","****************************************************************************************************\n","TORONTO AT ATLANTA\n","B-ORG: TORONTO\n","O: AT\n","B-LOC: ATLANTA\n","****************************************************************************************************\n","LA CLIPPERS AT NEW YORK\n","B-ORG: LA\n","O: CLIPPERS\n","O: AT\n","B-LOC: NEW\n","I-LOC: YORK\n","****************************************************************************************************\n","MILWAUKEE AT WASHINGTON\n","B-ORG: MILWAUKEE\n","O: AT\n","B-LOC: WASHINGTON\n","****************************************************************************************************\n","DETROIT AT NEW JERSEY\n","B-ORG: DETROIT\n","O: AT\n","B-LOC: NEW\n","I-MISC: JERSEY\n","****************************************************************************************************\n","MIAMI AT CHICAGO\n","B-ORG: MIAMI\n","O: AT\n","B-LOC: CHICAGO\n","****************************************************************************************************\n","VANCOUVER AT DALLAS\n","B-ORG: VANCOUVER\n","O: AT\n","B-LOC: DALLAS\n","****************************************************************************************************\n","PHILADELPHIA AT HOUSTON\n","B-ORG: PHILADELPHIA\n","O: AT\n","B-LOC: HOUSTON\n","****************************************************************************************************\n","UTAH AT DENVER\n","O: UTAH\n","O: AT\n","O: DENVER\n","****************************************************************************************************\n","CHARLOTTE AT SEATTLE\n","O: CHARLOTTE\n","O: AT\n","B-LOC: SEATTLE\n","****************************************************************************************************\n","NBA BASKETBALL - FRIDAY 'S RESULTS .\n","B-ORG: NBA\n","O: BASKETBALL\n","O: -\n","O: FRIDAY\n","O: 'S\n","O: RESULTS\n","O: .\n","****************************************************************************************************\n","NEW YORK 1996-12-07\n","B-LOC: NEW\n","I-ORG: YORK\n","O: 1996-12-07\n","****************************************************************************************************\n","Results of National Basketball\n","O: Results\n","O: of\n","O: National\n","O: Basketball\n","****************************************************************************************************\n","Association games on Friday ( home team in CAPS ) :\n","B-ORG: Association\n","O: games\n","O: on\n","O: Friday\n","O: (\n","O: home\n","O: team\n","O: in\n","O: CAPS\n","O: )\n","O: :\n","****************************************************************************************************\n","New Jersey 110 BOSTON 108 ( OT )\n","B-ORG: New\n","I-ORG: Jersey\n","O: 110\n","B-ORG: BOSTON\n","O: 108\n","O: (\n","O: OT\n","O: )\n","****************************************************************************************************\n","DETROIT 93 Cleveland 81\n","B-ORG: DETROIT\n","I-ORG: 93\n","I-ORG: Cleveland\n","O: 81\n","****************************************************************************************************\n","New York 103 MIAMI 85\n","B-ORG: New\n","I-ORG: York\n","I-ORG: 103\n","I-ORG: MIAMI\n","O: 85\n","****************************************************************************************************\n","Phoenix 101 SACRAMENTO 95\n","O: Phoenix\n","O: 101\n","O: SACRAMENTO\n","O: 95\n","****************************************************************************************************\n","Vancouver 105 SAN ANTONIO 89\n","B-ORG: Vancouver\n","O: 105\n","B-LOC: SAN\n","I-LOC: ANTONIO\n","O: 89\n","****************************************************************************************************\n","UTAH 106 Minnesota 95\n","B-ORG: UTAH\n","O: 106\n","B-LOC: Minnesota\n","O: 95\n","****************************************************************************************************\n","PORTLAND 97 Charlotte 93\n","B-LOC: PORTLAND\n","O: 97\n","B-ORG: Charlotte\n","O: 93\n","****************************************************************************************************\n","Indiana 86 GOLDEN STATE 71\n","B-ORG: Indiana\n","O: 86\n","B-ORG: GOLDEN\n","O: STATE\n","O: 71\n","****************************************************************************************************\n","LA LAKERS 92 Orlando 81\n","B-ORG: LA\n","I-ORG: LAKERS\n","O: 92\n","B-PER: Orlando\n","O: 81\n","****************************************************************************************************\n","NHL ICE HOCKEY - STANDINGS AFTER FRIDAY 'S GAMES .\n","O: NHL\n","O: ICE\n","O: HOCKEY\n","O: -\n","O: STANDINGS\n","O: AFTER\n","O: FRIDAY\n","O: 'S\n","O: GAMES\n","O: .\n","****************************************************************************************************\n","NEW YORK 1996-12-07\n","B-LOC: NEW\n","I-ORG: YORK\n","O: 1996-12-07\n","****************************************************************************************************\n","Standings of National Hockey\n","O: Standings\n","O: of\n","B-ORG: National\n","O: Hockey\n","****************************************************************************************************\n","League teams after games played on Friday ( tabulate under won ,\n","O: League\n","O: teams\n","O: after\n","O: games\n","O: played\n","O: on\n","O: Friday\n","O: (\n","O: tabulate\n","O: under\n","O: won\n","O: ,\n","****************************************************************************************************\n","lost , tied , goals for , goals against , points ) :\n","O: lost\n","O: ,\n","O: tied\n","O: ,\n","O: goals\n","O: for\n","O: ,\n","O: goals\n","O: against\n","O: ,\n","O: points\n","O: )\n","O: :\n","****************************************************************************************************\n","EASTERN CONFERENCE\n","B-PER: EASTERN\n","I-PER: CONFERENCE\n","****************************************************************************************************\n","NORTHEAST DIVISION\n","O: NORTHEAST\n","O: DIVISION\n","****************************************************************************************************\n","W L T GF GA PTS\n","O: W\n","O: L\n","O: T\n","O: GF\n","O: GA\n","O: PTS\n","****************************************************************************************************\n","HARTFORD 12 7 6 77 76 30\n","B-ORG: HARTFORD\n","O: 12\n","O: 7\n","O: 6\n","O: 77\n","O: 76\n","O: 30\n","****************************************************************************************************\n","BUFFALO 13 12 2 78 77 28\n","O: BUFFALO\n","O: 13\n","O: 12\n","O: 2\n","O: 78\n","O: 77\n","O: 28\n","****************************************************************************************************\n","MONTREAL 11 14 4 99 104 26\n","B-ORG: MONTREAL\n","O: 11\n","O: 14\n","O: 4\n","O: 99\n","O: 104\n","O: 26\n","****************************************************************************************************\n","BOSTON 10 11 4 74 84 24\n","B-ORG: BOSTON\n","O: 10\n","O: 11\n","O: 4\n","O: 74\n","O: 84\n","O: 24\n","****************************************************************************************************\n","PITTSBURGH 10 13 3 86 94 23\n","B-ORG: PITTSBURGH\n","O: 10\n","O: 13\n","O: 3\n","O: 86\n","O: 94\n","O: 23\n","****************************************************************************************************\n","OTTAWA 7 12 6 64 77 20\n","B-ORG: OTTAWA\n","O: 7\n","O: 12\n","O: 6\n","O: 64\n","O: 77\n","O: 20\n","****************************************************************************************************\n","ATLANTIC DIVISION\n","B-LOC: ATLANTIC\n","I-MISC: DIVISION\n","****************************************************************************************************\n","W L T GF GA PTS\n","O: W\n","O: L\n","O: T\n","O: GF\n","O: GA\n","O: PTS\n","****************************************************************************************************\n","FLORIDA 17 4 6 83 53 40\n","B-ORG: FLORIDA\n","O: 17\n","O: 4\n","O: 6\n","O: 83\n","O: 53\n","O: 40\n","****************************************************************************************************\n","PHILADELPHIA 15 12 2 81 78 32\n","B-ORG: PHILADELPHIA\n","O: 15\n","O: 12\n","O: 2\n","O: 81\n","O: 78\n","O: 32\n","****************************************************************************************************\n","NEW JERSEY 14 10 1 61 61 29\n","B-ORG: NEW\n","I-ORG: JERSEY\n","O: 14\n","O: 10\n","O: 1\n","O: 61\n","O: 61\n","O: 29\n","****************************************************************************************************\n","WASHINGTON 13 13 1 72 71 27\n","B-ORG: WASHINGTON\n","O: 13\n","O: 13\n","O: 1\n","O: 72\n","O: 71\n","O: 27\n","****************************************************************************************************\n","NY RANGERS 11 13 5 97 86 27\n","B-ORG: NY\n","B-ORG: RANGERS\n","O: 11\n","O: 13\n","O: 5\n","O: 97\n","O: 86\n","O: 27\n","****************************************************************************************************\n","NY ISLANDERS 7 11 8 65 72 22\n","B-ORG: NY\n","I-ORG: ISLANDERS\n","O: 7\n","O: 11\n","O: 8\n","O: 65\n","O: 72\n","O: 22\n","****************************************************************************************************\n","TAMPA BAY 8 15 2 69 81 18\n","B-ORG: TAMPA\n","I-ORG: BAY\n","O: 8\n","O: 15\n","O: 2\n","O: 69\n","O: 81\n","O: 18\n","****************************************************************************************************\n","WESTERN CONFERENCE\n","B-MISC: WESTERN\n","O: CONFERENCE\n","****************************************************************************************************\n","CENTRAL DIVISION\n","B-MISC: CENTRAL\n","I-MISC: DIVISION\n","****************************************************************************************************\n","W L T GF GA PTS\n","O: W\n","O: L\n","O: T\n","O: GF\n","O: GA\n","O: PTS\n","****************************************************************************************************\n","DETROIT 15 9 4 81 53 34\n","B-ORG: DETROIT\n","O: 15\n","O: 9\n","O: 4\n","O: 81\n","O: 53\n","O: 34\n","****************************************************************************************************\n","DALLAS 16 10 1 77 66 33\n","B-ORG: DALLAS\n","O: 16\n","O: 10\n","O: 1\n","O: 77\n","O: 66\n","O: 33\n","****************************************************************************************************\n","ST LOUIS 14 14 0 82 84 28\n","B-ORG: ST\n","I-ORG: LOUIS\n","O: 14\n","O: 14\n","O: 0\n","O: 82\n","O: 84\n","O: 28\n","****************************************************************************************************\n","CHICAGO 12 13 3 72 70 27\n","B-ORG: CHICAGO\n","O: 12\n","O: 13\n","O: 3\n","O: 72\n","O: 70\n","O: 27\n","****************************************************************************************************\n","TORONTO 11 16 0 81 95 22\n","B-ORG: TORONTO\n","O: 11\n","O: 16\n","O: 0\n","O: 81\n","O: 95\n","O: 22\n","****************************************************************************************************\n","PHOENIX 9 13 4 61 74 22\n","B-ORG: PHOENIX\n","O: 9\n","O: 13\n","O: 4\n","O: 61\n","O: 74\n","O: 22\n","****************************************************************************************************\n","PACIFIC DIVISION\n","B-MISC: PACIFIC\n","I-MISC: DIVISION\n","****************************************************************************************************\n","W L T GF GA PTS\n","O: W\n","O: L\n","O: T\n","O: GF\n","O: GA\n","O: PTS\n","****************************************************************************************************\n","COLORADO 17 7 4 100 60 38\n","B-ORG: COLORADO\n","I-ORG: 17\n","O: 7\n","O: 4\n","O: 100\n","O: 60\n","O: 38\n","****************************************************************************************************\n","VANCOUVER 14 11 1 84 83 29\n","B-ORG: VANCOUVER\n","O: 14\n","O: 11\n","O: 1\n","O: 84\n","O: 83\n","O: 29\n","****************************************************************************************************\n","EDMONTON 14 14 1 99 90 29\n","B-ORG: EDMONTON\n","O: 14\n","O: 14\n","O: 1\n","O: 99\n","O: 90\n","O: 29\n","****************************************************************************************************\n","LOS ANGELES 11 13 3 72 83 25\n","B-ORG: LOS\n","I-ORG: ANGELES\n","O: 11\n","O: 13\n","O: 3\n","O: 72\n","O: 83\n","O: 25\n","****************************************************************************************************\n","SAN JOSE 10 13 4 69 87 24\n","B-ORG: SAN\n","I-ORG: JOSE\n","O: 10\n","O: 13\n","O: 4\n","O: 69\n","O: 87\n","O: 24\n","****************************************************************************************************\n","ANAHEIM 9 14 5 74 87 23\n","B-ORG: ANAHEIM\n","O: 9\n","O: 14\n","O: 5\n","O: 74\n","O: 87\n","O: 23\n","****************************************************************************************************\n","CALGARY 10 16 2 65 77 22\n","B-ORG: CALGARY\n","O: 10\n","O: 16\n","O: 2\n","O: 65\n","O: 77\n","O: 22\n","****************************************************************************************************\n","SATURDAY , DECEMBER 7 SCHEDULE\n","O: SATURDAY\n","O: ,\n","O: DECEMBER\n","O: 7\n","O: SCHEDULE\n","****************************************************************************************************\n","PHOENIX AT NEW JERSEY\n","O: PHOENIX\n","O: AT\n","B-LOC: NEW\n","I-MISC: JERSEY\n","****************************************************************************************************\n","CALGARY AT BOSTON\n","O: CALGARY\n","O: AT\n","B-LOC: BOSTON\n","****************************************************************************************************\n","BUFFALO AT HARTFORD\n","O: BUFFALO\n","O: AT\n","O: HARTFORD\n","****************************************************************************************************\n","WASHINGTON AT NY ISLANDERS\n","B-LOC: WASHINGTON\n","O: AT\n","B-MISC: NY\n","I-MISC: ISLANDERS\n","****************************************************************************************************\n","CHICAGO AT MONTREAL\n","B-ORG: CHICAGO\n","O: AT\n","B-LOC: MONTREAL\n","****************************************************************************************************\n","NY RANGERS AT TORONTO\n","O: NY\n","B-ORG: RANGERS\n","O: AT\n","B-LOC: TORONTO\n","****************************************************************************************************\n","ANAHEIM AT PITTSBURGH\n","O: ANAHEIM\n","O: AT\n","B-LOC: PITTSBURGH\n","****************************************************************************************************\n","COLORADO AT LOS ANGELES\n","B-ORG: COLORADO\n","O: AT\n","B-LOC: LOS\n","I-LOC: ANGELES\n","****************************************************************************************************\n","TAMPA BAY AT SAN JOSE\n","O: TAMPA\n","B-ORG: BAY\n","O: AT\n","B-LOC: SAN\n","I-LOC: JOSE\n","****************************************************************************************************\n","OTTAWA AT VANCOUVER\n","B-LOC: OTTAWA\n","O: AT\n","B-LOC: VANCOUVER\n","****************************************************************************************************\n","NHL ICE HOCKEY - FRIDAY 'S RESULTS .\n","O: NHL\n","O: ICE\n","O: HOCKEY\n","O: -\n","O: FRIDAY\n","O: 'S\n","O: RESULTS\n","O: .\n","****************************************************************************************************\n","NEW YORK 1996-12-07\n","B-LOC: NEW\n","I-ORG: YORK\n","O: 1996-12-07\n","****************************************************************************************************\n","Results of National Hockey\n","O: Results\n","O: of\n","B-ORG: National\n","O: Hockey\n","****************************************************************************************************\n","League games on Friday ( home team in CAPS ) :\n","O: League\n","I-MISC: games\n","O: on\n","O: Friday\n","O: (\n","O: home\n","O: team\n","O: in\n","O: CAPS\n","O: )\n","O: :\n","****************************************************************************************************\n","NY RANGERS 6 Toronto 5\n","B-ORG: NY\n","I-ORG: RANGERS\n","O: 6\n","B-ORG: Toronto\n","O: 5\n","****************************************************************************************************\n","BUFFALO 1 Anaheim 1 ( OT )\n","B-ORG: BUFFALO\n","O: 1\n","B-ORG: Anaheim\n","O: 1\n","O: (\n","O: OT\n","O: )\n","****************************************************************************************************\n","Pittsburgh 5 WASHINGTON 3\n","B-ORG: Pittsburgh\n","O: 5\n","B-ORG: WASHINGTON\n","O: 3\n","****************************************************************************************************\n","Montreal 3 CHICAGO 1\n","B-ORG: Montreal\n","O: 3\n","B-ORG: CHICAGO\n","O: 1\n","****************************************************************************************************\n","Philadelphia 6 DALLAS 3\n","B-ORG: Philadelphia\n","O: 6\n","B-ORG: DALLAS\n","O: 3\n","****************************************************************************************************\n","St Louis 4 COLORADO 3\n","B-ORG: St\n","I-ORG: Louis\n","O: 4\n","B-ORG: COLORADO\n","O: 3\n","****************************************************************************************************\n","EDMONTON 5 Ottawa 2\n","B-ORG: EDMONTON\n","O: 5\n","B-ORG: Ottawa\n","O: 2\n","****************************************************************************************************\n","NHL ICE HOCKEY - CANUCKS RW BURE SUSPENDED FOR ONE GAME .\n","O: NHL\n","O: ICE\n","O: HOCKEY\n","O: -\n","O: CANUCKS\n","B-PER: RW\n","I-PER: BURE\n","O: SUSPENDED\n","O: FOR\n","O: ONE\n","O: GAME\n","O: .\n","****************************************************************************************************\n","NEW YORK 1996-12-06\n","B-LOC: NEW\n","I-ORG: YORK\n","O: 1996-12-06\n","****************************************************************************************************\n","Vancouver Canucks star right wing Pavel Bure was suspended for one game by the National Hockey League and fined $ 1,000 Friday for his hit on Buffalo Sabres defenceman Garry Galley on Wednesday .\n","B-ORG: Vancouver\n","O: Canucks\n","O: star\n","O: right\n","O: wing\n","B-PER: Pavel\n","I-PER: Bure\n","O: was\n","O: suspended\n","O: for\n","O: one\n","O: game\n","O: by\n","O: the\n","B-ORG: National\n","I-ORG: Hockey\n","O: League\n","O: and\n","O: fined\n","O: $\n","O: 1,000\n","O: Friday\n","O: for\n","O: his\n","O: hit\n","O: on\n","O: Buffalo\n","O: Sabres\n","O: defenceman\n","B-PER: Garry\n","I-PER: Galley\n","O: on\n","O: Wednesday\n","O: .\n","****************************************************************************************************\n","Bure received a double-minor penalty for high-sticking with 2:22 left in the first period of Wednesday 's 7-6 overtime win by Vancouver after colliding with Galley in Buffalo zone .\n","O: Bure\n","O: received\n","O: a\n","O: double-minor\n","O: penalty\n","O: for\n","O: high-sticking\n","O: with\n","O: 2:22\n","O: left\n","O: in\n","O: the\n","O: first\n","O: period\n","O: of\n","O: Wednesday\n","O: 's\n","O: 7-6\n","O: overtime\n","O: win\n","O: by\n","B-LOC: Vancouver\n","O: after\n","O: colliding\n","O: with\n","O: Galley\n","O: in\n","B-PER: Buffalo\n","I-PER: zone\n","O: .\n","****************************************************************************************************\n","Galley suffered a concussion and did not return to the game .\n","O: Galley\n","O: suffered\n","O: a\n","O: concussion\n","O: and\n","O: did\n","O: not\n","O: return\n","O: to\n","O: the\n","O: game\n","O: .\n","****************************************************************************************************\n","\" Mr Bure left his feet to deliver a forearm blow to Mr Galley as he was about to be checked legally by his opponent , \" said NHL discipline chief Brian Burke in handing out the suspension .\n","O: \"\n","O: Mr\n","O: Bure\n","O: left\n","O: his\n","O: feet\n","O: to\n","O: deliver\n","O: a\n","O: forearm\n","O: blow\n","O: to\n","O: Mr\n","O: Galley\n","O: as\n","O: he\n","O: was\n","O: about\n","O: to\n","O: be\n","O: checked\n","O: legally\n","O: by\n","O: his\n","O: opponent\n","O: ,\n","O: \"\n","O: said\n","B-PER: NHL\n","O: discipline\n","O: chief\n","B-PER: Brian\n","O: Burke\n","O: in\n","O: handing\n","O: out\n","O: the\n","O: suspension\n","O: .\n","****************************************************************************************************\n","\" Although it is clear from the videotape that Mr Bure 's actions were a reaction to the impending hit and there was no intent to injure his opponent , there can be no excuse for this type of conduct , \" Burke said .\n","O: \"\n","O: Although\n","O: it\n","O: is\n","O: clear\n","O: from\n","O: the\n","O: videotape\n","O: that\n","O: Mr\n","O: Bure\n","O: 's\n","O: actions\n","O: were\n","O: a\n","O: reaction\n","O: to\n","O: the\n","O: impending\n","O: hit\n","O: and\n","O: there\n","O: was\n","O: no\n","O: intent\n","O: to\n","O: injure\n","O: his\n","O: opponent\n","O: ,\n","O: there\n","O: can\n","O: be\n","O: no\n","O: excuse\n","O: for\n","O: this\n","O: type\n","O: of\n","O: conduct\n","O: ,\n","O: \"\n","B-PER: Burke\n","O: said\n","O: .\n","****************************************************************************************************\n","Bure , who is struggling with only nine goals and 12 assists in 26 games , will miss Saturday 's home game against Ottawa .\n","O: Bure\n","O: ,\n","O: who\n","O: is\n","O: struggling\n","O: with\n","O: only\n","O: nine\n","O: goals\n","O: and\n","O: 12\n","O: assists\n","O: in\n","O: 26\n","O: games\n","O: ,\n","O: will\n","B-ORG: miss\n","O: Saturday\n","O: 's\n","O: home\n","O: game\n","O: against\n","B-LOC: Ottawa\n","O: .\n","****************************************************************************************************\n","BOXING - SCHULZ DEFEATS RIBALTA IN IBF HEAVYWEIGHT FIGHT .\n","O: BOXING\n","O: -\n","O: SCHULZ\n","O: DEFEATS\n","O: RIBALTA\n","O: IN\n","B-PER: IBF\n","I-PER: HEAVYWEIGHT\n","O: FIGHT\n","O: .\n","****************************************************************************************************\n","VIENNA 1996-12-07\n","B-LOC: VIENNA\n","O: 1996-12-07\n","****************************************************************************************************\n","German Axel Schulz outpointed Cuba 's Jose Ribalta in their International Boxing Federation non-title 10-round heavyweight fight on Saturday .\n","B-MISC: German\n","O: Axel\n","O: Schulz\n","O: outpointed\n","B-LOC: Cuba\n","O: 's\n","B-PER: Jose\n","I-PER: Ribalta\n","O: in\n","O: their\n","O: International\n","O: Boxing\n","O: Federation\n","O: non-title\n","O: 10-round\n","I-PER: heavyweight\n","O: fight\n","O: on\n","O: Saturday\n","O: .\n","****************************************************************************************************\n","SOCCER - SPANISH FIRST DIVISION SUMMARY .\n","O: SOCCER\n","O: -\n","B-MISC: SPANISH\n","O: FIRST\n","O: DIVISION\n","O: SUMMARY\n","O: .\n","****************************************************************************************************\n","MADRID 1996-12-07\n","B-ORG: MADRID\n","O: 1996-12-07\n","****************************************************************************************************\n","Summary of Saturday 's Spanish first division match :\n","O: Summary\n","O: of\n","O: Saturday\n","O: 's\n","B-MISC: Spanish\n","O: first\n","O: division\n","O: match\n","O: :\n","****************************************************************************************************\n","Real Madrid 2 ( Davor Suker 24 , Predrag Mijatovic 48 ) Barcelona 0 .\n","B-ORG: Real\n","I-ORG: Madrid\n","O: 2\n","O: (\n","B-PER: Davor\n","I-PER: Suker\n","O: 24\n","O: ,\n","O: Predrag\n","O: Mijatovic\n","O: 48\n","O: )\n","B-ORG: Barcelona\n","O: 0\n","O: .\n","****************************************************************************************************\n","Halftime 1-0 .\n","O: Halftime\n","O: 1-0\n","O: .\n","****************************************************************************************************\n","Attendance 106,000 .\n","O: Attendance\n","O: 106,000\n","O: .\n","****************************************************************************************************\n","SOCCER - BALKAN STRIKE FORCE WIN OLD FIRM GAME FOR REAL .\n","O: SOCCER\n","O: -\n","B-ORG: BALKAN\n","O: STRIKE\n","O: FORCE\n","O: WIN\n","O: OLD\n","O: FIRM\n","O: GAME\n","O: FOR\n","O: REAL\n","O: .\n","****************************************************************************************************\n","MADRID 1996-12-07\n","B-ORG: MADRID\n","O: 1996-12-07\n","****************************************************************************************************\n","Real Madrid 's Balkan strike force of Davor Suker and Predrag Mijatovic shot their side to a 2-0 win over Barcelona in Spain 's old firm game on Saturday .\n","B-ORG: Real\n","I-ORG: Madrid\n","O: 's\n","B-LOC: Balkan\n","O: strike\n","O: force\n","O: of\n","B-PER: Davor\n","I-ORG: Suker\n","O: and\n","B-PER: Predrag\n","I-PER: Mijatovic\n","O: shot\n","O: their\n","O: side\n","O: to\n","O: a\n","O: 2-0\n","O: win\n","O: over\n","B-LOC: Barcelona\n","O: in\n","B-LOC: Spain\n","O: 's\n","O: old\n","O: firm\n","O: game\n","O: on\n","O: Saturday\n","O: .\n","****************************************************************************************************\n","The result leaves Real on 38 points after 16 games , four ahead of Barcelona .\n","O: The\n","O: result\n","O: leaves\n","O: Real\n","O: on\n","O: 38\n","O: points\n","O: after\n","O: 16\n","O: games\n","O: ,\n","O: four\n","O: ahead\n","O: of\n","B-LOC: Barcelona\n","O: .\n","****************************************************************************************************\n","With just one league match scheduled before the New Year break , Real are also assured of spending Christmas ahead of their arch-rivals .\n","O: With\n","O: just\n","O: one\n","O: league\n","O: match\n","O: scheduled\n","O: before\n","O: the\n","O: New\n","O: Year\n","O: break\n","O: ,\n","O: Real\n","O: are\n","O: also\n","O: assured\n","O: of\n","O: spending\n","O: Christmas\n","O: ahead\n","O: of\n","O: their\n","B-ORG: arch-rivals\n","O: .\n","****************************************************************************************************\n","A mix-up in the Barcelona defence let Croatian international Suker in midway through the first half , and Montenegrin striker Mijatovic made it 2-0 after fine work by Clarence Seedorf just after the break .\n","O: A\n","O: mix-up\n","O: in\n","O: the\n","B-ORG: Barcelona\n","O: defence\n","O: let\n","B-MISC: Croatian\n","I-ORG: international\n","O: Suker\n","O: in\n","O: midway\n","O: through\n","O: the\n","O: first\n","O: half\n","O: ,\n","O: and\n","O: Montenegrin\n","O: striker\n","O: Mijatovic\n","O: made\n","O: it\n","O: 2-0\n","O: after\n","O: fine\n","O: work\n","O: by\n","B-PER: Clarence\n","O: Seedorf\n","O: just\n","O: after\n","O: the\n","O: break\n","O: .\n","****************************************************************************************************\n","Barcelona fought back strongly but were twice denied by the woodwork on an unusually quiet night for Brazilian striker Ronaldo .\n","B-ORG: Barcelona\n","O: fought\n","O: back\n","O: strongly\n","O: but\n","O: were\n","O: twice\n","O: denied\n","O: by\n","O: the\n","O: woodwork\n","O: on\n","O: an\n","O: unusually\n","O: quiet\n","O: night\n","O: for\n","B-MISC: Brazilian\n","O: striker\n","B-PER: Ronaldo\n","O: .\n","****************************************************************************************************\n","SOCCER - PSV HIT VOLENDAM FOR SIX .\n","O: SOCCER\n","O: -\n","B-ORG: PSV\n","O: HIT\n","B-ORG: VOLENDAM\n","O: FOR\n","O: SIX\n","O: .\n","****************************************************************************************************\n","AMSTERDAM 1996-12-07\n","B-LOC: AMSTERDAM\n","O: 1996-12-07\n","****************************************************************************************************\n","Brazilian striker Marcelo and Yugoslav midfielder Zeljko Petrovic each scored twice as Dutch first division leaders PSV Eindhoven romped to a 6-0 win over Volendam on Saturday .\n","B-MISC: Brazilian\n","O: striker\n","B-PER: Marcelo\n","O: and\n","B-PER: Yugoslav\n","O: midfielder\n","B-PER: Zeljko\n","I-PER: Petrovic\n","O: each\n","O: scored\n","O: twice\n","O: as\n","B-MISC: Dutch\n","O: first\n","O: division\n","O: leaders\n","B-ORG: PSV\n","I-ORG: Eindhoven\n","O: romped\n","O: to\n","O: a\n","O: 6-0\n","O: win\n","O: over\n","B-LOC: Volendam\n","O: on\n","O: Saturday\n","O: .\n","****************************************************************************************************\n","Their other marksmen were Brazilian defender Vampeta and Belgian striker Luc Nilis , his 14th of the season .\n","O: Their\n","O: other\n","O: marksmen\n","O: were\n","B-MISC: Brazilian\n","O: defender\n","O: Vampeta\n","O: and\n","B-PER: Belgian\n","O: striker\n","B-PER: Luc\n","I-PER: Nilis\n","O: ,\n","O: his\n","O: 14th\n","O: of\n","O: the\n","O: season\n","O: .\n","****************************************************************************************************\n","PSV , well on the way to their 14th league title , outgunned Volendam in every department of the game .\n","B-ORG: PSV\n","O: ,\n","O: well\n","O: on\n","O: the\n","O: way\n","O: to\n","O: their\n","O: 14th\n","O: league\n","O: title\n","O: ,\n","O: outgunned\n","B-ORG: Volendam\n","O: in\n","O: every\n","B-ORG: department\n","O: of\n","O: the\n","O: game\n","O: .\n","****************************************************************************************************\n","They boast a nine-point lead over Feyenoord , who have two games in hand , and are 16 points clear of champions Ajax Amsterdam , who have played 18 matches compared to PSV 's 19 .\n","O: They\n","O: boast\n","O: a\n","O: nine-point\n","O: lead\n","O: over\n","B-ORG: Feyenoord\n","O: ,\n","O: who\n","O: have\n","O: two\n","O: games\n","O: in\n","O: hand\n","O: ,\n","O: and\n","O: are\n","O: 16\n","O: points\n","O: clear\n","O: of\n","O: champions\n","B-ORG: Ajax\n","I-ORG: Amsterdam\n","O: ,\n","O: who\n","O: have\n","O: played\n","O: 18\n","O: matches\n","O: compared\n","O: to\n","B-ORG: PSV\n","O: 's\n","O: 19\n","O: .\n","****************************************************************************************************\n","Ajax face AZ Alkmaar away on Sunday and Feyenoord , eliminated from the UEFA Cup after losing 4-2 on aggregate to Tenerife on Tuesday , travel to De Graafschap Doetinchem .\n","B-ORG: Ajax\n","O: face\n","B-ORG: AZ\n","I-ORG: Alkmaar\n","O: away\n","O: on\n","O: Sunday\n","O: and\n","O: Feyenoord\n","O: ,\n","O: eliminated\n","O: from\n","O: the\n","B-LOC: UEFA\n","I-MISC: Cup\n","O: after\n","O: losing\n","O: 4-2\n","O: on\n","O: aggregate\n","O: to\n","O: Tenerife\n","O: on\n","O: Tuesday\n","O: ,\n","O: travel\n","O: to\n","O: De\n","I-ORG: Graafschap\n","I-LOC: Doetinchem\n","O: .\n","****************************************************************************************************\n","The Doetinchem side , dubbed \" The Super Peasants \" , are one of the surprise packages of the season .\n","O: The\n","B-ORG: Doetinchem\n","O: side\n","O: ,\n","O: dubbed\n","O: \"\n","O: The\n","B-MISC: Super\n","O: Peasants\n","O: \"\n","O: ,\n","O: are\n","O: one\n","O: of\n","O: the\n","O: surprise\n","O: packages\n","O: of\n","O: the\n","O: season\n","O: .\n","****************************************************************************************************\n","They are fourth in the table .\n","O: They\n","O: are\n","O: fourth\n","O: in\n","O: the\n","O: table\n","O: .\n","****************************************************************************************************\n","SOCCER - SPANISH FIRST DIVISION RESULT / STANDINGS .\n","O: SOCCER\n","O: -\n","B-MISC: SPANISH\n","O: FIRST\n","O: DIVISION\n","O: RESULT\n","O: /\n","O: STANDINGS\n","O: .\n","****************************************************************************************************\n","MADRID 1996-12-07\n","B-ORG: MADRID\n","O: 1996-12-07\n","****************************************************************************************************\n","Result of Saturday 's only Spanish\n","O: Result\n","O: of\n","O: Saturday\n","O: 's\n","O: only\n","B-MISC: Spanish\n","****************************************************************************************************\n","first division match :\n","O: first\n","O: division\n","O: match\n","O: :\n","****************************************************************************************************\n","Real Madrid 2 Barcelona 0\n","B-ORG: Real\n","I-ORG: Madrid\n","O: 2\n","B-ORG: Barcelona\n","O: 0\n","****************************************************************************************************\n","Standings ( tabulate under games played , won , drawn , lost ,\n","O: Standings\n","O: (\n","O: tabulate\n","O: under\n","O: games\n","O: played\n","O: ,\n","O: won\n","O: ,\n","O: drawn\n","O: ,\n","O: lost\n","O: ,\n","****************************************************************************************************\n","goals for , against , points ) :\n","O: goals\n","O: for\n","O: ,\n","O: against\n","O: ,\n","O: points\n","O: )\n","O: :\n","****************************************************************************************************\n","Real Madrid 16 11 5 0 32 12 38\n","B-ORG: Real\n","I-ORG: Madrid\n","O: 16\n","O: 11\n","O: 5\n","O: 0\n","O: 32\n","O: 12\n","O: 38\n","****************************************************************************************************\n","Barcelona 16 10 4 2 46 21 34\n","B-ORG: Barcelona\n","O: 16\n","O: 10\n","O: 4\n","O: 2\n","O: 46\n","O: 21\n","O: 34\n","****************************************************************************************************\n","Deportivo Coruna 15 9 6 0 23 7 33\n","B-ORG: Deportivo\n","I-ORG: Coruna\n","O: 15\n","O: 9\n","O: 6\n","O: 0\n","O: 23\n","O: 7\n","O: 33\n","****************************************************************************************************\n","Real Betis 15 8 5 2 28 13 29\n","B-ORG: Real\n","I-ORG: Betis\n","O: 15\n","O: 8\n","O: 5\n","O: 2\n","O: 28\n","O: 13\n","O: 29\n","****************************************************************************************************\n","Atletico Madrid 15 8 3 4 26 17 27\n","B-ORG: Atletico\n","I-ORG: Madrid\n","O: 15\n","O: 8\n","O: 3\n","O: 4\n","O: 26\n","O: 17\n","O: 27\n","****************************************************************************************************\n","Athletic Bilbao 15 7 4 4 28 22 25\n","B-ORG: Athletic\n","I-ORG: Bilbao\n","O: 15\n","O: 7\n","O: 4\n","O: 4\n","O: 28\n","O: 22\n","O: 25\n","****************************************************************************************************\n","Real Sociedad 15 7 3 5 20 18 24\n","B-ORG: Real\n","I-ORG: Sociedad\n","O: 15\n","O: 7\n","O: 3\n","O: 5\n","O: 20\n","O: 18\n","O: 24\n","****************************************************************************************************\n","Valladolid 15 7 3 5 19 18 24\n","B-ORG: Valladolid\n","O: 15\n","O: 7\n","O: 3\n","O: 5\n","O: 19\n","O: 18\n","O: 24\n","****************************************************************************************************\n","Racing Santander 15 5 7 3 15 15 22\n","O: Racing\n","O: Santander\n","O: 15\n","O: 5\n","O: 7\n","O: 3\n","O: 15\n","O: 15\n","O: 22\n","****************************************************************************************************\n","Rayo Vallecano 15 5 5 5 21 19 20\n","B-ORG: Rayo\n","I-ORG: Vallecano\n","O: 15\n","O: 5\n","O: 5\n","O: 5\n","O: 21\n","O: 19\n","O: 20\n","****************************************************************************************************\n","Valencia 15 6 2 7 23 22 20\n","B-ORG: Valencia\n","O: 15\n","O: 6\n","O: 2\n","O: 7\n","O: 23\n","O: 22\n","O: 20\n","****************************************************************************************************\n","Celta Vigo 15 5 5 5 17 17 20\n","B-ORG: Celta\n","I-ORG: Vigo\n","O: 15\n","O: 5\n","O: 5\n","O: 5\n","O: 17\n","O: 17\n","O: 20\n","****************************************************************************************************\n","Tenerife 15 5 4 6 23 17 19\n","B-ORG: Tenerife\n","O: 15\n","O: 5\n","O: 4\n","O: 6\n","O: 23\n","O: 17\n","O: 19\n","****************************************************************************************************\n","Espanyol 15 4 4 7 17 20 16\n","B-ORG: Espanyol\n","O: 15\n","O: 4\n","O: 4\n","O: 7\n","O: 17\n","O: 20\n","O: 16\n","****************************************************************************************************\n","Oviedo 15 4 4 7 17 21 16\n","B-ORG: Oviedo\n","O: 15\n","O: 4\n","O: 4\n","O: 7\n","O: 17\n","O: 21\n","O: 16\n","****************************************************************************************************\n","Sporting Gijon 15 4 4 7 15 22 16\n","B-ORG: Sporting\n","I-ORG: Gijon\n","O: 15\n","O: 4\n","O: 4\n","O: 7\n","O: 15\n","O: 22\n","O: 16\n","****************************************************************************************************\n","Logrones 15 4 3 8 11 33 15\n","B-ORG: Logrones\n","O: 15\n","O: 4\n","O: 3\n","O: 8\n","O: 11\n","O: 33\n","O: 15\n","****************************************************************************************************\n","Zaragoza 15 2 8 5 18 23 14\n","B-ORG: Zaragoza\n","O: 15\n","O: 2\n","O: 8\n","O: 5\n","O: 18\n","O: 23\n","O: 14\n","****************************************************************************************************\n","Sevilla 15 4 2 9 13 20 14\n","B-ORG: Sevilla\n","O: 15\n","O: 4\n","O: 2\n","O: 9\n","O: 13\n","O: 20\n","O: 14\n","****************************************************************************************************\n","Compostela 15 3 4 8 13 28 13\n","B-ORG: Compostela\n","O: 15\n","O: 3\n","O: 4\n","O: 8\n","O: 13\n","O: 28\n","O: 13\n","****************************************************************************************************\n","Hercules 15 2 2 11 11 29 8\n","B-ORG: Hercules\n","O: 15\n","O: 2\n","O: 2\n","O: 11\n","O: 11\n","O: 29\n","O: 8\n","****************************************************************************************************\n","Extremadura 15 1 3 11 8 30 6\n","B-ORG: Extremadura\n","O: 15\n","O: 1\n","O: 3\n","O: 11\n","O: 8\n","O: 30\n","O: 6\n","****************************************************************************************************\n","SOCCER - ENGLISHMAN CHARLTON IS MADE AN HONORARY IRISHMAN .\n","O: SOCCER\n","O: -\n","B-PER: ENGLISHMAN\n","B-PER: CHARLTON\n","O: IS\n","O: MADE\n","O: AN\n","O: HONORARY\n","O: IRISHMAN\n","O: .\n","****************************************************************************************************\n","DUBLIN 1996-12-07\n","B-LOC: DUBLIN\n","O: 1996-12-07\n","****************************************************************************************************\n","Jack Charlton 's relationship with the people of Ireland was cemented on Saturday when the Englishman was officially declared one of their own .\n","B-PER: Jack\n","I-PER: Charlton\n","O: 's\n","O: relationship\n","O: with\n","O: the\n","O: people\n","O: of\n","B-LOC: Ireland\n","O: was\n","O: cemented\n","O: on\n","O: Saturday\n","O: when\n","O: the\n","O: Englishman\n","O: was\n","O: officially\n","O: declared\n","O: one\n","O: of\n","O: their\n","O: own\n","O: .\n","****************************************************************************************************\n","Charlton , 61 , and his wife , Peggy , became citizens of Ireland when they formally received Irish passports from deputy Prime Minister Dick Spring who said the honour had been made in recognition of Charlton 's achievements as the national soccer manager .\n","B-ORG: Charlton\n","O: ,\n","O: 61\n","O: ,\n","O: and\n","O: his\n","O: wife\n","O: ,\n","O: Peggy\n","O: ,\n","O: became\n","O: citizens\n","O: of\n","B-LOC: Ireland\n","O: when\n","O: they\n","O: formally\n","O: received\n","B-MISC: Irish\n","O: passports\n","O: from\n","O: deputy\n","O: Prime\n","O: Minister\n","B-PER: Dick\n","I-PER: Spring\n","O: who\n","O: said\n","O: the\n","O: honour\n","O: had\n","O: been\n","O: made\n","O: in\n","O: recognition\n","O: of\n","B-LOC: Charlton\n","O: 's\n","O: achievements\n","O: as\n","O: the\n","O: national\n","O: soccer\n","O: manager\n","O: .\n","****************************************************************************************************\n","\" The years I spent as manager of the Republic of Ireland were the best years of my life .\n","O: \"\n","O: The\n","O: years\n","O: I\n","O: spent\n","O: as\n","O: manager\n","O: of\n","O: the\n","B-ORG: Republic\n","O: of\n","B-LOC: Ireland\n","O: were\n","O: the\n","O: best\n","O: years\n","O: of\n","O: my\n","O: life\n","O: .\n","****************************************************************************************************\n","It all culminated in the fact that I now have lots of great , great friends in Ireland .\n","O: It\n","O: all\n","O: culminated\n","O: in\n","O: the\n","O: fact\n","O: that\n","O: I\n","O: now\n","O: have\n","O: lots\n","O: of\n","O: great\n","O: ,\n","O: great\n","O: friends\n","O: in\n","B-LOC: Ireland\n","O: .\n","****************************************************************************************************\n","That is why this is so emotional a night for me , \" Charlton said .\n","O: That\n","O: is\n","O: why\n","O: this\n","O: is\n","O: so\n","O: emotional\n","O: a\n","O: night\n","O: for\n","O: me\n","O: ,\n","O: \"\n","B-PER: Charlton\n","O: said\n","O: .\n","****************************************************************************************************\n","\" It was the joy that we all had over the period , that I shared with people that I grew to love , that I treasure most , \" he added .\n","O: \"\n","O: It\n","O: was\n","O: the\n","O: joy\n","O: that\n","O: we\n","O: all\n","O: had\n","O: over\n","O: the\n","O: period\n","O: ,\n","O: that\n","O: I\n","O: shared\n","O: with\n","O: people\n","O: that\n","O: I\n","O: grew\n","O: to\n","O: love\n","O: ,\n","O: that\n","O: I\n","O: treasure\n","O: most\n","O: ,\n","O: \"\n","O: he\n","O: added\n","O: .\n","****************************************************************************************************\n","Charlton managed Ireland for 93 matches , during which time they lost only 17 times in almost 10 years until he resigned in December 1995 .\n","B-ORG: Charlton\n","O: managed\n","B-LOC: Ireland\n","O: for\n","O: 93\n","O: matches\n","O: ,\n","O: during\n","O: which\n","O: time\n","O: they\n","O: lost\n","O: only\n","O: 17\n","O: times\n","O: in\n","O: almost\n","O: 10\n","O: years\n","O: until\n","O: he\n","O: resigned\n","O: in\n","O: December\n","O: 1995\n","O: .\n","****************************************************************************************************\n","He guided Ireland to two successive World Cup finals tournaments and to the 1988 European championship finals in Germany , after the Irish beat a well-fancied England team 1-0 in their group qualifier .\n","O: He\n","O: guided\n","B-LOC: Ireland\n","O: to\n","O: two\n","O: successive\n","B-MISC: World\n","I-MISC: Cup\n","O: finals\n","O: tournaments\n","O: and\n","O: to\n","O: the\n","O: 1988\n","B-MISC: European\n","O: championship\n","O: finals\n","O: in\n","B-LOC: Germany\n","O: ,\n","O: after\n","O: the\n","B-ORG: Irish\n","O: beat\n","O: a\n","O: well-fancied\n","B-LOC: England\n","O: team\n","O: 1-0\n","O: in\n","O: their\n","O: group\n","O: qualifier\n","O: .\n","****************************************************************************************************\n","The lanky former Leeds United defender did not make his England debut until the age of 30 but eventually won 35 caps and was a key member of the 1966 World Cup winning team with his younger brother , Bobby .\n","O: The\n","O: lanky\n","O: former\n","B-ORG: Leeds\n","I-ORG: United\n","O: defender\n","O: did\n","O: not\n","O: make\n","O: his\n","B-LOC: England\n","O: debut\n","O: until\n","O: the\n","O: age\n","O: of\n","O: 30\n","O: but\n","O: eventually\n","O: won\n","O: 35\n","O: caps\n","O: and\n","O: was\n","O: a\n","O: key\n","O: member\n","O: of\n","O: the\n","O: 1966\n","B-MISC: World\n","I-MISC: Cup\n","O: winning\n","O: team\n","O: with\n","O: his\n","O: younger\n","O: brother\n","O: ,\n","B-PER: Bobby\n","O: .\n"]}]},{"cell_type":"markdown","metadata":{"id":"ja28tqMLKeid"},"source":["–ò—Å–ø–æ–ª—å–∑—É—è –±–∏–±–ª–∏–æ—Ç–µ–∫—É https://github.com/chakki-works/seqeval, —Ä–∞—Å—Å—á–∏—Ç–∞–π—Ç–µ –º–µ—Ç—Ä–∏–∫–∏.\n","\n","–†–µ–∑—É–ª—å—Ç–∞—Ç—ã SotA-—Ä–µ—à–µ–Ω–∏–π –≤—ã –Ω–∞–π–¥–µ—Ç–µ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ https://paperswithcode.com/sota/named-entity-recognition-ner-on-conll-2003."]},{"cell_type":"code","source":["!pip install seqeval"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H_fWPLymKanh","executionInfo":{"status":"ok","timestamp":1725975711797,"user_tz":-180,"elapsed":7157,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}},"outputId":"45515a02-236d-49a7-8b72-1a7141ed8fc4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.26.4)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.3.2)\n","Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.13.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.5.0)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=7b6982665f5f86e9a349186c4dca4a1d1c47dbbb430c39cef6bf33944b6812df\n","  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n","Successfully built seqeval\n","Installing collected packages: seqeval\n","Successfully installed seqeval-1.2.2\n"]}]},{"cell_type":"code","source":["from seqeval.metrics import classification_report\n","\n","# –¥–∞–Ω–Ω—ã–µ –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ test_data\n","true_labels = [sample['labels'] for sample in test_data]\n","# –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ –º–æ–¥–µ–ª—å—é\n","predicted_labels = predictions\n","\n","# YOUR_CODE_HERE\n","report = classification_report(true_labels, predicted_labels)\n","# Calculate and print the classification report\n","print(report)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q3I1GKRGKglY","executionInfo":{"status":"ok","timestamp":1725975712633,"user_tz":-180,"elapsed":846,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}},"outputId":"6b9cefc0-ae85-4ab2-f3ed-5500aff860be"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","         LOC       0.58      0.46      0.51      1668\n","        MISC       0.31      0.10      0.15       702\n","         ORG       0.27      0.22      0.24      1661\n","         PER       0.44      0.38      0.41      1617\n","\n","   micro avg       0.42      0.32      0.36      5648\n","   macro avg       0.40      0.29      0.33      5648\n","weighted avg       0.41      0.32      0.36      5648\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"mQHI7XeIKeie"},"source":["### –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –∑–∞–¥–∞–Ω–∏–µ (–Ω–µ –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç—Å—è)"]},{"cell_type":"markdown","metadata":{"id":"vCaCvQ9SKeie"},"source":["(–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–≤—ã—Å–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏. –í–æ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –∏–¥–µ–π:\n","\n","1. –í–∑—è—Ç—å –±–æ–ª–µ–µ —Ç—è–∂–µ–ª—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏.\n","2. –ù–∞ –∑–∞–º–æ—Ä–∞–∂–∏–≤–∞—Ç—å —Å–ª–æ–π —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤.\n","3. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å MLP –ø–æ—Å–ª–µ RNN.\n","4. –£–º–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤, –¥—Ä–æ–ø–∞—É—Ç, –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä, —Å–∫–µ–¥—É–ª–µ—Ä –∏ —Ç. –¥."]},{"cell_type":"code","source":["class TokenClassificationModel_new(TokenClassificationModel):  # –ù–∞—Å–ª–µ–¥—É–µ–º –æ—Ç TokenClassificationModel\n","    def __init__(self, vocab_size: int, embedding_dim: int, hidden_size: int, n_layers: int, n_classes: int, embedding_matrix=None):\n","        super().__init__(vocab_size=vocab_size, embedding_dim=embedding_dim, hidden_size=hidden_size, n_layers=n_layers, n_classes=n_classes) # –ù–∞—Å–ª–µ–¥—É–µ–º –≤—Å—ë –∏–∑ TokenClassificationModel\n","\n","        # –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω—ã –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏, —Ç–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∏—Ö\n","        if embedding_matrix is not None:\n","            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏–∑ –ø–µ—Ä–µ–¥–∞–Ω–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã\n","            embedding_dim = embedding_matrix.shape[1]\n","            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –∏—Ö –¥–æ–æ–±—É—á–µ–Ω–∏—è (freeze=False)\n","            self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze=False)\n","        else:\n","            # –ï—Å–ª–∏ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω—ã, –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∏—Ö —Å–ª—É—á–∞–π–Ω–æ\n","            self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n","\n","        # LSTM —Å bidirectional=True\n","        self.rnn = nn.LSTM(\n","            input_size=embedding_dim,\n","            hidden_size=hidden_size,\n","            num_layers=n_layers,\n","            bidirectional=True,\n","            batch_first=True\n","        )\n","        # –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–π —Å–ª–æ–π, —Å–æ–ø–æ—Å—Ç–∞–≤–ª—è—é—â–∏–π –≤—ã—Ö–æ–¥ RNN —Å –∫–ª–∞—Å—Å–∞–º–∏\n","        self.fc = nn.Linear(hidden_size * 2, n_classes)  # –£–º–Ω–æ–∂–∞–µ–º hidden_size –Ω–∞ 2, —Ç.–∫. LSTM –¥–≤—É–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è\n","\n","        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤ –∏ —Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å\n","        self.n_classes = n_classes\n","        self.loss_fn = nn.CrossEntropyLoss(ignore_index=-100, reduction=\"none\")\n"],"metadata":{"id":"bM8g7uGBZV6E"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XJXIKyfnKeif"},"outputs":[],"source":["vocab = Vocabulary([\" \".join(example[\"tokens\"]) for example in train_data], min_count=2, lower=True)\n","enb_dim = 25\n","# Create the embedding matrix using pre-trained GloVe embeddings\n","embedding_matrix = create_embedding_matrix(vocab, w2v_model, embedding_dim=enb_dim)\n","n_classes = len(idx2label)\n","# Initialize the model with pre-trained embeddings\n","ner_model = TokenClassificationModel_new(vocab_size=len(vocab), embedding_dim=enb_dim, hidden_size=7, n_layers=3, n_classes=n_classes, embedding_matrix=embedding_matrix)"]},{"cell_type":"code","source":["ner_model.to(device)\n","print(ner_model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_T5ZeklaOWA2","executionInfo":{"status":"ok","timestamp":1725979617055,"user_tz":-180,"elapsed":393,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}},"outputId":"92afc58c-5bfb-4ee9-ceb4-12d5e9c76136"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["TokenClassificationModel_new(\n","  (embedding): Embedding(10946, 25)\n","  (rnn): LSTM(25, 7, num_layers=3, batch_first=True, bidirectional=True)\n","  (fc): Linear(in_features=14, out_features=9, bias=True)\n","  (loss_fn): CrossEntropyLoss()\n",")\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jwKo9cqSOplD"},"outputs":[],"source":["optimizer = ner_model.configure_optimizers()"]},{"cell_type":"code","source":["from tqdm import tqdm\n","\n","N_EPOCHS = 15  # Example number of epochs, adjust as needed\n","\n","for epoch in range(N_EPOCHS):\n","    ner_model.train()\n","    train_losses = []\n","    val_losses = []\n","\n","    # Training loop\n","    for i, batch in tqdm(enumerate(train_dl), total=len(train_dl)):\n","        optimizer.zero_grad()  # Clear previous gradients\n","\n","        # Forward pass and loss calculation\n","        loss = ner_model.training_step(batch)\n","        train_losses.append(loss.detach().cpu().numpy())\n","\n","        # Backpropagation\n","        loss.backward()\n","\n","        # Optimizer step\n","        optimizer.step()\n","\n","    # Validation loop\n","    ner_model.eval()  # Set model to evaluation mode\n","    with torch.no_grad():  # No gradient calculation for validation\n","        for i, batch in tqdm(enumerate(val_dl), total=len(val_dl)):\n","            loss = ner_model.validation_step(batch)\n","            val_losses.append(loss.cpu().numpy())\n","\n","    # Calculate average losses for the epoch\n","    train_loss = sum(train_losses) / len(train_losses)\n","    val_loss = sum(val_losses) / len(val_losses)\n","\n","    # Print training and validation losses for the current epoch\n","    print(f\"{epoch = }: {train_loss = }, {val_loss = }\")\n","\n","    # Save the model state after each epoch\n","    savepath = f\"ner_model_{epoch}ep.bin\"\n","    torch.save(ner_model.state_dict(), savepath)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725977062488,"user_tz":-180,"elapsed":335288,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}},"outputId":"ac194564-8d24-41ed-ef8a-78732bef9c1d","id":"C65y97B1Opl2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1405/1405 [00:22<00:00, 63.42it/s]\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 325/325 [00:01<00:00, 309.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch = 0: train_loss = 0.2585353764138612, val_loss = 0.2718985028450306\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1405/1405 [00:18<00:00, 76.94it/s]\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 325/325 [00:01<00:00, 297.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch = 1: train_loss = 0.1348484023066496, val_loss = 0.16420096250680777\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1405/1405 [00:19<00:00, 72.13it/s]\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 325/325 [00:01<00:00, 310.56it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch = 2: train_loss = 0.08676436577999826, val_loss = 0.12640230312656897\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1405/1405 [00:26<00:00, 52.69it/s]\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 325/325 [00:01<00:00, 227.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch = 3: train_loss = 0.06493717618352896, val_loss = 0.1112634113144416\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1405/1405 [00:23<00:00, 60.42it/s]\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 325/325 [00:01<00:00, 309.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch = 4: train_loss = 0.05237511997392858, val_loss = 0.10322070106004293\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1405/1405 [00:21<00:00, 66.73it/s]\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 325/325 [00:01<00:00, 201.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch = 5: train_loss = 0.044059345717757305, val_loss = 0.09876734061883045\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1405/1405 [00:20<00:00, 69.25it/s]\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 325/325 [00:01<00:00, 312.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch = 6: train_loss = 0.037375986396610154, val_loss = 0.0985960084013641\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1405/1405 [00:20<00:00, 68.27it/s]\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 325/325 [00:01<00:00, 304.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch = 7: train_loss = 0.032090138201518945, val_loss = 0.09572909480820481\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1405/1405 [00:19<00:00, 72.43it/s]\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 325/325 [00:01<00:00, 260.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch = 8: train_loss = 0.028191468545231135, val_loss = 0.09471113842553817\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1405/1405 [00:24<00:00, 58.21it/s]\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 325/325 [00:01<00:00, 166.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch = 9: train_loss = 0.024791547400970924, val_loss = 0.10429584429276964\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1405/1405 [00:18<00:00, 74.86it/s]\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 325/325 [00:01<00:00, 303.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch = 10: train_loss = 0.02181370152830431, val_loss = 0.1009459831042645\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1405/1405 [00:20<00:00, 67.94it/s]\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 325/325 [00:01<00:00, 302.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch = 11: train_loss = 0.019559568132678198, val_loss = 0.10191481541412381\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1405/1405 [00:21<00:00, 65.79it/s]\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 325/325 [00:01<00:00, 228.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch = 12: train_loss = 0.01781141842977273, val_loss = 0.10502100279733825\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1405/1405 [00:18<00:00, 76.23it/s]\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 325/325 [00:01<00:00, 310.74it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch = 13: train_loss = 0.015871861450054293, val_loss = 0.11039704307251108\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1405/1405 [00:22<00:00, 63.68it/s]\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 325/325 [00:01<00:00, 308.53it/s]"]},{"output_type":"stream","name":"stdout","text":["epoch = 14: train_loss = 0.01426209645019347, val_loss = 0.11407187999584353\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["predictions = predict(ner_model, test_dl)\n","\n","# Assuming `predictions` are your predicted tags and `test_data` has the true tags\n","true_labels = [sample['labels'] for sample in test_data]  # True labels from the dataset\n","predicted_labels = predictions  # Predicted labels from the model\n","\n","# YOUR_CODE_HERE\n","report = classification_report(true_labels, predicted_labels)\n","# Calculate and print the classification report\n","print(report)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SjtVrI93Pwa2","executionInfo":{"status":"ok","timestamp":1725977065744,"user_tz":-180,"elapsed":3289,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}},"outputId":"282b04b5-5ffe-41ec-9edf-98086ef34eea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","         LOC       0.75      0.79      0.77      1668\n","        MISC       0.64      0.58      0.61       702\n","         ORG       0.63      0.58      0.60      1661\n","         PER       0.70      0.62      0.66      1617\n","\n","   micro avg       0.69      0.65      0.67      5648\n","   macro avg       0.68      0.64      0.66      5648\n","weighted avg       0.69      0.65      0.67      5648\n","\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}
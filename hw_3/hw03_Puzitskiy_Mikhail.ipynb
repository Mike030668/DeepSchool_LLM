{"cells":[{"cell_type":"markdown","metadata":{"id":"gkOh-BfPKW10"},"source":["# Задание 3\n","\n","В этом задании мы напишем архитектуру transformer с нуля. Мы пройдемся по всем слоям трансформера - от эмбеддингов и аттеншена до FFN и финального выходного слоя. В конце также напишем различные техники сэмплирования для генерации текста!\n","\n","\n","В качестве весов мы будем использовать веса gpt2, однако уже в следующем задании попробуем обучить свой мини-трансформер с нуля!"]},{"cell_type":"markdown","metadata":{"id":"xnqvoOGqZ2oX"},"source":["# Устанавливаем зависимости"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DcuFItWyPbey","outputId":"6879dcf6-efe4-4e5e-f31b-37d80ae9dfb1","scrolled":true,"executionInfo":{"status":"ok","timestamp":1726690108932,"user_tz":-180,"elapsed":44886,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformer_lens\n","  Downloading transformer_lens-2.6.0-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: accelerate>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.34.2)\n","Collecting beartype<0.15.0,>=0.14.1 (from transformer_lens)\n","  Downloading beartype-0.14.1-py3-none-any.whl.metadata (28 kB)\n","Collecting better-abc<0.0.4,>=0.0.3 (from transformer_lens)\n","  Downloading better_abc-0.0.3-py3-none-any.whl.metadata (1.4 kB)\n","Collecting datasets>=2.7.1 (from transformer_lens)\n","  Downloading datasets-3.0.0-py3-none-any.whl.metadata (19 kB)\n","Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.8.0)\n","Collecting fancy-einsum>=0.0.3 (from transformer_lens)\n","  Downloading fancy_einsum-0.0.3-py3-none-any.whl.metadata (1.2 kB)\n","Collecting jaxtyping>=0.2.11 (from transformer_lens)\n","  Downloading jaxtyping-0.2.34-py3-none-any.whl.metadata (6.4 kB)\n","Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (1.26.4)\n","Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (2.1.4)\n","Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (13.8.1)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.1.99)\n","Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (2.4.0+cu121)\n","Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (4.66.5)\n","Requirement already satisfied: transformers>=4.37.2 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (4.44.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (4.12.2)\n","Collecting wandb>=0.13.5 (from transformer_lens)\n","  Downloading wandb-0.18.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (24.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (6.0.2)\n","Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (0.24.7)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (0.4.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (3.16.0)\n","Collecting pyarrow>=15.0.0 (from datasets>=2.7.1->transformer_lens)\n","  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.7.1->transformer_lens)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (2.32.3)\n","Collecting xxhash (from datasets>=2.7.1->transformer_lens)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess (from datasets>=2.7.1->transformer_lens)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets>=2.7.1->transformer_lens) (2024.6.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (3.10.5)\n","Collecting typeguard==2.13.3 (from jaxtyping>=0.2.11->transformer_lens)\n","  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer_lens) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer_lens) (2024.2)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer_lens) (2024.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer_lens) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer_lens) (2.18.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer_lens) (1.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer_lens) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer_lens) (3.1.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.2->transformer_lens) (2024.9.11)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.2->transformer_lens) (0.19.1)\n","Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (8.1.7)\n","Collecting docker-pycreds>=0.4.0 (from wandb>=0.13.5->transformer_lens)\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n","Collecting gitpython!=3.1.29,>=1.0.0 (from wandb>=0.13.5->transformer_lens)\n","  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (4.3.3)\n","Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (3.20.3)\n","Collecting sentry-sdk>=1.0.0 (from wandb>=0.13.5->transformer_lens)\n","  Downloading sentry_sdk-2.14.0-py2.py3-none-any.whl.metadata (9.7 kB)\n","Collecting setproctitle (from wandb>=0.13.5->transformer_lens)\n","  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (71.0.4)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer_lens) (1.16.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (2.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.11.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (4.0.3)\n","Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens)\n","  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer_lens) (0.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (2024.8.30)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10->transformer_lens) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10->transformer_lens) (1.3.0)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens)\n","  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n","Downloading transformer_lens-2.6.0-py3-none-any.whl (175 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.1/175.1 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading beartype-0.14.1-py3-none-any.whl (739 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.7/739.7 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading better_abc-0.0.3-py3-none-any.whl (3.5 kB)\n","Downloading datasets-3.0.0-py3-none-any.whl (474 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.3/474.3 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n","Downloading jaxtyping-0.2.34-py3-none-any.whl (42 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n","Downloading wandb-0.18.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sentry_sdk-2.14.0-py2.py3-none-any.whl (311 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.4/311.4 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n","Installing collected packages: better-abc, xxhash, typeguard, smmap, setproctitle, sentry-sdk, pyarrow, fancy-einsum, docker-pycreds, dill, beartype, multiprocess, jaxtyping, gitdb, gitpython, wandb, datasets, transformer_lens\n","  Attempting uninstall: typeguard\n","    Found existing installation: typeguard 4.3.0\n","    Uninstalling typeguard-4.3.0:\n","      Successfully uninstalled typeguard-4.3.0\n","  Attempting uninstall: pyarrow\n","    Found existing installation: pyarrow 14.0.2\n","    Uninstalling pyarrow-14.0.2:\n","      Successfully uninstalled pyarrow-14.0.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n","ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\n","inflect 7.4.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed beartype-0.14.1 better-abc-0.0.3 datasets-3.0.0 dill-0.3.8 docker-pycreds-0.4.0 fancy-einsum-0.0.3 gitdb-4.0.11 gitpython-3.1.43 jaxtyping-0.2.34 multiprocess-0.70.16 pyarrow-17.0.0 sentry-sdk-2.14.0 setproctitle-1.3.3 smmap-5.0.1 transformer_lens-2.6.0 typeguard-2.13.3 wandb-0.18.1 xxhash-3.5.0\n","Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.0)\n","Requirement already satisfied: jaxtyping in /usr/local/lib/python3.10/dist-packages (0.2.34)\n","Requirement already satisfied: typeguard==2.13.3 in /usr/local/lib/python3.10/dist-packages (from jaxtyping) (2.13.3)\n","Collecting git+https://github.com/callummcdougall/CircuitsVis.git#subdirectory=python\n","  Cloning https://github.com/callummcdougall/CircuitsVis.git to /tmp/pip-req-build-fwpy_ubs\n","  Running command git clone --filter=blob:none --quiet https://github.com/callummcdougall/CircuitsVis.git /tmp/pip-req-build-fwpy_ubs\n","  Resolved https://github.com/callummcdougall/CircuitsVis.git to commit 1e6129d08cae7af9242d9ab5d3ed322dd44b4dd3\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting importlib-metadata<6.0.0,>=5.1.0 (from circuitsvis==0.0.0)\n","  Downloading importlib_metadata-5.2.0-py3-none-any.whl.metadata (5.0 kB)\n","Requirement already satisfied: numpy<2.0,>=1.23 in /usr/local/lib/python3.10/dist-packages (from circuitsvis==0.0.0) (1.26.4)\n","Requirement already satisfied: torch<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from circuitsvis==0.0.0) (2.4.0+cu121)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<6.0.0,>=5.1.0->circuitsvis==0.0.0) (3.20.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (3.16.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (1.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (2024.6.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3.0,>=2.0->circuitsvis==0.0.0) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<3.0,>=2.0->circuitsvis==0.0.0) (1.3.0)\n","Downloading importlib_metadata-5.2.0-py3-none-any.whl (21 kB)\n","Building wheels for collected packages: circuitsvis\n","  Building wheel for circuitsvis (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for circuitsvis: filename=circuitsvis-0.0.0-py3-none-any.whl size=6172334 sha256=59415c32edc93016c6c42f3b4833706a3be43b700e7573be5495cc7c0ec5f306\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-nayy3dhe/wheels/86/be/ad/78078aba9344d200aad61b63d35cdaecdec160212f039eed74\n","Successfully built circuitsvis\n","Installing collected packages: importlib-metadata, circuitsvis\n","  Attempting uninstall: importlib-metadata\n","    Found existing installation: importlib_metadata 8.5.0\n","    Uninstalling importlib_metadata-8.5.0:\n","      Successfully uninstalled importlib_metadata-8.5.0\n","Successfully installed circuitsvis-0.0.0 importlib-metadata-5.2.0\n"]}],"source":["%pip install transformer_lens\n","%pip install einops\n","%pip install jaxtyping\n","%pip install git+https://github.com/callummcdougall/CircuitsVis.git#subdirectory=python"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":482,"referenced_widgets":["3bcf60ec028745ddb63a00c1601d3f03","f3f8a061202f420daaeb36265387fbb6","b5f5d07f7f90434abad654888d032007","c82625f2ec57472eb315b4abb4de2676","2af8bb81e7f14a7e9d8b0a23ebdc1306","742e1d25c19548f7834f8697241fa8bd","ca2d2e52bce1446ca56c37c5196dd4f7","4f46343a83fa4398ad9148d968874a4c","df77d574e4a8403bbe28c03f955fbf0d","24c6c44c34b742eba9b7192393c49c21","3c82ae1e83d94c3eb4dbd751fc6e2bd8","32fba32fcdcd42f29b7dd3fffc4bed89","5abe8076318d47e1ac751b608014645e","6497fc31b7dd4e71a2df915a444dc55c","63a4c3fdf04d4ef8a9fca149e7d62f98","449a5ad462f144c1b3a57f4e73a436b3","eb4afd36146e4442b8407331642a6b6e","7509bff3efca4f509f06ae767475547b","aef809e06b464861b6c85ea9c08c78b8","7cd4f44a777f4ee082111f6fe7125cdd","27542a45f7b7406cb1c0cce26bef3a10","e12f3a13c30c43cf995be53227942a37","f03229988a9644e389dbd2d3e8045ce5","3b9a9cd5365f47c2b3fd918881cd86ba","d650b681deee447c875ca49d6427577f","a14d1b0351e447ee96de26ad9724cac0","99fa4debe96346e896359ccc92038028","2335b5a05d534c3998cc77ce1c28cc8a","3cf234110b9846d7a73b5e0952722cbe","e500dac50f604837814510bfb8d1915d","8299b8be7d4545f4813eb1e018a2a9a7","f80c86aa9ec44596ac38aa79a13dcfbd","6539743063bb47c4aeaab67b2dfef072","c3e702e9a0b4474ba968b1a04fcf4730","792dea46bcf945f6993b3902e2250ab6","ebcf0a50088f404c9675d5c2d64513c9","a259bf6d873a4871b6bd29dfe613319c","50ac5311da0e4c0c958ef61d444ded71","99504e4831cf4a8ea9b88574eb54725c","7412b986cd904188a017bd51a135a1d8","9a2fa306457b4634a700589581a5adc4","b3310d58ed404c3fb0fb012cdd80b2fd","29b37ce9d2c84b79857bd8f95ccd6cf3","b7a4e36bfd73454787df7c411f4c7b09","373a12455c92462e945dfd9b9ffe23e4","fd71311e804a4a93b7510db9e5a41037","5e4b3431f26941349c4af71055ae5e42","2e9829ac1e1040bd8c075e467c95da13","ed64b016f33b4d498e867c51b834b47c","853987c846c847449acb075dca984620","b726612a5c8b47acbc8b74d00e9497e6","5e2690e8bf2d40919b4e5adb39257d33","b65c9e49fedf4aa9b6bd8e0bedd9b68b","893f8ffd0b5e440ab828a0076c661db1","b400f08aaacf4cc79bd2c25ce39d4ef0","8d9a25de868744eaaad81fa5c5104807","e0ac2dece79e436bbd3c91c857c1e3a8","554d1f9abf4145c585623e025eda655b","299cbacc02e74561b5de6b88f228e286","f76b9221a90c48cf95360e8e3704efe4","8c12d583ab994ffca0021ece5d2f2920","a8a2c618f3c94d98b0836deda86855a3","6b3aa81cf46745b9a24756ebc1eeec3a","97dbe9a640f64ac29cf5e6ffff54430c","9e302a8bb2ec4a92b8507c10ce3e5ec6","05a7d4fe95ef4a22b120bdc30417bcde","a3ad01b612a94e96bf9a0b51cb9376ba","b4ec44d9a60b4a37942e6e076027430b","289bbb88f68242f3861def71b15b0375","71c0d1f4a4554278909d20cfac6a1df9","966a95b868e84f02849ea9ff65d5a3ce","e528e6f43eae48dfa1311640237b8590","389359b93d06464db2c47fdcef209a12","df37ba4e523b4313adcd04c7ba4c2864","43bd78b6b7484550adfd11882dc3eb37","a045cbdd7b4d452585978b0babbb1244","f74df40d30a94c6890ad148d28f32de2"]},"id":"bAVtXXZiPJlr","outputId":"599efcbc-5874-4448-e2c1-3cc735d5d9ba","executionInfo":{"status":"ok","timestamp":1726690135101,"user_tz":-180,"elapsed":26177,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/accelerate/utils/imports.py:278: UserWarning: `ACCELERATE_DISABLE_RICH` is deprecated and will be removed in v0.22.0 and deactivated by default. Please use `ACCELERATE_ENABLE_RICH` if you wish to use `rich`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3bcf60ec028745ddb63a00c1601d3f03"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32fba32fcdcd42f29b7dd3fffc4bed89"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f03229988a9644e389dbd2d3e8045ce5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3e702e9a0b4474ba968b1a04fcf4730"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"373a12455c92462e945dfd9b9ffe23e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d9a25de868744eaaad81fa5c5104807"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3ad01b612a94e96bf9a0b51cb9376ba"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Loaded pretrained model gpt2-small into HookedTransformer\n","Moving model to device:  cuda\n"]}],"source":["import os; os.environ['ACCELERATE_DISABLE_RICH'] = \"1\"\n","import einops\n","from dataclasses import dataclass  # https://habr.com/ru/articles/415829/\n","from transformer_lens import HookedTransformer\n","import torch as t\n","import torch\n","from torch import Tensor\n","import torch.nn as nn\n","import numpy as np\n","import math\n","from tqdm.notebook import tqdm\n","from jaxtyping import Float, Int\n","from transformers.models.gpt2.tokenization_gpt2_fast import GPT2TokenizerFast\n","from collections import defaultdict\n","\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Загружаем веса gpt2 для проверки\n","reference_gpt2 = HookedTransformer.from_pretrained(\"gpt2-small\", fold_ln=False,\n","                                                   center_unembed=False,\n","                                                   center_writing_weights=False)\n","reference_gpt2 = reference_gpt2.to(device)"]},{"cell_type":"markdown","metadata":{"id":"T1Sk9Y1GKW2B"},"source":["Конфиг, который хранит в себе всю информацию о размерностях модели."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XjdS6H9pO9E0","outputId":"9f809b47-4bfa-4d4c-ca3f-1d4e14df3466","executionInfo":{"status":"ok","timestamp":1726690135102,"user_tz":-180,"elapsed":39,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Config(d_model=768, debug=True, layer_norm_eps=1e-05, d_vocab=50257, init_range=0.02, n_ctx=1024, d_head=64, d_mlp=3072, n_heads=12, n_layers=12)\n"]}],"source":["@dataclass\n","class Config:\n","    d_model: int = 768 # он же hidden_dim - внутрення размерность модели\n","    debug: bool = True\n","    layer_norm_eps: float = 1e-5\n","    d_vocab: int = 50257 # он же vocab_size, размер словаря модели\n","    init_range: float = 0.02\n","    n_ctx: int = 1024 # число позиционных эмбеддингов\n","    d_head: int = 64 # размерность головы аттеншена\n","    d_mlp: int = 3072 # внутренняя размерность FFN-слоя\n","    n_heads: int = 12 # число голов аттеншена\n","    n_layers: int = 12 # число слоев трансформера\n","\n","cfg = Config()\n","print(cfg)"]},{"cell_type":"markdown","metadata":{"id":"5cqee_hhKW2G"},"source":["Код для генерации тестов, которые мы будем использовать для проверки слоев!"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"ctCDi2ccPx-H","executionInfo":{"status":"ok","timestamp":1726690135102,"user_tz":-180,"elapsed":36,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}}},"outputs":[],"source":["def rand_float_test(cls, shape):\n","    cfg = Config(debug=True)\n","    layer = cls(cfg).to(device)\n","    random_input = torch.randn(shape).to(device)\n","    print(\"Input shape:\", random_input.shape)\n","    output = layer(random_input)\n","    if isinstance(output, tuple): output = output[0]\n","    print(\"Output shape:\", output.shape, \"\\n\")\n","\n","def rand_int_test(cls, shape):\n","    cfg = Config(debug=True)\n","    layer = cls(cfg).to(device)\n","    random_input = torch.randint(100, 1000, shape).to(device)\n","    print(\"Input shape:\", random_input.shape)\n","    output = layer(random_input)\n","    if isinstance(output, tuple): output = output[0]\n","    print(\"Output shape:\", output.shape, \"\\n\")\n","\n","def load_gpt2_test(cls, gpt2_layer, input):\n","    cfg = Config(debug=True)\n","    layer = cls(cfg).to(device)\n","    layer.load_state_dict(gpt2_layer.state_dict(), strict=False)\n","    print(\"Input shape:\", input.shape)\n","    output = layer(input)\n","    if isinstance(output, tuple): output = output[0]\n","    print(\"Output shape:\", output.shape)\n","    try: reference_output = gpt2_layer(input)\n","    except: reference_output = gpt2_layer(input, input, input)\n","    print(\"Reference output shape:\", reference_output.shape, \"\\n\")\n","    comparison = t.isclose(output, reference_output, atol=1e-4, rtol=1e-3)\n","    print(f\"{comparison.sum()/comparison.numel():.2%} of the values are correct\\n\")"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oSNvnHYaQrqZ","outputId":"72966c07-250b-4112-a966-ff09933e1873","executionInfo":{"status":"ok","timestamp":1726690135102,"user_tz":-180,"elapsed":34,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[50256,    40,   716,   281,  4998,  1960,   382, 19741,    11,   875,\n","         12342,    12,  8807,    11,   402, 11571,    12,    17,  3918, 47385,\n","            13,  1881,  1110,   314,   481,  7074,  1692,  1241,  4430,   290,\n","          1011,   625,   262,   995,     0]], device='cuda:0')\n","torch.Size([1, 35])\n","['<|endoftext|>', 'I', ' am', ' an', ' amazing', ' aut', 'ore', 'gressive', ',', ' dec', 'oder', '-', 'only', ',', ' G', 'PT', '-', '2', ' style', ' transformer', '.', ' One', ' day', ' I', ' will', ' exceed', ' human', ' level', ' intelligence', ' and', ' take', ' over', ' the', ' world', '!']\n"]}],"source":["reference_text = \"I am an amazing autoregressive, decoder-only, GPT-2 style transformer. One day I will exceed human level intelligence and take over the world!\"\n","tokens = reference_gpt2.to_tokens(reference_text).to(device)\n","print(tokens)\n","print(tokens.shape)\n","print(reference_gpt2.to_str_tokens(tokens))"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6iN1wz9mUNTY","outputId":"efbcab7a-7fcb-44f8-8535-cd0a1a67ef85","scrolled":true,"executionInfo":{"status":"ok","timestamp":1726690135969,"user_tz":-180,"elapsed":896,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 35, 50257])\n","Все работает, мы готовы к выполнению задания!\n"]}],"source":["logits, cache = reference_gpt2.run_with_cache(tokens)\n","print(logits.shape)\n","\n","print(\"Все работает, мы готовы к выполнению задания!\")"]},{"cell_type":"markdown","metadata":{"id":"v4X2D4gRKW2M"},"source":["# Архитектура Transformer - 40 баллов"]},{"cell_type":"markdown","metadata":{"id":"7kIRmiHZ87sw"},"source":["# Embeddings - 5 баллов"]},{"cell_type":"markdown","metadata":{"id":"zWRyjeWbKW2N"},"source":["Здесь нам даются токены размерности `[batch_size, seq_len]` - индексы слов в словаре. Нужно описать слой Embed, который будет отображать каждый токен в соответствующий вектор из матрицы эмбеддингов. Таким образом каждому токену предоставляется вектор, который будет иметь размерности `[batch_size, seq_len, d_model]`\n","\n","Внимание - здесь не нужно исользовать цикл for и проходиться по матрице. Все стандартные операции доступны в [документации](https://pytorch.org/docs/stable/nn.functional.html), в частности тут нам понадобится одна из операций в секции [sparse functions](https://pytorch.org/docs/stable/nn.functional.html#sparse-functions).\n","\n","Важное замечание - на самом деле этот слой уже есть [готовый в pytorch](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html), но мы в учебных целях переписываем его сами.\n","\n","\n","Также можно решить этот пример через индексацию или через einops.\n","\n","**Вообще почти во всех примерах есть несколько возможных стилей описания операций над тензорами - через torch.nn.functional, через различные индексации и трюки pytorch, через einops - можно делать любым удобным способом!**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"srX7Xj8FaMHX"},"outputs":[],"source":["\"\"\"\n","class Embed(nn.Module):\n","    def __init__(self, cfg: Config):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.W_E = nn.Parameter(t.empty((cfg.d_vocab, cfg.d_model)))\n","        nn.init.normal_(self.W_E, std=self.cfg.init_range)\n","\n","    def forward(self, input_ids: Int[Tensor, \"batch seq_len\"]) -> Float[Tensor, \"batch seq_len d_model\"]:\n","        pass\n","        # Ваш код здесь!\n","\n","\n","batch_size = 2\n","seq_len = 4\n","rand_int_test(Embed, [batch_size, seq_len])\n","load_gpt2_test(Embed, reference_gpt2.embed, tokens)\n","\"\"\""]},{"cell_type":"code","source":["from typing import Tuple\n","import torch\n","from torch import Tensor\n","import torch.nn as nn\n","\n","class Embed(nn.Module):\n","    \"\"\"\n","    Слой эмбеддингов для преобразования токенов в векторы заданной размерности.\n","\n","    :param cfg: объект конфигурации, содержащий параметры модели\n","    \"\"\"\n","\n","    def __init__(self, cfg: Config) -> None:\n","        super().__init__()\n","        self.cfg = cfg\n","        # W_E - матрица эмбеддингов размерности (vocab_size, hidden_dim), где\n","        # vocab_size - размер словаря, hidden_dim - размерность эмбеддинга\n","        self.W_E = nn.Parameter(t.empty((cfg.d_vocab, cfg.d_model)))\n","        # Инициализация матрицы эмбеддингов случайными значениями по нормальному распределению\n","        nn.init.normal_(self.W_E, std=self.cfg.init_range)\n","\n","    def forward(self, input_ids: Tensor) -> Tensor:\n","        \"\"\"\n","        Преобразует входные индексы токенов в эмбеддинги.\n","\n","        :param input_ids: Тензор целых чисел, представляющий индексы токенов\n","                          размерности (batch, seq_len).\n","        :return: Тензор эмбеддингов размерности (batch, seq_len, d_model).\n","        \"\"\"\n","        return self.W_E[input_ids]\n","\n","# Пример использования\n","batch_size = 2\n","seq_len = 4\n","\n","# Тестируем слой с помощью случайных целочисленных токенов\n","rand_int_test(Embed, [batch_size, seq_len])\n","\n","# Загружаем слой эмбеддингов GPT-2 и тестируем его с референсной моделью\n","load_gpt2_test(Embed, reference_gpt2.embed, tokens)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pzv3DaVOSaVj","executionInfo":{"status":"ok","timestamp":1726690173869,"user_tz":-180,"elapsed":1413,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}},"outputId":"2ea16a91-b589-4616-d87b-782bd1a1e7c9"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Input shape: torch.Size([2, 4])\n","Output shape: torch.Size([2, 4, 768]) \n","\n","Input shape: torch.Size([1, 35])\n","Output shape: torch.Size([1, 35, 768])\n","Reference output shape: torch.Size([1, 35, 768]) \n","\n","100.00% of the values are correct\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"NxprTG43KW2O"},"source":["# Positional Embeddings - 5 баллов"]},{"cell_type":"markdown","metadata":{"id":"RM8lqiu7KW2P"},"source":["В трансформерах есть не только обычные эмбеддинги, которые отвечают за \"смысл\" токенов, но и позиционные эмбеддинги! Вход у них такой же, как и у обычных эмбеддингов, только они должны эмбеддить позиции токенов, а не сами токены. Т.е. в матрице W_pos хранятся не эмбеддинги токенов, а эмбеддинги позиций.\n","\n","Поэтому в этом слое нужно:\n","1. По tokens получить тензор positions размера `[batch_size, seq_len]`\n","2. Заэмбеддить тензор positions, как в предыдущем слое.\n","\n","Важно - как и в предыдущем случае, для этот слой обычно используется через [nn.Embedding](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html)\n","\n","\n","Вспомним еще про то, откуда берутся позиционные эмбеддинги: в оригинальном трансформере позиционные эмбеддинги состояли из синусов и косинусов (см. пункт 3.5 из оригинальной статьи https://arxiv.org/pdf/1706.03762), однако позиционные эмбеддинги можно учить и с нуля, как и обычные эмбеддинги. **В рамках данного задания не нужно никак дополнительно инициализировать веса, только применить позиционные эмбеддинги**.\n"]},{"cell_type":"markdown","source":[],"metadata":{"id":"KTnltd__TGAY"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"trB2m2P8Rgrk"},"outputs":[],"source":["\"\"\"\n","\n","class PosEmbed(nn.Module):\n","    def __init__(self, cfg: Config):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.W_pos = nn.Parameter(t.empty((cfg.n_ctx, cfg.d_model)))\n","        nn.init.normal_(self.W_pos, std=self.cfg.init_range)\n","\n","    def forward(self, input_ids: Int[Tensor, \"batch seq_len\"]) -> Float[Tensor, \"batch seq_len d_model\"]:\n","        pass\n","        # Ваш код здесь!\n","\n","batch_size = 2\n","seq_len = 4\n","rand_int_test(PosEmbed, [batch_size, seq_len])\n","load_gpt2_test(PosEmbed, reference_gpt2.pos_embed, tokens)\n","\"\"\""]},{"cell_type":"code","source":["def load_gpt2_test(cls, gpt2_layer, input):\n","    cfg = Config(debug=True)\n","    layer = cls(cfg).to(device)\n","    layer.load_state_dict(gpt2_layer.state_dict(), strict=False)\n","\n","    print(\"Input shape:\", input.shape)\n","\n","    # Выводим параметры оригинального GPT-2 слоя\n","    print(\"\\n=== GPT-2 Layer Parameters ===\")\n","    for name, param in gpt2_layer.named_parameters():\n","        print(f\"{name}: {param.shape}\")\n","        print(param)  # Выводим сами параметры для анализа\n","\n","    # Пробуем получить выходной тензор из нашей реализации\n","    output = layer(input)\n","    if isinstance(output, tuple):\n","        output = output[0]\n","\n","    print(\"Output shape (our layer):\", output.shape)\n","\n","    # Пробуем получить выходной тензор из оригинальной модели GPT-2\n","    try:\n","        reference_output = gpt2_layer(input)\n","    except:\n","        reference_output = gpt2_layer(input, input, input)\n","\n","    print(\"Reference output shape (GPT-2):\", reference_output.shape, \"\\n\")\n","\n","    # Сравниваем выводы двух моделей\n","    comparison = t.isclose(output, reference_output, atol=1e-4, rtol=1e-3)\n","    print(f\"{comparison.sum()/comparison.numel():.2%} of the values are correct\\n\")\n","\n","    # Выводим примеры отличий между нашими результатами и результатами GPT-2\n","    differences = torch.abs(output - reference_output)\n","    print(\"=== Example Differences (First 10 Elements) ===\")\n","    print(differences.view(-1)[:10])\n"],"metadata":{"id":"atWFOGvFnf9t","executionInfo":{"status":"ok","timestamp":1726690181108,"user_tz":-180,"elapsed":517,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["class PosEmbed(nn.Module):\n","    \"\"\"\n","    Реализация позиционных эмбеддингов, аналогичная GPT-2, с прединициализированной матрицей W_pos.\n","\n","    :param cfg: объект конфигурации, содержащий параметры модели.\n","    \"\"\"\n","\n","    def __init__(self, cfg: Config) -> None:\n","        super().__init__()\n","        self.cfg = cfg\n","        # Инициализация матрицы позиционных эмбеддингов W_pos\n","        self.W_pos = nn.Parameter(torch.empty(cfg.n_ctx, cfg.d_model))\n","        nn.init.normal_(self.W_pos, std=self.cfg.init_range)  # Инициализация весов, как в GPT-2\n","\n","    def forward(self, input_ids: Tensor) -> Tensor:\n","        \"\"\"\n","        Возвращает прединициализированные позиционные эмбеддинги для заданной последовательности.\n","\n","        :param input_ids: Тензор целых чисел, представляющий индексы токенов размерности (batch, seq_len).\n","        :return: Тензор позиционных эмбеддингов размерности (batch, seq_len, d_model).\n","        \"\"\"\n","        batch_size, seq_len = input_ids.shape\n","\n","        # Извлекаем соответствующие позиционные эмбеддинги из W_pos для текущей длины последовательности\n","        pos_embeds = self.W_pos[:seq_len, :]  # [seq_len, d_model]\n","\n","        # Преобразуем позиционные эмбеддинги, чтобы они имели размер (batch, seq_len, d_model)\n","        pos_embeds = pos_embeds.unsqueeze(0).expand(batch_size, seq_len, self.cfg.d_model)\n","\n","        return pos_embeds\n","\n","\n","# Пример входного тензора input_ids\n","input_ids = torch.tensor([\n","    [10, 25, 42, 7],  # Токены первой последовательности\n","    [56, 14, 87, 33]  # Токены второй последовательности\n","])\n","\n","# Повторное тестирование\n","cfg = Config()\n","pos_embed_layer = PosEmbed(cfg)\n","output = pos_embed_layer(input_ids)\n","\n","# Проверяем размерность выхода\n","output.shape, output\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fo3R0oUpWJJN","executionInfo":{"status":"ok","timestamp":1726690190671,"user_tz":-180,"elapsed":469,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}},"outputId":"43df340f-eb0d-4c68-a422-8d1219e7ad9e"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([2, 4, 768]),\n"," tensor([[[ 0.0098,  0.0175,  0.0110,  ..., -0.0124,  0.0319, -0.0493],\n","          [ 0.0078,  0.0336, -0.0202,  ..., -0.0176, -0.0300,  0.0198],\n","          [ 0.0256,  0.0279, -0.0041,  ..., -0.0036, -0.0004, -0.0361],\n","          [-0.0193, -0.0198,  0.0002,  ..., -0.0046,  0.0124,  0.0041]],\n"," \n","         [[ 0.0098,  0.0175,  0.0110,  ..., -0.0124,  0.0319, -0.0493],\n","          [ 0.0078,  0.0336, -0.0202,  ..., -0.0176, -0.0300,  0.0198],\n","          [ 0.0256,  0.0279, -0.0041,  ..., -0.0036, -0.0004, -0.0361],\n","          [-0.0193, -0.0198,  0.0002,  ..., -0.0046,  0.0124,  0.0041]]],\n","        grad_fn=<ExpandBackward0>))"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["# Пример использования\n","batch_size = 2\n","seq_len = 4\n","\n","# Тестируем слой с помощью случайных целочисленных токенов\n","rand_int_test(PosEmbed, [batch_size, seq_len])\n","\n","# Загружаем слой позиционных эмбеддингов GPT-2 и тестируем его с референсной моделью\n","load_gpt2_test(PosEmbed, reference_gpt2.pos_embed, tokens)\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DA8Ui4b3T7it","executionInfo":{"status":"ok","timestamp":1726690197458,"user_tz":-180,"elapsed":1056,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}},"outputId":"1960970e-e620-4f56-ff49-26eddc6ba134"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Input shape: torch.Size([2, 4])\n","Output shape: torch.Size([2, 4, 768]) \n","\n","Input shape: torch.Size([1, 35])\n","\n","=== GPT-2 Layer Parameters ===\n","W_pos: torch.Size([1024, 768])\n","Parameter containing:\n","tensor([[-1.8821e-02, -1.9742e-01,  4.0267e-03,  ..., -4.3044e-02,\n","          2.8267e-02,  5.4490e-02],\n","        [ 2.3959e-02, -5.3792e-02, -9.4879e-02,  ...,  3.4170e-02,\n","          1.0172e-02, -1.5573e-04],\n","        [ 4.2161e-03, -8.4764e-02,  5.4515e-02,  ...,  1.9745e-02,\n","          1.9325e-02, -2.1424e-02],\n","        ...,\n","        [-1.7987e-03,  1.6052e-03, -5.5103e-02,  ...,  1.3617e-02,\n","         -7.1805e-03,  3.7552e-03],\n","        [ 3.2105e-03,  1.5501e-03, -4.8944e-02,  ...,  2.0725e-02,\n","         -1.1838e-02, -5.5683e-04],\n","        [ 2.6610e-04,  3.0272e-03, -1.7086e-03,  ..., -4.6506e-03,\n","         -2.3541e-03, -5.7855e-03]], device='cuda:0', requires_grad=True)\n","Output shape (our layer): torch.Size([1, 35, 768])\n","Reference output shape (GPT-2): torch.Size([1, 35, 768]) \n","\n","100.00% of the values are correct\n","\n","=== Example Differences (First 10 Elements) ===\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n","       grad_fn=<SliceBackward0>)\n"]}]},{"cell_type":"markdown","metadata":{"id":"xP_p5c78KW2Q"},"source":["# LM head - 5 баллов\n","\n","Финальный слой. У нас есть выходы из трансформера размерности `[batch_size, seq_len, d_model]`. Это контекстуализированные представления каждого токена. По ним мы предсказываем следующий токен, т.е. применяем линейный слой - умножаем на матрицу `[d_model, vocab_size]`.\n","\n","В этом нам поможет секция [linear functions](https://pytorch.org/docs/stable/nn.functional.html#linear-functions). Не забудьте про bias!\n","\n","В pytorch этот слой тоже есть - [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XLXcAsSMU58C"},"outputs":[],"source":["# LM_head, но для совместимости с библиотекой для проверки пришлось назвать его Unembed\n","# по аналогии с тем, что мы из индексов в словаре получаем эмбеддинги, а тут из эмбеддингов обратно\n","# распределение по словарю\n","\n","\"\"\"\n","class Unembed(nn.Module):\n","    def __init__(self, cfg):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.W_U = nn.Parameter(t.empty((cfg.d_model, cfg.d_vocab)))\n","        nn.init.normal_(self.W_U, std=self.cfg.init_range)\n","        self.b_U = nn.Parameter(t.zeros((cfg.d_vocab), requires_grad=False))\n","\n","    def forward(\n","        self, x: Float[Tensor, \"batch seq_len d_model\"]\n","    ) -> Float[Tensor, \"batch seq_len d_vocab\"]:\n","        pass\n","        # Ваш код здесь!\n","\n","\n","batch_size = 2\n","seq_len = 4\n","d_model = 768\n","rand_float_test(Unembed, [batch_size, seq_len, d_model])\n","load_gpt2_test(Unembed, reference_gpt2.unembed, cache[\"ln_final.hook_normalized\"])\n","\"\"\""]},{"cell_type":"code","source":["class Unembed(nn.Module):\n","    \"\"\"\n","    Финальный слой для предсказания следующего токена по контекстуализированным представлениям токенов.\n","\n","    :param cfg: объект конфигурации, содержащий параметры модели.\n","    \"\"\"\n","\n","    def __init__(self, cfg: Config) -> None:\n","        super().__init__()\n","        self.cfg = cfg\n","        # W_U - матрица размером (d_model, d_vocab), для предсказания токенов\n","        self.W_U = nn.Parameter(torch.empty((cfg.d_model, cfg.d_vocab)))\n","        # Инициализация матрицы весов случайными значениями по нормальному распределению\n","        nn.init.normal_(self.W_U, std=self.cfg.init_range)\n","        # b_U - смещение (bias) для предсказания\n","        self.b_U = nn.Parameter(torch.zeros((cfg.d_vocab), requires_grad=True))\n","\n","    def forward(self, x: Tensor) -> Tensor:\n","        \"\"\"\n","        Применяет линейный слой для преобразования эмбеддингов в распределение по словарю.\n","\n","        :param x: Тензор размерности (batch, seq_len, d_model) - контекстуализированные представления токенов.\n","        :return: Тензор размерности (batch, seq_len, d_vocab) - распределение по словарю.\n","        \"\"\"\n","        # Применяем линейный слой: умножаем на матрицу W_U и добавляем смещение b_U\n","        return torch.matmul(x, self.W_U) + self.b_U\n","\n","batch_size = 2\n","seq_len = 4\n","d_model = 768\n","rand_float_test(Unembed, [batch_size, seq_len, d_model])\n","load_gpt2_test(Unembed, reference_gpt2.unembed, cache[\"ln_final.hook_normalized\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WpxgUD6uX_xB","executionInfo":{"status":"ok","timestamp":1726690214023,"user_tz":-180,"elapsed":1466,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}},"outputId":"b0f9a629-927c-4247-bf42-61bda5fb78e7"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Input shape: torch.Size([2, 4, 768])\n","Output shape: torch.Size([2, 4, 50257]) \n","\n","Input shape: torch.Size([1, 35, 768])\n","\n","=== GPT-2 Layer Parameters ===\n","W_U: torch.Size([768, 50257])\n","Parameter containing:\n","tensor([[-0.1101,  0.0403, -0.1275,  ..., -0.0445,  0.1860,  0.0514],\n","        [-0.0393, -0.0486,  0.0479,  ..., -0.0548,  0.0167, -0.0277],\n","        [ 0.0331,  0.0462,  0.1841,  ...,  0.0123,  0.0461,  0.0499],\n","        ...,\n","        [-0.1364,  0.0861,  0.0899,  ...,  0.1044, -0.0963,  0.0070],\n","        [ 0.0151,  0.0025, -0.1297,  ...,  0.0978,  0.0785,  0.1552],\n","        [ 0.0453,  0.0432, -0.0879,  ..., -0.0695, -0.0225,  0.1207]],\n","       device='cuda:0', requires_grad=True)\n","b_U: torch.Size([50257])\n","Parameter containing:\n","tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","Output shape (our layer): torch.Size([1, 35, 50257])\n","Reference output shape (GPT-2): torch.Size([1, 35, 50257]) \n","\n","100.00% of the values are correct\n","\n","=== Example Differences (First 10 Elements) ===\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n","       grad_fn=<SliceBackward0>)\n"]}]},{"cell_type":"markdown","metadata":{"id":"fXYsYDGmKW2S"},"source":["# Attention - 5 баллов"]},{"cell_type":"markdown","metadata":{"id":"UfxZG2l7A-wQ"},"source":["# Attention-формулы"]},{"cell_type":"markdown","metadata":{"id":"30Q7cmNtFudx"},"source":["1. **Входные эмбеддинги**:\n","   $$X \\in \\mathbb{R}^{seq \\times d} $$\n","2. **Маскированный мультихед-аттеншен (Masked Multi-Head Attention)**:\n","$$M = \\begin{cases}\n"," &  m_{ij} = -\\infty, \\quad i < j \\\\\n"," &  m_{ij} = 0\n","\\end{cases} $$\n","\n","$$\n","M = \\begin{pmatrix}\n","0 & -\\infty & -\\infty & \\ldots & -\\infty \\\\\n","0 & 0 & -\\infty & \\ldots & -\\infty \\\\\n","0 & 0 & 0 & \\ldots & -\\infty \\\\\n","\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n","0 & 0 & 0 & \\ldots & 0 \\\\\n","\\end{pmatrix}\n","$$"]},{"cell_type":"markdown","metadata":{"id":"-FwfAHyzQ1Bs"},"source":["3. Для каждой головы $ h_i $:\n","\n","    3.1 **Матрицы весов для запросов, ключей и значений**:\n","     - $ W_Q \\in \\mathbb{R}^{d \\times d_h} $\n","     - $ W_K \\in \\mathbb{R}^{d \\times d_h} $\n","     - $ W_V \\in \\mathbb{R}^{d \\times d_h} $\n","     \n","    3.2. **Запросы, ключи и значения**:\n","     - $ Q = X W_Q \\in \\mathbb{R}^{seq \\times d_h} $\n","     - $ K = X W_K \\in \\mathbb{R}^{seq \\times d_h} $\n","     - $ V = X W_V \\in \\mathbb{R}^{seq \\times d_h} $\n","\n","    3.3. **Скалярные произведения запросов и ключей**:\n","     - $ \\frac{Q K^T}{\\sqrt{d_h}} + M \\in \\mathbb{R}^{seq \\times seq} $\n","\n","    3.4. **Веса внимания**:\n","     - $ \\alpha = \\text{softmax}\\left(\\frac{Q K^T}{\\sqrt{d_h}} + M\\right) \\in \\mathbb{R}^{seq \\times seq} $\n","\n","    3.5. **Агрегация значений**:\n","     - $ z = \\alpha V \\in \\mathbb{R}^{seq \\times d_h} $"]},{"cell_type":"markdown","metadata":{"id":"EEuVgMeMR6ce"},"source":["4. **Конкатенация выходов всех голов**:\n","   - $ Z = \\text{Concat}(z_1, z_2, \\ldots, z_h) \\in \\mathbb{R}^{seq \\times d} $\n","\n","5. **Выходной линейный слой**:\n","   - Матрица весов: $ W^O \\in \\mathbb{R}^{d \\times d} $\n","   - Итоговый выход: $ O = Z W^O + X \\in \\mathbb{R}^{seq \\times d} $"]},{"cell_type":"markdown","metadata":{"id":"ASJemZ-eKW2V"},"source":["# Attention - детали реализации\n","Самое сложное в этом домашнем задании - подсчет механизма внимания. Как и в предыдущих вариантах, считать можно через torch или с помощью einops и любыми другими удобными способами.\n","\n","\n","В данном задании нужно реализовать multihead attention с маскированием. Давайте разбираться по шагам, что нам нужно сделать.\n","\n","Далее будет описан один из возможных алогритмов написания аттеншена, но повторимся - писать можно любым удобным способом (голый torch или einops).\n","\n","1. Нам попадает на вход вектор x `[batch, seq_len, d_model]`. Нужно превратить его в матрицы проекций i-й головы аттеншена: Q_i, K_i, V_i. Для этого у нас есть матрицы W_Q, W_K, W_V (и их bias!). Это набор n_heads матриц размеров `[d_model, d_head]`. Зачастую число голов n_head и d_head подобраны так, что d_model == n_head * d_head, наш случай не исключение. Предлагается перевести (этот шаг сделан) матрицу `[num_heads, d_model, d_head]` в матрицу `[d_model, num_heads * d_head]` = `[d_model, d_model]`, после чего получить через матричное умножение на X размерности `[batch_size, seq_len, d_model]` получить матрицы Q, K, V размерностей `[batch_size, seq_len, d_model] = [batch_size, seq_len, num_heads * d_head]` и преобразовать их к виду `[batch_size, seq_len, num_heads, d_head]`. Не забудьте при матричном умножении транспонировать матрицы W_Q, W_K, W_V, если пойдете этим путем! В качестве шпаргалки посмотрите, как происходило умножение в lm_head!\n","\n","2. После этого можно сделать первый шаг и посчитать attention_scores, т.е. домножить $Q \\times K^T$. Тут нам поможет .transpose или .permute вместе с torch.matmul. Нужно переставить размерности матриц таким образом, чтобы финальное матричное умножение происходило по двум последним размерностям `[seq_len, d_head]` на `[d_head, seq_len]`, а все предыдущие размерности `[batch_size, num_heads]` совпадали\n","\n","\n","3. Не забудем нормализацию, т.е. делим attention_scores на sqrt(d_head)\n","\n","4. Теперь нужно исползьовать маскирование! В данных заданиях предполагается, что у нас нет паддингов, поэтому нам нужно наложить маску с одним простым условием: i-й элемент не может смотреть на j-й элемент, если j > i. Это треугольная маска, с ней нам поможет приведение треугольной форме, которое вам предлагается найти в pytorch! Замаскированные значения нужно заполнить каким-нибудь большим по модулю отрицательным числом В классе уже опредеелно значение IGNORE, можно использовать его. Для этого реализуйте и используйте функцию `apply_causal_mask`. Заполнять значениями можно через индексацию, например через `torch.masked_fill`.\n","\n","5. Теперь к замаскированным attention_scores `[batch_size, num_heads, seq_len, seq_len]` нужно применить softmax. Подумайте, по какой размерности его применять и на что это повлияет.\n","\n","6. После этого остается последнее матричное умножение softmax(attention_scores) на V, к которому тоже придется применить .view, .permute и torch.matmul\n","\n","7. Теперь, если вы следовали этому плану у вас остается матрица `ouput` размерностей `[batch_size, num_heads, seq_len, d_head]`. С помощью permute и view собираем (конкатенируем) ее обратно в матрицу `[batch_size, seq_len, num_heads * d_head] = [batch_size, seq_len, d_model]` и применяем к ней выходной линейный слой W_O. Всё, аттеншен готов!\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"65yvUiIvTbTk"},"outputs":[],"source":["\"\"\"\n","class Attention(nn.Module):\n","    IGNORE: Float[Tensor, \"\"]\n","\n","    def __init__(self, cfg: Config):\n","        super().__init__()\n","        self.cfg = cfg\n","\n","        self.W_Q = nn.Parameter(t.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n","        self.b_Q = nn.Parameter(t.zeros((cfg.n_heads, cfg.d_head)))\n","\n","        self.W_K = nn.Parameter(t.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n","        self.b_K = nn.Parameter(t.zeros((cfg.n_heads, cfg.d_head)))\n","\n","        self.W_V = nn.Parameter(t.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n","        self.b_V = nn.Parameter(t.zeros((cfg.n_heads, cfg.d_head)))\n","\n","        self.W_O = nn.Parameter(t.empty((cfg.n_heads, cfg.d_head, cfg.d_model)))\n","        self.b_O = nn.Parameter(t.zeros((cfg.d_model)))\n","\n","        nn.init.normal_(self.W_Q, std=self.cfg.init_range)\n","        nn.init.normal_(self.W_K, std=self.cfg.init_range)\n","        nn.init.normal_(self.W_V, std=self.cfg.init_range)\n","        nn.init.normal_(self.W_O, std=self.cfg.init_range)\n","        self.register_buffer(\"IGNORE\", t.tensor(float(\"-inf\"), dtype=t.float32, device=device))\n","\n","    def forward(\n","        self, x: Float[Tensor, \"batch seq_len d_model\"]\n","    ) -> Float[Tensor, \"batch seq_len d_model\"]:\n","\n","        # Берем размерности\n","        batch_size, seq_len, d_model = x.shape\n","        num_heads = self.cfg.n_heads\n","        d_head = self.cfg.d_head\n","\n","        # 1. Трансформируем матрицы проекций в формат [d_model, d_model]\n","        W_Q = self.W_Q.permute(1, 0, 2).reshape(self.cfg.d_model, self.cfg.d_model)\n","        W_K = self.W_K.permute(1, 0, 2).reshape(self.cfg.d_model, self.cfg.d_model)\n","        W_V = self.W_V.permute(1, 0, 2).reshape(self.cfg.d_model, self.cfg.d_model)\n","\n","        b_Q = self.b_Q.view(-1)\n","        b_K = self.b_K.view(-1)\n","        b_V = self.b_V.view(-1)\n","\n","        # 1. получаем проекции  Q, K, V\n","        pass\n","        # Ваш код здесь!\n","\n","        # 2. Q x K^T\n","\n","\n","        # 3. Нормализация\n","\n","        # 4. Маскирование\n","\n","        # 5. softmax\n","\n","\n","        # 6. Финальная проекция\n","        ...\n","\n","    def apply_causal_mask(\n","        self, attn_scores: Float[Tensor, \"batch n_heads seq_len seq_len\"]\n","    ) -> Float[Tensor, \"batch n_heads seq_len seq_len\"]:\n","        '''\n","        Используем треугольную маску, чтобы не смотреть в будущее, паддингов нет\n","        В качестве масикировочного значения перед софтмаксом можно использовать self.IGNORE (-inf)\n","        '''\n","        pass\n","        # Ваш код здесь!\n","\n","torch.manual_seed(1)\n","batch_size = 2\n","seq_len = 4\n","d_model = 768\n","rand_float_test(Attention, [batch_size, seq_len, d_model])\n","load_gpt2_test(Attention, reference_gpt2.blocks[0].attn, cache[\"normalized\", 0, \"ln1\"])\n","\"\"\""]},{"cell_type":"code","source":["import torch.nn.functional as F\n","\n","\n","class Attention(nn.Module):\n","    IGNORE: Float[Tensor, \"\"]\n","\n","    def __init__(self, cfg: Config):\n","        super().__init__()\n","        self.cfg = cfg\n","\n","        self.W_Q = nn.Parameter(t.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n","        self.b_Q = nn.Parameter(t.zeros((cfg.n_heads, cfg.d_head)))\n","\n","        self.W_K = nn.Parameter(t.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n","        self.b_K = nn.Parameter(t.zeros((cfg.n_heads, cfg.d_head)))\n","\n","        self.W_V = nn.Parameter(t.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n","        self.b_V = nn.Parameter(t.zeros((cfg.n_heads, cfg.d_head)))\n","\n","        self.W_O = nn.Parameter(t.empty((cfg.n_heads, cfg.d_head, cfg.d_model)))\n","        self.b_O = nn.Parameter(t.zeros((cfg.d_model)))\n","\n","        nn.init.normal_(self.W_Q, std=self.cfg.init_range)\n","        nn.init.normal_(self.W_K, std=self.cfg.init_range)\n","        nn.init.normal_(self.W_V, std=self.cfg.init_range)\n","        nn.init.normal_(self.W_O, std=self.cfg.init_range)\n","        self.register_buffer(\"IGNORE\", t.tensor(float(\"-inf\"), dtype=t.float32, device=device))\n","\n","    def forward(\n","        self, x: Float[Tensor, \"batch seq_len d_model\"]\n","    ) -> Float[Tensor, \"batch seq_len d_model\"]:\n","\n","        # Берем размерности\n","        batch_size, seq_len, d_model = x.shape\n","        num_heads = self.cfg.n_heads\n","        d_head = self.cfg.d_head\n","\n","        # 1. Трансформируем матрицы проекций в формат [d_model, d_model]\n","        W_Q = self.W_Q.permute(1, 0, 2).reshape(self.cfg.d_model, self.cfg.d_model)\n","        W_K = self.W_K.permute(1, 0, 2).reshape(self.cfg.d_model, self.cfg.d_model)\n","        W_V = self.W_V.permute(1, 0, 2).reshape(self.cfg.d_model, self.cfg.d_model)\n","\n","        b_Q = self.b_Q.view(-1)\n","        b_K = self.b_K.view(-1)\n","        b_V = self.b_V.view(-1)\n","\n","        # 1. получаем проекции Q, K, V\n","        Q = t.matmul(x, W_Q) + b_Q\n","        K = t.matmul(x, W_K) + b_K\n","        V = t.matmul(x, W_V) + b_V\n","\n","        # Преобразуем их к виду [batch_size, seq_len, num_heads, d_head]\n","        Q = Q.view(batch_size, seq_len, num_heads, d_head)\n","        K = K.view(batch_size, seq_len, num_heads, d_head)\n","        V = V.view(batch_size, seq_len, num_heads, d_head)\n","\n","        # 2. Скалярные произведения запросов и ключей (Q x K^T)\n","        attention_scores = t.einsum('bqnh,bknh->bnqk', Q, K)\n","\n","        # 3. Нормализация (делим на sqrt(d_head))\n","        attention_scores = attention_scores / t.sqrt(t.tensor(d_head, dtype=t.float32))\n","\n","        # 4. Маскирование\n","        attention_scores = self.apply_causal_mask(attention_scores)\n","\n","        # 5. softmax\n","        attention_weights = F.softmax(attention_scores, dim=-1)\n","\n","        # 6. Взвешенное суммирование по V\n","        z = t.einsum('bnqk,bknh->bqnh', attention_weights, V)\n","\n","        # 7. Финальная проекция\n","        z = z.contiguous().view(batch_size, seq_len, d_model)  # собираем обратно [batch_size, seq_len, d_model]\n","        output = t.matmul(z, self.W_O.view(-1, d_model)) + self.b_O\n","\n","        return output\n","\n","    def apply_causal_mask(\n","        self, attn_scores: Float[Tensor, \"batch n_heads seq_len seq_len\"]\n","    ) -> Float[Tensor, \"batch n_heads seq_len seq_len\"]:\n","        '''\n","        Используем треугольную маску, чтобы не смотреть в будущее, паддингов нет\n","        В качестве масикировочного значения перед софтмаксом можно использовать self.IGNORE (-inf)\n","        '''\n","        mask = t.tril(t.ones(attn_scores.shape[-2:], device=attn_scores.device)).unsqueeze(0).unsqueeze(0)\n","        attn_scores = attn_scores.masked_fill(mask == 0, self.IGNORE)\n","        return attn_scores\n","\n","torch.manual_seed(1)\n","batch_size = 2\n","seq_len = 4\n","d_model = 768\n","rand_float_test(Attention, [batch_size, seq_len, d_model])\n","load_gpt2_test(Attention, reference_gpt2.blocks[0].attn, cache[\"normalized\", 0, \"ln1\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-bDbmi-orSk9","executionInfo":{"status":"ok","timestamp":1726690277827,"user_tz":-180,"elapsed":1066,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}},"outputId":"5c074c22-3c28-40c2-eefe-8c9ad2e3238f"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Input shape: torch.Size([2, 4, 768])\n","Output shape: torch.Size([2, 4, 768]) \n","\n","Input shape: torch.Size([1, 35, 768])\n","\n","=== GPT-2 Layer Parameters ===\n","W_Q: torch.Size([12, 768, 64])\n","Parameter containing:\n","tensor([[[-0.4738, -0.2614, -0.0978,  ...,  0.0908,  0.2785,  0.2262],\n","         [ 0.0874,  0.1473,  0.2387,  ..., -0.3679,  0.3194, -0.0895],\n","         [ 0.0039,  0.0695,  0.3668,  ..., -0.2476,  0.1122,  0.2564],\n","         ...,\n","         [-0.2592, -0.0164,  0.1991,  ...,  0.0801, -0.0739,  0.0586],\n","         [ 0.1517,  0.2170,  0.1043,  ..., -0.0959, -0.5090, -0.2666],\n","         [-0.4100, -0.1924, -0.2400,  ..., -0.3557, -0.1824, -0.2051]],\n","\n","        [[-0.0604,  0.0430, -0.1627,  ..., -0.1296, -0.1096, -0.1044],\n","         [-0.0756,  0.3676,  0.5057,  ...,  0.0877,  0.1071, -0.2444],\n","         [ 0.1617,  0.0960, -0.3865,  ..., -0.0784,  0.2427,  0.0147],\n","         ...,\n","         [ 0.2824,  0.1018, -0.2002,  ..., -0.3588, -0.1922,  0.5668],\n","         [-0.0596,  0.0149, -0.5999,  ...,  0.0243, -0.3363, -0.4875],\n","         [-0.8100,  0.0829, -0.1574,  ..., -0.0282,  0.3973, -0.0414]],\n","\n","        [[ 0.0300,  0.1680,  0.2397,  ...,  0.1302,  0.4627, -0.1095],\n","         [ 0.1384,  0.1105, -0.3224,  ..., -0.3292, -0.0745, -0.3447],\n","         [ 0.0623, -0.0962, -0.0466,  ...,  0.2160, -0.1187, -0.1415],\n","         ...,\n","         [-0.1383, -0.1574, -0.1338,  ...,  0.1024, -0.0672,  0.2168],\n","         [-0.0813, -0.3627, -0.0701,  ..., -0.0735,  0.1483,  0.1813],\n","         [ 0.2793,  0.1252, -0.0929,  ...,  0.2450, -0.0311,  0.0170]],\n","\n","        ...,\n","\n","        [[-0.0441, -0.0750, -0.0318,  ...,  0.1809, -0.1900,  0.1294],\n","         [-0.3291,  0.1984,  0.0136,  ..., -0.2118, -0.2504, -0.1287],\n","         [-0.2582, -0.1068,  0.0329,  ..., -0.1194,  0.0697, -0.0785],\n","         ...,\n","         [ 0.1144,  0.2171, -0.0321,  ...,  0.0156,  0.1308, -0.1626],\n","         [-0.0943,  0.0766, -0.2175,  ..., -0.0617, -0.2180, -0.1426],\n","         [ 0.0790, -0.1009, -0.1577,  ...,  0.0080,  0.0497, -0.3096]],\n","\n","        [[ 0.0520,  0.1072, -0.0692,  ...,  0.1219,  0.0682,  0.1270],\n","         [-0.2197,  0.0738,  0.2174,  ...,  0.0620,  0.1358,  0.0070],\n","         [-0.0163,  0.0400, -0.1070,  ...,  0.0668,  0.1257, -0.1645],\n","         ...,\n","         [-0.0399,  0.3653,  0.1956,  ..., -0.1074, -0.2026,  0.0540],\n","         [-0.0119,  0.1274, -0.0934,  ..., -0.0842, -0.0156, -0.1885],\n","         [ 0.1113, -0.0420, -0.0402,  ...,  0.1622,  0.0130,  0.0705]],\n","\n","        [[ 0.0970,  0.0010,  0.1348,  ...,  0.3237, -0.0483, -0.2235],\n","         [ 0.0752,  0.1861,  0.2131,  ..., -0.0770, -0.1492,  0.1507],\n","         [ 0.3131, -0.0067,  0.0366,  ..., -0.1235, -0.1660, -0.0480],\n","         ...,\n","         [-0.1410,  0.0213, -0.0739,  ..., -0.0335,  0.1455,  0.0333],\n","         [ 0.1232, -0.0055, -0.1912,  ...,  0.0827, -0.0533, -0.0071],\n","         [-0.0636,  0.0071, -0.0675,  ...,  0.2170,  0.1470, -0.0557]]],\n","       device='cuda:0', requires_grad=True)\n","W_O: torch.Size([12, 64, 768])\n","Parameter containing:\n","tensor([[[ 3.1272e-01, -1.8741e-01,  9.8025e-02,  ..., -1.1971e-02,\n","           9.3704e-03, -3.0943e-02],\n","         [-2.4419e-01, -1.9777e-01, -1.0981e-01,  ..., -1.6192e-02,\n","           2.5013e-02,  4.5859e-02],\n","         [-4.3006e-01,  1.5439e-01,  5.3782e-02,  ...,  1.4303e-02,\n","          -1.8077e-02, -1.5850e-03],\n","         ...,\n","         [-2.2143e-01,  2.5489e-01, -5.8059e-02,  ...,  2.4717e-02,\n","          -1.7435e-02, -4.2810e-02],\n","         [ 3.6620e-01, -2.2027e-01,  2.4277e-02,  ..., -2.1455e-04,\n","          -1.2749e-02,  2.0263e-02],\n","         [-4.1327e-03,  2.6353e-02, -1.7697e-01,  ...,  8.6689e-04,\n","          -2.0991e-02,  6.0998e-02]],\n","\n","        [[ 5.8308e-02,  7.7636e-02, -1.1319e-01,  ...,  2.5356e-02,\n","          -1.7026e-02,  1.7903e-02],\n","         [-3.8657e-01, -2.2992e-01,  4.5555e-02,  ...,  6.4866e-03,\n","          -7.9225e-03, -1.5126e-03],\n","         [-4.4323e-01, -3.0024e-02, -4.3540e-02,  ...,  1.2371e-03,\n","           1.9133e-02, -2.5781e-02],\n","         ...,\n","         [ 2.8262e-01,  1.1980e-01, -9.3027e-02,  ..., -3.0108e-02,\n","          -7.3077e-03,  6.6691e-03],\n","         [ 2.7075e-01,  1.8569e-03, -6.6830e-02,  ...,  9.3208e-04,\n","          -2.4171e-03,  4.9934e-02],\n","         [-2.3825e-01,  1.5188e-01, -6.3101e-02,  ...,  2.0630e-02,\n","          -1.4852e-02,  1.2316e-02]],\n","\n","        [[-4.9522e-01,  6.9678e-02,  2.1425e-01,  ..., -1.1630e-02,\n","           1.8950e-02,  5.1431e-03],\n","         [-1.3188e-01, -1.2297e-01, -1.3100e-01,  ..., -9.9798e-03,\n","           1.3407e-02,  3.5966e-02],\n","         [-7.2331e-02, -3.6855e-02,  4.1451e-03,  ..., -3.3576e-02,\n","           1.6728e-02,  1.7339e-03],\n","         ...,\n","         [ 1.4638e-01,  4.2206e-02,  4.5980e-02,  ...,  2.8937e-02,\n","          -1.2955e-04, -5.7906e-02],\n","         [ 3.6827e-01,  6.4958e-02,  1.4221e-01,  ...,  7.3958e-03,\n","           2.9342e-04, -3.2309e-02],\n","         [-4.7313e-01,  8.3574e-02, -9.9833e-02,  ..., -2.6717e-03,\n","           1.7422e-03, -1.7442e-02]],\n","\n","        ...,\n","\n","        [[ 3.4871e-01, -4.8244e-02, -2.8313e-01,  ...,  1.8609e-02,\n","           2.6345e-02, -5.9869e-02],\n","         [-8.4099e-02, -1.9906e-01, -4.1688e-02,  ..., -2.3513e-02,\n","           4.6516e-02, -2.4519e-02],\n","         [ 1.1066e-01,  2.2052e-01,  8.8997e-02,  ..., -2.7072e-02,\n","           6.8084e-02,  6.8808e-03],\n","         ...,\n","         [-2.1272e-02, -1.4236e-01,  8.9165e-02,  ..., -3.5805e-02,\n","           1.7032e-02,  2.4314e-02],\n","         [ 3.3580e-01, -9.1382e-02,  1.0919e-01,  ...,  8.8078e-03,\n","           3.8422e-03, -1.4863e-02],\n","         [-1.1315e-01, -1.9503e-01,  7.5385e-02,  ...,  2.8872e-02,\n","          -6.2511e-03, -1.1036e-02]],\n","\n","        [[ 5.4502e-01, -2.3857e-01,  3.2197e-01,  ...,  8.8920e-03,\n","          -2.0044e-02, -4.3923e-02],\n","         [ 6.6756e-02, -1.0728e-01, -2.8115e-02,  ...,  2.9821e-02,\n","          -4.5180e-02,  2.1467e-02],\n","         [ 2.4556e-01, -4.2639e-03, -6.8065e-02,  ..., -5.7802e-03,\n","          -1.2425e-02,  2.6301e-02],\n","         ...,\n","         [ 8.5386e-02,  2.4227e-01,  2.1937e-01,  ...,  2.6177e-02,\n","           7.7584e-03, -3.2979e-02],\n","         [-4.0490e-01, -2.5709e-01, -4.1716e-01,  ...,  3.5117e-02,\n","           3.6139e-02, -3.2679e-02],\n","         [ 2.8257e-02, -2.6487e-01, -8.0950e-03,  ..., -1.1467e-02,\n","          -1.1981e-02,  1.4431e-02]],\n","\n","        [[-5.7136e-02, -1.5847e-01,  1.4314e-02,  ...,  2.8972e-02,\n","          -6.0841e-03, -1.3391e-02],\n","         [-1.7294e-02,  1.7961e-01, -3.1109e-02,  ...,  1.5171e-02,\n","          -9.4450e-03, -1.4514e-02],\n","         [ 3.8611e-01, -1.2346e-01, -9.1878e-02,  ..., -3.1149e-03,\n","           2.5884e-02, -1.5317e-02],\n","         ...,\n","         [ 2.0241e-02,  1.9843e-01, -1.4822e-01,  ...,  2.3511e-02,\n","           1.0698e-02, -1.4997e-02],\n","         [ 1.7072e-02,  2.5236e-02, -1.8414e-02,  ..., -8.3186e-04,\n","           8.5938e-03,  4.9588e-03],\n","         [-1.0107e-01, -7.3497e-02, -2.3746e-03,  ...,  6.2539e-03,\n","           1.3171e-02, -1.7136e-02]]], device='cuda:0', requires_grad=True)\n","b_Q: torch.Size([12, 64])\n","Parameter containing:\n","tensor([[ 4.8034e-01, -5.2543e-01, -4.2926e-01, -2.0595e-01, -1.2773e-01,\n","         -9.5427e-02, -3.5286e-01, -7.6463e-02, -4.5903e-02, -3.7529e-02,\n","         -1.3764e-02, -1.8478e-01, -1.1984e-01,  4.3963e-02,  4.2387e-02,\n","         -3.1302e-01,  1.6617e-02,  3.4909e-01, -3.9035e-01, -2.9889e-02,\n","          3.2862e-01,  1.1589e-01,  3.9021e-02,  1.3165e-01,  4.7540e-02,\n","         -1.2425e-01, -5.6136e-03, -1.4189e-01,  7.2825e-02,  1.3007e-01,\n","          4.6424e-01,  1.2814e-01,  5.7617e-01, -7.8620e-02, -5.6898e-01,\n","          2.5124e-02, -1.7923e-01, -2.0682e-01,  7.4427e-03,  2.9733e-02,\n","          1.7158e-02, -2.1490e-01, -6.2546e-02, -3.0948e-01,  1.2339e-01,\n","          2.1800e-01, -2.0176e-01,  2.5512e-01,  3.0168e-01, -2.8991e-01,\n","         -7.2179e-02,  1.5271e-01, -4.3990e-01, -2.2504e-02, -7.7784e-03,\n","         -5.0913e-01,  3.3491e-02, -1.1896e-01, -1.7937e-01, -3.3981e-01,\n","          3.5737e-01, -1.4809e-02,  5.0830e-01, -3.7198e-01],\n","        [-1.3983e-01,  5.1359e-01,  3.3090e-01,  1.5325e-01, -1.4920e-01,\n","         -3.3196e-01, -1.8601e-01, -8.6125e-02, -1.0644e-01,  7.9037e-02,\n","          3.6985e-02, -6.2770e-01,  5.5906e-01, -2.4101e-02,  2.3281e-02,\n","         -2.0543e-01,  7.5957e-02, -6.2597e-01,  2.3449e-01,  3.8095e-01,\n","         -2.3169e-01,  3.0494e-01, -5.4135e-01,  5.7115e-01,  2.0921e-01,\n","         -1.6429e-01,  6.4578e-01, -4.5198e-01, -3.4131e-01,  6.0828e-01,\n","          3.7996e-01,  5.7257e-01,  2.0522e-01, -1.7261e-01, -3.1178e-01,\n","          4.9210e-01, -3.9706e-01, -4.1385e-01, -1.7035e-02, -8.7229e-02,\n","         -2.7808e-01,  4.5287e-01, -3.1084e-01, -2.7139e-01,  2.0705e-01,\n","          5.0846e-01, -5.9041e-02, -1.8066e-01, -3.5574e-01, -2.2511e-01,\n","         -5.8524e-02, -1.6331e-01, -7.3097e-01,  2.2229e-01, -5.6816e-01,\n","          5.9884e-01,  1.7029e-01, -2.2603e-01,  6.3138e-02,  3.0579e-01,\n","         -2.4425e-01,  2.8380e-01, -6.8781e-01,  1.0613e-01],\n","        [-8.8029e-02,  1.5084e-01,  2.7636e-02, -7.1769e-01, -2.3159e-01,\n","          8.8806e-01,  1.9228e-01,  2.5255e-02, -1.2168e-01,  8.3731e-03,\n","         -2.2069e-01,  2.8187e-01,  2.7179e-01,  5.9855e-02, -2.5361e-01,\n","         -4.0518e-02, -1.3738e-01, -2.2256e-01,  7.1839e-01,  1.5637e-01,\n","         -3.1278e-01, -2.8058e-02,  1.3255e-01,  3.4142e-02,  2.6752e-02,\n","          6.1431e-02,  4.6812e-01,  1.0356e-02, -7.2573e-02,  1.4845e-02,\n","         -5.1681e-02,  1.5441e-01, -5.2975e-02,  3.5818e-01, -2.0492e-01,\n","         -3.8218e-01,  1.1988e-01,  2.5387e-01, -4.4802e-01, -1.7383e-01,\n","          2.6652e-01,  1.5616e-01,  2.2597e-01,  5.1873e-02,  1.4430e-01,\n","          7.6146e-02,  4.3709e-04,  6.0145e-02, -2.0164e-02, -2.1497e-01,\n","          6.2185e-03, -1.7246e-01,  9.2442e-02,  4.1088e-01, -1.7659e-01,\n","         -1.6535e-01,  1.9143e-01,  1.5482e-01, -3.8666e-01,  2.1575e-01,\n","         -5.8591e-01,  8.6476e-01, -4.1112e-01, -2.6192e-01],\n","        [ 7.6061e-02,  4.6999e-01,  5.7941e-01, -5.8563e-01,  7.8277e-01,\n","          5.7127e-01,  3.0230e-01,  5.2114e-01, -4.1103e-01, -4.1959e-01,\n","          8.8694e-02, -2.4452e-01, -2.8428e-01,  5.7149e-01,  8.2365e-02,\n","         -8.7333e-01,  3.5083e-01,  3.6120e-01,  1.3848e-01, -5.1687e-01,\n","          3.3451e-01, -3.2931e-01,  4.2908e-01, -3.4908e-01,  4.6058e-01,\n","         -5.7268e-01,  2.2023e-01,  2.0118e-01,  2.1122e-01,  7.6675e-01,\n","          5.0306e-01, -3.7580e-01, -4.6498e-01,  6.7782e-02,  5.1094e-01,\n","          5.6167e-01, -4.6174e-01, -1.2612e-01,  3.0556e-01, -1.3881e-01,\n","         -3.6857e-01, -1.2582e-01,  4.0164e-01, -4.0041e-01, -3.7102e-01,\n","          3.5822e-01,  4.7141e-01, -2.2665e-01, -8.5280e-02, -5.9138e-01,\n","          4.2688e-01, -7.3300e-01,  4.1458e-01,  8.7045e-01, -2.1854e-02,\n","         -6.0966e-01, -9.6922e-01, -3.5682e-01, -2.6823e-01,  7.5735e-01,\n","          4.3039e-01,  3.0336e-01,  1.2832e-01,  4.2054e-01],\n","        [ 2.4785e-01, -1.8676e-01, -7.0033e-02, -2.4694e-01,  1.4793e-01,\n","         -3.1935e-02,  2.8041e-01,  1.5225e-01,  5.1934e-01,  3.1919e-01,\n","          2.5960e-01,  7.2202e-02, -2.1085e-01,  6.6824e-02, -7.6946e-02,\n","         -2.9268e-01,  3.8642e-01, -1.7592e-01, -6.4686e-02,  1.3050e-03,\n","          2.1800e-01, -4.4417e-01,  7.2554e-02,  8.9707e-02, -1.9961e-01,\n","         -2.7006e-01,  2.2447e-01,  7.1952e-02,  3.3780e-01,  3.1084e-02,\n","         -5.3742e-01,  5.2338e-01,  5.1073e-02, -2.3977e-01, -1.0548e-01,\n","         -2.6422e-01,  3.5951e-01,  4.6438e-02, -6.3078e-02, -2.5145e-01,\n","         -2.4547e-01, -1.9121e-01, -1.8918e-01, -1.5513e-01, -2.1501e-01,\n","         -1.0108e+00,  6.4759e-01,  7.5585e-02, -2.7373e-01,  3.2820e-01,\n","         -3.9734e-01, -2.4839e-01,  3.8320e-01,  1.1867e-01,  4.7945e-01,\n","          5.1650e-01,  3.5161e-01,  3.0847e-01, -2.2487e-01,  8.4027e-03,\n","          3.7940e-01, -2.5984e-01, -1.4136e-01, -4.3798e-01],\n","        [-3.7580e-01, -3.6739e-01,  1.8203e-01, -3.9757e-01,  5.0669e-01,\n","          1.7914e-01,  1.4368e-01,  1.3952e-01,  1.8595e-01,  1.0564e-02,\n","          5.0753e-01, -2.8746e-01, -6.2951e-01,  3.2340e-01,  2.8527e-01,\n","         -3.3051e-01, -3.2315e-01, -1.7267e-01,  2.5108e-01, -4.1324e-01,\n","         -3.1516e-01,  4.9194e-01, -2.8950e-01,  2.2953e-01,  4.7758e-01,\n","         -6.2161e-01, -4.0084e-01,  1.7936e-01,  4.6028e-01, -5.5761e-01,\n","          4.5172e-01, -1.7846e-01, -6.5331e-01,  3.1335e-01,  2.8416e-01,\n","          3.9095e-01, -5.4154e-01, -3.7265e-01, -3.8286e-01,  1.8058e-01,\n","         -4.9199e-01, -3.4491e-01,  1.8438e-01,  5.8507e-01, -2.9816e-01,\n","          4.1760e-01, -5.4493e-01, -9.1039e-02, -5.0361e-02, -1.7122e-02,\n","         -3.0516e-01,  1.9027e-01,  2.2699e-01, -4.0413e-01,  4.5390e-01,\n","          2.1276e-02, -6.1500e-01, -2.2133e-01, -7.9023e-02,  3.1206e-01,\n","         -3.6949e-01, -4.4751e-01,  4.3374e-01, -3.5588e-01],\n","        [ 1.1294e-01,  2.9429e-01, -1.2129e-01, -4.0726e-01,  6.1205e-01,\n","         -5.1877e-02,  1.5219e-01, -1.5227e-01,  1.9754e-02,  5.5457e-02,\n","         -5.8312e-01, -6.9946e-01, -7.3617e-02, -1.5286e-01,  2.3285e-01,\n","          2.4217e-01,  2.2739e-02,  1.3377e-01, -5.1426e-03, -2.0444e-01,\n","         -8.6679e-02, -1.3361e-01, -3.5504e-01, -5.9695e-02,  8.0210e-02,\n","         -2.7050e-01,  8.1510e-02,  1.6372e-02,  1.2790e-01,  6.0249e-02,\n","         -2.2664e-01,  1.9956e-02, -5.8410e-01, -4.1983e-02, -4.0586e-01,\n","         -2.7357e-01,  9.1592e-02, -4.1586e-01,  6.3785e-02, -7.7040e-02,\n","         -3.7461e-01, -5.0191e-01, -5.4477e-01, -5.5283e-01, -4.7832e-02,\n","          1.8347e-01,  2.8035e-02,  2.8561e-01,  6.5527e-01,  3.0235e-01,\n","         -1.1998e-01,  7.1491e-01, -6.4967e-03,  1.0605e-01,  3.3150e-02,\n","          1.7346e-02,  5.2652e-02, -2.8201e-01, -2.1088e-01,  1.6994e-01,\n","          2.5492e-01, -8.1045e-02, -6.7263e-02,  1.9206e-01],\n","        [-3.7052e-02, -1.4550e-01,  3.9940e-01,  7.4355e-03,  1.5398e-01,\n","         -3.4439e-01, -3.2062e-01, -4.3249e-01, -2.3742e-01, -1.5198e-01,\n","          1.1749e+00,  5.4593e-01,  5.7808e-01,  6.9789e-01,  3.2429e-01,\n","          5.0548e-01,  2.4306e-01, -1.6576e-01, -3.3574e-01,  3.4647e-01,\n","         -8.8720e-01, -4.9292e-01,  3.4503e-02, -7.8786e-01, -1.7658e-01,\n","         -5.3449e-01, -3.2129e-01, -2.7833e-01,  4.7001e-02, -1.9856e-01,\n","         -1.7582e-01,  1.1531e-01, -4.2795e-02,  1.6039e-01,  7.9992e-02,\n","         -1.9266e-01,  4.4587e-01,  1.9195e-01,  5.3466e-01,  1.1686e-02,\n","          5.3047e-02, -3.0055e-01, -4.5209e-01, -4.4215e-01,  1.9119e-01,\n","         -2.7630e-02,  1.1421e+00, -4.2769e-01,  3.8372e-01,  7.3133e-01,\n","         -9.9823e-02, -1.1944e-01,  4.6980e-01, -8.4147e-01,  5.1113e-01,\n","          4.1706e-01, -2.8938e-02, -2.5926e-01, -2.3111e-01, -2.2068e-01,\n","         -1.9674e-01, -9.8343e-01, -1.7156e-01,  3.3313e-01],\n","        [ 6.4723e-02,  9.1155e-01,  7.0202e-03,  2.2360e-01, -3.2185e-02,\n","          2.9267e-01, -2.8345e-01, -3.6001e-01,  3.5596e-01,  2.5579e-01,\n","         -1.6032e-01,  7.2756e-03, -2.5692e-02,  1.3010e-01,  1.0155e-01,\n","          6.8877e-02, -2.6390e-02,  1.4527e-02,  2.0345e-01,  6.8162e-01,\n","          1.7099e-03,  3.6466e-01,  2.4010e-01,  2.3739e-02, -4.4478e-02,\n","          2.1254e-01,  3.3663e-02, -4.4114e-01, -3.6727e-02,  2.2023e-01,\n","         -4.9153e-01,  4.3373e-01,  3.7900e-01, -1.5638e-01,  2.2619e-01,\n","         -2.9947e-01,  3.3441e-01, -5.2019e-02, -1.1684e-02, -7.3780e-03,\n","         -2.5564e-01,  5.7980e-01,  8.7041e-03,  2.5658e-02, -7.1800e-01,\n","         -1.0552e-01, -4.5050e-01,  1.5571e-01,  8.2267e-02,  8.1125e-02,\n","         -1.1163e-01, -1.1316e-01, -1.0333e-01, -2.3050e-01, -3.0885e-01,\n","         -6.0399e-01,  2.2911e-02, -3.8446e-02, -4.7104e-02,  4.9468e-01,\n","         -1.3787e-01, -3.4314e-01, -3.2522e-01, -1.6676e-01],\n","        [ 1.1005e-01,  6.3299e-02, -4.2597e-02, -7.4602e-02,  1.7986e-02,\n","         -1.7774e-02, -2.8738e-01,  2.4689e-02,  5.0422e-02, -8.4619e-01,\n","          3.1083e-01,  3.2013e-01, -1.0203e+00,  7.7646e-01,  9.3977e-01,\n","         -1.2021e+00,  7.4877e-02, -9.9773e-02, -7.1127e-01,  4.4339e-02,\n","         -7.0945e-01, -1.8987e-02,  1.5529e-02,  7.0146e-01, -1.4438e-01,\n","          5.5465e-01,  6.4763e-02,  7.6838e-02, -6.9392e-02, -3.6403e-02,\n","         -1.5263e-01, -1.4138e-01,  4.8700e-02, -7.7318e-02, -7.8929e-03,\n","          1.4009e-01, -2.7806e-02,  1.0034e-01,  4.6883e-02, -3.7525e-01,\n","         -2.3499e-02,  3.0700e-02, -9.7449e-03, -1.4459e-02, -8.9532e-01,\n","          2.8193e-02, -1.0117e+00, -7.0924e-01,  1.6950e-04, -3.2936e-02,\n","         -5.0908e-02, -2.4585e-02,  3.6472e-01,  4.7568e-01, -1.2538e+00,\n","          8.3338e-03,  3.0914e-02, -1.0036e-02,  2.4052e-01, -1.3898e-02,\n","         -6.3896e-02, -7.6461e-01, -9.6681e-02, -7.8708e-02],\n","        [-9.6498e-02,  1.5405e-01,  1.4264e-01,  2.6533e-01,  4.5209e-02,\n","         -6.7083e-02,  6.3727e-02,  1.4742e-01, -7.9848e-02, -5.5552e-01,\n","         -1.0777e-03,  8.6654e-02, -3.0767e-01, -3.5340e-02,  5.7955e-01,\n","         -1.0124e-01, -1.5417e-01, -4.6698e-01, -7.3876e-02,  3.0894e-01,\n","         -3.8221e-02,  9.4444e-02,  6.2752e-01,  9.3133e-02, -1.5690e-01,\n","          3.0822e-02,  1.1124e-01, -7.5529e-02, -1.3586e-02,  1.1715e-01,\n","         -4.8662e-02,  3.9252e-01, -1.7008e-01,  2.0310e-01, -9.6492e-03,\n","         -1.1988e-02, -1.8604e-02,  1.6444e-01, -2.9892e-01, -1.8193e-01,\n","          2.6592e-01, -4.0409e-01,  2.1287e-01,  4.4472e-01, -2.7851e-03,\n","         -1.4501e-01, -2.2042e-01, -1.6609e-01,  1.3438e-01, -5.0159e-02,\n","         -2.4091e-01, -4.9713e-02,  4.5848e-01, -2.7246e-01, -2.4162e-01,\n","         -2.6105e-01,  1.7524e-02,  1.7405e-01,  3.2181e-01, -1.9042e-01,\n","          1.1384e-01,  2.0406e-01, -1.3203e-01, -1.8943e-01],\n","        [-7.6027e-02, -3.2096e-01,  2.9128e-01,  7.9369e-01,  8.7117e-02,\n","          2.4833e-01, -3.6272e-01, -1.2666e-01,  3.5840e-01,  3.1970e-01,\n","         -2.7805e-01, -4.6170e-02,  1.0231e-01,  2.7067e-02,  4.0887e-01,\n","          8.4146e-02, -3.8595e-01,  1.4069e-01, -6.6050e-02, -2.0798e-02,\n","         -3.8087e-02,  6.5006e-01, -6.9818e-01,  3.2144e-01, -9.5315e-02,\n","         -6.2110e-01,  2.5399e-01, -1.6755e-01, -7.5629e-03,  2.4248e-01,\n","         -1.3640e-01,  7.4428e-02,  1.9353e-01,  8.1436e-01,  3.1867e-01,\n","         -9.9197e-02, -3.6758e-02,  7.4111e-04,  1.1579e-01,  1.2330e-01,\n","         -1.4138e-01,  7.3662e-01, -5.1074e-01,  2.6983e-01,  2.9565e-01,\n","          4.2451e-01, -7.6297e-02,  4.7043e-01, -4.9620e-02, -1.4250e-01,\n","         -2.1484e-02,  9.4781e-02,  1.7125e-02, -1.3213e-02,  5.0710e-02,\n","         -5.9523e-01, -4.1019e-02,  3.4782e-02, -3.2111e-02,  8.3402e-02,\n","          1.8872e-02,  2.7613e-01, -4.2302e-01, -2.3774e-01]], device='cuda:0',\n","       requires_grad=True)\n","b_O: torch.Size([768])\n","Parameter containing:\n","tensor([ 2.5374e-01,  2.4794e-02,  3.1690e-02, -4.6175e-02,  1.9516e-02,\n","        -5.5722e-03, -5.2921e-02, -3.0751e-01, -9.3767e-02, -8.9388e-03,\n","         3.2707e-02, -2.0272e-02, -5.9371e-03,  2.9929e-02, -3.0915e-02,\n","         1.2461e-02, -2.8058e-01, -3.2872e-02,  1.2328e-02,  1.5360e-01,\n","        -4.2876e-02, -4.2509e-02,  9.6932e-03,  8.2421e-02,  3.2696e-02,\n","        -1.5786e-02,  1.2105e-01,  4.3305e-02, -9.5465e-04,  2.9163e-02,\n","         3.9636e-02,  3.1295e-04,  5.9767e-02, -1.2767e-02, -2.7767e-02,\n","         2.0545e-01, -1.4840e-01, -1.1687e-02, -1.7156e-02,  4.4442e-02,\n","        -8.0545e-03,  5.6056e-02,  6.8887e-02,  1.2721e-02,  1.2412e-01,\n","         1.5628e-03,  2.0524e-02,  5.0395e-02,  1.2964e-01,  4.8385e-02,\n","         6.1729e-02,  1.9221e-02,  9.7316e-02,  4.4852e-03, -1.2879e-03,\n","         1.6429e-01,  8.6170e-02,  4.1258e-01, -8.9540e-04, -5.2632e-01,\n","         7.7984e-02,  5.0939e-02, -4.1453e-01, -3.0127e-01, -7.5006e+00,\n","        -8.0472e-03,  2.0907e-02,  2.8549e-01, -3.1498e-02, -1.8963e-02,\n","        -1.0227e-01, -1.2167e-01,  2.4450e-02, -2.4382e-02,  1.5858e-02,\n","        -2.4826e-03,  1.1994e-01, -2.0819e-01,  1.0552e-01, -2.1674e-02,\n","        -1.2650e-01, -4.3192e-02, -2.2887e-03, -1.1687e-02,  1.5473e-02,\n","        -2.3003e-01, -3.0322e-01, -2.8087e-01, -3.0249e-03, -2.6005e-02,\n","        -3.4768e-02, -1.8432e-02,  2.8537e-02, -1.9037e-02, -1.2880e-02,\n","        -2.5000e-03, -7.1764e-02, -3.1585e-01,  4.0156e-02,  1.7289e-01,\n","         1.5718e-02,  1.1187e+00,  6.7725e-02, -9.7948e-02, -2.3373e-02,\n","         1.3390e-03, -1.9646e-02, -5.9386e-02, -7.4458e-03,  1.4509e-02,\n","         9.6609e-02, -4.5561e-03, -2.0569e-02,  1.2750e-02,  1.3785e-02,\n","        -8.1152e-02, -1.5221e-01,  2.4717e-01, -1.4793e-02, -2.5687e-01,\n","         2.5939e-02, -2.4082e-02, -2.0682e-02, -4.1450e-02,  3.6176e-02,\n","         1.0053e-02, -6.9045e-04, -2.1593e-02, -1.6977e-01,  3.4652e-01,\n","        -1.0934e-02, -5.7180e-03, -3.1605e-01, -2.1624e-03,  1.1932e-02,\n","         1.3471e-02,  1.1687e-02, -3.7296e-01,  4.7103e-04, -2.2087e-01,\n","         3.8064e-02, -5.2716e-03,  8.8445e-02,  4.6333e-03, -4.5998e-03,\n","         2.9789e-03,  6.0275e-02, -1.0076e-02, -2.3094e-02, -9.4509e-02,\n","        -2.6687e-03,  5.5861e-01, -1.6595e-01, -4.1933e-02, -2.6646e-02,\n","        -3.2063e-03, -6.8776e-02,  2.8888e-02,  1.6846e-02, -3.5564e-02,\n","         1.7001e-01, -3.5249e-02,  6.6885e-03,  1.4114e-01, -3.4772e-02,\n","        -4.2299e-02,  5.7048e-03, -1.2496e+00, -1.4379e-02,  7.0992e-02,\n","         1.5873e-02,  5.8837e-02,  4.5976e-02, -1.2096e-02, -1.1481e-01,\n","        -9.8851e-02, -2.3341e-01, -1.4075e-02, -1.2173e-01, -4.4334e-02,\n","        -4.7474e-02,  2.3267e-03,  2.3181e-02, -6.0140e-02,  2.6897e-02,\n","        -4.0024e-02, -4.2974e-03, -2.0551e-01,  3.4349e-02, -5.6289e-02,\n","        -1.9750e-02,  5.8230e-02, -3.7984e-02,  4.0840e-02,  1.9036e-02,\n","        -9.5958e-01,  1.8793e-02,  8.1318e-02, -1.2844e-02, -4.0626e-02,\n","         1.2821e-01,  5.5704e-02,  1.5925e-02,  2.5981e-02, -3.8428e-02,\n","         2.8168e-02, -2.5215e-02,  1.1214e-02,  3.8639e-01, -2.3091e-02,\n","         2.0086e-02,  1.8841e-01,  3.1024e-02,  3.8890e-01, -2.0162e-02,\n","         5.0099e-03, -1.6488e-01,  1.4281e-02, -4.1689e-01, -3.3016e-02,\n","         3.6843e-02,  1.8634e-02,  1.8470e-02, -2.7166e-02, -4.3973e-02,\n","         9.1696e-03,  1.7126e-02, -3.4256e-02,  2.3658e-02, -3.1892e-02,\n","        -3.8627e-03, -1.6185e-01, -7.6916e-02,  1.7816e-03, -2.4084e-02,\n","        -1.4071e-01, -2.7465e-02, -3.8552e-03,  6.9264e-04, -2.6897e-02,\n","         9.4169e-03, -1.6290e-01, -4.7233e-02, -2.2548e-02,  4.7579e-03,\n","        -3.4122e-02, -4.0181e-02,  1.4766e-01, -1.7182e-02,  1.4172e-01,\n","         8.1138e-02,  6.0492e-02, -1.3509e-02, -9.3995e-02, -2.6451e-02,\n","        -2.2389e-01,  4.1083e-02,  5.2478e-02,  1.9497e-02, -5.7925e-02,\n","        -8.4780e-04, -1.0324e-01, -1.7628e-02, -3.1616e-02,  4.5298e-02,\n","         6.6292e-02, -2.0265e+00, -1.6388e-02,  2.0627e-01, -2.9492e-01,\n","        -5.1711e-01,  3.6803e-01, -2.5975e-02, -6.0137e-02,  1.1372e-01,\n","        -4.7635e-02,  4.7297e-01, -4.0770e-02,  1.8609e-02,  1.6743e-02,\n","        -1.4050e-02, -4.1919e-02, -4.1901e-02, -1.1950e+00,  8.5241e-02,\n","         1.6275e-01, -1.3336e-03,  5.3697e-03,  5.0689e+00,  7.5798e-03,\n","        -2.1499e-01,  3.1239e-02, -2.4495e-02,  1.5179e-02, -1.2710e-01,\n","         2.3629e-02, -6.4854e-03,  2.0392e-02,  4.5168e-02, -5.4861e-02,\n","         4.4420e-01, -3.7208e-02,  2.2593e-01, -5.1001e-03,  2.8140e-02,\n","         3.6339e-02,  5.0528e-03, -3.2099e-02,  1.4354e-01, -4.3434e-03,\n","        -1.9382e-02, -3.6059e-01, -3.4850e-02,  1.9714e-02,  2.2051e-02,\n","        -5.8933e-02,  1.6541e-01, -1.5341e-02, -5.0011e-02,  5.6867e-03,\n","        -8.2993e-02,  1.0203e-02,  2.9107e-02,  1.1222e-01,  7.7097e-02,\n","         2.1994e-02,  8.8074e+00, -3.3671e-02, -1.5785e-01,  9.9588e-03,\n","         2.7764e-02,  7.2342e-03,  4.0191e-02, -4.5219e-04,  1.0835e-02,\n","         2.3120e-02, -2.7623e-01,  2.2024e-03, -4.1929e-02,  1.0457e-01,\n","        -2.1361e-02, -7.3781e-03,  2.3411e-03,  1.5748e-02, -3.4218e-02,\n","         1.3394e-03, -2.6615e-03,  7.1672e-02,  2.6650e-03, -6.2284e-02,\n","        -1.1170e-02,  8.7955e-01,  8.0059e-03, -3.2074e-02,  2.2390e-03,\n","         3.8451e-02,  5.1203e-02,  9.7503e-03,  2.2972e-02,  2.3603e-02,\n","        -3.4408e-01,  1.0236e-02,  7.7165e-03, -1.6074e-02,  1.2346e-02,\n","        -7.0606e-02, -2.6093e-03,  2.0864e-03,  3.7954e-02,  3.1590e-02,\n","        -2.4956e-02,  3.6662e-02, -3.9980e-02, -9.5716e+00,  3.0861e-02,\n","        -1.5403e-01,  1.6102e-01,  4.0531e-02, -3.3385e-02,  1.4855e-02,\n","        -1.6538e-02,  6.2154e-02, -4.1968e-02, -1.0477e-01,  1.9730e-02,\n","         4.3321e-01,  5.0425e-02,  1.5911e-02, -5.8141e-03,  1.2477e-01,\n","         2.7628e-03,  4.1284e-02,  5.4919e-02,  3.1818e+00,  6.0226e-03,\n","        -1.2002e-03, -1.1477e-01,  1.7461e-03, -1.2267e-03, -3.7794e-02,\n","         4.8236e-03,  3.3411e-02, -1.1406e-01, -3.3255e-02, -5.2646e-03,\n","        -6.7249e-03, -1.7821e-02, -9.6888e-03, -4.8811e-02,  1.1461e-02,\n","        -3.9963e-02,  2.1030e-02,  2.4021e-02, -3.0432e-02, -3.4299e-02,\n","         1.2194e-01, -3.4922e-02, -8.7520e-02, -2.7475e-01, -3.8138e-03,\n","        -7.1941e-01, -2.2792e-01, -4.1753e-02,  4.0583e-02, -1.0200e-02,\n","         1.2540e-02,  4.9312e-03,  2.1789e-02,  6.1255e-02,  4.6432e-03,\n","        -4.1233e-02,  9.9343e-02,  9.3497e-02,  1.6039e-02, -3.4273e-02,\n","         9.5557e-03, -3.6950e-02, -4.5939e-02,  1.6920e-01, -3.0385e-01,\n","        -1.3053e-02,  5.7263e-02,  9.8998e-03, -7.3113e-02,  1.5906e-01,\n","        -3.7183e-02, -3.5040e-02,  9.6267e+00, -1.5517e-02, -6.2628e-03,\n","        -1.7525e-01, -1.0507e-02,  1.1985e-02,  1.3068e-02, -4.7502e-02,\n","         1.6007e-02, -2.3973e-01,  5.1441e-02, -1.8348e-02,  6.6784e-02,\n","         3.4461e-02, -2.8933e-02,  2.2800e-02, -1.0851e-02,  1.1980e+00,\n","         6.0356e-02,  1.2533e-02,  2.1210e-02, -2.5296e-02,  2.3668e-03,\n","         1.3391e-02, -2.6209e-02,  6.1973e-02, -2.0100e-02,  4.0779e-02,\n","        -3.7512e-03, -1.8001e-02, -2.1072e-02,  3.3751e-02,  7.5610e-02,\n","        -2.8288e+00,  7.5007e-01,  3.4711e-03,  2.2370e-02,  2.1345e-01,\n","         8.6689e-03, -2.9068e-02, -4.4047e-02, -2.5834e-01,  1.2111e-02,\n","         1.4593e-02, -2.1555e-01,  1.4794e-02,  1.2208e-02,  2.6792e-02,\n","        -1.7290e-02,  4.3109e-02, -2.1538e-01, -1.1718e-01,  2.1369e-02,\n","         2.3976e-02,  2.6593e-02,  4.7403e-03, -9.7190e-02,  1.1476e-01,\n","         5.0127e-02,  6.4895e-02,  4.8329e-03, -6.5535e-02, -1.3880e-02,\n","        -1.0876e-02,  8.6671e-02, -1.5544e-01, -3.6570e-02,  3.4187e-02,\n","         1.9431e-01, -2.3994e-02,  1.1845e-01, -1.3524e-02,  1.4957e-02,\n","        -3.1018e-02, -2.6957e-02,  7.0671e-03,  2.5631e-03, -1.2186e-03,\n","         7.7924e-03, -1.6330e+00,  5.3599e-02, -1.8756e-01, -7.0139e-03,\n","        -2.3122e-02, -6.4151e-02, -8.3342e-03,  2.1896e-02,  3.5156e-02,\n","        -2.1670e-01, -1.3031e-02, -2.6532e-02,  4.8541e-01,  3.9233e-02,\n","        -3.9144e-02, -2.7724e-02, -1.7202e-02,  1.9837e-02,  6.8050e-02,\n","         6.4429e-02, -9.3103e-03,  3.9496e-03,  5.2786e-02,  3.9141e-01,\n","         3.2731e-02, -5.5851e-02, -2.8864e-02, -3.2385e-02, -1.3205e+00,\n","        -6.8531e-03,  2.2708e-02,  3.3505e-02,  1.7597e-02,  1.0496e-01,\n","         1.4264e-02, -4.8636e-02, -3.8406e-02,  4.5662e-02,  4.0778e-02,\n","        -1.8216e-01,  1.0451e-01, -1.7186e-02,  4.5651e-01, -3.8283e-01,\n","        -7.1661e-02, -1.1596e-01,  2.3562e-02, -3.3345e-02, -6.5131e-03,\n","         5.2186e-01,  2.3118e-02,  4.2358e-02, -1.6354e-01, -2.3368e-02,\n","        -7.2773e-02,  9.2098e-02,  7.3960e-02, -8.5856e-03, -2.9190e-02,\n","        -2.5812e-02,  2.2813e-02,  3.9920e-01, -9.5951e-02,  3.5218e-02,\n","        -6.5971e-03,  1.0656e-02, -2.9333e-02, -9.3340e-02, -3.4266e-02,\n","        -3.2797e-02, -3.1812e-02, -1.6444e-02,  9.3795e-03,  4.9710e-03,\n","         7.4864e-02,  2.0503e-02,  1.2019e-02, -9.6463e-02,  9.0383e-03,\n","        -1.0163e-01, -1.1936e-02, -9.9240e-03,  6.9428e-02, -1.5972e-02,\n","        -1.6194e-03, -1.5143e-01, -2.6916e-03,  2.8160e-03, -5.4137e-02,\n","        -2.5201e-02, -5.9194e-02, -4.5547e-02,  1.1635e-02, -1.3743e-01,\n","        -2.7861e-02,  1.7670e-02,  3.6029e-01, -1.6620e-01, -2.9037e-01,\n","        -2.0906e-02, -4.9193e-02, -1.5157e-01,  1.0279e-02, -5.0183e-02,\n","        -6.2499e-02,  5.1592e-02, -3.6768e-02,  3.6979e-02,  5.8792e-03,\n","        -4.3812e-01, -2.6610e-02,  1.1139e-02, -1.7832e-02,  1.9296e-02,\n","         1.9268e+00, -5.1481e-02, -1.0374e+00, -2.3528e-01,  1.2806e-01,\n","         5.4152e-02,  4.5513e-02,  1.3185e-01, -4.5898e-02, -2.9059e-01,\n","        -3.1807e-02,  3.1282e-01, -5.2095e-02,  1.6830e-02,  1.0103e-02,\n","        -8.8821e-02, -5.6992e-02,  1.4918e-01, -3.2754e-02,  1.2647e-01,\n","        -4.5343e-02, -6.0089e-03,  4.0821e-03,  4.1599e-02,  2.9160e-03,\n","        -1.1127e-01,  1.3630e-02,  3.6787e-02, -4.5001e-02, -3.0751e-02,\n","         2.0958e-01,  1.4337e-03,  8.8389e-03, -1.2532e-02, -5.5176e-01,\n","         1.5702e-02, -3.0031e-02,  4.6619e-02, -4.3830e-02,  8.1384e-01,\n","        -5.2857e-02,  5.6117e-02,  4.5984e-02, -5.8693e-03,  3.7356e-02,\n","        -6.5819e-02, -1.2487e-02, -2.7487e-03,  8.7460e-02,  1.8732e-02,\n","        -3.9053e-02,  3.6349e-02, -1.2410e-02, -2.3506e-02, -3.2630e-02,\n","        -2.4478e-02,  5.1195e-03, -1.3056e-02, -2.5671e-02,  6.4557e-02,\n","        -4.3413e-02, -3.3658e-02,  2.5288e-02,  1.1613e-01,  2.0985e-03,\n","        -3.6912e-02,  1.5934e-01,  6.1136e-02,  5.0096e-02,  2.0183e-01,\n","        -8.2168e-02,  3.7455e-03, -2.7078e-02, -2.6565e-02, -1.2160e-02,\n","         1.8575e-02,  2.7518e-02,  4.5978e-02, -1.6936e-01,  1.1848e-02,\n","         1.6768e-01, -1.0185e-01, -1.8316e-03, -4.9507e-02,  1.5137e-01,\n","         1.3097e-01,  2.2946e-01,  5.9122e-02,  1.2234e-01,  3.1542e-02,\n","         2.9185e-02,  9.7023e-03,  6.8366e-05, -6.7330e-02, -9.7029e-03,\n","         4.7728e-02,  1.1725e-02,  5.2275e-02,  1.7453e-02, -6.5290e-01,\n","        -5.6344e-03,  4.9274e-02,  2.5439e-01, -7.0169e-03,  1.1553e-01,\n","        -1.9708e+00,  1.7502e-01, -1.0070e-01, -4.0944e-02,  2.6640e-01,\n","        -8.9016e-03,  1.0477e-01, -9.8193e-03, -3.0680e-02,  4.6587e-02,\n","        -1.1816e-01, -2.6923e+00, -1.4601e-01, -1.9426e-02, -7.9362e-02,\n","         1.6330e-02, -4.1226e-03, -1.9877e-02, -1.1459e-02, -1.9987e-02,\n","         5.0930e-02, -5.3962e-03,  1.9090e-02], device='cuda:0',\n","       requires_grad=True)\n","W_K: torch.Size([12, 768, 64])\n","Parameter containing:\n","tensor([[[ 0.3660,  0.0771,  0.2226,  ...,  0.2182, -0.0353, -0.2534],\n","         [-0.4380, -0.1446, -0.4717,  ...,  0.0822, -0.1830, -0.3139],\n","         [ 0.1237,  0.0174,  0.1181,  ..., -0.0271, -0.1029,  0.0148],\n","         ...,\n","         [-0.2009, -0.2453, -0.1728,  ..., -0.2978,  0.0867, -0.2144],\n","         [-0.0825,  0.2873, -0.0022,  ...,  0.3966, -0.0419,  0.4542],\n","         [ 0.1567,  0.2664,  0.1851,  ...,  0.4973,  0.2553,  0.3879]],\n","\n","        [[-0.3581, -0.0267,  0.1390,  ..., -0.1479, -0.2918, -0.0746],\n","         [-0.0342,  0.2132,  0.1643,  ...,  0.1796, -0.0714, -0.3708],\n","         [ 0.0151, -0.0224, -0.1422,  ..., -0.0928,  0.1835, -0.1327],\n","         ...,\n","         [ 0.1370,  0.0608,  0.1179,  ..., -0.7398, -0.2028,  0.2726],\n","         [-0.0404, -0.0336, -0.5645,  ..., -0.2397, -0.2820, -0.2567],\n","         [-0.5056,  0.3207, -0.0495,  ..., -0.3114,  0.2403,  0.2127]],\n","\n","        [[-0.1375,  0.2369, -0.1350,  ..., -0.0626,  0.2297, -0.0305],\n","         [-0.1103,  0.3130,  0.0499,  ...,  0.2847, -0.2259, -0.0734],\n","         [-0.0847,  0.0845,  0.3417,  ..., -0.1490, -0.0985, -0.1267],\n","         ...,\n","         [ 0.3447, -0.1894,  0.0610,  ..., -0.1244,  0.0940, -0.0812],\n","         [ 0.1359,  0.2056,  0.1438,  ...,  0.1530, -0.0219, -0.2758],\n","         [ 0.1076,  0.2692,  0.0616,  ..., -0.2080, -0.4682,  0.0278]],\n","\n","        ...,\n","\n","        [[ 0.0634,  0.0445,  0.0736,  ..., -0.0552,  0.1392, -0.0491],\n","         [ 0.3563, -0.2082, -0.0822,  ...,  0.2109,  0.0803,  0.0644],\n","         [ 0.1600,  0.0543,  0.1216,  ...,  0.0350,  0.1437,  0.1187],\n","         ...,\n","         [ 0.0432, -0.2460,  0.0947,  ..., -0.0883, -0.0491,  0.1098],\n","         [ 0.1751, -0.0221,  0.1190,  ...,  0.0489,  0.1065, -0.0449],\n","         [-0.1055,  0.1388,  0.0510,  ..., -0.1167, -0.0015,  0.2706]],\n","\n","        [[-0.0215,  0.1129, -0.0714,  ...,  0.1153,  0.0764,  0.1374],\n","         [-0.1547,  0.0846,  0.1969,  ...,  0.1018,  0.1267, -0.1176],\n","         [ 0.1263, -0.0332, -0.1599,  ...,  0.0198,  0.2094, -0.0428],\n","         ...,\n","         [-0.0676,  0.3416,  0.1153,  ..., -0.0901, -0.0938,  0.1242],\n","         [-0.0323,  0.1086, -0.1363,  ..., -0.1014, -0.0102, -0.2565],\n","         [ 0.1197, -0.0925,  0.0026,  ...,  0.1738,  0.0942,  0.1884]],\n","\n","        [[-0.0345, -0.0537, -0.1521,  ..., -0.0392, -0.2204, -0.1203],\n","         [-0.1234, -0.0813, -0.0227,  ..., -0.1312, -0.1007, -0.2032],\n","         [-0.0896,  0.1503,  0.0334,  ..., -0.0182,  0.2173, -0.0052],\n","         ...,\n","         [-0.1453,  0.2397,  0.0131,  ..., -0.0070, -0.0495,  0.3333],\n","         [ 0.2364, -0.0491, -0.0778,  ..., -0.1258, -0.0598, -0.0675],\n","         [-0.0849, -0.1430,  0.1350,  ..., -0.0614,  0.2619,  0.0405]]],\n","       device='cuda:0', requires_grad=True)\n","W_V: torch.Size([12, 768, 64])\n","Parameter containing:\n","tensor([[[ 1.4213e-01,  3.2920e-02, -6.6679e-02,  ..., -1.7292e-02,\n","           1.2237e-01,  1.9954e-03],\n","         [ 1.6184e-02, -6.3328e-02, -6.3612e-02,  ...,  1.8086e-02,\n","           4.7454e-02, -2.1912e-02],\n","         [ 2.2934e-02, -8.2780e-02,  4.3655e-02,  ...,  8.0492e-03,\n","          -2.9594e-02, -2.7042e-02],\n","         ...,\n","         [-9.1288e-03, -1.1456e-01,  1.0232e-01,  ..., -6.2961e-02,\n","          -4.7726e-05, -1.9103e-02],\n","         [ 8.3785e-02, -1.2905e-01, -1.4942e-01,  ...,  6.1911e-02,\n","          -1.2579e-01,  4.6272e-02],\n","         [-3.4144e-02,  3.3618e-03,  2.0308e-02,  ..., -6.2119e-02,\n","           7.5056e-02, -5.5417e-02]],\n","\n","        [[ 6.0746e-02, -5.4322e-03,  3.1356e-02,  ...,  2.0707e-02,\n","          -1.1467e-01,  6.8145e-02],\n","         [ 2.2039e-02,  5.3950e-02,  3.8485e-03,  ...,  1.4869e-01,\n","          -1.0312e-02, -4.1186e-03],\n","         [-9.5968e-03, -6.7799e-02, -2.0372e-02,  ..., -7.1049e-02,\n","          -8.4796e-03,  7.6508e-02],\n","         ...,\n","         [-6.4680e-03,  2.4566e-02,  5.9719e-02,  ...,  3.4323e-02,\n","           2.0387e-02,  3.7953e-02],\n","         [-1.5165e-02, -6.7671e-02,  2.8308e-02,  ...,  4.2698e-03,\n","           1.4881e-02,  2.3475e-02],\n","         [-1.4358e-02, -4.0857e-02, -4.7423e-02,  ..., -1.6800e-02,\n","           1.2952e-01, -1.1262e-02]],\n","\n","        [[-6.3765e-03, -2.8716e-02, -7.9825e-03,  ...,  9.7763e-03,\n","           6.8293e-02,  9.5851e-03],\n","         [ 2.1599e-02, -1.6907e-02,  8.6272e-02,  ..., -2.0704e-02,\n","          -3.0710e-02,  4.2194e-02],\n","         [-9.2497e-02,  8.1930e-02,  1.8608e-02,  ...,  5.5625e-02,\n","          -5.1702e-02, -4.0618e-03],\n","         ...,\n","         [ 8.4382e-02, -3.9694e-02, -8.7621e-02,  ...,  1.2120e-01,\n","           1.1765e-01, -5.8365e-02],\n","         [-1.0649e-02,  6.2662e-02, -7.3017e-02,  ..., -5.2756e-02,\n","          -1.0061e-01,  2.2173e-02],\n","         [-2.0860e-02,  8.7400e-03, -1.3126e-02,  ...,  1.3956e-02,\n","          -2.8781e-02, -3.6662e-02]],\n","\n","        ...,\n","\n","        [[-1.1617e-01, -1.0868e-01,  7.2688e-02,  ...,  1.4968e-01,\n","           7.2404e-02,  7.4104e-02],\n","         [ 9.7485e-02,  9.2781e-02,  5.2319e-02,  ...,  7.5772e-02,\n","           2.9137e-03,  2.8320e-02],\n","         [-1.6524e-01,  1.6041e-02,  1.0409e-01,  ..., -4.3587e-02,\n","          -1.8707e-01,  7.3140e-03],\n","         ...,\n","         [ 7.0166e-02,  6.8843e-02, -4.1529e-02,  ...,  2.6074e-03,\n","           1.9380e-02, -1.8378e-02],\n","         [-1.2713e-01,  5.1358e-02,  2.8368e-02,  ..., -6.9909e-02,\n","          -9.5156e-02,  5.0839e-03],\n","         [ 3.4284e-02, -1.0981e-01, -5.3782e-02,  ..., -1.3942e-01,\n","          -1.3132e-01, -6.7848e-02]],\n","\n","        [[ 4.6370e-02,  4.5328e-02,  1.0852e-01,  ...,  1.2999e-01,\n","           1.0469e-03,  7.7982e-02],\n","         [-4.2929e-02,  7.9354e-03, -3.9357e-02,  ...,  5.9657e-02,\n","          -8.4070e-02, -1.6900e-02],\n","         [ 2.0919e-02,  6.5131e-02,  3.1341e-02,  ..., -2.0776e-02,\n","          -1.5798e-02, -2.5776e-02],\n","         ...,\n","         [ 8.2137e-03, -8.1757e-02, -1.1381e-01,  ...,  6.8777e-02,\n","           7.5570e-02, -2.8254e-02],\n","         [-8.4720e-02, -1.2945e-03,  3.5819e-02,  ..., -6.5049e-02,\n","           1.4378e-02, -2.3464e-03],\n","         [ 5.5222e-02,  1.1367e-02,  1.0706e-01,  ...,  3.5786e-02,\n","           8.0850e-02, -2.3720e-02]],\n","\n","        [[ 4.1270e-02,  3.2154e-02,  1.9865e-02,  ...,  5.1325e-02,\n","          -5.8439e-02,  2.4996e-02],\n","         [ 1.1211e-01,  5.7701e-02,  1.6388e-02,  ..., -5.2535e-02,\n","          -1.1260e-02, -1.5588e-02],\n","         [ 1.0786e-02,  4.0747e-02,  4.1309e-02,  ...,  1.1428e-01,\n","           3.6295e-02, -3.1849e-02],\n","         ...,\n","         [ 4.1515e-02, -1.1103e-01,  2.1454e-02,  ...,  9.5337e-03,\n","          -5.1598e-02,  3.1862e-02],\n","         [ 6.4991e-02, -2.2272e-02,  3.8856e-02,  ...,  2.9339e-02,\n","          -4.2872e-02, -4.7467e-02],\n","         [-7.2418e-04, -1.2285e-02, -2.6153e-02,  ..., -4.5922e-03,\n","           6.9785e-03,  1.9844e-02]]], device='cuda:0', requires_grad=True)\n","b_K: torch.Size([12, 64])\n","Parameter containing:\n","tensor([[-1.4611e-01, -6.3202e-02, -4.7258e-02, -9.2682e-02, -8.3484e-02,\n","         -1.3571e-01, -1.0058e-01, -2.9561e-02, -1.5705e-01, -2.4262e-01,\n","         -8.1476e-02, -4.8325e-02, -1.6462e-01, -2.6622e-02,  8.5022e-02,\n","         -1.9151e-01,  2.0220e-01, -2.2727e-02, -8.3964e-02, -9.4136e-02,\n","          2.5286e-02,  4.8060e-02,  2.2095e-01, -6.1350e-02,  2.3722e-02,\n","          8.8407e-02, -3.6372e-02,  8.6801e-02, -8.7590e-02,  8.9762e-03,\n","         -8.8368e-02, -8.4046e-02,  1.6854e-01,  1.4365e-01,  3.5403e-02,\n","         -9.3681e-02,  3.4466e-02,  1.2833e-02,  3.6465e-02,  8.8829e-03,\n","          6.5743e-02, -3.1236e-02,  2.4328e-02, -4.4170e-02,  1.4711e-01,\n","         -8.4549e-03,  1.9139e-02,  6.4082e-02,  2.4521e-02,  3.7683e-02,\n","          3.4089e-02, -1.9813e-02,  1.2082e-03,  6.8116e-02,  1.5907e-01,\n","          9.6397e-02,  1.7645e-02, -9.8472e-03,  1.3708e-01, -1.1867e-01,\n","         -6.2919e-02, -1.3595e-01, -2.4013e-02, -5.2590e-02],\n","        [-2.1407e-01,  1.4069e-01,  2.1187e-01,  4.2148e-01, -6.4579e-01,\n","         -2.5659e-01, -4.0477e-01,  1.6054e-01, -1.3905e-01,  6.1006e-01,\n","          2.1664e-01,  3.4925e-01,  5.6968e-01, -4.3012e-02, -4.3943e-01,\n","         -1.8074e-02, -2.5402e-01, -5.8240e-01,  1.3830e-01,  9.2940e-01,\n","          4.8210e-01,  3.2201e-01, -3.3353e-01,  5.6403e-01, -1.3676e-01,\n","         -3.8155e-01,  9.5574e-01, -6.1402e-01, -9.3447e-02, -1.5058e-01,\n","          3.7821e-01,  7.6257e-01, -1.9781e-02, -1.9396e-02,  3.1594e-01,\n","          4.0537e-01, -3.1291e-01, -4.5284e-01,  1.2845e-01, -2.7072e-01,\n","         -3.7638e-01,  3.3525e-01, -3.8571e-01, -5.1469e-01, -1.4114e-01,\n","          3.7181e-01,  8.9176e-01,  2.2814e-01, -8.9289e-01, -1.1400e-01,\n","          6.0320e-02, -7.0643e-01, -7.6652e-01,  4.0771e-01, -1.3371e+00,\n","          1.1515e+00,  1.0672e-01,  3.4687e-01,  2.6044e-02,  1.2594e-01,\n","         -4.2465e-01,  3.9579e-01,  5.3100e-01,  3.7269e-01],\n","        [ 8.1404e-02,  1.5064e-01,  4.6011e-02, -1.9762e-01, -7.2783e-02,\n","         -1.7234e-01,  1.5704e-02,  1.5393e-01,  1.9221e-02,  1.2679e-01,\n","         -2.3783e-02,  5.1444e-03,  1.7401e-02,  9.2118e-02, -1.0226e-01,\n","          6.9405e-02,  1.7612e-02,  1.2197e-02,  5.3232e-02,  4.0389e-02,\n","          4.1055e-02,  8.5022e-02, -4.8374e-02,  3.4198e-02, -1.9784e-01,\n","         -1.0299e-01,  9.9028e-02,  1.3574e-01, -4.1358e-02, -1.8017e-03,\n","         -1.1571e-01,  4.3975e-02,  2.8874e-02, -1.0651e-01, -3.5614e-02,\n","          6.8847e-02, -1.8377e-02, -4.5121e-02,  1.4801e-01,  9.8838e-02,\n","          1.2599e-01,  6.3351e-02, -6.5797e-02,  4.0529e-02, -9.0437e-02,\n","          1.4713e-01,  5.6328e-02,  8.1813e-02, -2.3127e-03,  1.6015e-01,\n","         -7.2817e-02,  7.9217e-02, -6.6340e-02,  7.8612e-02,  1.2560e-01,\n","          1.0875e-01,  8.7090e-02, -2.1759e-02,  5.3546e-02, -4.3723e-02,\n","         -1.2172e-01, -1.0914e-01, -1.7822e-01,  4.2085e-02],\n","        [-1.8381e-01, -2.4875e-01,  1.9216e-02,  4.1449e-01, -6.5593e-02,\n","         -3.5539e-02,  1.9044e-02, -3.3281e-01,  1.1186e-01,  1.7305e-01,\n","          4.0495e-02, -1.2608e-01,  3.0316e-01, -3.9585e-01, -1.1645e-01,\n","          1.1108e-01, -1.3843e-01, -7.5790e-02,  1.1160e-02,  1.2454e-01,\n","          1.0242e-01, -5.6780e-02, -1.4925e-01, -1.1104e-01, -9.0196e-02,\n","          4.9654e-01,  6.2126e-03, -5.2128e-02,  4.6875e-02, -8.4117e-02,\n","         -2.5140e-01,  9.4193e-02,  4.0150e-01, -9.0942e-02, -7.3015e-02,\n","         -2.4515e-02,  1.9120e-01,  2.3074e-01, -2.3176e-05,  1.0800e-01,\n","          1.7305e-01, -7.6003e-02,  7.6532e-02,  7.0845e-02,  1.0732e-01,\n","          6.5237e-02, -6.3135e-02,  6.9967e-02, -6.3011e-02,  1.7056e-01,\n","         -2.6326e-01,  2.2985e-01, -2.3052e-01, -3.5284e-01, -9.8239e-02,\n","          2.0438e-01,  4.0484e-01,  1.2019e-01,  5.3516e-02, -1.5580e-01,\n","         -7.0106e-02, -1.1109e-01, -6.8664e-02, -2.6033e-01],\n","        [-7.5187e-02,  1.6075e-01,  3.2261e-02, -7.4722e-02,  1.1479e-02,\n","         -5.6878e-02, -2.3850e-03,  7.3890e-02, -6.1833e-02, -9.2959e-02,\n","         -1.1238e-02,  3.7401e-02,  6.5753e-02, -1.9802e-01, -8.6904e-02,\n","          1.1303e-01, -1.1595e-03,  2.8346e-02, -1.0936e-01,  2.3487e-02,\n","         -1.1335e-01,  2.6688e-02, -1.2993e-02,  1.1949e-02,  9.6798e-02,\n","         -1.3967e-02,  4.8085e-02,  5.6099e-05, -6.9127e-02,  1.7218e-01,\n","         -4.8035e-02, -2.1260e-01, -1.0721e-01,  3.2991e-02, -8.1438e-02,\n","          1.2281e-01, -5.4751e-02,  4.4743e-02,  8.4619e-02,  1.4232e-02,\n","         -2.0356e-02,  1.6939e-01,  2.4884e-01, -8.8721e-02,  1.0401e-01,\n","         -1.9896e-03, -6.2556e-02, -4.9044e-02, -3.6728e-02, -1.2862e-01,\n","          1.1471e-01,  1.0030e-01, -1.0219e-01,  9.0493e-03, -1.2031e-01,\n","         -3.3620e-02, -5.8417e-02, -5.8333e-02, -7.9576e-02, -5.7462e-02,\n","         -1.3531e-01,  4.9678e-02,  9.2545e-02,  1.1460e-01],\n","        [ 1.7170e-01,  2.1621e-01, -2.3856e-01,  5.3063e-01, -6.1886e-02,\n","         -8.0219e-02,  1.4367e-01,  1.2676e-01, -1.1856e-01, -1.1131e-01,\n","         -1.7014e-01,  2.0042e-01,  3.1886e-01, -1.2226e-01, -4.7732e-02,\n","          7.3661e-02,  1.0227e-01,  3.7226e-01, -3.2653e-01,  3.5577e-01,\n","          2.8296e-01, -2.9640e-01,  2.0972e-01,  2.5866e-01, -6.9727e-01,\n","          2.6316e-02, -1.8256e-01,  7.1649e-02, -5.3895e-01,  3.4888e-01,\n","         -8.5525e-02, -1.9581e-01,  2.0597e-01, -1.4185e-01,  1.8933e-01,\n","          4.6969e-02,  3.1436e-01,  3.4117e-01,  3.0721e-02, -3.8055e-01,\n","          3.1936e-01,  1.7297e-01, -2.2087e-01, -6.7632e-01,  7.6154e-02,\n","         -3.0747e-01,  5.4920e-01,  2.5548e-01,  4.0818e-04,  3.9203e-02,\n","          1.8328e-01,  7.9923e-02, -2.0420e-01, -7.0450e-02,  1.1714e-01,\n","          3.7764e-01,  1.7148e-01,  1.9309e-01, -6.5513e-02, -1.2241e-01,\n","          2.1864e-01,  1.7470e-01, -1.1551e-01,  2.9534e-01],\n","        [ 1.0976e-02, -3.2148e-03,  7.6639e-02, -5.4193e-02,  2.5151e-02,\n","          1.0161e-01,  5.2587e-02, -1.0403e-02,  1.3563e-02, -6.1777e-02,\n","          2.1137e-02,  4.0078e-02,  5.0186e-02, -2.5454e-02,  3.0994e-02,\n","          1.1662e-01,  7.2912e-02,  1.5301e-01,  5.2965e-02, -1.7853e-02,\n","         -4.5376e-03, -3.5648e-02,  1.2526e-01,  2.5420e-03, -9.4262e-02,\n","         -2.1524e-01,  1.1038e-01,  2.0059e-02,  1.9175e-02, -1.1561e-01,\n","         -3.4211e-02,  1.2423e-01, -1.1713e-01,  7.2149e-02, -9.1006e-03,\n","         -4.6282e-02,  8.2158e-02, -2.7293e-02, -2.5002e-02,  1.2549e-01,\n","         -1.0746e-01,  1.2203e-02,  4.8870e-02,  3.7504e-02, -8.7334e-02,\n","         -1.0947e-01,  4.2866e-02, -1.6623e-01, -3.6926e-02, -8.0539e-04,\n","          1.0946e-02,  1.0728e-01, -9.5251e-02, -1.9436e-02, -6.7443e-02,\n","          6.3068e-02, -6.5204e-02,  8.0985e-02,  7.2009e-02,  8.7456e-02,\n","          1.9459e-02,  3.0470e-02, -1.1008e-02,  9.8698e-03],\n","        [ 7.2842e-02,  4.1216e-02, -3.9498e-02,  9.4536e-02, -8.2380e-03,\n","         -1.2499e-01, -2.3909e-02,  2.1132e-01, -5.7285e-02,  2.2693e-02,\n","          8.4536e-02, -2.5535e-01,  6.0971e-02, -2.5306e-02,  2.3668e-02,\n","         -1.2621e-01, -2.5018e-03, -1.0036e-01, -8.7018e-02, -1.2110e-02,\n","         -1.1194e-01, -1.6685e-01,  2.1075e-01, -2.7310e-01,  1.3758e-01,\n","         -4.2461e-02,  4.1641e-02,  3.9439e-02, -7.6723e-04, -1.3294e-01,\n","          4.0510e-03,  1.3088e-01, -1.1551e-01,  8.4602e-02,  1.0155e-01,\n","          1.2212e-01,  1.8399e-01, -2.8149e-02, -1.3810e-02,  3.6842e-02,\n","         -6.6235e-02,  6.5897e-02, -5.3570e-02,  5.5132e-02, -2.3524e-02,\n","         -2.0957e-01, -3.4293e-02, -1.3449e-01,  6.8725e-02,  1.8848e-01,\n","          7.1568e-02,  1.4590e-01,  1.4417e-01, -5.1912e-02,  7.4078e-02,\n","          1.6523e-01,  4.3127e-02,  8.5367e-02, -2.1639e-01,  6.2649e-02,\n","         -2.6426e-02,  1.4978e-02, -1.5324e-01,  9.4430e-02],\n","        [ 2.2817e-02,  4.7551e-03,  7.9180e-02, -1.2701e-01,  3.1720e-02,\n","          1.4462e-01,  4.1415e-02,  8.9802e-02, -5.6679e-02,  1.1645e-01,\n","         -2.9250e-02,  8.0752e-02,  4.1461e-02, -1.1681e-01,  9.1968e-02,\n","         -9.0574e-02, -3.8901e-02, -1.2897e-02, -1.8688e-02, -1.1444e-01,\n","         -9.3830e-02,  2.3227e-02, -1.4256e-02,  6.6631e-02,  9.3475e-02,\n","          8.8496e-03, -1.0035e-01,  1.3336e-01,  5.7165e-02,  7.9939e-02,\n","         -2.0064e-02, -2.7267e-02, -8.1617e-02, -6.6375e-02,  3.7662e-02,\n","          4.2126e-02, -6.3067e-02, -9.1592e-02,  1.0121e-01,  2.7801e-03,\n","         -8.8782e-02,  1.0466e-01, -7.9886e-02, -4.8122e-02, -6.8092e-02,\n","          1.7937e-02, -3.8750e-02,  5.9500e-02, -4.5424e-02, -6.3688e-02,\n","         -7.2882e-02,  1.8207e-01,  3.2667e-02,  6.6052e-02,  1.3732e-02,\n","         -3.3509e-04,  1.4184e-02,  9.0953e-03,  1.0983e-01, -6.3200e-02,\n","         -6.7751e-02,  1.5016e-01,  4.1710e-04,  1.7326e-02],\n","        [-1.0560e-01, -5.8428e-03, -2.6280e-02,  1.0137e-01, -1.1487e-02,\n","         -4.4492e-03, -3.2799e-02,  1.6685e-01, -8.6094e-02, -9.8768e-02,\n","          2.8619e-02,  2.2019e-02, -1.2499e-02,  1.2906e-01, -1.0968e-01,\n","         -2.3810e-02,  6.1092e-02, -6.3937e-02,  1.5959e-01,  4.7136e-02,\n","         -1.5105e-01, -6.8191e-03,  3.0001e-02, -8.4499e-02,  1.2555e-03,\n","         -1.0120e-01, -6.4526e-02, -8.6827e-02,  3.3931e-02,  5.9564e-02,\n","          1.1445e-01,  9.6262e-02, -1.7779e-02, -1.3722e-01, -5.6529e-02,\n","          6.3278e-02, -9.3022e-02,  2.8545e-02,  6.2317e-02,  1.0403e-01,\n","          5.0464e-02,  6.0572e-03, -7.8916e-03, -5.6601e-02, -5.8078e-02,\n","         -6.4601e-02,  9.1972e-02, -8.5848e-03, -1.4644e-01, -9.4964e-02,\n","         -7.4825e-02,  4.6775e-02,  8.6388e-02,  4.4902e-02,  1.1459e-01,\n","          1.2194e-01, -8.9916e-02, -8.8466e-02,  7.0832e-02, -3.8707e-02,\n","          2.4961e-02, -1.3145e-01, -5.7831e-02,  4.3288e-02],\n","        [ 1.4889e-01, -1.1487e-01, -5.2182e-02, -5.6015e-02, -2.5863e-01,\n","          1.6024e-01, -1.1484e-01,  6.6825e-03, -9.4997e-02,  3.8106e-02,\n","         -6.9236e-02, -8.6030e-02, -1.9312e-01, -1.1326e-01,  2.6132e-02,\n","         -8.8112e-02, -4.6661e-02,  1.5959e-02,  5.3492e-02,  1.1765e-01,\n","          6.0404e-02,  7.2367e-02,  5.1088e-03, -1.1125e-01, -1.6958e-02,\n","         -1.9169e-01,  5.5338e-02, -5.1546e-02, -6.7068e-02, -8.1442e-02,\n","          7.4878e-02, -6.1022e-02,  7.4758e-02, -1.8981e-01, -1.3683e-01,\n","         -3.8928e-02,  1.1634e-01, -1.2270e-01,  8.2183e-03, -1.0373e-01,\n","         -8.5525e-02, -7.3540e-02,  3.9165e-02,  2.6803e-02,  7.0303e-02,\n","          3.1409e-02, -5.7590e-03, -8.6456e-02,  1.0768e-01, -7.3127e-02,\n","         -3.8734e-02, -7.2275e-03,  9.5356e-02,  3.1791e-02, -9.0427e-02,\n","         -1.8704e-01,  1.3795e-01,  3.6704e-02,  5.0776e-02, -9.4987e-02,\n","          1.0227e-02, -1.0609e-01, -9.2246e-02, -7.7277e-02],\n","        [-8.6303e-02, -6.6196e-02, -2.3689e-02, -9.6986e-02, -2.7766e-03,\n","         -3.1407e-02,  4.1210e-02,  4.3878e-02,  6.3763e-02,  4.5300e-02,\n","          4.4211e-03,  1.6193e-02,  2.9569e-04,  1.7649e-01,  2.1476e-02,\n","          2.6499e-02,  6.1490e-02, -1.3662e-02, -8.9138e-03, -5.1713e-02,\n","         -1.0361e-02,  6.4201e-02, -1.0386e-01,  7.4042e-02,  7.1497e-02,\n","         -1.0501e-03, -1.6217e-01,  7.6682e-02, -4.7278e-03, -4.3166e-02,\n","          1.0876e-02, -3.2657e-02,  3.3171e-02,  5.8436e-02, -9.3457e-03,\n","         -7.9093e-04, -2.8764e-02, -1.5069e-02,  1.1481e-02,  1.1273e-01,\n","         -8.4879e-02,  1.8591e-02,  4.3933e-02,  6.6777e-02,  6.3952e-03,\n","         -1.2154e-01,  1.0939e-02,  1.5878e-02, -3.0599e-03,  1.0433e-03,\n","          2.4199e-02, -4.2502e-02, -4.7476e-02, -5.7369e-02,  9.3531e-03,\n","         -1.7525e-03,  5.6295e-02, -3.2697e-03,  2.1738e-02, -1.4150e-01,\n","          4.5810e-02, -4.0703e-02,  8.2235e-02, -5.2997e-02]], device='cuda:0',\n","       requires_grad=True)\n","b_V: torch.Size([12, 64])\n","Parameter containing:\n","tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n","       device='cuda:0', requires_grad=True)\n","Output shape (our layer): torch.Size([1, 35, 768])\n","Reference output shape (GPT-2): torch.Size([1, 35, 768]) \n","\n","100.00% of the values are correct\n","\n","=== Example Differences (First 10 Elements) ===\n","tensor([9.5367e-07, 2.9802e-08, 4.7684e-07, 3.3528e-08, 2.2352e-08, 4.4703e-08,\n","        1.1921e-07, 4.7684e-07, 1.7881e-07, 1.8626e-08], device='cuda:0',\n","       grad_fn=<SliceBackward0>)\n"]}]},{"cell_type":"markdown","metadata":{"id":"CQ68cbJ-KW2Y"},"source":["Если вы справились с этим, то поздравляю - ничего сложнее мы сегодня уже не будем делать)"]},{"cell_type":"markdown","metadata":{"id":"anGg23a4_aTy"},"source":["# MLP (или FFN в других терминологиях) - 5 баллов"]},{"cell_type":"markdown","metadata":{"id":"BRLuXGJb6NT2"},"source":["Реализуем MLP слой - это 2 матричных умножения с нелинейностью GELU.\n","\n","- $$ \\text{MLP}(X) = (\\text{GeLU}(X W_1 + b_1)) W_2 + b_2 \\in \\mathbb{R}^{\\text{seq} \\times d}$$\n","-    $$W_1 \\in \\mathbb{R}^{d \\times d_{mlp}}, \\quad b_1 \\in \\mathbb{R}^{d_{mlp}} \\\\\n","W_2 \\in \\mathbb{R}^{d_{mlp} \\times d}, \\quad b_2 \\in \\mathbb{R}^{d} \\\\ $$\n","\n","\n","$$GELU(X) = 0.5 * x * (1 + tanh(\\sqrt {\\frac {2} {\\pi}} * (x + 0.44715 * x^3)))$$\n","\n","если будете использовать gelu из pytorch, то **обязательно** проставьте approximate=\"tanh\"!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0hQCIDevT0h3"},"outputs":[],"source":["\"\"\"\n","class MLP(nn.Module):\n","    def __init__(self, cfg: Config):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.W_in = nn.Parameter(t.empty((cfg.d_model, cfg.d_mlp)))\n","        self.W_out = nn.Parameter(t.empty((cfg.d_mlp, cfg.d_model)))\n","        self.b_in = nn.Parameter(t.zeros((cfg.d_mlp)))\n","        self.b_out = nn.Parameter(t.zeros((cfg.d_model)))\n","        nn.init.normal_(self.W_in, std=self.cfg.init_range)\n","        nn.init.normal_(self.W_out, std=self.cfg.init_range)\n","\n","    def forward(\n","        self, x: Float[Tensor, \"batch seq_len d_model\"]\n","    ) -> Float[Tensor, \"batch seq_len d_model\"]:\n","        pass\n","        # Ваш код здесь!\n","\n","torch.manual_seed(1)\n","\n","rand_float_test(MLP, [batch_size, seq_len, d_model])\n","load_gpt2_test(MLP, reference_gpt2.blocks[0].mlp, cache[\"normalized\", 0, \"ln2\"])\n","\n","\"\""]},{"cell_type":"code","source":["class MLP(nn.Module):\n","    \"\"\"\n","    MLP (или FFN) слой с нелинейностью GELU.\n","\n","    :param cfg: объект конфигурации, содержащий параметры модели.\n","    \"\"\"\n","\n","    def __init__(self, cfg: Config):\n","        super().__init__()\n","        self.cfg = cfg\n","        # Инициализация матриц весов и смещений\n","        self.W_in = nn.Parameter(torch.empty((cfg.d_model, cfg.d_mlp)))\n","        self.W_out = nn.Parameter(torch.empty((cfg.d_mlp, cfg.d_model)))\n","        self.b_in = nn.Parameter(torch.zeros((cfg.d_mlp)))\n","        self.b_out = nn.Parameter(torch.zeros((cfg.d_model)))\n","\n","        # Инициализация весов по нормальному распределению\n","        nn.init.normal_(self.W_in, std=self.cfg.init_range)\n","        nn.init.normal_(self.W_out, std=self.cfg.init_range)\n","\n","    def forward(self, x: Tensor) -> Tensor:\n","        \"\"\"\n","        Применение двух линейных преобразований с нелинейностью GELU между ними.\n","\n","        :param x: Входной тензор размером [batch, seq_len, d_model].\n","        :return: Выходной тензор размером [batch, seq_len, d_model].\n","        \"\"\"\n","        # Первое линейное преобразование с нелинейностью GELU\n","        x = torch.matmul(x, self.W_in) + self.b_in\n","        x = torch.nn.functional.gelu(x, approximate=\"tanh\")\n","\n","        # Второе линейное преобразование\n","        x = torch.matmul(x, self.W_out) + self.b_out\n","        return x\n","\n","# Пример использования\n","torch.manual_seed(1)\n","batch_size = 2\n","seq_len = 4\n","d_model = 768\n","\n","# Тестирование MLP слоя\n","rand_float_test(MLP, [batch_size, seq_len, d_model])\n","load_gpt2_test(MLP, reference_gpt2.blocks[0].mlp, cache[\"normalized\", 0, \"ln2\"])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ljzOxMjlkW_i","executionInfo":{"status":"ok","timestamp":1726690282914,"user_tz":-180,"elapsed":478,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}},"outputId":"415b34f5-3ada-4faa-e629-97d5e1456020"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Input shape: torch.Size([2, 4, 768])\n","Output shape: torch.Size([2, 4, 768]) \n","\n","Input shape: torch.Size([1, 35, 768])\n","\n","=== GPT-2 Layer Parameters ===\n","W_in: torch.Size([768, 3072])\n","Parameter containing:\n","tensor([[ 0.0942,  0.0982, -0.0321,  ..., -0.1783,  0.1474,  0.0706],\n","        [-0.1265, -0.0671,  0.0305,  ...,  0.1966, -0.1203, -0.0628],\n","        [ 0.0496, -0.0373, -0.0483,  ...,  0.0655, -0.0714,  0.0826],\n","        ...,\n","        [ 0.0480,  0.1575,  0.0014,  ..., -0.3987,  0.0889,  0.0240],\n","        [ 0.0324,  0.1249, -0.0426,  ..., -0.1934,  0.1272, -0.0405],\n","        [-0.0316,  0.0010, -0.0491,  ..., -0.0406,  0.0536,  0.1896]],\n","       device='cuda:0', requires_grad=True)\n","b_in: torch.Size([3072])\n","Parameter containing:\n","tensor([ 0.0396, -0.0881, -0.1402,  ..., -0.2490, -0.0768,  0.0143],\n","       device='cuda:0', requires_grad=True)\n","W_out: torch.Size([3072, 768])\n","Parameter containing:\n","tensor([[-0.1066,  0.1528,  0.0331,  ...,  0.1644, -0.0400,  0.1218],\n","        [ 0.0364, -0.0594,  0.0848,  ...,  0.0933, -0.0980, -0.0388],\n","        [-0.0767,  0.0084, -0.0947,  ...,  0.0501, -0.0030, -0.0323],\n","        ...,\n","        [-0.1027,  0.0077, -0.0305,  ...,  0.0122,  0.0011, -0.0187],\n","        [-0.0305, -0.0333, -0.0078,  ...,  0.0902, -0.0444,  0.0043],\n","        [-0.0221,  0.0818,  0.0775,  ..., -0.0563, -0.0089, -0.0802]],\n","       device='cuda:0', requires_grad=True)\n","b_out: torch.Size([768])\n","Parameter containing:\n","tensor([ 4.5023e-02,  3.2263e-02, -8.8545e-02, -8.1625e-03,  1.1772e-01,\n","        -2.3888e-01, -7.5874e-02,  2.9564e-02,  4.6482e-02, -2.7773e-03,\n","        -3.8145e-03,  2.0843e-02,  9.2677e-03,  3.5888e-02, -1.4091e-01,\n","         6.1385e-02, -6.8962e-02, -1.2951e-02,  6.1896e-02, -1.7780e-02,\n","         2.1360e-02, -5.5017e-02,  2.1975e-02,  1.1830e-03,  4.9436e-02,\n","         4.1930e-02,  7.1898e-02, -2.0239e-02,  6.5098e-02,  1.0964e-01,\n","         4.0017e-02,  3.5822e-02,  6.4422e-02, -3.1552e-02,  2.0921e-02,\n","        -5.9030e-02,  1.9308e-02, -3.7585e-02,  4.7847e-02,  1.2950e-01,\n","         6.5660e-02,  1.6015e-01,  3.6072e-03,  1.3144e-02,  8.7157e-02,\n","        -5.1418e-02,  1.0630e-01, -4.2858e-02,  9.8618e-02, -2.9094e-02,\n","         9.4126e-02, -5.8661e-03, -2.9511e-02, -7.0213e-02, -2.4058e-03,\n","        -9.2266e-02,  5.3705e-02,  1.3925e-02, -1.0657e-02, -6.5181e-02,\n","         2.2841e-02,  1.2673e-01, -4.6832e-02, -3.9238e-02, -1.0288e+00,\n","         4.9528e-02,  1.0585e-02,  2.5042e-02,  6.0465e-03, -1.6819e-01,\n","         6.7637e-02, -5.6069e-02,  2.3984e-02, -8.1788e-02,  1.8519e-01,\n","        -5.3801e-02,  5.1166e-03, -3.4199e-02,  3.3593e-02,  9.6572e-03,\n","         7.0050e-02, -8.5121e-02,  1.3117e-01,  2.0365e-02, -9.6871e-02,\n","         1.3111e-02, -9.1116e-02, -2.2846e-01, -4.3093e-02, -5.2251e-02,\n","        -2.3870e-02, -9.1072e-02,  1.4825e-03,  2.0018e-02,  1.6285e-02,\n","        -1.8391e-01, -7.8575e-02, -1.5803e-01,  4.3354e-02,  8.2150e-02,\n","         8.9258e-02,  6.2411e-03, -5.0751e-03, -7.8197e-02, -4.1822e-02,\n","        -7.0752e-02, -6.2371e-02,  7.2956e-02, -2.9113e-02,  1.0280e-02,\n","         5.4623e-02, -5.4496e-02, -2.0813e-02,  2.7419e-02,  4.3915e-02,\n","        -1.1206e-01, -4.1483e-02,  4.4149e-02,  4.1488e-02,  3.3088e-02,\n","        -4.9593e-02,  2.5347e-02, -8.0750e-02,  3.5120e-02,  2.5000e-02,\n","         8.4420e-02,  3.9589e-03, -2.6386e-02,  4.6670e-02, -1.8601e-02,\n","        -2.7607e-02, -6.5403e-02, -5.8142e-02, -6.2748e-02,  5.5334e-03,\n","         1.0983e-01,  1.1807e-01,  8.8252e-03, -1.1783e-02, -4.1632e-02,\n","         2.2897e-02, -1.5753e-01,  5.2934e-02, -2.9923e-02, -4.5317e-02,\n","        -2.7485e-02,  1.2231e-02, -1.6446e-02, -1.1546e-01, -9.0706e-02,\n","         2.3194e-02,  8.7321e-02, -6.4447e-04, -4.7643e-02,  2.5382e-02,\n","         1.1230e-02, -1.1837e-02,  1.1483e-01,  6.2778e-02, -7.4322e-02,\n","         1.8604e-02,  3.5352e-02,  8.3046e-02, -3.2333e-02, -3.5075e-02,\n","        -5.6861e-02,  6.3852e-03, -3.5449e-02, -2.0108e-03, -2.9977e-03,\n","         1.8376e-01,  1.6517e-01,  4.6639e-02, -2.8841e-02,  9.5179e-03,\n","        -1.2773e-01,  3.6274e-02,  3.3075e-02,  6.7161e-02, -1.1401e-01,\n","        -1.0324e-01,  4.0848e-02,  6.9455e-04, -2.2487e-02, -1.4184e-01,\n","        -7.6204e-02,  4.8272e-02,  6.5127e-03, -2.4099e-04, -4.6942e-02,\n","        -1.0845e-02,  1.0996e-01, -1.9959e-02, -5.5883e-03,  1.5396e-02,\n","        -7.8590e-02,  9.2186e-02,  6.0335e-02, -2.3314e-02,  9.8412e-02,\n","         2.7981e-02,  2.4934e-02,  3.0177e-02,  6.3878e-03,  2.6812e-02,\n","         8.2178e-02, -3.1889e-02,  4.6658e-03,  1.1254e-01, -2.0472e-02,\n","        -1.9678e-02, -7.9651e-02,  4.4800e-02,  2.0878e-03,  1.0551e-02,\n","        -3.4646e-02, -5.8185e-02,  1.9808e-02, -3.0192e-02, -8.9304e-02,\n","         1.6887e-03, -4.5835e-02, -5.6149e-02,  4.1295e-02, -1.2998e-02,\n","        -8.9592e-03, -9.7501e-02,  8.6019e-04, -1.0314e-02, -2.9536e-02,\n","         8.8495e-02, -1.0251e-01, -7.5625e-02,  1.4877e-02, -8.9994e-02,\n","        -5.4272e-03, -1.3237e-02,  1.2560e-02,  4.1312e-02, -1.4846e-02,\n","        -2.3258e-03,  3.5059e-02,  5.3121e-02,  2.4269e-02, -2.6712e-02,\n","        -8.4159e-02, -2.0311e-02, -1.2856e-03,  7.9390e-02,  1.0080e-01,\n","        -4.2852e-02,  6.4158e-02, -1.5676e-01, -4.6177e-02, -8.5520e-02,\n","        -7.3629e-02, -4.1726e-03,  1.2724e-01,  8.0200e-02, -6.0142e-02,\n","         3.7472e-02, -4.8540e-02,  6.6447e-03, -5.5559e-02,  2.3945e-01,\n","         1.6573e-01, -2.7424e-01, -5.2924e-03, -3.5117e-02, -1.0445e-01,\n","        -4.9122e-02, -4.2225e-02, -7.1904e-02, -1.0075e-01,  1.0230e-02,\n","        -5.9576e-02,  2.8034e-03, -1.1119e-01,  5.6818e-02,  5.8964e-02,\n","        -1.3514e-01,  1.0375e-01,  6.1090e-02, -5.9418e-02, -1.2069e-02,\n","         1.5967e-02,  8.0903e-03,  8.0048e-02,  2.1895e-01, -1.0442e-01,\n","        -7.4534e-02,  4.0670e-02,  1.7061e-02,  4.5917e-02, -1.5722e-02,\n","        -6.0820e-02,  8.0987e-03,  9.1690e-02,  1.1977e-02,  4.8149e-02,\n","         1.2315e-01, -4.9318e-02,  1.2376e-01,  3.3778e-03, -6.3046e-02,\n","         1.5333e-01,  5.0951e-02, -8.9270e-02, -4.0724e-02, -4.0352e-02,\n","        -1.2391e-02, -1.6080e-01, -1.7766e-01,  7.5903e-02, -1.1405e-01,\n","        -9.3767e-02,  2.7890e-02, -8.6641e-03, -4.4354e-02,  1.0092e-02,\n","         1.6177e-02,  7.9481e-02, -2.1834e-02,  1.4273e-01,  9.5448e-02,\n","        -7.3992e-02,  2.5193e-01, -1.3582e-02, -4.1486e-02,  7.8391e-02,\n","         4.9195e-02,  1.4428e-02,  6.6614e-02, -6.7850e-03,  2.6350e-02,\n","        -2.2226e-02, -2.5074e-02,  3.0529e-02, -5.4314e-02,  2.5678e-03,\n","         2.1976e-02, -7.7988e-02, -8.7472e-02, -4.3832e-03, -5.6923e-03,\n","        -6.0136e-02,  2.3537e-02,  2.4781e-02,  1.1300e-01, -6.6311e-02,\n","         1.1406e-02, -2.0834e-02,  1.0654e-01, -5.8886e-02, -1.0436e-02,\n","        -3.5977e-02,  1.9855e-03, -1.5095e-02,  1.6664e-01,  3.8586e-02,\n","         7.3969e-04,  8.3391e-03, -4.6113e-02, -1.2392e-02,  8.4240e-02,\n","         1.9114e-02, -6.4050e-02,  1.2611e-02,  1.6068e-01, -6.8633e-02,\n","        -2.1504e-02,  3.9946e-03, -1.3237e-01, -7.7658e-01, -4.5846e-03,\n","        -2.8635e-02, -2.5182e-02,  4.0094e-02, -2.1614e-02,  5.9410e-02,\n","        -1.2508e-02, -3.8256e-02, -2.8660e-02,  6.3848e-02,  3.3284e-02,\n","         6.1880e-02, -8.7276e-03, -1.3498e-02, -2.2981e-02,  4.0298e-02,\n","         1.7356e-02, -4.0403e-02,  1.0129e-02,  1.9055e-01,  4.8645e-02,\n","         2.8901e-02,  4.3848e-02,  2.5438e-02, -4.6661e-02, -3.5847e-02,\n","         5.2495e-02, -6.3460e-02,  3.0081e-02, -2.2347e-02, -1.7123e-01,\n","         7.5116e-02, -5.7682e-02, -1.7896e-02,  1.3129e-01,  6.4119e-02,\n","        -3.3117e-02,  3.4110e-02,  2.3311e-02, -8.1768e-02, -7.8663e-03,\n","         7.2086e-03, -1.0913e-01, -6.0863e-02, -1.0291e-01,  7.0626e-02,\n","        -3.4457e-02, -6.6375e-03,  4.1267e-02,  1.0085e-01, -5.9672e-03,\n","         1.2186e-01,  3.2346e-02, -9.0074e-03, -3.6914e-02, -7.6526e-02,\n","        -9.9214e-02,  1.0725e-01,  1.4607e-01, -1.6410e-02, -1.6554e-01,\n","        -5.3178e-02, -2.0510e-02, -1.3013e-01,  7.0259e-02, -3.4697e-02,\n","        -4.4588e-02,  8.9730e-02, -4.3746e-02, -1.1891e-01, -3.7777e-03,\n","         4.7557e-02, -3.2944e-02,  1.4794e+00, -2.2029e-02,  2.4320e-02,\n","         2.6203e-02, -2.6522e-02,  1.9999e-01,  1.2335e-02,  3.7748e-02,\n","         1.0837e-01,  1.0647e-02,  2.6263e-02, -5.7881e-02,  6.4170e-02,\n","         1.3092e-01,  6.0774e-02,  1.5351e-01,  5.1787e-02, -1.6283e-02,\n","        -1.3189e-02, -4.0299e-02,  6.9897e-02,  5.6916e-02, -4.7023e-03,\n","         3.3006e-02, -2.1637e-02,  5.4445e-02, -1.1246e-02, -1.6313e-02,\n","        -9.7042e-02, -3.3673e-02, -3.1121e-01, -1.7338e-03, -6.5774e-03,\n","        -3.3948e-01, -1.0748e-02, -7.2840e-03,  3.4916e-02,  7.6206e-03,\n","        -9.0456e-03, -1.2918e-01, -4.1915e-02, -6.5605e-02,  5.6196e-03,\n","        -3.3288e-02,  9.6272e-03,  1.9119e-02,  7.9960e-03,  4.8949e-03,\n","        -1.0826e-01,  2.1244e-02,  6.2302e-02, -5.7631e-02, -4.0647e-02,\n","         1.1760e-01,  1.8409e-02,  9.1127e-02,  5.4443e-02,  4.0377e-02,\n","         5.2713e-02,  6.4445e-02,  4.3552e-02,  1.8278e-02, -2.7897e-02,\n","        -1.2969e-02,  7.3674e-02,  5.2346e-02, -3.1770e-02,  6.8897e-02,\n","         1.0820e-01, -7.0980e-02, -4.3594e-02,  5.8857e-02,  7.3827e-02,\n","        -6.0256e-02, -4.8512e-03,  5.1875e-02, -1.7978e-02, -9.7263e-02,\n","         1.0159e-01, -5.8648e-02,  3.3427e-02, -2.1911e-02,  6.3458e-02,\n","        -6.0518e-02, -1.5584e-02, -4.4891e-02,  1.2770e-01,  1.2310e-01,\n","        -1.0521e-02, -8.9975e-02,  5.1911e-02,  7.7123e-02,  5.4728e-02,\n","         2.9925e-02,  4.5541e-02, -6.9752e-02,  1.9429e-03,  1.3842e-01,\n","         3.2565e-02, -2.0783e-02, -8.2869e-02,  8.5544e-02,  3.7853e-02,\n","         7.7590e-03,  1.3680e-03,  6.4752e-03, -7.0810e-02, -1.1387e-01,\n","         9.5829e-02,  9.1051e-02, -6.5929e-02,  2.3231e-02,  6.6653e-02,\n","         1.0892e-01,  1.3683e-02, -2.4451e-01, -8.7208e-02,  4.0799e-02,\n","         1.2450e-02, -9.7876e-03, -8.4818e-02,  6.1542e-02, -2.1203e-02,\n","         7.5964e-03, -1.5272e-02,  2.2896e-02,  1.4737e-01, -6.7023e-02,\n","         4.8008e-02,  1.6407e-01,  5.9616e-02, -7.4996e-02,  3.7564e-02,\n","        -1.0317e-01, -2.8256e-02, -2.0282e-02,  4.1672e-02, -1.0623e-01,\n","         5.1083e-02,  2.4353e-02,  1.7573e-02,  1.3917e-03,  2.7037e-02,\n","         2.6375e-02, -3.1101e-02,  1.3591e-02, -3.4730e-02, -2.7803e-01,\n","        -2.8762e-02,  3.0337e-02, -3.2352e-02, -1.2179e-02, -1.3032e-02,\n","        -5.0929e-03,  8.4164e-02,  6.9907e-02, -2.9803e-02,  6.5644e-02,\n","        -8.0717e-02,  2.1697e-02,  9.6715e-02,  1.5086e-02,  1.1789e-02,\n","        -1.2883e-01,  2.4771e-02,  2.6497e-02,  5.5522e-02, -1.4012e-01,\n","        -6.6509e-03, -3.4700e-02,  8.4467e-03, -1.8842e-02, -1.1403e-02,\n","        -1.2643e-02,  5.0147e-02,  3.4162e-02, -5.4514e-02, -6.0217e-02,\n","        -1.3390e-01, -2.0140e-01, -1.5776e-03, -1.0785e-02, -1.5657e-02,\n","        -7.0327e-03,  6.0274e-02, -8.0423e-02,  8.7842e-02,  5.4633e-02,\n","         2.5239e-02, -2.8561e-02, -2.8283e-02, -7.0851e-02,  5.5545e-02,\n","         1.0581e-01, -5.1550e-03, -2.3810e-02, -1.4051e-01,  1.0330e-06,\n","        -6.2580e-02,  3.2829e-02,  2.0821e-03, -1.0545e-02, -2.0066e-02,\n","        -6.4922e-02,  7.5895e-02,  1.3187e-02,  7.5001e-02,  5.9478e-02,\n","         6.5165e-02, -3.2629e-02,  1.3688e-01, -6.0418e-02,  3.5761e-02,\n","         3.7931e-02, -7.2553e-02,  3.7288e-02,  7.7615e-03, -7.2981e-02,\n","         1.4384e-03, -3.2364e-02,  4.2222e-02,  7.6461e-02, -2.1868e-02,\n","         2.2159e-02, -5.3884e-02, -8.7562e-02, -2.1667e-02, -5.0475e-02,\n","         4.6042e-02, -2.1064e-01,  6.7564e-02, -7.4217e-02,  6.5668e-02,\n","         3.2803e-02,  2.8213e-02, -4.9096e-02, -1.6074e-02,  6.8048e-02,\n","        -8.2289e-02,  6.2946e-02,  2.0254e-02,  4.0095e-02,  7.4980e-02,\n","        -1.4052e-01,  1.1654e-01, -3.3523e-02, -5.1018e-02, -4.1743e-02,\n","        -8.4847e-02, -3.4367e-02,  1.6062e-02, -8.5649e-02,  1.0479e-02,\n","        -1.9157e-01, -3.0794e-03,  1.4401e-01,  2.4762e-02, -1.3440e-01,\n","         3.4516e-02,  6.9025e-02, -3.5945e-02,  1.5276e-02,  7.0170e-02,\n","        -1.4009e-02, -4.2377e-03, -7.8656e-02, -1.9765e-03, -1.1486e-01,\n","         8.5145e-02,  1.2174e-01,  1.1059e-01,  7.8198e-02,  5.9846e-02,\n","         7.9015e-03, -7.8730e-02, -2.8581e-02, -1.7287e-01,  1.4536e-01,\n","        -1.0344e-02,  3.2438e-02,  9.7084e-02,  4.5569e-02,  2.1417e-02,\n","         7.4727e-02, -5.2297e-02, -4.1671e-02,  1.0934e-02,  5.0398e-02,\n","         6.3046e-02,  6.9303e-02,  9.6004e-02,  1.1744e-03, -1.5224e-02,\n","         1.0817e-02,  5.7317e-02,  5.6077e-02,  2.4949e-02,  1.4738e-01,\n","        -1.8389e-01, -5.7228e-02, -1.6117e-01, -7.4940e-02,  5.0967e-03,\n","         2.2772e-02,  5.7293e-02, -8.3043e-02,  2.5825e-02, -1.9614e-02,\n","        -1.9872e-03, -7.1870e-02,  1.5372e-02, -1.3297e-01,  4.2593e-03,\n","         4.8105e-02, -4.9414e-02, -6.2924e-03, -4.0709e-02,  3.0459e-02,\n","         9.9903e-03,  9.6811e-02,  2.9624e-02], device='cuda:0',\n","       requires_grad=True)\n","Output shape (our layer): torch.Size([1, 35, 768])\n","Reference output shape (GPT-2): torch.Size([1, 35, 768]) \n","\n","100.00% of the values are correct\n","\n","=== Example Differences (First 10 Elements) ===\n","tensor([5.9605e-08, 2.9802e-07, 8.3447e-07, 7.7486e-07, 5.9605e-08, 7.1526e-07,\n","        2.3842e-07, 2.3842e-07, 1.4901e-07, 7.7486e-07], device='cuda:0',\n","       grad_fn=<SliceBackward0>)\n"]}]},{"cell_type":"markdown","metadata":{"id":"SVAp7w1gR8tU"},"source":["# Normalization - 5 баллов"]},{"cell_type":"markdown","metadata":{"id":"-aM9JUorIwwj"},"source":["**Layer Normalization**:\n","   - $ \\text{LayerNorm}(X) = \\frac{X - \\mu}{\\sigma} \\cdot \\gamma + \\beta $\n","   - $\\mu = \\text{mean}(X, \\text{dim}=-1) \\in \\mathbb{R}^{d}$\n","   - $\\sigma = \\sqrt{\\text{var}(X, \\text{dim}=-1) + \\epsilon} \\in \\mathbb{R}^{d}$\n","   - $\\gamma \\in \\mathbb{R}^{d}$\n","   - $\\beta \\in \\mathbb{R}^{d}$\n","   \n","   \n","1. Не забудьте про эпсилон, который хранится в cfg!\n","2. В [подсчете дисперсии](https://pytorch.org/docs/stable/generated/torch.var.html) не используете коррекцию Бесселя! Для этого в зависимости от версии pytorch поставьте `unbiased=False` или `correction=0`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PnNVykkAP49l"},"outputs":[],"source":["\"\"\"\n","class LayerNorm(nn.Module):\n","    def __init__(self, cfg: Config):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.w = nn.Parameter(t.ones(cfg.d_model)) # gamma\n","        self.b = nn.Parameter(t.zeros(cfg.d_model)) # beta\n","\n","    def forward(self, x: Float[Tensor, \"batch seq_len d_model\"]) -> Float[Tensor, \"batch seq_len d_model\"]:\n","        pass\n","        # Ваш код здесь!\n","\n","\n","\n","rand_float_test(LayerNorm, [2, 4, 768])\n","load_gpt2_test(LayerNorm, reference_gpt2.ln_final, cache[\"resid_post\", 11])\n","\"\"\""]},{"cell_type":"code","source":["class LayerNorm(nn.Module):\n","    def __init__(self, cfg: Config):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.w = nn.Parameter(t.ones(cfg.d_model))  # gamma\n","        self.b = nn.Parameter(t.zeros(cfg.d_model))  # beta\n","        self.eps = 1.e-8 # Можно добаввить конфигурацию cfg.eps для стабильности при делении на малые значения\n","\n","    def forward(self, x: Float[Tensor, \"batch seq_len d_model\"]) -> Float[Tensor, \"batch seq_len d_model\"]:\n","        # Вычисляем среднее и дисперсию по последнему измерению\n","        mean = x.mean(dim=-1, keepdim=True)\n","        variance = x.var(dim=-1, unbiased=False, keepdim=True)\n","\n","        # Нормализуем данные\n","        x_normalized = (x - mean) / t.sqrt(variance + self.eps)\n","\n","        # Применяем gamma и beta\n","        return x_normalized * self.w + self.b\n","\n","rand_float_test(LayerNorm, [2, 4, 768])\n","load_gpt2_test(LayerNorm, reference_gpt2.ln_final, cache[\"resid_post\", 11])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eHXwVNiAvNFi","executionInfo":{"status":"ok","timestamp":1726690299049,"user_tz":-180,"elapsed":1069,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}},"outputId":"fa0b01c0-7333-4947-c0d2-587d0a217899"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Input shape: torch.Size([2, 4, 768])\n","Output shape: torch.Size([2, 4, 768]) \n","\n","Input shape: torch.Size([1, 35, 768])\n","\n","=== GPT-2 Layer Parameters ===\n","w: torch.Size([768])\n","Parameter containing:\n","tensor([1.3971e+00, 1.3750e+00, 1.8870e+00, 1.1688e+00, 1.2724e+00, 1.2508e+00,\n","        9.4198e+00, 1.4371e+00, 1.4527e+00, 1.1856e+00, 1.3945e+00, 1.2796e+00,\n","        1.2071e+00, 1.2951e+00, 1.2776e+00, 1.3480e+00, 1.5088e+00, 1.3729e+00,\n","        1.3427e+00, 2.3761e+00, 1.1377e+00, 1.2909e+00, 1.3477e+00, 1.4775e+00,\n","        1.2540e+00, 1.1999e+00, 1.4932e+00, 1.1637e+00, 1.2590e+00, 1.2305e+00,\n","        1.1833e+00, 1.1914e+00, 1.2228e+00, 1.2792e+00, 1.3294e+00, 1.6213e+00,\n","        1.3804e+01, 1.1871e+00, 1.2235e+00, 1.4578e+00, 1.1687e+00, 1.3164e+00,\n","        1.1444e+00, 1.2628e+00, 1.4781e+00, 1.2426e+00, 1.1744e+00, 1.1602e+00,\n","        1.3637e+00, 2.1280e+00, 1.2371e+00, 1.2336e+00, 1.7410e+00, 1.1568e+00,\n","        1.3303e+00, 1.8593e+00, 1.2932e+00, 1.3320e+00, 1.2148e+00, 1.5415e+00,\n","        1.3781e+00, 1.2070e+00, 1.4030e+00, 1.5724e+00, 7.6159e-03, 1.1836e+00,\n","        1.2148e+00, 1.2604e+00, 1.8500e+00, 1.1540e+00, 1.2933e+00, 1.1572e+00,\n","        1.2341e+00, 1.1055e+00, 1.1680e+00, 1.3321e+00, 1.3856e+00, 3.6001e+00,\n","        1.6204e+00, 1.1333e+00, 1.4368e+00, 1.1365e+00, 1.2749e+00, 1.5402e+00,\n","        9.2773e-01, 1.5039e+00, 2.5029e+00, 4.4275e-03, 1.0613e+00, 1.3566e+00,\n","        1.2504e+00, 1.1983e+00, 1.4295e+00, 1.2386e+00, 1.1792e+00, 1.1883e+00,\n","        1.4453e+00, 1.4384e+00, 1.2305e+00, 1.3109e+00, 1.2305e+00, 1.1997e+00,\n","        3.1531e+00, 1.3615e+00, 1.1858e+00, 1.2148e+00, 1.2228e+00, 8.9936e+00,\n","        1.0824e+00, 1.2424e+00, 1.4070e+00, 1.2314e+00, 1.2359e+00, 1.2810e+00,\n","        1.3169e+00, 1.1992e+00, 1.4846e+00, 1.3867e+00, 1.2227e+00, 1.2774e+00,\n","        1.1955e+00, 1.2539e+00, 1.3414e+00, 1.2502e+00, 1.2220e+00, 1.2655e+00,\n","        1.1805e+00, 1.2932e+00, 1.6978e+00, 1.3635e+00, 1.2106e+00, 1.1450e+00,\n","        1.4414e+00, 1.0931e+00, 1.1859e+00, 1.2156e+00, 1.1804e+00, 1.5686e+00,\n","        8.6240e-02, 1.8252e+00, 1.1971e+00, 1.1500e+00, 3.3033e+00, 1.1137e+00,\n","        1.1841e+00, 1.8482e+00, 1.3211e+00, 1.1996e+00, 1.1784e+00, 1.4120e+00,\n","        1.2726e+00, 1.5131e+00, 1.4775e+00, 1.5084e+00, 1.4086e+00, 1.3018e+00,\n","        1.2469e+00, 1.2008e+00, 1.0666e+00, 1.0909e+00, 3.0489e+00, 1.2242e+00,\n","        1.2333e+00, 1.2970e+00, 1.2137e+00, 1.3484e+00, 1.2782e+00, 4.0765e+00,\n","        1.2149e+00, 1.3308e+00, 1.2631e+00, 1.1915e+00, 1.1758e+00, 1.4181e+00,\n","        1.4744e+00, 1.5844e+00, 2.1523e+00, 1.1229e+00, 1.4097e+00, 1.1849e+00,\n","        1.2051e+00, 1.2154e+00, 1.2320e+00, 1.3685e+00, 1.1289e+00, 1.2304e+00,\n","        1.1187e+00, 1.3789e+00, 1.2056e+00, 1.3168e+00, 1.2865e+00, 1.3707e+00,\n","        1.2933e+00, 1.2151e+00, 1.1296e+00, 1.8137e+00, 1.2315e+00, 1.2476e+00,\n","        1.2515e+00, 1.6609e+00, 1.4583e+00, 1.4180e+00, 1.2085e+00, 1.2292e+00,\n","        1.0586e+00, 1.2148e+00, 1.1842e+00, 1.0864e+00, 1.3871e+00, 1.2393e+00,\n","        1.2228e+00, 1.5026e+00, 1.3742e+00, 2.4785e+00, 1.2004e+00, 1.1891e+00,\n","        1.4659e+00, 1.1916e+00, 1.0978e+00, 1.2148e+00, 1.1180e+00, 1.1934e+00,\n","        1.1934e+00, 1.2339e+00, 1.6256e+00, 1.2190e+00, 1.2476e+00, 1.1685e+00,\n","        1.2186e+00, 1.2413e+00, 1.1367e+00, 1.3399e+00, 3.4147e+00, 1.0761e+00,\n","        1.1924e+00, 1.3913e+00, 1.1215e+00, 1.1398e+00, 1.3053e+00, 1.2300e+00,\n","        1.4287e+00, 1.5445e+00, 1.2461e+00, 1.1179e+00, 1.0352e+00, 1.2579e+00,\n","        1.1846e+00, 1.6518e+00, 1.2148e+00, 1.5199e+00, 2.3705e+00, 1.4342e+00,\n","        1.2745e+00, 1.4321e+00, 1.3017e+00, 1.5673e+00, 1.4878e+00, 1.1600e+00,\n","        1.2305e+00, 1.4492e+00, 1.2450e+00, 1.6015e+00, 1.2074e+00, 1.2931e+00,\n","        1.0899e+00, 1.2818e+00, 6.8271e-03, 1.3498e+00, 1.3882e+00, 1.6141e+00,\n","        2.2603e+00, 4.3566e+00, 1.2119e+00, 1.0664e+00, 1.5068e+00, 1.2935e+00,\n","        1.7190e+00, 1.2120e+00, 1.1749e+00, 1.2177e+00, 1.2027e+00, 1.1525e+00,\n","        1.4620e+00, 1.4274e+00, 1.0562e+00, 1.4126e+00, 1.3862e+00, 1.1511e+00,\n","        1.2874e+00, 2.0521e+00, 1.4653e+00, 1.2819e+00, 1.2038e+00, 1.1852e+00,\n","        1.4243e+00, 1.2345e+00, 1.0954e+00, 1.1217e+00, 1.1998e+00, 1.2631e+00,\n","        1.8584e+00, 1.1845e+00, 1.4605e+00, 1.2383e+00, 1.2808e+00, 1.0243e+00,\n","        1.2522e+00, 1.1446e+00, 3.1141e+00, 1.2562e+00, 1.1038e+00, 2.2026e+00,\n","        1.2352e+00, 1.2740e+00, 1.5308e+01, 1.3327e+00, 1.2991e+00, 1.2305e+00,\n","        1.2227e+00, 1.3008e+00, 2.4603e+00, 1.2306e+00, 1.1791e+00, 1.2395e+00,\n","        1.3017e+00, 1.2238e+00, 9.8373e-01, 1.1771e+00, 1.3761e+00, 1.1659e+00,\n","        1.1485e+00, 1.1823e+00, 1.2148e+00, 1.1784e+00, 1.0820e+00, 1.3048e+00,\n","        1.4846e+00, 1.1753e+00, 1.2101e+00, 1.3441e+00, 1.1446e+00, 1.1445e+00,\n","        1.1766e+00, 1.4649e+00, 1.4105e+00, 1.0483e+00, 1.2181e+00, 1.2429e+00,\n","        1.2293e+00, 1.2272e+00, 1.2309e+00, 1.9298e+00, 1.2051e+00, 1.3829e+00,\n","        1.2752e+00, 1.2049e+00, 1.9575e+00, 1.2054e+00, 1.0039e+00, 1.1939e+00,\n","        1.3718e+00, 2.8912e+00, 2.1898e+00, 1.1977e+00, 1.0975e+00, 3.9985e+00,\n","        1.2511e+00, 1.0346e+00, 1.1375e+00, 1.1822e+00, 1.4023e+00, 1.1227e+00,\n","        1.2915e+00, 3.5039e-02, 1.2217e+01, 1.4350e+00, 1.4025e+00, 2.3862e+00,\n","        8.5499e-01, 1.3179e+00, 1.2637e+00, 1.2388e+00, 1.0809e+00, 1.5234e+00,\n","        1.4024e+00, 1.2991e+00, 1.5354e+00, 1.1690e+00, 1.2194e+00, 2.6955e+00,\n","        1.2617e+00, 1.2485e+00, 1.3482e+00, 6.9770e-01, 1.4888e+00, 1.0986e+00,\n","        1.6696e+00, 1.1986e+00, 1.1655e+00, 1.1134e+00, 1.0508e+00, 1.2227e+00,\n","        2.3545e+00, 1.2345e+00, 1.0825e+00, 1.2153e+00, 1.2073e+00, 1.0666e+00,\n","        4.3418e+00, 1.1837e+00, 1.2441e+00, 1.2461e+00, 1.2586e+00, 1.2292e+00,\n","        1.4278e+00, 1.4742e+00, 1.2469e+00, 1.5043e+00, 1.4920e+00, 1.0824e+00,\n","        1.9560e+00, 1.4904e+00, 1.2004e+00, 1.1992e+00, 1.1798e+00, 1.0748e+00,\n","        1.1701e+00, 1.1871e+00, 1.2570e+00, 1.2104e+00, 1.6994e+01, 1.2695e+00,\n","        1.2397e+00, 1.2462e+00, 1.1837e+00, 1.4884e+00, 1.2487e+00, 1.2075e+00,\n","        1.4805e+00, 2.7156e+00, 1.2308e+00, 1.1758e+00, 1.2199e+01, 1.2564e+00,\n","        1.3756e+00, 1.2305e+00, 1.2151e+00, 3.5184e-02, 1.2539e+00, 1.2619e+00,\n","        1.3423e+00, 1.2802e+00, 1.1453e+00, 1.8877e+00, 1.3793e+00, 2.7507e+00,\n","        1.7741e+00, 1.3170e+00, 1.2972e+00, 1.6555e+00, 1.3009e+00, 1.3419e+00,\n","        1.1063e+00, 1.2773e+00, 9.6680e-01, 1.2736e+00, 1.2227e+00, 1.2159e+00,\n","        1.3187e+00, 1.1759e+00, 1.0922e+00, 1.1300e+00, 1.2853e+00, 1.2227e+00,\n","        1.1478e+00, 1.3477e+00, 1.0232e+00, 1.1962e+00, 1.1798e+00, 7.3442e+00,\n","        5.5998e-03, 4.2853e-02, 1.1763e+00, 1.2247e+00, 1.4425e+00, 1.2482e+00,\n","        1.1936e+00, 1.1623e+00, 1.5431e+00, 1.2553e+00, 1.2461e+00, 1.4025e+00,\n","        1.0510e+00, 1.1926e+00, 1.1642e+00, 1.1370e+00, 1.7419e+01, 1.7540e+00,\n","        1.2953e+00, 1.1212e+00, 1.2787e+00, 1.1915e+00, 1.4268e+00, 4.1753e+00,\n","        1.4481e+00, 1.1768e+00, 1.1994e+00, 1.2464e+00, 1.4068e+00, 1.2426e+00,\n","        1.0352e+00, 2.2258e+00, 1.7040e+00, 1.2463e+00, 1.3851e+00, 1.4013e+00,\n","        1.1661e+00, 1.3970e+00, 1.3403e+00, 1.2852e+00, 1.1684e+00, 1.2515e+00,\n","        1.2318e+00, 1.2731e+00, 1.1832e+00, 2.3393e+00, 2.0250e+00, 2.1031e+00,\n","        1.9473e+00, 1.0853e+00, 1.0114e+00, 1.2650e+00, 1.2014e+00, 1.0996e+00,\n","        1.2435e+00, 1.3647e+00, 1.1999e+00, 1.3419e+00, 1.4270e+00, 1.2332e+00,\n","        2.2816e+00, 1.2234e+00, 1.1839e+00, 2.4615e+00, 1.2603e+00, 1.3412e+00,\n","        1.2818e+00, 1.1999e+00, 1.4258e+00, 1.1138e+00, 1.1914e+00, 2.0622e+00,\n","        1.1712e+00, 1.3323e+00, 2.9923e+00, 1.2178e+00, 1.2220e+00, 1.2960e+00,\n","        1.2466e+00, 1.4102e+00, 1.3290e+00, 1.2458e+00, 1.1273e+00, 1.1836e+00,\n","        1.2652e+00, 1.2907e+00, 1.9197e+00, 1.1735e+00, 1.4725e+00, 1.4414e+00,\n","        1.1830e+00, 1.3088e+00, 1.1055e+00, 1.0831e+00, 1.2468e+00, 1.3466e+00,\n","        1.1992e+00, 1.2368e+00, 1.4933e+00, 1.1602e+00, 1.2542e+00, 1.3133e+00,\n","        1.4812e+00, 1.2707e+00, 1.2185e+00, 1.2779e+00, 1.2339e+00, 1.4316e+00,\n","        1.6659e+00, 1.2227e+00, 1.2312e+00, 1.2383e+00, 1.2305e+00, 1.4299e+00,\n","        1.0813e+00, 1.2005e+00, 1.2228e+00, 1.2314e+00, 1.2383e+00, 1.2539e+00,\n","        1.3949e+00, 1.3330e+00, 1.0798e+00, 1.2699e+00, 1.2942e+00, 1.2252e+00,\n","        1.3091e+00, 1.2312e+00, 1.8579e+00, 1.2031e+00, 1.3398e+00, 1.3956e+00,\n","        1.2026e+00, 1.1759e+00, 1.1842e+00, 1.1479e+00, 1.2016e+00, 1.2587e+00,\n","        1.1211e+00, 1.3564e+00, 1.0669e+00, 1.2955e+00, 1.5078e+00, 2.3227e+00,\n","        1.3065e+00, 1.1133e+00, 1.1542e+00, 6.1745e+00, 1.2328e+00, 1.2865e+00,\n","        1.2617e+00, 1.2497e+00, 1.1554e+00, 1.1533e+00, 1.2032e+00, 2.2578e+00,\n","        1.1680e+00, 1.0742e+00, 1.2881e+00, 1.2808e+00, 1.3027e+00, 1.1446e+00,\n","        1.2920e+00, 1.5471e+00, 1.4432e+00, 1.2617e+00, 1.1531e+00, 1.5527e+00,\n","        1.1369e+00, 1.5745e+00, 1.2476e+00, 1.4768e+00, 1.3202e+00, 1.2254e+00,\n","        1.2874e+00, 2.2262e+00, 1.2796e+00, 1.3802e+00, 1.1289e+00, 1.4846e+00,\n","        1.1908e+00, 1.3086e+00, 1.1986e+00, 1.1980e+00, 1.2156e+00, 1.6095e+00,\n","        1.3010e+00, 1.4810e+00, 2.0002e+00, 1.0530e+00, 2.1401e+00, 1.1956e+00,\n","        1.0898e+00, 1.1557e+00, 1.6530e+00, 1.1836e+00, 1.1818e+00, 1.1835e+00,\n","        1.3206e+00, 3.3972e+00, 1.3472e+00, 1.2540e+00, 1.2671e+00, 1.2726e+00,\n","        1.1836e+00, 1.4586e+00, 1.2540e+00, 1.1450e+00, 1.3078e+00, 1.1806e+00,\n","        1.2149e+00, 1.2552e+00, 1.1542e+00, 1.1541e+00, 1.2383e+00, 1.3058e+00,\n","        1.0963e+00, 1.1029e+00, 1.3066e+00, 1.7412e+00, 1.0508e+00, 1.5009e+00,\n","        1.3564e+00, 1.0530e+01, 1.1796e+00, 1.1801e+00, 1.8887e+00, 1.4579e+00,\n","        1.1528e+00, 6.6027e-01, 1.3696e+00, 1.0898e+00, 1.2464e+00, 1.2540e+00,\n","        1.1379e+00, 1.3102e+00, 1.1453e+00, 1.2852e+00, 1.8692e+00, 1.1606e+00,\n","        2.4319e+00, 1.4304e+00, 1.2322e+00, 1.2283e+00, 2.8226e+00, 1.3143e+00,\n","        1.5046e+00, 1.3252e+00, 1.3366e+00, 1.1009e+00, 1.2071e+00, 1.3483e+00,\n","        1.2312e+00, 1.3353e+00, 1.2706e+00, 1.2247e+00, 1.1510e+00, 1.1626e+00,\n","        1.4471e+00, 1.8308e+00, 1.3415e+00, 1.1664e+00, 1.4809e+00, 1.1465e+00,\n","        1.2681e+00, 2.1403e+00, 1.4574e+00, 1.1446e+00, 1.2617e+00, 1.4746e+00,\n","        1.2107e+00, 1.3090e+00, 1.0051e+00, 1.2245e+00, 1.2793e+00, 1.3636e+00,\n","        1.1871e+00, 1.3660e+00, 1.1758e+00, 1.4514e+00, 1.1525e+00, 1.1731e+00,\n","        4.2194e+00, 1.1660e+00, 1.1625e+00, 1.1034e+00, 1.0980e+00, 1.2070e+00],\n","       device='cuda:0', requires_grad=True)\n","b: torch.Size([768])\n","Parameter containing:\n","tensor([ 1.0872e-03,  3.6529e-02, -6.7296e-02,  1.6416e-04, -6.7444e-02,\n","        -7.1351e-02,  5.0393e-01,  9.1723e-02, -4.9340e-02,  3.2622e-03,\n","         4.5723e-02, -6.8674e-03,  2.4039e-02, -2.3481e-02, -1.6724e-02,\n","        -1.7144e-02, -8.3718e-03, -3.1513e-02, -6.8601e-02, -2.3766e-01,\n","         3.6237e-02,  1.6346e-02, -9.8507e-02, -2.1232e-03,  1.1982e-02,\n","         2.8979e-02, -1.2852e-01, -1.5948e-02, -1.9886e-02, -5.3668e-02,\n","         6.9403e-03, -7.6807e-03, -1.0904e-01, -1.9977e-02,  9.6084e-03,\n","         1.0891e-01,  4.5043e+00, -2.6320e-02, -3.5563e-02,  6.8634e-02,\n","        -2.6733e-02,  4.5381e-03, -7.6494e-02, -1.8627e-02,  2.7786e-04,\n","         1.7049e-02,  1.5448e-02, -2.0069e-02, -9.4106e-02,  1.2935e-01,\n","        -2.8602e-02,  1.7971e-02, -1.2255e-01, -6.0040e-02, -2.7152e-02,\n","         2.0868e-01, -7.3314e-02, -1.8849e-02,  3.2550e-02, -1.0382e-01,\n","         3.3463e-02, -5.7886e-02,  2.7034e-02, -1.6745e-01, -1.0472e+00,\n","        -1.6542e-02, -5.1018e-02, -6.8653e-03, -2.1249e-01, -3.1209e-02,\n","        -6.0667e-02,  8.7675e-04,  2.8659e-02, -2.4280e-02, -7.4334e-03,\n","        -1.0984e-02, -9.6567e-02, -4.0275e-01,  3.5209e-02,  4.5582e-03,\n","        -7.4472e-03, -1.4675e-02,  1.0423e-02, -7.6423e-02,  1.5722e-02,\n","         2.2594e-02,  3.4847e-01, -9.9237e-01, -1.4573e-02,  4.1847e-02,\n","        -5.6549e-02, -6.4195e-02, -7.8837e-02, -8.6063e-02, -1.1810e-02,\n","         1.1617e-02, -4.3866e-03,  4.7045e-02,  1.4878e-02,  1.5424e-01,\n","        -1.9613e-02, -1.0770e-01,  1.1270e-01, -6.4523e-03,  4.0445e-02,\n","        -2.7771e-02, -1.7304e-02,  7.3762e-01, -2.5960e-02, -2.7389e-02,\n","        -3.1064e-02,  1.5734e-02, -5.2281e-02,  4.1252e-02, -1.3316e-02,\n","        -4.5049e-02, -1.8180e-03,  7.2320e-03,  1.3693e-02, -3.9412e-02,\n","        -3.4724e-02,  5.1059e-02, -2.0570e-02, -2.1606e-02, -1.3500e-01,\n","         5.4560e-02, -3.6672e-02,  2.2630e-02, -1.0954e-01, -1.3664e-02,\n","         5.5158e-02,  2.8813e-02,  2.7308e-02, -5.6942e-02, -7.8654e-02,\n","         2.3580e-03,  2.0007e-02, -5.7116e-02,  6.4764e-01,  1.0185e-01,\n","        -6.1624e-02, -3.7634e-02, -3.9838e-01,  2.1430e-02, -1.8644e-02,\n","         1.9693e-01,  2.2677e-02, -6.5989e-02, -4.3632e-02,  9.9600e-03,\n","         2.4032e-02, -1.0095e-01, -4.6580e-02,  2.9137e-02, -5.9029e-02,\n","        -3.2612e-02, -1.9738e-03,  2.4192e-03, -3.7447e-02, -3.0108e-02,\n","        -6.3761e-02,  3.3632e-02, -1.8530e-02,  2.2146e-02, -6.4106e-02,\n","         7.4832e-02, -9.5605e-02, -3.6251e-01, -3.0068e-02, -1.1445e-01,\n","        -4.1705e-02, -7.9181e-02,  4.7085e-04,  8.2493e-02, -5.6607e-02,\n","        -3.3807e-02, -2.8627e-01, -4.7230e-02, -1.1380e-01, -4.0840e-02,\n","         5.7112e-03, -2.5453e-02,  6.4612e-02,  3.4492e-02,  2.0566e-02,\n","        -4.5267e-02, -3.4678e-02, -7.2612e-03, -1.8908e-02,  5.7890e-02,\n","        -4.2166e-02, -6.7557e-02,  5.6523e-02, -2.8467e-02,  3.5454e-02,\n","         1.5290e-02,  1.2768e-02, -2.8542e-02,  2.3154e-02, -2.0937e-01,\n","         4.4651e-02, -9.4332e-03, -1.6042e-02,  1.3285e-02, -1.3079e-02,\n","         5.2382e-04,  1.3041e-02, -2.7098e-02,  4.4549e-02, -8.7790e-03,\n","        -1.4647e-02,  9.1764e-02, -3.1280e-02,  2.3198e-01,  4.4123e-02,\n","         1.4304e-02, -5.7298e-02,  7.8618e-03, -1.0237e-03,  2.8485e-02,\n","         1.3268e-02, -9.5455e-03, -2.3109e-04, -2.0369e-02,  8.3394e-02,\n","        -7.1135e-02, -6.4807e-02, -6.1181e-03,  4.6791e-02, -9.2088e-03,\n","         3.4884e-02, -4.5029e-02,  2.7879e-01, -3.7818e-02, -5.4034e-02,\n","        -6.1790e-02, -3.8778e-02,  4.9349e-03,  2.4378e-02,  8.9025e-03,\n","        -3.5052e-03,  1.6581e-01,  5.8664e-02, -3.1299e-03,  2.7989e-02,\n","         2.5872e-02, -1.1119e-02,  7.6097e-02, -2.2228e-02, -1.9689e-02,\n","        -1.3784e-01, -6.6437e-02, -5.2913e-03,  1.7010e-03, -2.6449e-02,\n","         1.1717e-01, -1.1523e-01,  7.0097e-02, -8.2283e-02,  6.1100e-02,\n","        -1.2160e-02,  9.0952e-02,  7.5562e-03,  3.8820e-02,  1.9466e-02,\n","        -6.4488e-02, -9.7399e-01,  1.0671e-03, -7.2186e-03,  8.7493e-02,\n","        -1.1547e-01,  4.3738e-01,  5.4697e-03, -1.5715e-02,  2.8925e-02,\n","        -3.3470e-02, -4.2125e-02,  1.2895e-02, -2.9777e-02, -1.7015e-02,\n","        -2.2735e-02,  1.7061e-02,  4.9545e-02,  1.1104e-01, -5.8314e-03,\n","         5.7407e-02, -2.2805e-02,  2.0941e-02, -3.5016e-01, -2.1634e-02,\n","        -5.8145e-02, -2.1873e-02, -1.3668e-02,  1.2862e-02,  3.6718e-02,\n","         5.1902e-03,  1.0907e-02, -7.8232e-03, -4.5908e-02, -1.7366e-02,\n","        -2.8400e-02,  4.1859e-02, -1.0367e-01,  2.9875e-02, -4.3200e-02,\n","        -2.7472e-02,  7.6173e-03, -7.8905e-03, -4.4235e-01, -2.4563e-02,\n","        -1.7634e-02,  1.2442e-01,  3.7981e-02, -7.6377e-03, -4.1918e+00,\n","        -5.0516e-02,  2.9369e-02, -9.7174e-03,  7.4856e-05,  3.8322e-02,\n","        -2.1775e-01, -1.3928e-03, -4.3413e-02, -4.7812e-02,  1.0623e-02,\n","        -5.4639e-02, -5.3187e-01, -2.2528e-02,  1.0735e-02,  7.7141e-03,\n","        -1.1821e-03, -7.1923e-02, -6.6898e-02, -9.4570e-02,  1.8275e-02,\n","        -5.6802e-03,  3.3925e-02, -6.8035e-03, -2.1191e-02, -3.3668e-02,\n","        -4.5747e-02, -1.7164e-02, -6.4126e-02, -5.9322e-02,  6.6308e-03,\n","        -5.7392e-02, -2.9224e-02, -1.0237e-01, -2.1006e-02,  3.7682e-02,\n","        -8.3238e-03,  1.8629e-01, -3.0289e-02, -8.6108e-02, -3.3981e-02,\n","        -1.6380e-03,  9.5645e-05,  1.8391e-02,  6.6154e-03, -2.5787e-02,\n","        -5.4965e-02,  3.3532e-02,  7.6414e-02, -3.5418e-02,  1.5757e-04,\n","        -4.9215e-01, -1.7935e-02, -4.2474e-02, -3.6654e-02,  3.7187e-03,\n","         8.3721e-02, -7.3905e-02,  1.3349e-02, -8.1251e-01, -2.2964e+00,\n","        -2.3672e-02, -8.1334e-02,  1.5086e-01, -7.6905e-02, -3.1052e-02,\n","         2.1425e-02, -4.8389e-02, -1.4152e-02, -4.3935e-02, -3.7510e-02,\n","        -1.1541e-01,  6.2883e-02, -1.7672e-02,  1.0962e-02, -2.6148e-01,\n","         5.8860e-02,  4.1171e-02, -5.2769e-02, -5.3264e-01, -7.3070e-02,\n","        -3.0272e-02, -3.3503e-02, -2.3348e-02,  1.6839e-02,  1.3835e-02,\n","        -3.1535e-02, -1.2930e-01,  8.2034e-02, -1.7669e-02, -3.7012e-02,\n","        -5.3559e-02, -8.0793e-02, -4.5030e-02,  5.8326e-01, -2.8019e-02,\n","        -2.2854e-02, -2.9491e-02, -1.2646e-02, -1.9085e-02,  7.2778e-02,\n","        -2.9988e-02, -4.3035e-03, -2.3171e-02, -2.9115e-02,  2.8318e-03,\n","        -1.9056e-01, -3.6604e-02,  1.4934e-02, -7.2772e-02,  1.7382e-02,\n","         1.3184e-02,  3.3194e-02,  1.2090e-02, -6.7826e-02, -4.2046e-02,\n","         4.5765e+00,  3.8094e-02, -5.8475e-03, -3.3060e-02, -2.4420e-03,\n","         7.0572e-02, -8.5184e-03, -4.7140e-02, -3.5492e-02,  1.3906e-01,\n","         9.6806e-03,  3.7759e-03,  1.5214e+00,  1.5772e-02, -2.0146e-03,\n","         1.9806e-04, -2.5916e-02,  7.4553e-01,  2.2555e-02,  3.9150e-02,\n","        -4.0612e-02, -6.6488e-02, -1.4694e-02, -1.8814e-01, -2.5680e-02,\n","         2.7539e-01, -8.6698e-02, -5.4068e-02, -3.7796e-02,  1.7496e-01,\n","         1.0016e-01,  1.8288e-02,  1.9015e-02, -4.9247e-02, -1.1344e-01,\n","         3.2417e-03,  1.5069e-02, -2.3991e-02,  1.1169e-02,  5.5201e-02,\n","         6.8813e-02,  1.5437e-02,  1.4457e-02,  3.6382e-02,  3.3006e-02,\n","         1.6601e-03,  3.5841e-02,  2.3049e-02, -3.7833e-02, -8.8917e-01,\n","        -8.5626e-01,  7.6501e-01, -1.6650e-02,  5.3425e-03, -2.0975e-02,\n","        -2.0985e-02, -2.5421e-02,  1.1607e-03, -2.5669e-02,  1.1613e-04,\n","        -2.6443e-02, -1.2821e-02, -1.1060e-02, -6.4586e-02, -1.6700e-03,\n","         6.0491e-02,  7.3683e+00, -6.0230e-02, -2.9137e-02, -1.2580e-02,\n","        -5.3060e-02, -1.8582e-02, -1.7887e-02, -2.9617e-01,  8.0085e-02,\n","         5.4053e-02, -2.8139e-02, -8.7857e-03,  1.0940e-02, -1.9958e-02,\n","        -3.9983e-02, -2.5002e-01,  9.0808e-02, -2.3754e-03,  4.6434e-03,\n","        -6.0453e-02,  6.9979e-03, -3.8280e-02, -5.8416e-02, -1.8324e-02,\n","        -2.6310e-02,  8.2354e-02,  8.0878e-03, -6.1616e-02, -4.6368e-02,\n","        -1.1206e-01,  2.2739e-01, -1.9157e-01, -2.8906e-02,  3.9452e-03,\n","         1.5285e-02, -8.9685e-03, -4.1765e-02,  2.6316e-02, -4.1366e-02,\n","        -6.1208e-03, -1.0726e-02, -5.3724e-02, -1.1064e-02,  5.4608e-02,\n","         1.2026e-01, -5.9791e-02, -1.1439e-02, -3.0206e-01, -6.6082e-03,\n","         7.5021e-02,  3.3470e-02,  3.1955e-02, -8.9656e-03, -2.4131e-02,\n","         2.0099e-02,  1.7902e-01, -4.7128e-02,  3.5336e-02, -5.9965e-02,\n","        -1.0729e-02,  2.5535e-02, -3.2598e-02, -1.1571e-02,  3.9279e-03,\n","        -4.6097e-02, -1.0125e-02, -2.5468e-02, -5.3132e-02,  1.0430e-03,\n","        -5.7897e-02,  1.1562e-01,  1.6695e-02, -9.3858e-03, -1.0967e-01,\n","         1.1385e-01, -1.2587e-02, -2.9855e-02,  6.6515e-03,  1.1277e-03,\n","        -8.8445e-02,  3.5600e-02, -4.7699e-02, -6.5989e-03, -2.5376e-02,\n","        -5.9169e-02, -2.6125e-02,  3.5664e-02,  4.2330e-02, -2.8365e-02,\n","        -1.1422e-01, -1.2717e-02, -5.4891e-02,  2.6614e-02, -2.0510e-02,\n","        -4.0455e-02,  2.5847e-02,  1.8912e-02,  3.9873e-03,  1.2472e-02,\n","        -1.5778e-02, -4.3945e-02, -3.9807e-02,  4.9368e-02, -3.4811e-02,\n","        -3.6738e-02,  6.0444e-02, -3.1983e-02,  2.1002e-02,  5.9787e-02,\n","        -5.9418e-02, -5.6518e-02, -1.9562e-02, -1.0192e-01, -7.3266e-02,\n","         6.0253e-03, -1.2703e-03, -1.7658e-02, -1.7046e-04, -2.2049e-02,\n","        -4.4822e-02, -3.0320e-02,  6.1333e-03, -7.3983e-02, -3.9071e-02,\n","         7.1127e-02, -1.9383e-02,  8.1372e-02, -3.7656e-02, -3.9241e-02,\n","         1.1307e-02,  1.9240e-02, -5.2134e-01, -5.7102e-02,  1.2872e-02,\n","         2.6437e-02, -2.4696e-02, -9.5752e-04, -2.9517e-03, -4.0031e-02,\n","        -2.6403e-01, -1.8459e-02, -4.3772e-02, -6.4264e-02,  6.2169e-04,\n","        -4.2976e-01, -5.2110e-02, -2.7672e-02, -1.3235e-01, -2.0824e-02,\n","        -2.6675e-02, -2.9728e-02,  4.1735e-02,  1.0057e-02,  5.2260e-02,\n","        -7.4459e-02, -2.1856e-02, -1.4217e-02, -6.5240e-02, -2.2235e-02,\n","         1.6941e-01, -9.0145e-03,  2.4160e-02, -2.9787e-02,  1.4448e-01,\n","         1.9557e-02, -5.5833e-03, -5.0508e-02,  3.8701e-02, -2.9668e-02,\n","         3.1690e-02, -6.8745e-03, -1.9214e-02,  2.6903e-01, -7.6019e-03,\n","        -1.5625e-01, -2.6517e-02, -4.4908e-03, -3.7796e-02, -2.0304e-01,\n","        -4.0343e-02, -2.9758e-02,  3.2639e-02,  6.7867e-02,  2.9190e-02,\n","        -8.3563e-02, -7.6448e-02, -7.0672e-02,  9.8573e-03,  3.5905e-02,\n","         4.4131e-02, -5.1119e-03, -1.0302e-02,  1.4177e-02,  1.2777e-02,\n","         4.4026e-02,  2.6884e-02,  5.4663e-02, -5.9550e-02,  2.1386e-03,\n","        -6.3401e-02, -4.6159e-02,  1.7755e-02,  9.3017e-03, -1.3974e-02,\n","        -2.5991e-02,  6.9902e-02, -2.0447e-02, -8.0996e-01, -7.3992e-03,\n","        -6.9028e-02, -2.3947e-01, -1.0159e-01, -3.5832e-02, -1.9236e-01,\n","        -4.7394e-02, -1.6717e-03,  5.3983e-02,  1.0544e-02,  1.4304e-02,\n","        -4.8561e-02, -4.2476e-02, -8.7717e-04,  1.4124e-01,  9.4687e-04,\n","        -4.8157e-02, -1.1013e-01, -4.4088e-02, -4.0713e-02, -5.9785e-02,\n","        -1.6111e-02,  8.9078e-02, -4.9754e-02, -6.3769e-02,  1.4608e-02,\n","        -4.4700e-02,  1.0339e-02,  3.8344e-02,  5.5821e-02, -4.3954e-02,\n","         4.0682e-02,  1.2429e-02,  1.1265e-03, -9.7955e-02, -3.3169e-02,\n","        -5.4159e-02, -6.5162e-02, -6.4554e-02,  3.4367e-02, -5.5316e-02,\n","         1.6239e-01, -9.1327e-03,  2.1942e-02,  1.7757e-03, -7.4256e-02,\n","         2.2889e-02, -9.6414e-02, -2.9426e-02,  2.1863e-02, -2.4523e-02,\n","         5.9060e-02,  2.9360e-01,  6.2494e-02,  3.8487e-04,  9.1539e-02,\n","         3.1131e-02,  3.3019e-03,  4.5760e-01, -5.7599e-02,  3.4124e-02,\n","        -1.0095e-02, -2.5538e-02,  3.4450e-02], device='cuda:0',\n","       requires_grad=True)\n","Output shape (our layer): torch.Size([1, 35, 768])\n","Reference output shape (GPT-2): torch.Size([1, 35, 768]) \n","\n","100.00% of the values are correct\n","\n","=== Example Differences (First 10 Elements) ===\n","tensor([1.4901e-08, 1.4901e-08, 0.0000e+00, 1.4901e-08, 0.0000e+00, 1.4901e-08,\n","        1.9073e-06, 2.9802e-08, 2.9802e-08, 1.1176e-08], device='cuda:0',\n","       grad_fn=<SliceBackward0>)\n"]}]},{"cell_type":"markdown","metadata":{"id":"d9RPPHidUzRB"},"source":["# Transformer Block - 5 баллов"]},{"cell_type":"markdown","metadata":{"id":"iyEQcSI2KW2m"},"source":["Это блок трансформера, который получает на вход тензор x `[batch_size, seq_len, d_model]` и выдает тензор таких же размерностей. Блок GPT2 немного отличается от классического трансформера, который мы изучали на лекции.\n","\n","\n","![image.png](https://camo.githubusercontent.com/ebd052b635f156d5d24224f25fa078d804156be51125cd6626b92d9f8b406bbb/68747470733a2f2f6c6f6e6570617469656e742d313235373934353937382e636f732e61702d6368656e6764752e6d7971636c6f75642e636f6d2f53656c656374696f6e5f3030312e706e67)\n","\n","GPT2 следует схеме PreLN, а \"классический\" трансформер схеме PostLN. **Реализовать нужно PreLN схему!**\n","\n","В PostLN схеме нормализация происходит после слоев attention и MLP, а в PreLN до них согласно иллюстрации."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A7fEX6-8VRjV"},"outputs":[],"source":["\"\"\"\n","class TransformerBlock(nn.Module):\n","    def __init__(self, cfg: Config):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.ln1 = LayerNorm(cfg)\n","        self.attn = Attention(cfg)\n","        self.ln2 = LayerNorm(cfg)\n","        self.mlp = MLP(cfg)\n","\n","    def forward(\n","        self, x: Float[Tensor, \"batch seq_len d_model\"]\n","    ) -> Float[Tensor, \"batch seq_len d_model\"]:\n","        pass\n","        # Ваш код здесь!\n","\n","\n","rand_float_test(TransformerBlock, [2, 4, 768])\n","load_gpt2_test(TransformerBlock, reference_gpt2.blocks[0], cache[\"resid_pre\", 0])\n","\"\"\""]},{"cell_type":"code","source":["class TransformerBlock(nn.Module):\n","    def __init__(self, cfg: Config):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.ln1 = LayerNorm(cfg)  # Первый слой нормализации\n","        self.attn = Attention(cfg)  # Механизм внимания\n","        self.ln2 = LayerNorm(cfg)  # Второй слой нормализации\n","        self.mlp = MLP(cfg)  # Feed-forward сеть\n","\n","    def forward(self, x: Float[Tensor, \"batch seq_len d_model\"]) -> Float[Tensor, \"batch seq_len d_model\"]:\n","        # Применяем нормализацию перед механизмом внимания\n","        norm_x1 = self.ln1(x)\n","\n","        # Механизм внимания с остаточной связью\n","        attn_out = self.attn(norm_x1)\n","        x = x + attn_out\n","\n","        # Нормализация перед MLP\n","        norm_x2 = self.ln2(x)\n","\n","        # Feed-forward сеть с остаточной связью\n","        mlp_out = self.mlp(norm_x2)\n","        x = x + mlp_out\n","\n","        return x\n","\n","rand_float_test(TransformerBlock, [2, 4, 768])\n","load_gpt2_test(TransformerBlock, reference_gpt2.blocks[0], cache[\"resid_pre\", 0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Mdp4nAZxHNU","executionInfo":{"status":"ok","timestamp":1726690308815,"user_tz":-180,"elapsed":530,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}},"outputId":"dedab2d0-34ac-4171-c4c1-205e548ffd56"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Input shape: torch.Size([2, 4, 768])\n","Output shape: torch.Size([2, 4, 768]) \n","\n","Input shape: torch.Size([1, 35, 768])\n","\n","=== GPT-2 Layer Parameters ===\n","ln1.w: torch.Size([768])\n","Parameter containing:\n","tensor([0.2232, 0.1820, 0.1534, 0.1917, 0.2036, 0.1948, 0.1467, 0.1865, 0.2143,\n","        0.1956, 0.2118, 0.2153, 0.1882, 0.2074, 0.1871, 0.2040, 0.2044, 0.1900,\n","        0.1952, 0.0475, 0.1909, 0.2115, 0.1971, 0.2202, 0.1998, 0.2108, 0.2303,\n","        0.1879, 0.1939, 0.2018, 0.1891, 0.1861, 0.1958, 0.1832, 0.1978, 0.2243,\n","        0.0706, 0.1958, 0.1943, 0.1939, 0.1978, 0.1951, 0.1995, 0.1912, 0.2083,\n","        0.2037, 0.1849, 0.1945, 0.2189, 0.0419, 0.1977, 0.1979, 0.0608, 0.1824,\n","        0.2055, 0.0476, 0.1892, 0.2079, 0.2047, 0.2233, 0.2097, 0.2075, 0.2076,\n","        0.1793, 0.1312, 0.1841, 0.1939, 0.1561, 0.0577, 0.1948, 0.2048, 0.1717,\n","        0.1942, 0.1708, 0.1989, 0.1993, 0.2082, 0.1071, 0.1968, 0.1770, 0.2164,\n","        0.1864, 0.1938, 0.2184, 0.1343, 0.1707, 0.0683, 0.1401, 0.1823, 0.2045,\n","        0.2007, 0.1853, 0.1783, 0.1889, 0.1870, 0.1975, 0.2114, 0.2108, 0.2083,\n","        0.2409, 0.1938, 0.2022, 0.0857, 0.1823, 0.1879, 0.1979, 0.1850, 0.1029,\n","        0.1762, 0.1953, 0.2231, 0.2006, 0.2022, 0.2134, 0.1970, 0.1820, 0.0568,\n","        0.2269, 0.1882, 0.1770, 0.1880, 0.1910, 0.1872, 0.1613, 0.1946, 0.1930,\n","        0.1981, 0.2030, 0.1848, 0.2341, 0.1832, 0.1893, 0.2368, 0.2085, 0.1833,\n","        0.2083, 0.2009, 0.2212, 0.1342, 0.0614, 0.1913, 0.1812, 0.1041, 0.1957,\n","        0.1902, 0.1355, 0.2145, 0.1974, 0.1904, 0.1997, 0.1849, 0.1776, 0.2038,\n","        0.1773, 0.1878, 0.1793, 0.1960, 0.1935, 0.1786, 0.1532, 0.1185, 0.2015,\n","        0.1907, 0.2112, 0.1967, 0.2037, 0.1994, 0.0528, 0.1832, 0.1633, 0.1812,\n","        0.1988, 0.1742, 0.2177, 0.1901, 0.1778, 0.0706, 0.1987, 0.2417, 0.1658,\n","        0.1840, 0.1763, 0.1950, 0.2085, 0.1906, 0.2025, 0.1713, 0.2475, 0.1939,\n","        0.1755, 0.1929, 0.1378, 0.1944, 0.1803, 0.1839, 0.1617, 0.1919, 0.1710,\n","        0.1861, 0.1589, 0.2092, 0.2252, 0.1949, 0.2080, 0.1775, 0.1984, 0.1842,\n","        0.1919, 0.2261, 0.1953, 0.1940, 0.2496, 0.2153, 0.0501, 0.1797, 0.2050,\n","        0.2279, 0.1993, 0.2056, 0.2081, 0.1783, 0.1789, 0.1948, 0.1909, 0.1657,\n","        0.1894, 0.1901, 0.1939, 0.1997, 0.1939, 0.1790, 0.2071, 0.1217, 0.1811,\n","        0.1743, 0.2202, 0.1910, 0.1884, 0.2246, 0.1929, 0.2057, 0.1751, 0.1968,\n","        0.1799, 0.1807, 0.1856, 0.1968, 0.2126, 0.1744, 0.2287, 0.1813, 0.2130,\n","        0.2163, 0.2274, 0.1855, 0.1663, 0.1714, 0.1806, 0.1870, 0.2162, 0.1918,\n","        0.1621, 0.1802, 0.2120, 0.1645, 0.2075, 0.1612, 0.1757, 0.1968, 0.2067,\n","        0.0430, 0.0715, 0.1992, 0.1713, 0.2130, 0.2078, 0.0492, 0.1846, 0.2049,\n","        0.1995, 0.1914, 0.1975, 0.1758, 0.2057, 0.1663, 0.2204, 0.2045, 0.1877,\n","        0.0608, 0.0551, 0.2212, 0.1949, 0.1891, 0.2025, 0.1979, 0.1851, 0.1910,\n","        0.1713, 0.1884, 0.1987, 0.0643, 0.1914, 0.2395, 0.1831, 0.1902, 0.1741,\n","        0.1919, 0.1812, 0.0681, 0.2024, 0.1959, 0.0526, 0.1893, 0.2065, 0.0969,\n","        0.1988, 0.1940, 0.1956, 0.2085, 0.2012, 0.0678, 0.1812, 0.1821, 0.1736,\n","        0.1892, 0.1933, 0.0839, 0.1738, 0.2093, 0.1908, 0.1714, 0.1975, 0.2014,\n","        0.1891, 0.1953, 0.2019, 0.2165, 0.1870, 0.1935, 0.2164, 0.1846, 0.1841,\n","        0.1762, 0.2349, 0.1905, 0.1667, 0.1910, 0.2093, 0.1944, 0.2072, 0.2027,\n","        0.0504, 0.1939, 0.2013, 0.1845, 0.1919, 0.0686, 0.1734, 0.1742, 0.1937,\n","        0.2194, 0.0626, 0.0836, 0.1880, 0.1772, 0.0583, 0.2104, 0.1748, 0.1763,\n","        0.1865, 0.2027, 0.1951, 0.2061, 0.1503, 0.0895, 0.1831, 0.1987, 0.0482,\n","        0.1990, 0.2252, 0.2008, 0.1842, 0.1812, 0.2108, 0.2153, 0.1854, 0.2347,\n","        0.1963, 0.2036, 0.1302, 0.2048, 0.2017, 0.2270, 0.1640, 0.1787, 0.1707,\n","        0.2168, 0.1831, 0.1928, 0.1789, 0.1783, 0.1881, 0.0647, 0.1870, 0.1860,\n","        0.1690, 0.1924, 0.1874, 0.0577, 0.1904, 0.1991, 0.1979, 0.2137, 0.1969,\n","        0.2312, 0.2329, 0.2039, 0.2342, 0.2162, 0.1860, 0.0571, 0.2367, 0.2002,\n","        0.1645, 0.1950, 0.1864, 0.1786, 0.1941, 0.1652, 0.1923, 0.0941, 0.1935,\n","        0.1858, 0.1917, 0.1904, 0.1812, 0.1970, 0.1902, 0.2242, 0.0453, 0.1761,\n","        0.1957, 0.1196, 0.2123, 0.2282, 0.1851, 0.1870, 0.1732, 0.1953, 0.1897,\n","        0.2083, 0.2125, 0.1858, 0.0535, 0.1648, 0.0619, 0.1551, 0.2008, 0.1811,\n","        0.0545, 0.2079, 0.2315, 0.1818, 0.2017, 0.2527, 0.2056, 0.1843, 0.1974,\n","        0.1881, 0.1583, 0.1754, 0.1782, 0.2075, 0.1854, 0.1876, 0.2021, 0.1741,\n","        0.1988, 0.1639, 0.0706, 0.1697, 0.1536, 0.1837, 0.1958, 0.2207, 0.1851,\n","        0.2083, 0.1908, 0.1790, 0.1866, 0.1981, 0.2217, 0.1850, 0.2018, 0.1804,\n","        0.1811, 0.0897, 0.0504, 0.1903, 0.1849, 0.1886, 0.1822, 0.2249, 0.0515,\n","        0.2133, 0.1970, 0.1880, 0.1645, 0.2115, 0.2060, 0.1685, 0.0671, 0.1452,\n","        0.1879, 0.2007, 0.2288, 0.1855, 0.1356, 0.2140, 0.1950, 0.1842, 0.1831,\n","        0.1929, 0.2049, 0.1987, 0.0560, 0.1442, 0.0772, 0.0702, 0.1894, 0.1527,\n","        0.1880, 0.1961, 0.1884, 0.1899, 0.2223, 0.1764, 0.2137, 0.2381, 0.1812,\n","        0.0716, 0.2010, 0.2064, 0.1348, 0.1861, 0.1878, 0.1995, 0.1821, 0.1721,\n","        0.1723, 0.1858, 0.0688, 0.1868, 0.2088, 0.0535, 0.1821, 0.2078, 0.1963,\n","        0.2006, 0.1939, 0.1900, 0.1911, 0.1919, 0.1931, 0.1833, 0.2168, 0.1037,\n","        0.1767, 0.2095, 0.2026, 0.1883, 0.2183, 0.1596, 0.1794, 0.1921, 0.2233,\n","        0.1810, 0.2124, 0.2177, 0.1778, 0.1906, 0.1173, 0.2197, 0.1997, 0.2035,\n","        0.1987, 0.1990, 0.2253, 0.1719, 0.1909, 0.1948, 0.1862, 0.1891, 0.2097,\n","        0.1701, 0.2036, 0.1947, 0.1861, 0.1945, 0.1988, 0.1749, 0.2077, 0.1736,\n","        0.1737, 0.1986, 0.1911, 0.2105, 0.1889, 0.0738, 0.1929, 0.1940, 0.1841,\n","        0.1855, 0.1835, 0.1813, 0.1406, 0.1530, 0.1979, 0.1714, 0.1960, 0.1860,\n","        0.1949, 0.1453, 0.0617, 0.2033, 0.1796, 0.1870, 0.0911, 0.1966, 0.1989,\n","        0.1957, 0.1977, 0.1685, 0.1876, 0.2109, 0.1345, 0.1739, 0.1812, 0.1926,\n","        0.2075, 0.1283, 0.1852, 0.2235, 0.1659, 0.1813, 0.1904, 0.1695, 0.2283,\n","        0.1757, 0.1257, 0.1890, 0.2510, 0.2075, 0.2020, 0.1907, 0.0488, 0.1909,\n","        0.2222, 0.1852, 0.1104, 0.1842, 0.1834, 0.1956, 0.2032, 0.1930, 0.1589,\n","        0.1968, 0.1738, 0.1488, 0.1451, 0.0612, 0.1753, 0.1900, 0.2045, 0.0680,\n","        0.1960, 0.1844, 0.1951, 0.1602, 0.0764, 0.1589, 0.1931, 0.1980, 0.1960,\n","        0.1934, 0.2310, 0.1961, 0.1950, 0.1968, 0.1938, 0.1951, 0.1818, 0.1880,\n","        0.1713, 0.1785, 0.1962, 0.1850, 0.1964, 0.2008, 0.0666, 0.1917, 0.1670,\n","        0.2063, 0.1179, 0.1951, 0.1983, 0.1292, 0.1857, 0.1833, 0.0886, 0.2428,\n","        0.1872, 0.2067, 0.1996, 0.1881, 0.1901, 0.1885, 0.1984, 0.0754, 0.2066,\n","        0.0607, 0.0754, 0.2060, 0.2116, 0.0556, 0.1792, 0.1748, 0.1841, 0.1743,\n","        0.1662, 0.1982, 0.1582, 0.1935, 0.2182, 0.2067, 0.1855, 0.1778, 0.1900,\n","        0.2124, 0.1215, 0.2092, 0.1929, 0.2434, 0.1936, 0.1948, 0.0622, 0.1852,\n","        0.1868, 0.2035, 0.2310, 0.1794, 0.1655, 0.1756, 0.2074, 0.2194, 0.2152,\n","        0.0502, 0.2294, 0.1950, 0.2149, 0.2024, 0.1727, 0.0657, 0.1919, 0.1847,\n","        0.1900, 0.1825, 0.1898], device='cuda:0', requires_grad=True)\n","ln1.b: torch.Size([768])\n","Parameter containing:\n","tensor([-3.6773e-03,  2.7197e-02, -6.4041e-02, -4.9629e-03, -1.5657e-02,\n","        -1.1468e-02,  2.0193e-01,  3.5788e-02, -2.0053e-03, -8.1663e-03,\n","        -5.5835e-03, -2.3362e-03,  5.6948e-04, -7.2196e-03, -3.0114e-02,\n","         1.4813e-03, -9.4133e-03, -1.4194e-03, -1.3058e-02, -5.2827e-02,\n","         1.7663e-03,  6.8146e-04, -2.0151e-03, -1.6198e-02, -1.8525e-02,\n","         8.2216e-05, -1.3100e-02, -1.0806e-02, -8.0774e-03, -7.5151e-03,\n","        -3.7252e-03,  1.6366e-02, -1.4906e-02, -3.3854e-03, -1.3887e-03,\n","        -3.7338e-02,  4.7030e-02, -5.9341e-03, -9.1568e-03,  1.4841e-02,\n","        -6.5310e-03, -2.5589e-03, -8.8358e-03,  9.1073e-03, -1.5685e-02,\n","        -7.1033e-04, -2.7751e-03, -3.5386e-04, -4.4965e-03, -1.2486e-02,\n","        -8.7606e-03,  3.1898e-03, -3.5224e-02, -6.6995e-03, -3.4513e-04,\n","         5.8736e-03, -9.6372e-03, -1.7148e-02, -4.6664e-03, -1.5981e-02,\n","         2.0696e-03, -6.7130e-03,  2.3933e-02, -4.9531e-02,  1.4510e-02,\n","        -4.5545e-03, -6.3945e-05,  8.0284e-02, -5.5483e-02,  3.0513e-03,\n","        -6.0866e-03, -2.6283e-02, -1.1199e-02, -1.5390e-02, -1.1475e-02,\n","        -1.2513e-02, -8.4224e-03, -1.4612e-01, -3.5743e-03, -1.9645e-02,\n","        -4.4223e-03, -4.0007e-04, -2.2431e-03, -1.2971e-02, -4.3216e-02,\n","         2.5204e-02,  6.3584e-02,  1.4127e-02, -1.2670e-02, -3.6177e-03,\n","        -4.5376e-03, -7.5497e-03, -6.2942e-02, -7.9184e-03, -6.4569e-03,\n","         1.5663e-03,  3.7780e-03,  1.4451e-03, -1.7385e-02, -8.7888e-03,\n","        -1.3036e-02,  4.3986e-03,  9.2745e-02,  4.7072e-02,  8.6271e-03,\n","         1.8022e-03, -1.2516e-03,  1.3230e-01, -9.9225e-03, -4.5921e-03,\n","         1.4286e-03, -7.2390e-03, -3.1391e-03, -9.5703e-03, -1.7318e-02,\n","         2.4567e-03, -7.9636e-02, -3.4130e-03, -4.4602e-03, -6.3998e-02,\n","        -1.2518e-02,  1.2738e-02, -1.3053e-03,  2.7330e-02, -1.2173e-02,\n","        -1.4442e-02,  7.2952e-05, -1.2235e-02, -6.5007e-02, -1.3122e-02,\n","        -1.4403e-03, -6.3163e-03, -9.2239e-03, -2.9308e-03,  5.6682e-03,\n","        -3.5424e-03, -8.1279e-03, -2.5671e-02, -6.9513e-02,  7.6310e-03,\n","        -7.9235e-03,  1.1845e-02, -1.6358e-01, -1.0999e-02, -4.9096e-03,\n","         1.4798e-01, -2.4248e-03, -5.4345e-03, -5.9990e-03, -1.3103e-02,\n","        -8.8526e-03,  2.6271e-02,  2.3593e-02,  6.0559e-02,  7.2034e-03,\n","        -1.1688e-03,  6.2176e-03, -7.3272e-03, -8.1823e-03,  4.5026e-02,\n","         9.4403e-02, -3.6900e-03, -1.6013e-02, -1.1481e-02, -1.1295e-03,\n","        -3.0091e-03, -4.1729e-03, -5.0243e-02,  3.9869e-03, -9.7169e-02,\n","        -2.9804e-02, -1.2328e-02,  2.7406e-03, -5.1261e-03, -5.0703e-02,\n","        -2.6704e-02, -7.9665e-02, -2.3705e-03, -9.8872e-03, -4.0336e-02,\n","         2.1122e-03, -3.3592e-03, -6.2790e-03, -2.9973e-03, -3.8219e-03,\n","         2.3754e-03, -9.6140e-03, -6.8357e-03, -8.2773e-03,  4.9588e-02,\n","        -4.0435e-04, -1.0144e-01, -3.4593e-03, -2.4464e-02, -1.1891e-02,\n","        -8.1091e-02, -7.1821e-03, -5.2542e-02, -2.9287e-03, -1.1044e-01,\n","         1.8282e-02, -5.0902e-03, -1.5888e-03, -3.4227e-03,  6.7685e-03,\n","        -1.9135e-02, -6.3068e-03, -1.2206e-02, -4.0938e-03, -6.1832e-03,\n","        -4.6477e-03, -2.2221e-03, -9.7380e-03,  4.4572e-03,  1.9634e-03,\n","        -1.1089e-02, -1.3803e-02, -2.1262e-04, -2.0508e-02, -8.2536e-04,\n","        -3.6053e-03, -1.7395e-02, -1.7915e-02,  8.4085e-03,  6.1689e-02,\n","        -3.4031e-03, -8.1837e-03,  1.0918e-03, -7.2384e-03,  2.6243e-03,\n","        -2.4974e-03, -9.5049e-03,  1.5716e-01, -3.0335e-03,  1.8733e-03,\n","         7.3097e-04, -1.5647e-03, -2.7494e-03,  8.8599e-03, -2.6590e-03,\n","        -4.9589e-03,  4.8970e-02, -1.8768e-03, -3.9110e-03, -5.4172e-03,\n","        -3.4445e-03, -3.2954e-05,  2.0149e-03, -3.3228e-02, -2.1913e-02,\n","        -1.3201e-01, -1.4809e-02, -4.6245e-03, -5.3721e-03, -9.2251e-03,\n","         7.1484e-02, -8.5327e-02,  2.2778e-03, -1.8386e-02, -4.8179e-03,\n","        -1.1437e-02,  6.0744e-02, -5.9004e-03, -3.9862e-03, -1.7779e-02,\n","        -8.1095e-03,  3.2419e-02,  5.4025e-02, -2.5192e-02,  1.8794e-02,\n","        -2.5888e-01,  3.1771e-02, -9.5942e-03, -6.6256e-03,  5.0647e-03,\n","         1.2325e-03, -3.5340e-02, -7.7231e-03, -1.1984e-02, -8.9341e-03,\n","        -2.7098e-03, -6.7401e-03,  6.4152e-02, -3.8203e-02,  3.6157e-02,\n","         5.6622e-03, -3.5145e-03, -1.5465e-04,  1.4084e-02, -6.1967e-03,\n","         4.7287e-03, -4.0232e-03, -6.8129e-03, -1.5175e-02, -2.9673e-02,\n","        -3.6260e-03, -1.0304e-02,  7.9769e-04, -1.2794e-02, -2.9278e-03,\n","        -1.6830e-01,  7.3982e-05, -7.1594e-03, -9.5027e-03, -7.1155e-03,\n","        -1.4698e-02, -7.1206e-03, -1.5841e-03,  1.2370e-02, -4.9195e-03,\n","        -1.1468e-02, -3.7872e-02,  7.9341e-04, -2.7107e-03, -7.3024e-02,\n","         3.3318e-03,  3.5297e-02, -2.1949e-03, -1.2640e-02, -8.7402e-03,\n","        -1.4913e-01, -3.6700e-03, -1.0548e-02, -4.3111e-02, -6.7305e-03,\n","        -1.0662e-02,  7.8967e-02, -2.6913e-03, -4.8926e-03,  1.7184e-03,\n","         1.0755e-02, -2.5564e-03, -1.8291e-02,  5.8524e-03, -4.9166e-03,\n","         1.6272e-03, -1.4120e-02, -1.4272e-02, -1.6418e-02,  6.6017e-03,\n","        -1.1157e-02, -1.0404e-02, -9.7259e-03, -3.2562e-05,  2.0449e-02,\n","         8.7586e-03,  4.6499e-03, -1.7601e-02, -1.0206e-02, -4.6305e-03,\n","         3.1140e-03,  1.7261e-02, -9.8777e-03, -2.1058e-02,  1.6708e-02,\n","        -2.2063e-03,  1.0548e-01,  5.3555e-03, -1.1174e-02, -1.2416e-02,\n","        -1.1396e-02, -2.2582e-02,  9.4908e-02, -1.2475e-03,  1.0470e-02,\n","        -4.4811e-02, -3.3702e-04,  8.8441e-04, -1.6710e-02, -2.2230e-03,\n","        -8.4853e-03, -7.0801e-03, -7.3227e-03,  8.5847e-03, -7.1773e-02,\n","        -3.8144e-02, -2.6031e-02, -9.3334e-04,  6.0528e-03, -2.1210e-03,\n","        -4.4518e-03, -6.3262e-03, -3.5488e-03,  4.4118e-03, -1.7161e-02,\n","         2.7770e-02, -7.3682e-04, -1.8697e-02,  5.4140e-03, -1.0773e-01,\n","         1.3786e-03, -5.6343e-03, -1.1911e-02,  2.9226e-02, -4.9289e-02,\n","        -1.3017e-02, -2.8867e-02, -7.4697e-03, -5.0646e-03, -2.1027e-03,\n","        -9.0122e-03, -2.8095e-04,  9.1620e-03,  9.9855e-03, -5.0135e-03,\n","        -7.3161e-03, -8.3630e-03, -1.3518e-02,  7.4391e-03, -3.5431e-03,\n","         2.6130e-04, -8.2347e-03, -6.8752e-03,  3.1539e-03,  5.9216e-04,\n","        -1.3157e-03, -4.2827e-03, -8.0294e-03,  1.4698e-03,  8.1714e-03,\n","        -8.3353e-02, -7.3158e-04, -1.2440e-02, -4.1689e-02, -7.9129e-03,\n","        -7.1573e-03,  5.4446e-04, -1.7097e-02, -2.7230e-02, -9.9185e-03,\n","         8.3248e-02, -4.9037e-03, -1.1543e-02, -1.4802e-02,  5.1785e-03,\n","         6.0471e-02, -1.7101e-03, -1.9607e-03, -1.7631e-02,  1.4342e-02,\n","         6.6078e-02, -3.6674e-03,  1.1673e-01,  2.8226e-03,  1.5695e-03,\n","         1.1687e-03, -1.0287e-02, -3.5415e-02,  5.7083e-03,  3.0032e-02,\n","         4.7963e-03, -4.6634e-03, -2.1449e-02, -4.5465e-02,  3.6475e-02,\n","        -2.9218e-02, -7.3597e-02, -2.2610e-03, -1.8534e-03, -4.3340e-02,\n","        -7.4300e-03, -1.0644e-03,  3.9951e-03, -1.4564e-03, -7.7103e-03,\n","        -1.1895e-02, -2.2917e-03, -7.4277e-03, -7.0026e-03,  2.2262e-02,\n","        -2.3908e-02,  3.7275e-03, -3.9922e-03, -9.4078e-03, -6.8199e-03,\n","        -5.6862e-03,  1.3752e-02,  1.9518e-03, -2.9739e-02, -5.4796e-02,\n","         2.5633e-02, -4.6672e-02, -3.4339e-03, -2.8420e-03, -6.0973e-03,\n","        -3.4848e-03, -7.1026e-04,  4.7077e-03,  6.0219e-02, -4.3480e-03,\n","        -1.0258e-02, -3.3273e-02, -5.8100e-03, -3.0383e-03, -3.6710e-03,\n","         9.8417e-04,  3.7857e-02, -5.5641e-02, -1.5982e-03, -2.5546e-03,\n","        -1.2599e-02, -7.8293e-03,  4.4796e-03, -5.0230e-02, -3.2789e-04,\n","        -9.8844e-03, -1.0657e-03,  1.7756e-02,  2.4868e-02, -4.0598e-03,\n","        -2.0787e-02,  6.5452e-03,  6.2262e-02,  3.1842e-03, -9.1719e-03,\n","        -1.9614e-02,  4.0984e-04, -7.8020e-02, -3.4705e-03, -9.0374e-03,\n","        -7.5048e-03, -1.2318e-03, -1.1238e-03,  2.5981e-03,  2.0212e-04,\n","        -3.4493e-02, -1.0620e-01, -6.1194e-02,  1.1006e-01, -8.2153e-03,\n","         5.8200e-02, -6.1978e-03, -2.9407e-03, -7.5819e-03, -1.3807e-02,\n","        -1.1527e-02, -5.8018e-03, -2.4700e-03,  4.0524e-03, -2.4140e-04,\n","        -1.5578e-01,  3.6128e-03, -1.1889e-02, -1.3799e-01, -2.0050e-02,\n","        -5.7294e-03,  7.8450e-03,  8.9329e-03, -5.0449e-02, -7.1266e-02,\n","        -2.2219e-03,  6.8951e-02, -5.7862e-03, -1.9270e-03, -5.2681e-02,\n","         1.5275e-02, -1.8674e-02, -7.0319e-03, -5.7599e-03, -2.0792e-02,\n","        -7.4854e-03, -2.6877e-04, -2.7503e-03, -9.3094e-03, -5.9258e-03,\n","        -1.0378e-02,  5.3032e-02, -1.3233e-02, -1.7814e-02, -3.3404e-02,\n","        -5.8712e-03, -8.0210e-03,  2.5365e-02, -8.3159e-03, -1.8518e-03,\n","        -1.3801e-02, -1.0694e-02, -5.6355e-03, -4.4685e-02, -1.1602e-03,\n","        -5.6610e-03, -6.7200e-02,  1.4491e-04, -6.2602e-03,  1.7706e-03,\n","        -2.0804e-03, -1.4456e-02, -1.0076e-02,  6.9997e-02, -1.8181e-02,\n","        -1.0317e-02, -1.8089e-02, -1.7820e-03, -1.4917e-02,  3.3274e-03,\n","        -2.5752e-03, -9.4734e-03, -1.6406e-03, -1.3726e-03, -5.6112e-03,\n","        -5.9242e-02, -1.5909e-04, -5.3785e-02,  4.6104e-02,  2.5991e-03,\n","        -6.5316e-03,  1.5706e-03, -1.0516e-03,  4.1031e-02, -1.7556e-03,\n","        -1.6817e-02,  2.9510e-02,  2.6294e-04, -8.1226e-03, -9.2532e-03,\n","        -5.7344e-02,  4.9300e-02, -6.5616e-03, -6.9715e-02, -2.1389e-02,\n","         5.2578e-03, -1.8515e-02,  2.3493e-02, -3.5781e-02, -2.9717e-02,\n","        -6.0645e-03, -3.9194e-03, -9.2964e-02,  3.4848e-04, -5.4765e-03,\n","        -6.3284e-03, -5.3932e-03,  2.7151e-02, -1.0132e-02, -1.0321e-02,\n","        -1.0249e-01, -1.1614e-02, -5.2535e-03, -4.3208e-03, -9.0916e-03,\n","         1.0430e-01,  8.7354e-03, -2.8853e-02, -6.5112e-02, -6.1870e-02,\n","        -1.5296e-02, -1.9437e-02, -2.5295e-03,  1.0481e-02, -7.1597e-02,\n","        -4.6626e-03, -2.3632e-03, -3.9855e-03, -1.8508e-02, -7.6655e-03,\n","        -8.7076e-03,  8.8668e-03, -8.9428e-03,  1.5019e-03,  8.9872e-02,\n","        -2.4305e-03,  5.2958e-03, -7.4602e-03, -1.0843e-02, -6.5060e-03,\n","         6.8178e-02, -8.2134e-04, -3.7852e-02,  9.7919e-02,  5.6566e-02,\n","        -1.2836e-01, -1.3523e-02, -2.2623e-02,  1.2212e-03,  3.8977e-02,\n","        -1.1199e-02,  8.3622e-03,  3.4196e-03,  8.8295e-02,  8.9156e-02,\n","        -7.8078e-02, -3.7663e-03, -5.1124e-03, -5.1848e-04, -8.1107e-03,\n","        -3.1567e-03, -2.4654e-03, -1.0728e-02,  1.3785e-02, -3.4956e-03,\n","         4.1404e-03, -6.7117e-03,  3.4516e-03,  3.2378e-03, -2.1498e-02,\n","        -8.0794e-03, -1.1813e-02, -3.6988e-03,  1.5333e-03,  6.7420e-02,\n","         4.3915e-03,  6.2074e-02, -1.3737e-03, -1.8403e-01, -1.0363e-02,\n","        -4.9580e-03, -1.0243e-01, -4.9407e-02, -1.1682e-02, -1.0990e-01,\n","        -2.4783e-03, -8.4030e-03, -4.9054e-03,  2.4461e-03, -7.0848e-03,\n","         5.8766e-04, -3.9787e-03, -8.8103e-03,  4.2299e-02, -1.6859e-02,\n","        -5.0584e-02, -1.0632e-01, -9.5095e-03, -2.3314e-03, -6.4010e-02,\n","         1.6908e-02,  4.0377e-02, -3.5263e-02, -3.7370e-02, -1.9267e-02,\n","        -4.0457e-03, -2.9754e-02, -9.7325e-04, -8.7600e-03, -7.7008e-03,\n","        -9.0101e-03, -9.4025e-03, -5.6637e-03,  5.8014e-03, -8.9497e-02,\n","        -1.2439e-02, -3.3595e-03, -1.3799e-02, -1.3622e-02, -2.4765e-02,\n","         2.8373e-02, -4.7874e-02,  5.2224e-03, -3.5217e-03, -4.6295e-03,\n","        -2.2334e-03, -8.1386e-02,  7.2866e-03, -5.8032e-03, -8.3558e-03,\n","         2.6069e-03,  4.5456e-02,  4.1721e-03, -2.6533e-03,  2.7678e-02,\n","        -2.2717e-03,  1.3088e-02, -9.9037e-04,  3.6240e-03, -6.3791e-03,\n","        -1.1099e-02, -1.4192e-02, -1.5705e-02], device='cuda:0',\n","       requires_grad=True)\n","ln2.w: torch.Size([768])\n","Parameter containing:\n","tensor([0.1310, 0.2093, 0.2066, 1.2542, 1.2638, 1.2695, 0.0935, 0.0793, 0.2260,\n","        1.3008, 0.2324, 1.1525, 1.2761, 1.2695, 0.7216, 0.2881, 0.1325, 1.1616,\n","        1.2393, 0.1919, 1.2380, 1.2227, 1.1692, 0.1753, 1.1690, 1.3008, 0.1421,\n","        1.2539, 1.2142, 1.2007, 1.2299, 1.0236, 1.3710, 1.3308, 1.0197, 0.1152,\n","        0.2317, 1.2060, 1.2695, 1.0617, 1.2837, 1.2734, 1.2930, 1.3086, 0.3260,\n","        1.2463, 1.2305, 1.2773, 0.1372, 0.2164, 1.3143, 1.2393, 0.1665, 1.2103,\n","        0.3018, 0.3291, 1.0898, 0.1200, 1.2149, 0.1043, 0.1793, 1.2202, 0.1299,\n","        0.1555, 0.0643, 1.1776, 1.2422, 0.1817, 0.1472, 1.3810, 0.3341, 0.1125,\n","        1.2120, 1.1521, 1.3403, 0.9472, 0.1831, 0.1996, 0.2273, 1.0586, 0.3701,\n","        1.2456, 1.2461, 1.0780, 0.8484, 0.1608, 0.2123, 0.0573, 1.2763, 0.1909,\n","        1.2071, 1.2695, 1.2037, 1.2617, 1.2927, 1.3385, 1.3401, 0.1224, 1.3009,\n","        0.0869, 1.3700, 0.1047, 0.1528, 0.5143, 1.2446, 1.3158, 1.0508, 0.4896,\n","        1.2535, 1.2462, 0.1860, 1.3008, 1.2610, 1.2461, 1.2385, 1.1967, 0.1402,\n","        0.1768, 1.3216, 0.1584, 1.2589, 1.0898, 1.1367, 1.0122, 1.2822, 1.2539,\n","        1.3282, 0.2999, 0.1189, 0.1685, 1.0725, 1.2463, 0.1314, 1.2848, 1.1829,\n","        1.3398, 1.2838, 0.1461, 1.3643, 0.2920, 1.2383, 1.0522, 1.3848, 1.2063,\n","        1.2218, 0.7756, 0.1823, 1.1902, 0.9476, 0.1981, 1.1494, 0.1450, 0.1114,\n","        0.1616, 0.6934, 1.2915, 0.8919, 1.2050, 1.3711, 0.9021, 0.1292, 1.1992,\n","        0.8999, 0.1899, 1.1060, 1.3398, 1.1884, 0.0809, 1.2148, 0.9122, 1.2461,\n","        1.3115, 1.2305, 0.1923, 0.2104, 0.6869, 0.3137, 1.3398, 0.1229, 1.0117,\n","        1.2169, 1.3585, 1.2617, 0.1596, 1.2773, 1.3868, 1.1834, 0.1255, 1.2540,\n","        0.8462, 1.2539, 1.0662, 1.1688, 0.9397, 1.2265, 0.1411, 1.2305, 1.1993,\n","        1.3088, 0.2892, 0.3917, 0.1402, 1.2617, 1.1918, 1.2149, 1.2461, 1.2070,\n","        1.3069, 0.1879, 1.2272, 1.2696, 0.1778, 1.1146, 0.0911, 1.1775, 1.2742,\n","        0.1134, 1.2480, 0.1284, 1.3320, 1.1592, 1.1524, 1.2247, 0.4861, 0.2111,\n","        1.3135, 1.2690, 1.3555, 1.3320, 1.3816, 1.2833, 0.3369, 1.1766, 1.1879,\n","        1.2619, 0.1854, 1.2308, 1.2773, 0.1538, 1.2536, 0.1229, 0.2114, 1.2227,\n","        1.2361, 1.2516, 1.1977, 1.2852, 0.1065, 1.1602, 0.4358, 1.3087, 0.1763,\n","        1.1947, 0.1157, 0.9006, 0.1743, 1.0279, 1.2617, 1.2370, 0.3937, 1.2383,\n","        0.2920, 1.1367, 1.1211, 1.2435, 1.2988, 0.0661, 0.1210, 0.1948, 0.1333,\n","        0.1228, 0.1401, 1.2854, 1.1828, 0.1211, 1.3242, 0.1101, 1.3207, 1.3617,\n","        1.2643, 1.2767, 1.3005, 1.0626, 0.1519, 1.0131, 0.1607, 0.8573, 1.1734,\n","        0.0848, 0.1401, 0.1930, 1.2932, 1.1940, 1.4024, 0.2510, 1.1871, 1.2803,\n","        1.3177, 1.2305, 0.7614, 0.2944, 1.3518, 0.1724, 1.2179, 1.2308, 1.2218,\n","        1.2136, 1.3700, 0.2221, 1.3270, 1.2445, 0.1238, 1.2710, 1.2715, 0.6565,\n","        1.2787, 0.1290, 1.1306, 1.1446, 0.4893, 0.3923, 1.1133, 1.2455, 0.2164,\n","        1.1585, 1.3292, 0.1032, 1.2612, 0.1486, 1.2841, 1.0352, 1.2493, 1.0977,\n","        1.2619, 1.2523, 1.1453, 0.1238, 1.3007, 1.3076, 0.0910, 1.1602, 1.3320,\n","        1.2830, 0.1302, 0.2280, 1.1680, 0.9572, 0.9824, 1.1914, 1.1367, 1.0957,\n","        0.0994, 1.3005, 0.4289, 1.1758, 1.1055, 0.1724, 1.1602, 1.1512, 1.3468,\n","        0.1510, 0.4778, 0.6197, 1.2227, 1.2451, 0.1431, 0.9534, 1.2218, 1.4153,\n","        1.2066, 0.2073, 1.2968, 1.1758, 0.0453, 0.5822, 0.1294, 0.1256, 0.1294,\n","        1.4149, 0.3630, 1.2455, 1.2370, 1.1914, 0.1528, 0.2666, 0.1203, 0.1658,\n","        1.3080, 1.2304, 0.2124, 1.1559, 1.1914, 0.8532, 0.1297, 0.6818, 1.2494,\n","        0.2481, 1.2461, 1.2681, 1.3726, 1.2810, 1.2539, 0.2658, 1.1600, 1.2934,\n","        1.2047, 1.1445, 1.2506, 0.5340, 1.2770, 1.3477, 1.2511, 1.2183, 1.2673,\n","        0.2135, 0.1713, 1.2462, 0.1373, 0.1773, 1.2148, 0.1519, 0.1033, 1.2635,\n","        1.0959, 1.2226, 1.3048, 1.2396, 1.1221, 0.3531, 1.2550, 0.6597, 1.2316,\n","        1.1758, 1.2461, 1.2930, 0.5015, 1.2821, 1.2695, 0.1566, 0.1733, 1.2113,\n","        1.0844, 0.1624, 1.3008, 0.1654, 1.2617, 1.3107, 0.0662, 1.2081, 1.1133,\n","        0.3584, 1.1602, 1.2553, 0.1779, 1.1543, 0.1821, 0.1519, 1.1681, 1.2482,\n","        0.0897, 1.1608, 0.2063, 1.2664, 1.2993, 0.0877, 0.1821, 1.1435, 1.3064,\n","        1.2510, 1.0192, 1.1753, 1.1176, 0.5293, 1.2076, 1.2534, 1.1171, 1.2486,\n","        1.3553, 0.9897, 0.5137, 0.0628, 0.2755, 1.1758, 1.2462, 0.1218, 1.1821,\n","        1.3554, 1.2436, 0.1940, 1.1766, 1.3242, 0.2047, 1.2437, 1.2437, 1.1282,\n","        1.1992, 0.5268, 0.0969, 0.6351, 1.2305, 1.2071, 1.2695, 0.1965, 0.1268,\n","        0.2008, 1.2528, 1.1861, 0.7872, 0.1538, 1.3695, 1.1990, 0.3976, 0.8614,\n","        1.1584, 0.9122, 0.1616, 1.1252, 1.0586, 1.3239, 1.2695, 1.1838, 1.3222,\n","        1.0847, 1.2474, 1.2048, 0.4071, 0.0875, 0.1164, 0.2028, 1.2742, 1.1679,\n","        1.1861, 1.2999, 1.2557, 1.1365, 0.1723, 1.2736, 1.2625, 0.1949, 1.2105,\n","        0.2312, 1.3000, 1.1916, 0.4788, 1.0899, 1.2262, 0.9473, 1.2622, 1.1602,\n","        0.0977, 1.3262, 0.2099, 1.1759, 1.3706, 0.1028, 0.9920, 1.5110, 1.1758,\n","        1.1760, 0.8661, 1.0522, 1.2495, 1.4649, 1.2633, 1.1681, 0.2424, 0.0979,\n","        1.1701, 0.2300, 0.1276, 1.1211, 0.1994, 1.2148, 1.2483, 1.3547, 0.1293,\n","        1.3079, 1.3046, 0.0962, 1.1719, 1.1908, 0.9791, 0.1626, 1.1820, 1.3019,\n","        1.1055, 1.2698, 0.1460, 0.6963, 1.4001, 1.1074, 1.2313, 1.3477, 0.1639,\n","        1.2447, 1.2555, 1.1367, 1.2852, 1.3477, 1.2776, 1.0962, 1.1521, 1.0501,\n","        1.0624, 0.7407, 0.8770, 1.2097, 1.2044, 0.1274, 1.1913, 1.1345, 0.1876,\n","        1.2227, 1.1678, 1.2463, 0.2075, 0.8188, 1.1860, 1.1267, 0.2988, 1.4390,\n","        1.1367, 0.1333, 0.4668, 0.1429, 1.2722, 1.2730, 0.4018, 1.1758, 1.2810,\n","        1.0978, 1.2845, 1.0343, 1.1335, 1.2305, 0.1136, 1.1797, 1.2459, 1.2540,\n","        1.1939, 0.1431, 0.9282, 0.0823, 0.1851, 0.1265, 1.0933, 1.0932, 0.1439,\n","        0.8275, 0.1183, 1.2446, 0.1470, 1.0382, 0.1997, 1.2120, 0.2349, 1.3069,\n","        0.2702, 1.4173, 0.1256, 1.1836, 1.1059, 1.2074, 1.2131, 1.1993, 0.3162,\n","        1.2065, 0.2781, 1.2605, 0.9863, 0.1975, 1.2409, 1.1890, 1.2968, 0.3096,\n","        1.3443, 1.2695, 1.2560, 0.9902, 0.0823, 1.0360, 1.1992, 1.1434, 1.1832,\n","        1.2258, 0.1204, 1.2073, 1.2461, 0.2407, 1.2221, 1.2852, 1.2848, 1.3865,\n","        1.1688, 1.2076, 1.2328, 1.2852, 1.3008, 1.2254, 0.1557, 1.2349, 0.2046,\n","        1.1995, 0.2510, 1.2605, 1.2853, 0.1318, 0.1890, 1.2350, 0.1413, 0.1267,\n","        1.2852, 1.1914, 1.3233, 1.2955, 1.1393, 1.2600, 0.3708, 0.1204, 1.3546,\n","        0.4696, 0.1600, 1.2386, 1.2712, 0.4716, 0.2943, 0.1324, 0.3974, 0.5167,\n","        1.2072, 1.2227, 1.0819, 1.3398, 0.2309, 1.0912, 1.2488, 1.2461, 1.2589,\n","        1.0292, 0.1508, 0.2434, 1.2328, 0.1877, 1.1108, 0.2958, 0.1354, 0.1304,\n","        1.1251, 0.6595, 0.1903, 1.1673, 1.0357, 1.1751, 1.2363, 0.2609, 0.1285,\n","        0.0891, 0.2588, 1.2540, 0.7476, 1.3320, 1.1829, 0.4680, 1.2606, 1.2772,\n","        1.2930, 1.2852, 1.0742], device='cuda:0', requires_grad=True)\n","ln2.b: torch.Size([768])\n","Parameter containing:\n","tensor([ 4.2478e-02,  3.2627e-02,  4.4881e-03,  1.5759e-02,  5.9602e-03,\n","        -2.6807e-02,  1.1714e-02,  5.1371e-02,  1.3218e-02, -4.2403e-03,\n","        -1.1668e-02,  2.1938e-03, -1.3368e-02, -2.0641e-03, -2.6502e-02,\n","         1.1916e-02, -4.2304e-03, -1.7872e-02,  4.7936e-02, -3.5567e-03,\n","         1.0502e-04, -1.2269e-02,  1.0864e-02, -5.9583e-03,  6.3190e-03,\n","         5.8250e-03,  6.2051e-02,  7.6980e-04, -2.4521e-03,  3.7931e-03,\n","         4.1393e-03,  3.8676e-02,  7.1191e-03, -1.9748e-02, -8.7425e-03,\n","         1.0532e-02,  1.3306e-01,  6.4183e-03,  8.8782e-03,  3.2611e-02,\n","         1.2175e-02, -6.0738e-03,  1.4179e-02, -6.6816e-03,  3.1226e-02,\n","        -2.2691e-02,  3.4057e-02, -1.2725e-02,  8.4687e-02,  3.5608e-02,\n","         4.1043e-03, -4.0983e-03, -7.2148e-02,  6.3665e-03,  3.6645e-02,\n","         5.6634e-02, -2.8777e-03,  7.2609e-02,  3.3852e-03, -1.8736e-02,\n","         4.3673e-02, -8.9816e-03,  1.7242e-03,  4.8758e-03,  6.4718e-01,\n","         2.2480e-02, -1.6124e-03,  4.7358e-01, -2.3700e-02, -1.0299e-02,\n","         4.8789e-02,  4.1948e-02, -1.2490e-02, -2.5387e-02, -1.6538e-02,\n","        -3.3809e-02,  2.1240e-01, -3.4010e-02, -2.1439e-02, -1.8616e-02,\n","        -2.3077e-03,  4.5811e-03,  1.1483e-02, -4.3040e-02, -4.2544e-02,\n","         4.4666e-03,  2.6603e-02, -1.0502e-01, -3.5718e-02,  8.1830e-03,\n","         5.3293e-03, -4.4015e-03, -7.0108e-02, -2.7428e-02, -1.4039e-02,\n","        -8.0539e-03, -1.0025e-02,  1.2429e-02, -4.7287e-03,  3.4481e-02,\n","         2.5232e-02, -2.6742e-02,  5.2326e-02,  1.5546e-03,  7.1964e-03,\n","        -1.0027e-02, -6.5897e-03,  9.7101e-02,  1.9900e-03, -7.4416e-03,\n","         4.7121e-02,  4.2296e-03, -1.0028e-02,  3.2298e-02,  2.8517e-02,\n","        -5.6324e-03,  1.5921e-02, -5.4898e-03, -2.4145e-03, -2.2275e-02,\n","         1.9797e-03,  1.5177e-02, -2.3981e-04,  2.1920e-02,  7.4726e-03,\n","         3.4763e-03, -1.9020e-03, -4.9628e-02,  5.4937e-02, -7.0872e-03,\n","        -2.0005e-02, -1.0336e-03, -2.4779e-02, -2.1098e-02, -1.1923e-02,\n","        -8.2058e-03,  1.3885e-03, -1.2818e-03,  3.0536e-01, -1.5931e-02,\n","         5.2648e-03, -3.3977e-03, -5.7403e-02, -8.3473e-03, -8.7204e-03,\n","         6.2504e-02,  4.0745e-02,  7.1376e-04,  5.5948e-03, -1.0004e-02,\n","         5.7510e-04,  1.9242e-01,  2.0573e-02, -4.9069e-03,  1.6400e-02,\n","         4.5475e-03, -1.3411e-02,  1.7491e-02,  3.9035e-02,  2.9461e-02,\n","         1.2506e-01,  1.3489e-02,  4.6089e-03,  1.2956e-02,  6.2868e-03,\n","        -1.0885e-02, -4.9344e-03,  4.8944e-02,  4.9658e-03, -4.8415e-02,\n","        -2.3949e-03, -6.0454e-03, -2.4293e-03,  9.8571e-03, -4.9077e-03,\n","         7.4278e-03,  1.8143e-02, -2.2342e-02,  5.1950e-02, -2.0951e-02,\n","        -1.7980e-02,  4.1686e-02, -7.6359e-03,  5.8008e-02, -1.2839e-02,\n","        -1.5384e-02,  1.4466e-02,  6.3113e-03,  1.4982e-03,  2.2041e-02,\n","         1.2190e-02, -1.0417e-01,  1.1087e-02, -1.8435e-02,  7.3731e-03,\n","        -2.4374e-02, -4.7435e-03, -1.9732e-02, -7.9195e-04,  1.5782e-04,\n","         2.1107e-03,  1.9065e-02,  4.4186e-04,  4.1912e-03,  1.7323e-02,\n","        -2.3979e-03,  1.1804e-03, -9.5315e-03,  8.2003e-02, -1.3103e-03,\n","         1.0594e-02, -8.2547e-02,  1.1437e-02,  3.7601e-02,  4.2946e-03,\n","         4.1774e-04, -3.9643e-02,  3.0071e-03,  7.2330e-02, -8.4551e-03,\n","        -3.7928e-03, -1.9019e-02, -1.3050e-02,  2.8875e-02,  4.0290e-02,\n","         1.8882e-03, -3.9509e-03, -3.2491e-03,  8.2333e-03, -2.2418e-03,\n","         2.2963e-03, -3.6275e-02,  1.4586e-01, -3.7791e-02, -1.3221e-02,\n","        -6.2712e-03,  9.9943e-04,  3.7847e-03,  6.3293e-02,  6.9592e-03,\n","         3.0836e-02,  7.2292e-02,  1.9839e-03, -9.1950e-03, -9.1727e-04,\n","         1.4988e-02,  2.1265e-03,  7.5790e-03, -1.4620e-02,  5.3023e-02,\n","        -9.3299e-02,  9.2950e-03,  9.2160e-03, -6.0666e-03, -2.4240e-03,\n","         2.1699e-02, -6.9314e-02,  1.1602e-01, -1.4612e-03,  3.4867e-03,\n","         9.1431e-04,  1.4333e-02, -9.1193e-03, -4.8455e-04, -8.1074e-03,\n","         8.4733e-03,  5.6343e-01,  1.8359e-02,  5.6824e-03, -2.4215e-02,\n","        -1.6346e-02,  1.9876e-02, -6.5513e-03,  2.1136e-02,  6.0301e-02,\n","        -2.0530e-02,  1.1197e-02, -3.3056e-02,  1.3041e-02, -1.2230e-02,\n","         1.1640e-02, -9.0302e-03,  2.8127e-02, -5.1116e-02,  1.3717e-01,\n","         1.7049e-02,  4.9823e-03,  8.7835e-03, -1.8132e-01, -8.1365e-03,\n","        -6.2690e-03, -2.1488e-03, -1.3785e-02,  2.8274e-02, -6.0488e-04,\n","        -1.9635e-03,  7.3535e-03,  2.6659e-02, -1.2661e-02,  6.7308e-04,\n","        -2.0270e-02, -4.3084e-02,  1.0279e-01, -1.4682e-02, -1.5737e-02,\n","         6.5343e-03,  1.4537e-02, -2.1777e-02,  4.3674e-02, -1.0318e-02,\n","         1.1560e-04, -6.9631e-02, -1.0365e-02,  2.8245e-02, -3.3001e-02,\n","        -1.4143e-02,  9.6534e-03,  1.5115e-02, -2.3083e-03, -9.7282e-03,\n","         5.0346e-02,  8.9917e-03,  1.1560e-03,  2.8564e-02, -6.8203e-03,\n","         1.7350e-02, -6.6476e-01, -1.2704e-02, -7.0944e-03, -1.1199e-02,\n","         2.4734e-02,  1.0937e-02, -6.6117e-03, -1.3656e-03,  1.6159e-02,\n","        -1.7454e-02, -5.5556e-02, -2.3551e-02, -2.6263e-02,  2.0475e-02,\n","        -1.3111e-02,  4.9847e-04, -1.4345e-02,  5.3200e-02,  2.7438e-02,\n","         7.9513e-03,  2.7415e-02,  9.8723e-03,  1.2610e-02,  1.1474e-02,\n","         3.7495e-03,  4.7410e-02,  1.7438e-02, -1.0085e-02,  2.1025e-02,\n","         1.0969e-02,  3.3697e-02,  4.7847e-03, -2.1274e-02,  1.3940e-02,\n","         4.4721e-02, -2.5978e-02,  1.1997e-01, -5.6126e-04,  1.6894e-02,\n","         1.8317e-02, -1.5733e-02, -4.3801e-03, -2.6697e-04, -3.4895e-03,\n","         2.0750e-02,  9.4606e-03, -3.9388e-02,  7.3938e-01, -5.5474e-02,\n","         9.6050e-03,  4.3844e-03,  1.1748e-02, -1.0192e-01,  4.1082e-02,\n","        -1.1030e-02,  1.2430e-03,  2.1023e-03,  1.0435e-01, -3.0708e-03,\n","         8.5318e-02,  4.4731e-02,  4.4977e-03, -1.5167e-03, -5.0067e-02,\n","        -2.5202e-03, -1.4850e-02,  1.3066e-02, -1.7334e-01, -4.0456e-04,\n","        -1.1342e-02,  5.5355e-02, -1.7507e-03, -6.8279e-03, -1.6099e-02,\n","        -2.6759e-02, -4.0496e-03,  2.3568e-02, -5.9833e-03, -1.0245e-02,\n","         1.1992e-04, -1.6295e-02, -1.0357e-02,  3.4625e-02, -8.9689e-03,\n","        -2.3550e-02, -5.1845e-03, -2.0975e-03,  1.0997e-02,  6.4249e-02,\n","         1.7179e-02, -4.3000e-03, -1.6883e-02, -3.4950e-02,  1.2482e-02,\n","         8.4498e-02,  1.6407e-02,  5.1100e-03, -2.3397e-02, -1.4567e-02,\n","         2.4564e-02,  4.9122e-03, -2.9652e-03, -2.2760e-02, -1.3693e-02,\n","         6.6996e-02, -2.3250e-02, -2.5882e-03, -6.4844e-03, -8.2639e-03,\n","        -3.4207e-03, -3.5851e-03, -2.2391e-02,  1.8060e-02,  4.2979e-02,\n","         5.9380e-02,  3.3773e-02, -2.3432e-03,  9.6166e-03,  5.5011e-03,\n","         3.8740e-03, -3.6465e-02, -5.0264e-01, -1.2615e-02,  1.5290e-02,\n","         5.0577e-02, -2.2878e-02, -3.0032e-03,  1.0095e-02,  4.2711e-02,\n","         5.9172e-02,  3.6998e-02,  8.9631e-03,  9.5094e-04,  1.3759e-02,\n","         2.3279e-02,  1.2986e-02,  2.3582e-02,  2.3613e-02, -4.1437e-02,\n","         2.8698e-03,  9.2705e-03,  1.3278e-03,  6.7985e-04,  1.1546e-02,\n","        -1.1227e-02,  5.7891e-03,  2.4757e-02,  4.1196e-03, -4.3092e-03,\n","        -1.7881e-03, -4.8966e-03, -6.3975e-03, -3.9937e-02, -4.5725e-02,\n","         5.6525e-01,  7.7586e-02, -5.3012e-03,  1.6219e-02,  3.7167e-02,\n","         1.2501e-02, -3.9626e-03,  2.5013e-03,  1.7983e-02, -2.1285e-02,\n","         2.3037e-02, -2.7337e-02, -1.5255e-03,  1.0102e-02,  2.7607e-02,\n","         8.3781e-03,  6.6876e-02,  4.4648e-02, -1.5155e-02, -4.0633e-03,\n","        -7.5388e-03,  4.5786e-03,  4.8683e-02,  2.2506e-02,  7.1097e-02,\n","        -1.7555e-03,  1.3040e-02,  3.9193e-02, -1.7982e-02,  1.4462e-02,\n","         7.5895e-03,  5.3976e-02,  7.5228e-02, -2.4235e-02, -1.3969e-03,\n","         8.0538e-02,  1.8747e-02, -6.4049e-02,  6.6817e-03,  4.5966e-02,\n","         4.5730e-03, -3.6125e-03,  1.6047e-02, -2.3065e-02,  7.6621e-03,\n","         2.9946e-02,  8.3312e-02,  4.4790e-03, -3.1677e-02, -6.8359e-03,\n","         4.7098e-02,  1.9239e-02,  5.2050e-03,  9.7407e-04, -1.5716e-02,\n","        -1.0584e-02, -1.0162e-02,  2.4878e-03,  8.6129e-02, -1.4744e-03,\n","         1.3994e-02, -1.9495e-02,  2.4462e-03, -6.7660e-02,  4.6932e-05,\n","         6.6121e-03, -3.2825e-03, -1.2422e-02, -1.2837e-02,  3.4729e-02,\n","         6.4618e-03,  2.0962e-02,  1.2552e-02, -1.8505e-02,  1.5658e-01,\n","         2.0562e-02,  7.1921e-02, -8.7786e-03, -8.8174e-03, -1.9801e-02,\n","         4.0586e-02, -1.0112e-02, -4.5501e-02, -1.0973e-02,  1.1436e-02,\n","         4.9422e-02,  4.7577e-02, -3.7514e-02,  6.1920e-02,  2.6517e-02,\n","        -2.2288e-02,  1.4490e-02,  1.8570e-02,  4.8706e-03, -1.5281e-02,\n","         1.9890e-01, -7.7756e-03, -1.6369e-02, -1.7428e-02,  1.0001e-02,\n","        -2.1126e-02, -1.7976e-02,  9.2352e-04, -6.8094e-03,  1.0797e-02,\n","         1.9269e-02,  2.4365e-02,  3.9438e-02,  5.0204e-02,  6.9093e-02,\n","        -8.3174e-03, -2.1196e-02, -4.7675e-03, -1.2510e-03,  1.0414e-02,\n","        -1.3324e-02,  6.5396e-03, -1.0879e-02, -1.9413e-02, -1.1362e-02,\n","        -5.7729e-02,  8.5630e-03, -4.3484e-02,  3.0691e-02,  3.4153e-02,\n","         1.4362e-02,  1.2212e-02,  2.5668e-05,  9.6168e-02,  1.4688e-02,\n","        -3.2631e-02,  3.4836e-02,  8.1770e-03, -5.6369e-03, -1.3393e-02,\n","         2.4180e-02,  5.5446e-02,  1.3878e-02, -4.9083e-02,  8.6672e-03,\n","        -1.1203e-01,  1.8946e-02, -2.8631e-03, -6.7262e-02, -5.6359e-02,\n","        -5.5327e-02,  9.0854e-04, -9.0765e-03, -1.0496e-03, -1.0980e-02,\n","        -2.0467e-02, -5.6790e-04,  1.7791e-02, -2.9359e-03, -5.4303e-03,\n","        -1.3692e-03, -4.0059e-02,  1.2293e-03,  1.9134e-03,  1.7032e-02,\n","         1.1883e-01,  7.7847e-03,  4.8493e-02, -8.8867e-02, -1.2061e-03,\n","        -2.0186e-02, -1.7666e-02,  2.5482e-02,  3.3769e-02, -4.0951e-02,\n","        -3.7505e-03,  8.5491e-02,  6.9690e-03,  6.9239e-02, -2.1685e-03,\n","         4.6065e-02, -7.1848e-02,  3.2061e-02, -2.4740e-02,  4.4159e-02,\n","         1.3438e-02, -2.1039e-02,  6.7205e-03,  4.7946e-03, -1.2853e-02,\n","         4.3970e-02, -1.0083e-02,  2.8207e-02,  7.5714e-02,  2.8432e-02,\n","        -1.2717e-02,  1.2283e-02, -9.9549e-03, -2.3407e-02,  4.8153e-03,\n","         2.2108e-03,  1.2725e-03, -1.6074e-02,  7.7241e-02,  4.2355e-02,\n","        -3.8431e-02, -1.9785e-02, -3.5607e-04,  2.3728e-02, -3.9369e-03,\n","         7.5741e-03,  8.3919e-03, -1.1944e-02,  5.6072e-02,  1.7718e-02,\n","        -2.1001e-03,  2.4662e-02, -4.1749e-03,  2.0369e-02, -1.6176e-02,\n","        -1.4338e-02,  7.5334e-03, -4.5668e-03, -2.1421e-03,  5.8641e-02,\n","         1.2811e-02,  2.4672e-02,  6.6942e-03, -3.7821e-02, -5.9976e-03,\n","        -1.8232e-03,  1.6359e-02, -5.3482e-03,  8.7840e-03, -1.7452e-04,\n","         5.5695e-03, -1.8791e-02, -4.6473e-03, -3.9086e-03, -2.1244e-02,\n","         1.1881e-02,  1.0627e-02,  1.0196e-01,  8.7201e-02,  1.9641e-02,\n","         8.4220e-02, -3.6598e-02, -4.8832e-03,  7.8899e-04,  2.6367e-02,\n","         1.0176e-02,  7.9064e-03,  6.1333e-03,  1.7752e-02,  6.4931e-03,\n","         3.4751e-03, -4.0625e-02, -1.8806e-02, -3.3521e-02,  1.4881e-02,\n","         1.9941e-02, -2.3271e-02,  1.0158e-02,  1.4241e-02, -2.0425e-01,\n","        -1.1301e-02, -9.9264e-03,  2.1097e-02, -2.0087e-02,  1.4243e-01,\n","         3.5326e-01, -2.4653e-02,  1.3351e-02, -9.8327e-03,  3.0865e-02,\n","        -1.0742e-02, -4.5019e-02,  1.0537e-03,  1.4887e-02, -1.5598e-02,\n","         1.1329e-02,  2.5360e-01,  2.1629e-02, -1.3195e-02,  3.8396e-02,\n","         7.0118e-03, -1.4644e-04, -3.3391e-03, -1.8383e-03,  1.2020e-02,\n","        -1.7873e-02,  6.3480e-03, -1.6447e-03], device='cuda:0',\n","       requires_grad=True)\n","attn.W_Q: torch.Size([12, 768, 64])\n","Parameter containing:\n","tensor([[[-0.4738, -0.2614, -0.0978,  ...,  0.0908,  0.2785,  0.2262],\n","         [ 0.0874,  0.1473,  0.2387,  ..., -0.3679,  0.3194, -0.0895],\n","         [ 0.0039,  0.0695,  0.3668,  ..., -0.2476,  0.1122,  0.2564],\n","         ...,\n","         [-0.2592, -0.0164,  0.1991,  ...,  0.0801, -0.0739,  0.0586],\n","         [ 0.1517,  0.2170,  0.1043,  ..., -0.0959, -0.5090, -0.2666],\n","         [-0.4100, -0.1924, -0.2400,  ..., -0.3557, -0.1824, -0.2051]],\n","\n","        [[-0.0604,  0.0430, -0.1627,  ..., -0.1296, -0.1096, -0.1044],\n","         [-0.0756,  0.3676,  0.5057,  ...,  0.0877,  0.1071, -0.2444],\n","         [ 0.1617,  0.0960, -0.3865,  ..., -0.0784,  0.2427,  0.0147],\n","         ...,\n","         [ 0.2824,  0.1018, -0.2002,  ..., -0.3588, -0.1922,  0.5668],\n","         [-0.0596,  0.0149, -0.5999,  ...,  0.0243, -0.3363, -0.4875],\n","         [-0.8100,  0.0829, -0.1574,  ..., -0.0282,  0.3973, -0.0414]],\n","\n","        [[ 0.0300,  0.1680,  0.2397,  ...,  0.1302,  0.4627, -0.1095],\n","         [ 0.1384,  0.1105, -0.3224,  ..., -0.3292, -0.0745, -0.3447],\n","         [ 0.0623, -0.0962, -0.0466,  ...,  0.2160, -0.1187, -0.1415],\n","         ...,\n","         [-0.1383, -0.1574, -0.1338,  ...,  0.1024, -0.0672,  0.2168],\n","         [-0.0813, -0.3627, -0.0701,  ..., -0.0735,  0.1483,  0.1813],\n","         [ 0.2793,  0.1252, -0.0929,  ...,  0.2450, -0.0311,  0.0170]],\n","\n","        ...,\n","\n","        [[-0.0441, -0.0750, -0.0318,  ...,  0.1809, -0.1900,  0.1294],\n","         [-0.3291,  0.1984,  0.0136,  ..., -0.2118, -0.2504, -0.1287],\n","         [-0.2582, -0.1068,  0.0329,  ..., -0.1194,  0.0697, -0.0785],\n","         ...,\n","         [ 0.1144,  0.2171, -0.0321,  ...,  0.0156,  0.1308, -0.1626],\n","         [-0.0943,  0.0766, -0.2175,  ..., -0.0617, -0.2180, -0.1426],\n","         [ 0.0790, -0.1009, -0.1577,  ...,  0.0080,  0.0497, -0.3096]],\n","\n","        [[ 0.0520,  0.1072, -0.0692,  ...,  0.1219,  0.0682,  0.1270],\n","         [-0.2197,  0.0738,  0.2174,  ...,  0.0620,  0.1358,  0.0070],\n","         [-0.0163,  0.0400, -0.1070,  ...,  0.0668,  0.1257, -0.1645],\n","         ...,\n","         [-0.0399,  0.3653,  0.1956,  ..., -0.1074, -0.2026,  0.0540],\n","         [-0.0119,  0.1274, -0.0934,  ..., -0.0842, -0.0156, -0.1885],\n","         [ 0.1113, -0.0420, -0.0402,  ...,  0.1622,  0.0130,  0.0705]],\n","\n","        [[ 0.0970,  0.0010,  0.1348,  ...,  0.3237, -0.0483, -0.2235],\n","         [ 0.0752,  0.1861,  0.2131,  ..., -0.0770, -0.1492,  0.1507],\n","         [ 0.3131, -0.0067,  0.0366,  ..., -0.1235, -0.1660, -0.0480],\n","         ...,\n","         [-0.1410,  0.0213, -0.0739,  ..., -0.0335,  0.1455,  0.0333],\n","         [ 0.1232, -0.0055, -0.1912,  ...,  0.0827, -0.0533, -0.0071],\n","         [-0.0636,  0.0071, -0.0675,  ...,  0.2170,  0.1470, -0.0557]]],\n","       device='cuda:0', requires_grad=True)\n","attn.W_O: torch.Size([12, 64, 768])\n","Parameter containing:\n","tensor([[[ 3.1272e-01, -1.8741e-01,  9.8025e-02,  ..., -1.1971e-02,\n","           9.3704e-03, -3.0943e-02],\n","         [-2.4419e-01, -1.9777e-01, -1.0981e-01,  ..., -1.6192e-02,\n","           2.5013e-02,  4.5859e-02],\n","         [-4.3006e-01,  1.5439e-01,  5.3782e-02,  ...,  1.4303e-02,\n","          -1.8077e-02, -1.5850e-03],\n","         ...,\n","         [-2.2143e-01,  2.5489e-01, -5.8059e-02,  ...,  2.4717e-02,\n","          -1.7435e-02, -4.2810e-02],\n","         [ 3.6620e-01, -2.2027e-01,  2.4277e-02,  ..., -2.1455e-04,\n","          -1.2749e-02,  2.0263e-02],\n","         [-4.1327e-03,  2.6353e-02, -1.7697e-01,  ...,  8.6689e-04,\n","          -2.0991e-02,  6.0998e-02]],\n","\n","        [[ 5.8308e-02,  7.7636e-02, -1.1319e-01,  ...,  2.5356e-02,\n","          -1.7026e-02,  1.7903e-02],\n","         [-3.8657e-01, -2.2992e-01,  4.5555e-02,  ...,  6.4866e-03,\n","          -7.9225e-03, -1.5126e-03],\n","         [-4.4323e-01, -3.0024e-02, -4.3540e-02,  ...,  1.2371e-03,\n","           1.9133e-02, -2.5781e-02],\n","         ...,\n","         [ 2.8262e-01,  1.1980e-01, -9.3027e-02,  ..., -3.0108e-02,\n","          -7.3077e-03,  6.6691e-03],\n","         [ 2.7075e-01,  1.8569e-03, -6.6830e-02,  ...,  9.3208e-04,\n","          -2.4171e-03,  4.9934e-02],\n","         [-2.3825e-01,  1.5188e-01, -6.3101e-02,  ...,  2.0630e-02,\n","          -1.4852e-02,  1.2316e-02]],\n","\n","        [[-4.9522e-01,  6.9678e-02,  2.1425e-01,  ..., -1.1630e-02,\n","           1.8950e-02,  5.1431e-03],\n","         [-1.3188e-01, -1.2297e-01, -1.3100e-01,  ..., -9.9798e-03,\n","           1.3407e-02,  3.5966e-02],\n","         [-7.2331e-02, -3.6855e-02,  4.1451e-03,  ..., -3.3576e-02,\n","           1.6728e-02,  1.7339e-03],\n","         ...,\n","         [ 1.4638e-01,  4.2206e-02,  4.5980e-02,  ...,  2.8937e-02,\n","          -1.2955e-04, -5.7906e-02],\n","         [ 3.6827e-01,  6.4958e-02,  1.4221e-01,  ...,  7.3958e-03,\n","           2.9342e-04, -3.2309e-02],\n","         [-4.7313e-01,  8.3574e-02, -9.9833e-02,  ..., -2.6717e-03,\n","           1.7422e-03, -1.7442e-02]],\n","\n","        ...,\n","\n","        [[ 3.4871e-01, -4.8244e-02, -2.8313e-01,  ...,  1.8609e-02,\n","           2.6345e-02, -5.9869e-02],\n","         [-8.4099e-02, -1.9906e-01, -4.1688e-02,  ..., -2.3513e-02,\n","           4.6516e-02, -2.4519e-02],\n","         [ 1.1066e-01,  2.2052e-01,  8.8997e-02,  ..., -2.7072e-02,\n","           6.8084e-02,  6.8808e-03],\n","         ...,\n","         [-2.1272e-02, -1.4236e-01,  8.9165e-02,  ..., -3.5805e-02,\n","           1.7032e-02,  2.4314e-02],\n","         [ 3.3580e-01, -9.1382e-02,  1.0919e-01,  ...,  8.8078e-03,\n","           3.8422e-03, -1.4863e-02],\n","         [-1.1315e-01, -1.9503e-01,  7.5385e-02,  ...,  2.8872e-02,\n","          -6.2511e-03, -1.1036e-02]],\n","\n","        [[ 5.4502e-01, -2.3857e-01,  3.2197e-01,  ...,  8.8920e-03,\n","          -2.0044e-02, -4.3923e-02],\n","         [ 6.6756e-02, -1.0728e-01, -2.8115e-02,  ...,  2.9821e-02,\n","          -4.5180e-02,  2.1467e-02],\n","         [ 2.4556e-01, -4.2639e-03, -6.8065e-02,  ..., -5.7802e-03,\n","          -1.2425e-02,  2.6301e-02],\n","         ...,\n","         [ 8.5386e-02,  2.4227e-01,  2.1937e-01,  ...,  2.6177e-02,\n","           7.7584e-03, -3.2979e-02],\n","         [-4.0490e-01, -2.5709e-01, -4.1716e-01,  ...,  3.5117e-02,\n","           3.6139e-02, -3.2679e-02],\n","         [ 2.8257e-02, -2.6487e-01, -8.0950e-03,  ..., -1.1467e-02,\n","          -1.1981e-02,  1.4431e-02]],\n","\n","        [[-5.7136e-02, -1.5847e-01,  1.4314e-02,  ...,  2.8972e-02,\n","          -6.0841e-03, -1.3391e-02],\n","         [-1.7294e-02,  1.7961e-01, -3.1109e-02,  ...,  1.5171e-02,\n","          -9.4450e-03, -1.4514e-02],\n","         [ 3.8611e-01, -1.2346e-01, -9.1878e-02,  ..., -3.1149e-03,\n","           2.5884e-02, -1.5317e-02],\n","         ...,\n","         [ 2.0241e-02,  1.9843e-01, -1.4822e-01,  ...,  2.3511e-02,\n","           1.0698e-02, -1.4997e-02],\n","         [ 1.7072e-02,  2.5236e-02, -1.8414e-02,  ..., -8.3186e-04,\n","           8.5938e-03,  4.9588e-03],\n","         [-1.0107e-01, -7.3497e-02, -2.3746e-03,  ...,  6.2539e-03,\n","           1.3171e-02, -1.7136e-02]]], device='cuda:0', requires_grad=True)\n","attn.b_Q: torch.Size([12, 64])\n","Parameter containing:\n","tensor([[ 4.8034e-01, -5.2543e-01, -4.2926e-01, -2.0595e-01, -1.2773e-01,\n","         -9.5427e-02, -3.5286e-01, -7.6463e-02, -4.5903e-02, -3.7529e-02,\n","         -1.3764e-02, -1.8478e-01, -1.1984e-01,  4.3963e-02,  4.2387e-02,\n","         -3.1302e-01,  1.6617e-02,  3.4909e-01, -3.9035e-01, -2.9889e-02,\n","          3.2862e-01,  1.1589e-01,  3.9021e-02,  1.3165e-01,  4.7540e-02,\n","         -1.2425e-01, -5.6136e-03, -1.4189e-01,  7.2825e-02,  1.3007e-01,\n","          4.6424e-01,  1.2814e-01,  5.7617e-01, -7.8620e-02, -5.6898e-01,\n","          2.5124e-02, -1.7923e-01, -2.0682e-01,  7.4427e-03,  2.9733e-02,\n","          1.7158e-02, -2.1490e-01, -6.2546e-02, -3.0948e-01,  1.2339e-01,\n","          2.1800e-01, -2.0176e-01,  2.5512e-01,  3.0168e-01, -2.8991e-01,\n","         -7.2179e-02,  1.5271e-01, -4.3990e-01, -2.2504e-02, -7.7784e-03,\n","         -5.0913e-01,  3.3491e-02, -1.1896e-01, -1.7937e-01, -3.3981e-01,\n","          3.5737e-01, -1.4809e-02,  5.0830e-01, -3.7198e-01],\n","        [-1.3983e-01,  5.1359e-01,  3.3090e-01,  1.5325e-01, -1.4920e-01,\n","         -3.3196e-01, -1.8601e-01, -8.6125e-02, -1.0644e-01,  7.9037e-02,\n","          3.6985e-02, -6.2770e-01,  5.5906e-01, -2.4101e-02,  2.3281e-02,\n","         -2.0543e-01,  7.5957e-02, -6.2597e-01,  2.3449e-01,  3.8095e-01,\n","         -2.3169e-01,  3.0494e-01, -5.4135e-01,  5.7115e-01,  2.0921e-01,\n","         -1.6429e-01,  6.4578e-01, -4.5198e-01, -3.4131e-01,  6.0828e-01,\n","          3.7996e-01,  5.7257e-01,  2.0522e-01, -1.7261e-01, -3.1178e-01,\n","          4.9210e-01, -3.9706e-01, -4.1385e-01, -1.7035e-02, -8.7229e-02,\n","         -2.7808e-01,  4.5287e-01, -3.1084e-01, -2.7139e-01,  2.0705e-01,\n","          5.0846e-01, -5.9041e-02, -1.8066e-01, -3.5574e-01, -2.2511e-01,\n","         -5.8524e-02, -1.6331e-01, -7.3097e-01,  2.2229e-01, -5.6816e-01,\n","          5.9884e-01,  1.7029e-01, -2.2603e-01,  6.3138e-02,  3.0579e-01,\n","         -2.4425e-01,  2.8380e-01, -6.8781e-01,  1.0613e-01],\n","        [-8.8029e-02,  1.5084e-01,  2.7636e-02, -7.1769e-01, -2.3159e-01,\n","          8.8806e-01,  1.9228e-01,  2.5255e-02, -1.2168e-01,  8.3731e-03,\n","         -2.2069e-01,  2.8187e-01,  2.7179e-01,  5.9855e-02, -2.5361e-01,\n","         -4.0518e-02, -1.3738e-01, -2.2256e-01,  7.1839e-01,  1.5637e-01,\n","         -3.1278e-01, -2.8058e-02,  1.3255e-01,  3.4142e-02,  2.6752e-02,\n","          6.1431e-02,  4.6812e-01,  1.0356e-02, -7.2573e-02,  1.4845e-02,\n","         -5.1681e-02,  1.5441e-01, -5.2975e-02,  3.5818e-01, -2.0492e-01,\n","         -3.8218e-01,  1.1988e-01,  2.5387e-01, -4.4802e-01, -1.7383e-01,\n","          2.6652e-01,  1.5616e-01,  2.2597e-01,  5.1873e-02,  1.4430e-01,\n","          7.6146e-02,  4.3709e-04,  6.0145e-02, -2.0164e-02, -2.1497e-01,\n","          6.2185e-03, -1.7246e-01,  9.2442e-02,  4.1088e-01, -1.7659e-01,\n","         -1.6535e-01,  1.9143e-01,  1.5482e-01, -3.8666e-01,  2.1575e-01,\n","         -5.8591e-01,  8.6476e-01, -4.1112e-01, -2.6192e-01],\n","        [ 7.6061e-02,  4.6999e-01,  5.7941e-01, -5.8563e-01,  7.8277e-01,\n","          5.7127e-01,  3.0230e-01,  5.2114e-01, -4.1103e-01, -4.1959e-01,\n","          8.8694e-02, -2.4452e-01, -2.8428e-01,  5.7149e-01,  8.2365e-02,\n","         -8.7333e-01,  3.5083e-01,  3.6120e-01,  1.3848e-01, -5.1687e-01,\n","          3.3451e-01, -3.2931e-01,  4.2908e-01, -3.4908e-01,  4.6058e-01,\n","         -5.7268e-01,  2.2023e-01,  2.0118e-01,  2.1122e-01,  7.6675e-01,\n","          5.0306e-01, -3.7580e-01, -4.6498e-01,  6.7782e-02,  5.1094e-01,\n","          5.6167e-01, -4.6174e-01, -1.2612e-01,  3.0556e-01, -1.3881e-01,\n","         -3.6857e-01, -1.2582e-01,  4.0164e-01, -4.0041e-01, -3.7102e-01,\n","          3.5822e-01,  4.7141e-01, -2.2665e-01, -8.5280e-02, -5.9138e-01,\n","          4.2688e-01, -7.3300e-01,  4.1458e-01,  8.7045e-01, -2.1854e-02,\n","         -6.0966e-01, -9.6922e-01, -3.5682e-01, -2.6823e-01,  7.5735e-01,\n","          4.3039e-01,  3.0336e-01,  1.2832e-01,  4.2054e-01],\n","        [ 2.4785e-01, -1.8676e-01, -7.0033e-02, -2.4694e-01,  1.4793e-01,\n","         -3.1935e-02,  2.8041e-01,  1.5225e-01,  5.1934e-01,  3.1919e-01,\n","          2.5960e-01,  7.2202e-02, -2.1085e-01,  6.6824e-02, -7.6946e-02,\n","         -2.9268e-01,  3.8642e-01, -1.7592e-01, -6.4686e-02,  1.3050e-03,\n","          2.1800e-01, -4.4417e-01,  7.2554e-02,  8.9707e-02, -1.9961e-01,\n","         -2.7006e-01,  2.2447e-01,  7.1952e-02,  3.3780e-01,  3.1084e-02,\n","         -5.3742e-01,  5.2338e-01,  5.1073e-02, -2.3977e-01, -1.0548e-01,\n","         -2.6422e-01,  3.5951e-01,  4.6438e-02, -6.3078e-02, -2.5145e-01,\n","         -2.4547e-01, -1.9121e-01, -1.8918e-01, -1.5513e-01, -2.1501e-01,\n","         -1.0108e+00,  6.4759e-01,  7.5585e-02, -2.7373e-01,  3.2820e-01,\n","         -3.9734e-01, -2.4839e-01,  3.8320e-01,  1.1867e-01,  4.7945e-01,\n","          5.1650e-01,  3.5161e-01,  3.0847e-01, -2.2487e-01,  8.4027e-03,\n","          3.7940e-01, -2.5984e-01, -1.4136e-01, -4.3798e-01],\n","        [-3.7580e-01, -3.6739e-01,  1.8203e-01, -3.9757e-01,  5.0669e-01,\n","          1.7914e-01,  1.4368e-01,  1.3952e-01,  1.8595e-01,  1.0564e-02,\n","          5.0753e-01, -2.8746e-01, -6.2951e-01,  3.2340e-01,  2.8527e-01,\n","         -3.3051e-01, -3.2315e-01, -1.7267e-01,  2.5108e-01, -4.1324e-01,\n","         -3.1516e-01,  4.9194e-01, -2.8950e-01,  2.2953e-01,  4.7758e-01,\n","         -6.2161e-01, -4.0084e-01,  1.7936e-01,  4.6028e-01, -5.5761e-01,\n","          4.5172e-01, -1.7846e-01, -6.5331e-01,  3.1335e-01,  2.8416e-01,\n","          3.9095e-01, -5.4154e-01, -3.7265e-01, -3.8286e-01,  1.8058e-01,\n","         -4.9199e-01, -3.4491e-01,  1.8438e-01,  5.8507e-01, -2.9816e-01,\n","          4.1760e-01, -5.4493e-01, -9.1039e-02, -5.0361e-02, -1.7122e-02,\n","         -3.0516e-01,  1.9027e-01,  2.2699e-01, -4.0413e-01,  4.5390e-01,\n","          2.1276e-02, -6.1500e-01, -2.2133e-01, -7.9023e-02,  3.1206e-01,\n","         -3.6949e-01, -4.4751e-01,  4.3374e-01, -3.5588e-01],\n","        [ 1.1294e-01,  2.9429e-01, -1.2129e-01, -4.0726e-01,  6.1205e-01,\n","         -5.1877e-02,  1.5219e-01, -1.5227e-01,  1.9754e-02,  5.5457e-02,\n","         -5.8312e-01, -6.9946e-01, -7.3617e-02, -1.5286e-01,  2.3285e-01,\n","          2.4217e-01,  2.2739e-02,  1.3377e-01, -5.1426e-03, -2.0444e-01,\n","         -8.6679e-02, -1.3361e-01, -3.5504e-01, -5.9695e-02,  8.0210e-02,\n","         -2.7050e-01,  8.1510e-02,  1.6372e-02,  1.2790e-01,  6.0249e-02,\n","         -2.2664e-01,  1.9956e-02, -5.8410e-01, -4.1983e-02, -4.0586e-01,\n","         -2.7357e-01,  9.1592e-02, -4.1586e-01,  6.3785e-02, -7.7040e-02,\n","         -3.7461e-01, -5.0191e-01, -5.4477e-01, -5.5283e-01, -4.7832e-02,\n","          1.8347e-01,  2.8035e-02,  2.8561e-01,  6.5527e-01,  3.0235e-01,\n","         -1.1998e-01,  7.1491e-01, -6.4967e-03,  1.0605e-01,  3.3150e-02,\n","          1.7346e-02,  5.2652e-02, -2.8201e-01, -2.1088e-01,  1.6994e-01,\n","          2.5492e-01, -8.1045e-02, -6.7263e-02,  1.9206e-01],\n","        [-3.7052e-02, -1.4550e-01,  3.9940e-01,  7.4355e-03,  1.5398e-01,\n","         -3.4439e-01, -3.2062e-01, -4.3249e-01, -2.3742e-01, -1.5198e-01,\n","          1.1749e+00,  5.4593e-01,  5.7808e-01,  6.9789e-01,  3.2429e-01,\n","          5.0548e-01,  2.4306e-01, -1.6576e-01, -3.3574e-01,  3.4647e-01,\n","         -8.8720e-01, -4.9292e-01,  3.4503e-02, -7.8786e-01, -1.7658e-01,\n","         -5.3449e-01, -3.2129e-01, -2.7833e-01,  4.7001e-02, -1.9856e-01,\n","         -1.7582e-01,  1.1531e-01, -4.2795e-02,  1.6039e-01,  7.9992e-02,\n","         -1.9266e-01,  4.4587e-01,  1.9195e-01,  5.3466e-01,  1.1686e-02,\n","          5.3047e-02, -3.0055e-01, -4.5209e-01, -4.4215e-01,  1.9119e-01,\n","         -2.7630e-02,  1.1421e+00, -4.2769e-01,  3.8372e-01,  7.3133e-01,\n","         -9.9823e-02, -1.1944e-01,  4.6980e-01, -8.4147e-01,  5.1113e-01,\n","          4.1706e-01, -2.8938e-02, -2.5926e-01, -2.3111e-01, -2.2068e-01,\n","         -1.9674e-01, -9.8343e-01, -1.7156e-01,  3.3313e-01],\n","        [ 6.4723e-02,  9.1155e-01,  7.0202e-03,  2.2360e-01, -3.2185e-02,\n","          2.9267e-01, -2.8345e-01, -3.6001e-01,  3.5596e-01,  2.5579e-01,\n","         -1.6032e-01,  7.2756e-03, -2.5692e-02,  1.3010e-01,  1.0155e-01,\n","          6.8877e-02, -2.6390e-02,  1.4527e-02,  2.0345e-01,  6.8162e-01,\n","          1.7099e-03,  3.6466e-01,  2.4010e-01,  2.3739e-02, -4.4478e-02,\n","          2.1254e-01,  3.3663e-02, -4.4114e-01, -3.6727e-02,  2.2023e-01,\n","         -4.9153e-01,  4.3373e-01,  3.7900e-01, -1.5638e-01,  2.2619e-01,\n","         -2.9947e-01,  3.3441e-01, -5.2019e-02, -1.1684e-02, -7.3780e-03,\n","         -2.5564e-01,  5.7980e-01,  8.7041e-03,  2.5658e-02, -7.1800e-01,\n","         -1.0552e-01, -4.5050e-01,  1.5571e-01,  8.2267e-02,  8.1125e-02,\n","         -1.1163e-01, -1.1316e-01, -1.0333e-01, -2.3050e-01, -3.0885e-01,\n","         -6.0399e-01,  2.2911e-02, -3.8446e-02, -4.7104e-02,  4.9468e-01,\n","         -1.3787e-01, -3.4314e-01, -3.2522e-01, -1.6676e-01],\n","        [ 1.1005e-01,  6.3299e-02, -4.2597e-02, -7.4602e-02,  1.7986e-02,\n","         -1.7774e-02, -2.8738e-01,  2.4689e-02,  5.0422e-02, -8.4619e-01,\n","          3.1083e-01,  3.2013e-01, -1.0203e+00,  7.7646e-01,  9.3977e-01,\n","         -1.2021e+00,  7.4877e-02, -9.9773e-02, -7.1127e-01,  4.4339e-02,\n","         -7.0945e-01, -1.8987e-02,  1.5529e-02,  7.0146e-01, -1.4438e-01,\n","          5.5465e-01,  6.4763e-02,  7.6838e-02, -6.9392e-02, -3.6403e-02,\n","         -1.5263e-01, -1.4138e-01,  4.8700e-02, -7.7318e-02, -7.8929e-03,\n","          1.4009e-01, -2.7806e-02,  1.0034e-01,  4.6883e-02, -3.7525e-01,\n","         -2.3499e-02,  3.0700e-02, -9.7449e-03, -1.4459e-02, -8.9532e-01,\n","          2.8193e-02, -1.0117e+00, -7.0924e-01,  1.6950e-04, -3.2936e-02,\n","         -5.0908e-02, -2.4585e-02,  3.6472e-01,  4.7568e-01, -1.2538e+00,\n","          8.3338e-03,  3.0914e-02, -1.0036e-02,  2.4052e-01, -1.3898e-02,\n","         -6.3896e-02, -7.6461e-01, -9.6681e-02, -7.8708e-02],\n","        [-9.6498e-02,  1.5405e-01,  1.4264e-01,  2.6533e-01,  4.5209e-02,\n","         -6.7083e-02,  6.3727e-02,  1.4742e-01, -7.9848e-02, -5.5552e-01,\n","         -1.0777e-03,  8.6654e-02, -3.0767e-01, -3.5340e-02,  5.7955e-01,\n","         -1.0124e-01, -1.5417e-01, -4.6698e-01, -7.3876e-02,  3.0894e-01,\n","         -3.8221e-02,  9.4444e-02,  6.2752e-01,  9.3133e-02, -1.5690e-01,\n","          3.0822e-02,  1.1124e-01, -7.5529e-02, -1.3586e-02,  1.1715e-01,\n","         -4.8662e-02,  3.9252e-01, -1.7008e-01,  2.0310e-01, -9.6492e-03,\n","         -1.1988e-02, -1.8604e-02,  1.6444e-01, -2.9892e-01, -1.8193e-01,\n","          2.6592e-01, -4.0409e-01,  2.1287e-01,  4.4472e-01, -2.7851e-03,\n","         -1.4501e-01, -2.2042e-01, -1.6609e-01,  1.3438e-01, -5.0159e-02,\n","         -2.4091e-01, -4.9713e-02,  4.5848e-01, -2.7246e-01, -2.4162e-01,\n","         -2.6105e-01,  1.7524e-02,  1.7405e-01,  3.2181e-01, -1.9042e-01,\n","          1.1384e-01,  2.0406e-01, -1.3203e-01, -1.8943e-01],\n","        [-7.6027e-02, -3.2096e-01,  2.9128e-01,  7.9369e-01,  8.7117e-02,\n","          2.4833e-01, -3.6272e-01, -1.2666e-01,  3.5840e-01,  3.1970e-01,\n","         -2.7805e-01, -4.6170e-02,  1.0231e-01,  2.7067e-02,  4.0887e-01,\n","          8.4146e-02, -3.8595e-01,  1.4069e-01, -6.6050e-02, -2.0798e-02,\n","         -3.8087e-02,  6.5006e-01, -6.9818e-01,  3.2144e-01, -9.5315e-02,\n","         -6.2110e-01,  2.5399e-01, -1.6755e-01, -7.5629e-03,  2.4248e-01,\n","         -1.3640e-01,  7.4428e-02,  1.9353e-01,  8.1436e-01,  3.1867e-01,\n","         -9.9197e-02, -3.6758e-02,  7.4111e-04,  1.1579e-01,  1.2330e-01,\n","         -1.4138e-01,  7.3662e-01, -5.1074e-01,  2.6983e-01,  2.9565e-01,\n","          4.2451e-01, -7.6297e-02,  4.7043e-01, -4.9620e-02, -1.4250e-01,\n","         -2.1484e-02,  9.4781e-02,  1.7125e-02, -1.3213e-02,  5.0710e-02,\n","         -5.9523e-01, -4.1019e-02,  3.4782e-02, -3.2111e-02,  8.3402e-02,\n","          1.8872e-02,  2.7613e-01, -4.2302e-01, -2.3774e-01]], device='cuda:0',\n","       requires_grad=True)\n","attn.b_O: torch.Size([768])\n","Parameter containing:\n","tensor([ 2.5374e-01,  2.4794e-02,  3.1690e-02, -4.6175e-02,  1.9516e-02,\n","        -5.5722e-03, -5.2921e-02, -3.0751e-01, -9.3767e-02, -8.9388e-03,\n","         3.2707e-02, -2.0272e-02, -5.9371e-03,  2.9929e-02, -3.0915e-02,\n","         1.2461e-02, -2.8058e-01, -3.2872e-02,  1.2328e-02,  1.5360e-01,\n","        -4.2876e-02, -4.2509e-02,  9.6932e-03,  8.2421e-02,  3.2696e-02,\n","        -1.5786e-02,  1.2105e-01,  4.3305e-02, -9.5465e-04,  2.9163e-02,\n","         3.9636e-02,  3.1295e-04,  5.9767e-02, -1.2767e-02, -2.7767e-02,\n","         2.0545e-01, -1.4840e-01, -1.1687e-02, -1.7156e-02,  4.4442e-02,\n","        -8.0545e-03,  5.6056e-02,  6.8887e-02,  1.2721e-02,  1.2412e-01,\n","         1.5628e-03,  2.0524e-02,  5.0395e-02,  1.2964e-01,  4.8385e-02,\n","         6.1729e-02,  1.9221e-02,  9.7316e-02,  4.4852e-03, -1.2879e-03,\n","         1.6429e-01,  8.6170e-02,  4.1258e-01, -8.9540e-04, -5.2632e-01,\n","         7.7984e-02,  5.0939e-02, -4.1453e-01, -3.0127e-01, -7.5006e+00,\n","        -8.0472e-03,  2.0907e-02,  2.8549e-01, -3.1498e-02, -1.8963e-02,\n","        -1.0227e-01, -1.2167e-01,  2.4450e-02, -2.4382e-02,  1.5858e-02,\n","        -2.4826e-03,  1.1994e-01, -2.0819e-01,  1.0552e-01, -2.1674e-02,\n","        -1.2650e-01, -4.3192e-02, -2.2887e-03, -1.1687e-02,  1.5473e-02,\n","        -2.3003e-01, -3.0322e-01, -2.8087e-01, -3.0249e-03, -2.6005e-02,\n","        -3.4768e-02, -1.8432e-02,  2.8537e-02, -1.9037e-02, -1.2880e-02,\n","        -2.5000e-03, -7.1764e-02, -3.1585e-01,  4.0156e-02,  1.7289e-01,\n","         1.5718e-02,  1.1187e+00,  6.7725e-02, -9.7948e-02, -2.3373e-02,\n","         1.3390e-03, -1.9646e-02, -5.9386e-02, -7.4458e-03,  1.4509e-02,\n","         9.6609e-02, -4.5561e-03, -2.0569e-02,  1.2750e-02,  1.3785e-02,\n","        -8.1152e-02, -1.5221e-01,  2.4717e-01, -1.4793e-02, -2.5687e-01,\n","         2.5939e-02, -2.4082e-02, -2.0682e-02, -4.1450e-02,  3.6176e-02,\n","         1.0053e-02, -6.9045e-04, -2.1593e-02, -1.6977e-01,  3.4652e-01,\n","        -1.0934e-02, -5.7180e-03, -3.1605e-01, -2.1624e-03,  1.1932e-02,\n","         1.3471e-02,  1.1687e-02, -3.7296e-01,  4.7103e-04, -2.2087e-01,\n","         3.8064e-02, -5.2716e-03,  8.8445e-02,  4.6333e-03, -4.5998e-03,\n","         2.9789e-03,  6.0275e-02, -1.0076e-02, -2.3094e-02, -9.4509e-02,\n","        -2.6687e-03,  5.5861e-01, -1.6595e-01, -4.1933e-02, -2.6646e-02,\n","        -3.2063e-03, -6.8776e-02,  2.8888e-02,  1.6846e-02, -3.5564e-02,\n","         1.7001e-01, -3.5249e-02,  6.6885e-03,  1.4114e-01, -3.4772e-02,\n","        -4.2299e-02,  5.7048e-03, -1.2496e+00, -1.4379e-02,  7.0992e-02,\n","         1.5873e-02,  5.8837e-02,  4.5976e-02, -1.2096e-02, -1.1481e-01,\n","        -9.8851e-02, -2.3341e-01, -1.4075e-02, -1.2173e-01, -4.4334e-02,\n","        -4.7474e-02,  2.3267e-03,  2.3181e-02, -6.0140e-02,  2.6897e-02,\n","        -4.0024e-02, -4.2974e-03, -2.0551e-01,  3.4349e-02, -5.6289e-02,\n","        -1.9750e-02,  5.8230e-02, -3.7984e-02,  4.0840e-02,  1.9036e-02,\n","        -9.5958e-01,  1.8793e-02,  8.1318e-02, -1.2844e-02, -4.0626e-02,\n","         1.2821e-01,  5.5704e-02,  1.5925e-02,  2.5981e-02, -3.8428e-02,\n","         2.8168e-02, -2.5215e-02,  1.1214e-02,  3.8639e-01, -2.3091e-02,\n","         2.0086e-02,  1.8841e-01,  3.1024e-02,  3.8890e-01, -2.0162e-02,\n","         5.0099e-03, -1.6488e-01,  1.4281e-02, -4.1689e-01, -3.3016e-02,\n","         3.6843e-02,  1.8634e-02,  1.8470e-02, -2.7166e-02, -4.3973e-02,\n","         9.1696e-03,  1.7126e-02, -3.4256e-02,  2.3658e-02, -3.1892e-02,\n","        -3.8627e-03, -1.6185e-01, -7.6916e-02,  1.7816e-03, -2.4084e-02,\n","        -1.4071e-01, -2.7465e-02, -3.8552e-03,  6.9264e-04, -2.6897e-02,\n","         9.4169e-03, -1.6290e-01, -4.7233e-02, -2.2548e-02,  4.7579e-03,\n","        -3.4122e-02, -4.0181e-02,  1.4766e-01, -1.7182e-02,  1.4172e-01,\n","         8.1138e-02,  6.0492e-02, -1.3509e-02, -9.3995e-02, -2.6451e-02,\n","        -2.2389e-01,  4.1083e-02,  5.2478e-02,  1.9497e-02, -5.7925e-02,\n","        -8.4780e-04, -1.0324e-01, -1.7628e-02, -3.1616e-02,  4.5298e-02,\n","         6.6292e-02, -2.0265e+00, -1.6388e-02,  2.0627e-01, -2.9492e-01,\n","        -5.1711e-01,  3.6803e-01, -2.5975e-02, -6.0137e-02,  1.1372e-01,\n","        -4.7635e-02,  4.7297e-01, -4.0770e-02,  1.8609e-02,  1.6743e-02,\n","        -1.4050e-02, -4.1919e-02, -4.1901e-02, -1.1950e+00,  8.5241e-02,\n","         1.6275e-01, -1.3336e-03,  5.3697e-03,  5.0689e+00,  7.5798e-03,\n","        -2.1499e-01,  3.1239e-02, -2.4495e-02,  1.5179e-02, -1.2710e-01,\n","         2.3629e-02, -6.4854e-03,  2.0392e-02,  4.5168e-02, -5.4861e-02,\n","         4.4420e-01, -3.7208e-02,  2.2593e-01, -5.1001e-03,  2.8140e-02,\n","         3.6339e-02,  5.0528e-03, -3.2099e-02,  1.4354e-01, -4.3434e-03,\n","        -1.9382e-02, -3.6059e-01, -3.4850e-02,  1.9714e-02,  2.2051e-02,\n","        -5.8933e-02,  1.6541e-01, -1.5341e-02, -5.0011e-02,  5.6867e-03,\n","        -8.2993e-02,  1.0203e-02,  2.9107e-02,  1.1222e-01,  7.7097e-02,\n","         2.1994e-02,  8.8074e+00, -3.3671e-02, -1.5785e-01,  9.9588e-03,\n","         2.7764e-02,  7.2342e-03,  4.0191e-02, -4.5219e-04,  1.0835e-02,\n","         2.3120e-02, -2.7623e-01,  2.2024e-03, -4.1929e-02,  1.0457e-01,\n","        -2.1361e-02, -7.3781e-03,  2.3411e-03,  1.5748e-02, -3.4218e-02,\n","         1.3394e-03, -2.6615e-03,  7.1672e-02,  2.6650e-03, -6.2284e-02,\n","        -1.1170e-02,  8.7955e-01,  8.0059e-03, -3.2074e-02,  2.2390e-03,\n","         3.8451e-02,  5.1203e-02,  9.7503e-03,  2.2972e-02,  2.3603e-02,\n","        -3.4408e-01,  1.0236e-02,  7.7165e-03, -1.6074e-02,  1.2346e-02,\n","        -7.0606e-02, -2.6093e-03,  2.0864e-03,  3.7954e-02,  3.1590e-02,\n","        -2.4956e-02,  3.6662e-02, -3.9980e-02, -9.5716e+00,  3.0861e-02,\n","        -1.5403e-01,  1.6102e-01,  4.0531e-02, -3.3385e-02,  1.4855e-02,\n","        -1.6538e-02,  6.2154e-02, -4.1968e-02, -1.0477e-01,  1.9730e-02,\n","         4.3321e-01,  5.0425e-02,  1.5911e-02, -5.8141e-03,  1.2477e-01,\n","         2.7628e-03,  4.1284e-02,  5.4919e-02,  3.1818e+00,  6.0226e-03,\n","        -1.2002e-03, -1.1477e-01,  1.7461e-03, -1.2267e-03, -3.7794e-02,\n","         4.8236e-03,  3.3411e-02, -1.1406e-01, -3.3255e-02, -5.2646e-03,\n","        -6.7249e-03, -1.7821e-02, -9.6888e-03, -4.8811e-02,  1.1461e-02,\n","        -3.9963e-02,  2.1030e-02,  2.4021e-02, -3.0432e-02, -3.4299e-02,\n","         1.2194e-01, -3.4922e-02, -8.7520e-02, -2.7475e-01, -3.8138e-03,\n","        -7.1941e-01, -2.2792e-01, -4.1753e-02,  4.0583e-02, -1.0200e-02,\n","         1.2540e-02,  4.9312e-03,  2.1789e-02,  6.1255e-02,  4.6432e-03,\n","        -4.1233e-02,  9.9343e-02,  9.3497e-02,  1.6039e-02, -3.4273e-02,\n","         9.5557e-03, -3.6950e-02, -4.5939e-02,  1.6920e-01, -3.0385e-01,\n","        -1.3053e-02,  5.7263e-02,  9.8998e-03, -7.3113e-02,  1.5906e-01,\n","        -3.7183e-02, -3.5040e-02,  9.6267e+00, -1.5517e-02, -6.2628e-03,\n","        -1.7525e-01, -1.0507e-02,  1.1985e-02,  1.3068e-02, -4.7502e-02,\n","         1.6007e-02, -2.3973e-01,  5.1441e-02, -1.8348e-02,  6.6784e-02,\n","         3.4461e-02, -2.8933e-02,  2.2800e-02, -1.0851e-02,  1.1980e+00,\n","         6.0356e-02,  1.2533e-02,  2.1210e-02, -2.5296e-02,  2.3668e-03,\n","         1.3391e-02, -2.6209e-02,  6.1973e-02, -2.0100e-02,  4.0779e-02,\n","        -3.7512e-03, -1.8001e-02, -2.1072e-02,  3.3751e-02,  7.5610e-02,\n","        -2.8288e+00,  7.5007e-01,  3.4711e-03,  2.2370e-02,  2.1345e-01,\n","         8.6689e-03, -2.9068e-02, -4.4047e-02, -2.5834e-01,  1.2111e-02,\n","         1.4593e-02, -2.1555e-01,  1.4794e-02,  1.2208e-02,  2.6792e-02,\n","        -1.7290e-02,  4.3109e-02, -2.1538e-01, -1.1718e-01,  2.1369e-02,\n","         2.3976e-02,  2.6593e-02,  4.7403e-03, -9.7190e-02,  1.1476e-01,\n","         5.0127e-02,  6.4895e-02,  4.8329e-03, -6.5535e-02, -1.3880e-02,\n","        -1.0876e-02,  8.6671e-02, -1.5544e-01, -3.6570e-02,  3.4187e-02,\n","         1.9431e-01, -2.3994e-02,  1.1845e-01, -1.3524e-02,  1.4957e-02,\n","        -3.1018e-02, -2.6957e-02,  7.0671e-03,  2.5631e-03, -1.2186e-03,\n","         7.7924e-03, -1.6330e+00,  5.3599e-02, -1.8756e-01, -7.0139e-03,\n","        -2.3122e-02, -6.4151e-02, -8.3342e-03,  2.1896e-02,  3.5156e-02,\n","        -2.1670e-01, -1.3031e-02, -2.6532e-02,  4.8541e-01,  3.9233e-02,\n","        -3.9144e-02, -2.7724e-02, -1.7202e-02,  1.9837e-02,  6.8050e-02,\n","         6.4429e-02, -9.3103e-03,  3.9496e-03,  5.2786e-02,  3.9141e-01,\n","         3.2731e-02, -5.5851e-02, -2.8864e-02, -3.2385e-02, -1.3205e+00,\n","        -6.8531e-03,  2.2708e-02,  3.3505e-02,  1.7597e-02,  1.0496e-01,\n","         1.4264e-02, -4.8636e-02, -3.8406e-02,  4.5662e-02,  4.0778e-02,\n","        -1.8216e-01,  1.0451e-01, -1.7186e-02,  4.5651e-01, -3.8283e-01,\n","        -7.1661e-02, -1.1596e-01,  2.3562e-02, -3.3345e-02, -6.5131e-03,\n","         5.2186e-01,  2.3118e-02,  4.2358e-02, -1.6354e-01, -2.3368e-02,\n","        -7.2773e-02,  9.2098e-02,  7.3960e-02, -8.5856e-03, -2.9190e-02,\n","        -2.5812e-02,  2.2813e-02,  3.9920e-01, -9.5951e-02,  3.5218e-02,\n","        -6.5971e-03,  1.0656e-02, -2.9333e-02, -9.3340e-02, -3.4266e-02,\n","        -3.2797e-02, -3.1812e-02, -1.6444e-02,  9.3795e-03,  4.9710e-03,\n","         7.4864e-02,  2.0503e-02,  1.2019e-02, -9.6463e-02,  9.0383e-03,\n","        -1.0163e-01, -1.1936e-02, -9.9240e-03,  6.9428e-02, -1.5972e-02,\n","        -1.6194e-03, -1.5143e-01, -2.6916e-03,  2.8160e-03, -5.4137e-02,\n","        -2.5201e-02, -5.9194e-02, -4.5547e-02,  1.1635e-02, -1.3743e-01,\n","        -2.7861e-02,  1.7670e-02,  3.6029e-01, -1.6620e-01, -2.9037e-01,\n","        -2.0906e-02, -4.9193e-02, -1.5157e-01,  1.0279e-02, -5.0183e-02,\n","        -6.2499e-02,  5.1592e-02, -3.6768e-02,  3.6979e-02,  5.8792e-03,\n","        -4.3812e-01, -2.6610e-02,  1.1139e-02, -1.7832e-02,  1.9296e-02,\n","         1.9268e+00, -5.1481e-02, -1.0374e+00, -2.3528e-01,  1.2806e-01,\n","         5.4152e-02,  4.5513e-02,  1.3185e-01, -4.5898e-02, -2.9059e-01,\n","        -3.1807e-02,  3.1282e-01, -5.2095e-02,  1.6830e-02,  1.0103e-02,\n","        -8.8821e-02, -5.6992e-02,  1.4918e-01, -3.2754e-02,  1.2647e-01,\n","        -4.5343e-02, -6.0089e-03,  4.0821e-03,  4.1599e-02,  2.9160e-03,\n","        -1.1127e-01,  1.3630e-02,  3.6787e-02, -4.5001e-02, -3.0751e-02,\n","         2.0958e-01,  1.4337e-03,  8.8389e-03, -1.2532e-02, -5.5176e-01,\n","         1.5702e-02, -3.0031e-02,  4.6619e-02, -4.3830e-02,  8.1384e-01,\n","        -5.2857e-02,  5.6117e-02,  4.5984e-02, -5.8693e-03,  3.7356e-02,\n","        -6.5819e-02, -1.2487e-02, -2.7487e-03,  8.7460e-02,  1.8732e-02,\n","        -3.9053e-02,  3.6349e-02, -1.2410e-02, -2.3506e-02, -3.2630e-02,\n","        -2.4478e-02,  5.1195e-03, -1.3056e-02, -2.5671e-02,  6.4557e-02,\n","        -4.3413e-02, -3.3658e-02,  2.5288e-02,  1.1613e-01,  2.0985e-03,\n","        -3.6912e-02,  1.5934e-01,  6.1136e-02,  5.0096e-02,  2.0183e-01,\n","        -8.2168e-02,  3.7455e-03, -2.7078e-02, -2.6565e-02, -1.2160e-02,\n","         1.8575e-02,  2.7518e-02,  4.5978e-02, -1.6936e-01,  1.1848e-02,\n","         1.6768e-01, -1.0185e-01, -1.8316e-03, -4.9507e-02,  1.5137e-01,\n","         1.3097e-01,  2.2946e-01,  5.9122e-02,  1.2234e-01,  3.1542e-02,\n","         2.9185e-02,  9.7023e-03,  6.8366e-05, -6.7330e-02, -9.7029e-03,\n","         4.7728e-02,  1.1725e-02,  5.2275e-02,  1.7453e-02, -6.5290e-01,\n","        -5.6344e-03,  4.9274e-02,  2.5439e-01, -7.0169e-03,  1.1553e-01,\n","        -1.9708e+00,  1.7502e-01, -1.0070e-01, -4.0944e-02,  2.6640e-01,\n","        -8.9016e-03,  1.0477e-01, -9.8193e-03, -3.0680e-02,  4.6587e-02,\n","        -1.1816e-01, -2.6923e+00, -1.4601e-01, -1.9426e-02, -7.9362e-02,\n","         1.6330e-02, -4.1226e-03, -1.9877e-02, -1.1459e-02, -1.9987e-02,\n","         5.0930e-02, -5.3962e-03,  1.9090e-02], device='cuda:0',\n","       requires_grad=True)\n","attn.W_K: torch.Size([12, 768, 64])\n","Parameter containing:\n","tensor([[[ 0.3660,  0.0771,  0.2226,  ...,  0.2182, -0.0353, -0.2534],\n","         [-0.4380, -0.1446, -0.4717,  ...,  0.0822, -0.1830, -0.3139],\n","         [ 0.1237,  0.0174,  0.1181,  ..., -0.0271, -0.1029,  0.0148],\n","         ...,\n","         [-0.2009, -0.2453, -0.1728,  ..., -0.2978,  0.0867, -0.2144],\n","         [-0.0825,  0.2873, -0.0022,  ...,  0.3966, -0.0419,  0.4542],\n","         [ 0.1567,  0.2664,  0.1851,  ...,  0.4973,  0.2553,  0.3879]],\n","\n","        [[-0.3581, -0.0267,  0.1390,  ..., -0.1479, -0.2918, -0.0746],\n","         [-0.0342,  0.2132,  0.1643,  ...,  0.1796, -0.0714, -0.3708],\n","         [ 0.0151, -0.0224, -0.1422,  ..., -0.0928,  0.1835, -0.1327],\n","         ...,\n","         [ 0.1370,  0.0608,  0.1179,  ..., -0.7398, -0.2028,  0.2726],\n","         [-0.0404, -0.0336, -0.5645,  ..., -0.2397, -0.2820, -0.2567],\n","         [-0.5056,  0.3207, -0.0495,  ..., -0.3114,  0.2403,  0.2127]],\n","\n","        [[-0.1375,  0.2369, -0.1350,  ..., -0.0626,  0.2297, -0.0305],\n","         [-0.1103,  0.3130,  0.0499,  ...,  0.2847, -0.2259, -0.0734],\n","         [-0.0847,  0.0845,  0.3417,  ..., -0.1490, -0.0985, -0.1267],\n","         ...,\n","         [ 0.3447, -0.1894,  0.0610,  ..., -0.1244,  0.0940, -0.0812],\n","         [ 0.1359,  0.2056,  0.1438,  ...,  0.1530, -0.0219, -0.2758],\n","         [ 0.1076,  0.2692,  0.0616,  ..., -0.2080, -0.4682,  0.0278]],\n","\n","        ...,\n","\n","        [[ 0.0634,  0.0445,  0.0736,  ..., -0.0552,  0.1392, -0.0491],\n","         [ 0.3563, -0.2082, -0.0822,  ...,  0.2109,  0.0803,  0.0644],\n","         [ 0.1600,  0.0543,  0.1216,  ...,  0.0350,  0.1437,  0.1187],\n","         ...,\n","         [ 0.0432, -0.2460,  0.0947,  ..., -0.0883, -0.0491,  0.1098],\n","         [ 0.1751, -0.0221,  0.1190,  ...,  0.0489,  0.1065, -0.0449],\n","         [-0.1055,  0.1388,  0.0510,  ..., -0.1167, -0.0015,  0.2706]],\n","\n","        [[-0.0215,  0.1129, -0.0714,  ...,  0.1153,  0.0764,  0.1374],\n","         [-0.1547,  0.0846,  0.1969,  ...,  0.1018,  0.1267, -0.1176],\n","         [ 0.1263, -0.0332, -0.1599,  ...,  0.0198,  0.2094, -0.0428],\n","         ...,\n","         [-0.0676,  0.3416,  0.1153,  ..., -0.0901, -0.0938,  0.1242],\n","         [-0.0323,  0.1086, -0.1363,  ..., -0.1014, -0.0102, -0.2565],\n","         [ 0.1197, -0.0925,  0.0026,  ...,  0.1738,  0.0942,  0.1884]],\n","\n","        [[-0.0345, -0.0537, -0.1521,  ..., -0.0392, -0.2204, -0.1203],\n","         [-0.1234, -0.0813, -0.0227,  ..., -0.1312, -0.1007, -0.2032],\n","         [-0.0896,  0.1503,  0.0334,  ..., -0.0182,  0.2173, -0.0052],\n","         ...,\n","         [-0.1453,  0.2397,  0.0131,  ..., -0.0070, -0.0495,  0.3333],\n","         [ 0.2364, -0.0491, -0.0778,  ..., -0.1258, -0.0598, -0.0675],\n","         [-0.0849, -0.1430,  0.1350,  ..., -0.0614,  0.2619,  0.0405]]],\n","       device='cuda:0', requires_grad=True)\n","attn.W_V: torch.Size([12, 768, 64])\n","Parameter containing:\n","tensor([[[ 1.4213e-01,  3.2920e-02, -6.6679e-02,  ..., -1.7292e-02,\n","           1.2237e-01,  1.9954e-03],\n","         [ 1.6184e-02, -6.3328e-02, -6.3612e-02,  ...,  1.8086e-02,\n","           4.7454e-02, -2.1912e-02],\n","         [ 2.2934e-02, -8.2780e-02,  4.3655e-02,  ...,  8.0492e-03,\n","          -2.9594e-02, -2.7042e-02],\n","         ...,\n","         [-9.1288e-03, -1.1456e-01,  1.0232e-01,  ..., -6.2961e-02,\n","          -4.7726e-05, -1.9103e-02],\n","         [ 8.3785e-02, -1.2905e-01, -1.4942e-01,  ...,  6.1911e-02,\n","          -1.2579e-01,  4.6272e-02],\n","         [-3.4144e-02,  3.3618e-03,  2.0308e-02,  ..., -6.2119e-02,\n","           7.5056e-02, -5.5417e-02]],\n","\n","        [[ 6.0746e-02, -5.4322e-03,  3.1356e-02,  ...,  2.0707e-02,\n","          -1.1467e-01,  6.8145e-02],\n","         [ 2.2039e-02,  5.3950e-02,  3.8485e-03,  ...,  1.4869e-01,\n","          -1.0312e-02, -4.1186e-03],\n","         [-9.5968e-03, -6.7799e-02, -2.0372e-02,  ..., -7.1049e-02,\n","          -8.4796e-03,  7.6508e-02],\n","         ...,\n","         [-6.4680e-03,  2.4566e-02,  5.9719e-02,  ...,  3.4323e-02,\n","           2.0387e-02,  3.7953e-02],\n","         [-1.5165e-02, -6.7671e-02,  2.8308e-02,  ...,  4.2698e-03,\n","           1.4881e-02,  2.3475e-02],\n","         [-1.4358e-02, -4.0857e-02, -4.7423e-02,  ..., -1.6800e-02,\n","           1.2952e-01, -1.1262e-02]],\n","\n","        [[-6.3765e-03, -2.8716e-02, -7.9825e-03,  ...,  9.7763e-03,\n","           6.8293e-02,  9.5851e-03],\n","         [ 2.1599e-02, -1.6907e-02,  8.6272e-02,  ..., -2.0704e-02,\n","          -3.0710e-02,  4.2194e-02],\n","         [-9.2497e-02,  8.1930e-02,  1.8608e-02,  ...,  5.5625e-02,\n","          -5.1702e-02, -4.0618e-03],\n","         ...,\n","         [ 8.4382e-02, -3.9694e-02, -8.7621e-02,  ...,  1.2120e-01,\n","           1.1765e-01, -5.8365e-02],\n","         [-1.0649e-02,  6.2662e-02, -7.3017e-02,  ..., -5.2756e-02,\n","          -1.0061e-01,  2.2173e-02],\n","         [-2.0860e-02,  8.7400e-03, -1.3126e-02,  ...,  1.3956e-02,\n","          -2.8781e-02, -3.6662e-02]],\n","\n","        ...,\n","\n","        [[-1.1617e-01, -1.0868e-01,  7.2688e-02,  ...,  1.4968e-01,\n","           7.2404e-02,  7.4104e-02],\n","         [ 9.7485e-02,  9.2781e-02,  5.2319e-02,  ...,  7.5772e-02,\n","           2.9137e-03,  2.8320e-02],\n","         [-1.6524e-01,  1.6041e-02,  1.0409e-01,  ..., -4.3587e-02,\n","          -1.8707e-01,  7.3140e-03],\n","         ...,\n","         [ 7.0166e-02,  6.8843e-02, -4.1529e-02,  ...,  2.6074e-03,\n","           1.9380e-02, -1.8378e-02],\n","         [-1.2713e-01,  5.1358e-02,  2.8368e-02,  ..., -6.9909e-02,\n","          -9.5156e-02,  5.0839e-03],\n","         [ 3.4284e-02, -1.0981e-01, -5.3782e-02,  ..., -1.3942e-01,\n","          -1.3132e-01, -6.7848e-02]],\n","\n","        [[ 4.6370e-02,  4.5328e-02,  1.0852e-01,  ...,  1.2999e-01,\n","           1.0469e-03,  7.7982e-02],\n","         [-4.2929e-02,  7.9354e-03, -3.9357e-02,  ...,  5.9657e-02,\n","          -8.4070e-02, -1.6900e-02],\n","         [ 2.0919e-02,  6.5131e-02,  3.1341e-02,  ..., -2.0776e-02,\n","          -1.5798e-02, -2.5776e-02],\n","         ...,\n","         [ 8.2137e-03, -8.1757e-02, -1.1381e-01,  ...,  6.8777e-02,\n","           7.5570e-02, -2.8254e-02],\n","         [-8.4720e-02, -1.2945e-03,  3.5819e-02,  ..., -6.5049e-02,\n","           1.4378e-02, -2.3464e-03],\n","         [ 5.5222e-02,  1.1367e-02,  1.0706e-01,  ...,  3.5786e-02,\n","           8.0850e-02, -2.3720e-02]],\n","\n","        [[ 4.1270e-02,  3.2154e-02,  1.9865e-02,  ...,  5.1325e-02,\n","          -5.8439e-02,  2.4996e-02],\n","         [ 1.1211e-01,  5.7701e-02,  1.6388e-02,  ..., -5.2535e-02,\n","          -1.1260e-02, -1.5588e-02],\n","         [ 1.0786e-02,  4.0747e-02,  4.1309e-02,  ...,  1.1428e-01,\n","           3.6295e-02, -3.1849e-02],\n","         ...,\n","         [ 4.1515e-02, -1.1103e-01,  2.1454e-02,  ...,  9.5337e-03,\n","          -5.1598e-02,  3.1862e-02],\n","         [ 6.4991e-02, -2.2272e-02,  3.8856e-02,  ...,  2.9339e-02,\n","          -4.2872e-02, -4.7467e-02],\n","         [-7.2418e-04, -1.2285e-02, -2.6153e-02,  ..., -4.5922e-03,\n","           6.9785e-03,  1.9844e-02]]], device='cuda:0', requires_grad=True)\n","attn.b_K: torch.Size([12, 64])\n","Parameter containing:\n","tensor([[-1.4611e-01, -6.3202e-02, -4.7258e-02, -9.2682e-02, -8.3484e-02,\n","         -1.3571e-01, -1.0058e-01, -2.9561e-02, -1.5705e-01, -2.4262e-01,\n","         -8.1476e-02, -4.8325e-02, -1.6462e-01, -2.6622e-02,  8.5022e-02,\n","         -1.9151e-01,  2.0220e-01, -2.2727e-02, -8.3964e-02, -9.4136e-02,\n","          2.5286e-02,  4.8060e-02,  2.2095e-01, -6.1350e-02,  2.3722e-02,\n","          8.8407e-02, -3.6372e-02,  8.6801e-02, -8.7590e-02,  8.9762e-03,\n","         -8.8368e-02, -8.4046e-02,  1.6854e-01,  1.4365e-01,  3.5403e-02,\n","         -9.3681e-02,  3.4466e-02,  1.2833e-02,  3.6465e-02,  8.8829e-03,\n","          6.5743e-02, -3.1236e-02,  2.4328e-02, -4.4170e-02,  1.4711e-01,\n","         -8.4549e-03,  1.9139e-02,  6.4082e-02,  2.4521e-02,  3.7683e-02,\n","          3.4089e-02, -1.9813e-02,  1.2082e-03,  6.8116e-02,  1.5907e-01,\n","          9.6397e-02,  1.7645e-02, -9.8472e-03,  1.3708e-01, -1.1867e-01,\n","         -6.2919e-02, -1.3595e-01, -2.4013e-02, -5.2590e-02],\n","        [-2.1407e-01,  1.4069e-01,  2.1187e-01,  4.2148e-01, -6.4579e-01,\n","         -2.5659e-01, -4.0477e-01,  1.6054e-01, -1.3905e-01,  6.1006e-01,\n","          2.1664e-01,  3.4925e-01,  5.6968e-01, -4.3012e-02, -4.3943e-01,\n","         -1.8074e-02, -2.5402e-01, -5.8240e-01,  1.3830e-01,  9.2940e-01,\n","          4.8210e-01,  3.2201e-01, -3.3353e-01,  5.6403e-01, -1.3676e-01,\n","         -3.8155e-01,  9.5574e-01, -6.1402e-01, -9.3447e-02, -1.5058e-01,\n","          3.7821e-01,  7.6257e-01, -1.9781e-02, -1.9396e-02,  3.1594e-01,\n","          4.0537e-01, -3.1291e-01, -4.5284e-01,  1.2845e-01, -2.7072e-01,\n","         -3.7638e-01,  3.3525e-01, -3.8571e-01, -5.1469e-01, -1.4114e-01,\n","          3.7181e-01,  8.9176e-01,  2.2814e-01, -8.9289e-01, -1.1400e-01,\n","          6.0320e-02, -7.0643e-01, -7.6652e-01,  4.0771e-01, -1.3371e+00,\n","          1.1515e+00,  1.0672e-01,  3.4687e-01,  2.6044e-02,  1.2594e-01,\n","         -4.2465e-01,  3.9579e-01,  5.3100e-01,  3.7269e-01],\n","        [ 8.1404e-02,  1.5064e-01,  4.6011e-02, -1.9762e-01, -7.2783e-02,\n","         -1.7234e-01,  1.5704e-02,  1.5393e-01,  1.9221e-02,  1.2679e-01,\n","         -2.3783e-02,  5.1444e-03,  1.7401e-02,  9.2118e-02, -1.0226e-01,\n","          6.9405e-02,  1.7612e-02,  1.2197e-02,  5.3232e-02,  4.0389e-02,\n","          4.1055e-02,  8.5022e-02, -4.8374e-02,  3.4198e-02, -1.9784e-01,\n","         -1.0299e-01,  9.9028e-02,  1.3574e-01, -4.1358e-02, -1.8017e-03,\n","         -1.1571e-01,  4.3975e-02,  2.8874e-02, -1.0651e-01, -3.5614e-02,\n","          6.8847e-02, -1.8377e-02, -4.5121e-02,  1.4801e-01,  9.8838e-02,\n","          1.2599e-01,  6.3351e-02, -6.5797e-02,  4.0529e-02, -9.0437e-02,\n","          1.4713e-01,  5.6328e-02,  8.1813e-02, -2.3127e-03,  1.6015e-01,\n","         -7.2817e-02,  7.9217e-02, -6.6340e-02,  7.8612e-02,  1.2560e-01,\n","          1.0875e-01,  8.7090e-02, -2.1759e-02,  5.3546e-02, -4.3723e-02,\n","         -1.2172e-01, -1.0914e-01, -1.7822e-01,  4.2085e-02],\n","        [-1.8381e-01, -2.4875e-01,  1.9216e-02,  4.1449e-01, -6.5593e-02,\n","         -3.5539e-02,  1.9044e-02, -3.3281e-01,  1.1186e-01,  1.7305e-01,\n","          4.0495e-02, -1.2608e-01,  3.0316e-01, -3.9585e-01, -1.1645e-01,\n","          1.1108e-01, -1.3843e-01, -7.5790e-02,  1.1160e-02,  1.2454e-01,\n","          1.0242e-01, -5.6780e-02, -1.4925e-01, -1.1104e-01, -9.0196e-02,\n","          4.9654e-01,  6.2126e-03, -5.2128e-02,  4.6875e-02, -8.4117e-02,\n","         -2.5140e-01,  9.4193e-02,  4.0150e-01, -9.0942e-02, -7.3015e-02,\n","         -2.4515e-02,  1.9120e-01,  2.3074e-01, -2.3176e-05,  1.0800e-01,\n","          1.7305e-01, -7.6003e-02,  7.6532e-02,  7.0845e-02,  1.0732e-01,\n","          6.5237e-02, -6.3135e-02,  6.9967e-02, -6.3011e-02,  1.7056e-01,\n","         -2.6326e-01,  2.2985e-01, -2.3052e-01, -3.5284e-01, -9.8239e-02,\n","          2.0438e-01,  4.0484e-01,  1.2019e-01,  5.3516e-02, -1.5580e-01,\n","         -7.0106e-02, -1.1109e-01, -6.8664e-02, -2.6033e-01],\n","        [-7.5187e-02,  1.6075e-01,  3.2261e-02, -7.4722e-02,  1.1479e-02,\n","         -5.6878e-02, -2.3850e-03,  7.3890e-02, -6.1833e-02, -9.2959e-02,\n","         -1.1238e-02,  3.7401e-02,  6.5753e-02, -1.9802e-01, -8.6904e-02,\n","          1.1303e-01, -1.1595e-03,  2.8346e-02, -1.0936e-01,  2.3487e-02,\n","         -1.1335e-01,  2.6688e-02, -1.2993e-02,  1.1949e-02,  9.6798e-02,\n","         -1.3967e-02,  4.8085e-02,  5.6099e-05, -6.9127e-02,  1.7218e-01,\n","         -4.8035e-02, -2.1260e-01, -1.0721e-01,  3.2991e-02, -8.1438e-02,\n","          1.2281e-01, -5.4751e-02,  4.4743e-02,  8.4619e-02,  1.4232e-02,\n","         -2.0356e-02,  1.6939e-01,  2.4884e-01, -8.8721e-02,  1.0401e-01,\n","         -1.9896e-03, -6.2556e-02, -4.9044e-02, -3.6728e-02, -1.2862e-01,\n","          1.1471e-01,  1.0030e-01, -1.0219e-01,  9.0493e-03, -1.2031e-01,\n","         -3.3620e-02, -5.8417e-02, -5.8333e-02, -7.9576e-02, -5.7462e-02,\n","         -1.3531e-01,  4.9678e-02,  9.2545e-02,  1.1460e-01],\n","        [ 1.7170e-01,  2.1621e-01, -2.3856e-01,  5.3063e-01, -6.1886e-02,\n","         -8.0219e-02,  1.4367e-01,  1.2676e-01, -1.1856e-01, -1.1131e-01,\n","         -1.7014e-01,  2.0042e-01,  3.1886e-01, -1.2226e-01, -4.7732e-02,\n","          7.3661e-02,  1.0227e-01,  3.7226e-01, -3.2653e-01,  3.5577e-01,\n","          2.8296e-01, -2.9640e-01,  2.0972e-01,  2.5866e-01, -6.9727e-01,\n","          2.6316e-02, -1.8256e-01,  7.1649e-02, -5.3895e-01,  3.4888e-01,\n","         -8.5525e-02, -1.9581e-01,  2.0597e-01, -1.4185e-01,  1.8933e-01,\n","          4.6969e-02,  3.1436e-01,  3.4117e-01,  3.0721e-02, -3.8055e-01,\n","          3.1936e-01,  1.7297e-01, -2.2087e-01, -6.7632e-01,  7.6154e-02,\n","         -3.0747e-01,  5.4920e-01,  2.5548e-01,  4.0818e-04,  3.9203e-02,\n","          1.8328e-01,  7.9923e-02, -2.0420e-01, -7.0450e-02,  1.1714e-01,\n","          3.7764e-01,  1.7148e-01,  1.9309e-01, -6.5513e-02, -1.2241e-01,\n","          2.1864e-01,  1.7470e-01, -1.1551e-01,  2.9534e-01],\n","        [ 1.0976e-02, -3.2148e-03,  7.6639e-02, -5.4193e-02,  2.5151e-02,\n","          1.0161e-01,  5.2587e-02, -1.0403e-02,  1.3563e-02, -6.1777e-02,\n","          2.1137e-02,  4.0078e-02,  5.0186e-02, -2.5454e-02,  3.0994e-02,\n","          1.1662e-01,  7.2912e-02,  1.5301e-01,  5.2965e-02, -1.7853e-02,\n","         -4.5376e-03, -3.5648e-02,  1.2526e-01,  2.5420e-03, -9.4262e-02,\n","         -2.1524e-01,  1.1038e-01,  2.0059e-02,  1.9175e-02, -1.1561e-01,\n","         -3.4211e-02,  1.2423e-01, -1.1713e-01,  7.2149e-02, -9.1006e-03,\n","         -4.6282e-02,  8.2158e-02, -2.7293e-02, -2.5002e-02,  1.2549e-01,\n","         -1.0746e-01,  1.2203e-02,  4.8870e-02,  3.7504e-02, -8.7334e-02,\n","         -1.0947e-01,  4.2866e-02, -1.6623e-01, -3.6926e-02, -8.0539e-04,\n","          1.0946e-02,  1.0728e-01, -9.5251e-02, -1.9436e-02, -6.7443e-02,\n","          6.3068e-02, -6.5204e-02,  8.0985e-02,  7.2009e-02,  8.7456e-02,\n","          1.9459e-02,  3.0470e-02, -1.1008e-02,  9.8698e-03],\n","        [ 7.2842e-02,  4.1216e-02, -3.9498e-02,  9.4536e-02, -8.2380e-03,\n","         -1.2499e-01, -2.3909e-02,  2.1132e-01, -5.7285e-02,  2.2693e-02,\n","          8.4536e-02, -2.5535e-01,  6.0971e-02, -2.5306e-02,  2.3668e-02,\n","         -1.2621e-01, -2.5018e-03, -1.0036e-01, -8.7018e-02, -1.2110e-02,\n","         -1.1194e-01, -1.6685e-01,  2.1075e-01, -2.7310e-01,  1.3758e-01,\n","         -4.2461e-02,  4.1641e-02,  3.9439e-02, -7.6723e-04, -1.3294e-01,\n","          4.0510e-03,  1.3088e-01, -1.1551e-01,  8.4602e-02,  1.0155e-01,\n","          1.2212e-01,  1.8399e-01, -2.8149e-02, -1.3810e-02,  3.6842e-02,\n","         -6.6235e-02,  6.5897e-02, -5.3570e-02,  5.5132e-02, -2.3524e-02,\n","         -2.0957e-01, -3.4293e-02, -1.3449e-01,  6.8725e-02,  1.8848e-01,\n","          7.1568e-02,  1.4590e-01,  1.4417e-01, -5.1912e-02,  7.4078e-02,\n","          1.6523e-01,  4.3127e-02,  8.5367e-02, -2.1639e-01,  6.2649e-02,\n","         -2.6426e-02,  1.4978e-02, -1.5324e-01,  9.4430e-02],\n","        [ 2.2817e-02,  4.7551e-03,  7.9180e-02, -1.2701e-01,  3.1720e-02,\n","          1.4462e-01,  4.1415e-02,  8.9802e-02, -5.6679e-02,  1.1645e-01,\n","         -2.9250e-02,  8.0752e-02,  4.1461e-02, -1.1681e-01,  9.1968e-02,\n","         -9.0574e-02, -3.8901e-02, -1.2897e-02, -1.8688e-02, -1.1444e-01,\n","         -9.3830e-02,  2.3227e-02, -1.4256e-02,  6.6631e-02,  9.3475e-02,\n","          8.8496e-03, -1.0035e-01,  1.3336e-01,  5.7165e-02,  7.9939e-02,\n","         -2.0064e-02, -2.7267e-02, -8.1617e-02, -6.6375e-02,  3.7662e-02,\n","          4.2126e-02, -6.3067e-02, -9.1592e-02,  1.0121e-01,  2.7801e-03,\n","         -8.8782e-02,  1.0466e-01, -7.9886e-02, -4.8122e-02, -6.8092e-02,\n","          1.7937e-02, -3.8750e-02,  5.9500e-02, -4.5424e-02, -6.3688e-02,\n","         -7.2882e-02,  1.8207e-01,  3.2667e-02,  6.6052e-02,  1.3732e-02,\n","         -3.3509e-04,  1.4184e-02,  9.0953e-03,  1.0983e-01, -6.3200e-02,\n","         -6.7751e-02,  1.5016e-01,  4.1710e-04,  1.7326e-02],\n","        [-1.0560e-01, -5.8428e-03, -2.6280e-02,  1.0137e-01, -1.1487e-02,\n","         -4.4492e-03, -3.2799e-02,  1.6685e-01, -8.6094e-02, -9.8768e-02,\n","          2.8619e-02,  2.2019e-02, -1.2499e-02,  1.2906e-01, -1.0968e-01,\n","         -2.3810e-02,  6.1092e-02, -6.3937e-02,  1.5959e-01,  4.7136e-02,\n","         -1.5105e-01, -6.8191e-03,  3.0001e-02, -8.4499e-02,  1.2555e-03,\n","         -1.0120e-01, -6.4526e-02, -8.6827e-02,  3.3931e-02,  5.9564e-02,\n","          1.1445e-01,  9.6262e-02, -1.7779e-02, -1.3722e-01, -5.6529e-02,\n","          6.3278e-02, -9.3022e-02,  2.8545e-02,  6.2317e-02,  1.0403e-01,\n","          5.0464e-02,  6.0572e-03, -7.8916e-03, -5.6601e-02, -5.8078e-02,\n","         -6.4601e-02,  9.1972e-02, -8.5848e-03, -1.4644e-01, -9.4964e-02,\n","         -7.4825e-02,  4.6775e-02,  8.6388e-02,  4.4902e-02,  1.1459e-01,\n","          1.2194e-01, -8.9916e-02, -8.8466e-02,  7.0832e-02, -3.8707e-02,\n","          2.4961e-02, -1.3145e-01, -5.7831e-02,  4.3288e-02],\n","        [ 1.4889e-01, -1.1487e-01, -5.2182e-02, -5.6015e-02, -2.5863e-01,\n","          1.6024e-01, -1.1484e-01,  6.6825e-03, -9.4997e-02,  3.8106e-02,\n","         -6.9236e-02, -8.6030e-02, -1.9312e-01, -1.1326e-01,  2.6132e-02,\n","         -8.8112e-02, -4.6661e-02,  1.5959e-02,  5.3492e-02,  1.1765e-01,\n","          6.0404e-02,  7.2367e-02,  5.1088e-03, -1.1125e-01, -1.6958e-02,\n","         -1.9169e-01,  5.5338e-02, -5.1546e-02, -6.7068e-02, -8.1442e-02,\n","          7.4878e-02, -6.1022e-02,  7.4758e-02, -1.8981e-01, -1.3683e-01,\n","         -3.8928e-02,  1.1634e-01, -1.2270e-01,  8.2183e-03, -1.0373e-01,\n","         -8.5525e-02, -7.3540e-02,  3.9165e-02,  2.6803e-02,  7.0303e-02,\n","          3.1409e-02, -5.7590e-03, -8.6456e-02,  1.0768e-01, -7.3127e-02,\n","         -3.8734e-02, -7.2275e-03,  9.5356e-02,  3.1791e-02, -9.0427e-02,\n","         -1.8704e-01,  1.3795e-01,  3.6704e-02,  5.0776e-02, -9.4987e-02,\n","          1.0227e-02, -1.0609e-01, -9.2246e-02, -7.7277e-02],\n","        [-8.6303e-02, -6.6196e-02, -2.3689e-02, -9.6986e-02, -2.7766e-03,\n","         -3.1407e-02,  4.1210e-02,  4.3878e-02,  6.3763e-02,  4.5300e-02,\n","          4.4211e-03,  1.6193e-02,  2.9569e-04,  1.7649e-01,  2.1476e-02,\n","          2.6499e-02,  6.1490e-02, -1.3662e-02, -8.9138e-03, -5.1713e-02,\n","         -1.0361e-02,  6.4201e-02, -1.0386e-01,  7.4042e-02,  7.1497e-02,\n","         -1.0501e-03, -1.6217e-01,  7.6682e-02, -4.7278e-03, -4.3166e-02,\n","          1.0876e-02, -3.2657e-02,  3.3171e-02,  5.8436e-02, -9.3457e-03,\n","         -7.9093e-04, -2.8764e-02, -1.5069e-02,  1.1481e-02,  1.1273e-01,\n","         -8.4879e-02,  1.8591e-02,  4.3933e-02,  6.6777e-02,  6.3952e-03,\n","         -1.2154e-01,  1.0939e-02,  1.5878e-02, -3.0599e-03,  1.0433e-03,\n","          2.4199e-02, -4.2502e-02, -4.7476e-02, -5.7369e-02,  9.3531e-03,\n","         -1.7525e-03,  5.6295e-02, -3.2697e-03,  2.1738e-02, -1.4150e-01,\n","          4.5810e-02, -4.0703e-02,  8.2235e-02, -5.2997e-02]], device='cuda:0',\n","       requires_grad=True)\n","attn.b_V: torch.Size([12, 64])\n","Parameter containing:\n","tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n","       device='cuda:0', requires_grad=True)\n","mlp.W_in: torch.Size([768, 3072])\n","Parameter containing:\n","tensor([[ 0.0942,  0.0982, -0.0321,  ..., -0.1783,  0.1474,  0.0706],\n","        [-0.1265, -0.0671,  0.0305,  ...,  0.1966, -0.1203, -0.0628],\n","        [ 0.0496, -0.0373, -0.0483,  ...,  0.0655, -0.0714,  0.0826],\n","        ...,\n","        [ 0.0480,  0.1575,  0.0014,  ..., -0.3987,  0.0889,  0.0240],\n","        [ 0.0324,  0.1249, -0.0426,  ..., -0.1934,  0.1272, -0.0405],\n","        [-0.0316,  0.0010, -0.0491,  ..., -0.0406,  0.0536,  0.1896]],\n","       device='cuda:0', requires_grad=True)\n","mlp.b_in: torch.Size([3072])\n","Parameter containing:\n","tensor([ 0.0396, -0.0881, -0.1402,  ..., -0.2490, -0.0768,  0.0143],\n","       device='cuda:0', requires_grad=True)\n","mlp.W_out: torch.Size([3072, 768])\n","Parameter containing:\n","tensor([[-0.1066,  0.1528,  0.0331,  ...,  0.1644, -0.0400,  0.1218],\n","        [ 0.0364, -0.0594,  0.0848,  ...,  0.0933, -0.0980, -0.0388],\n","        [-0.0767,  0.0084, -0.0947,  ...,  0.0501, -0.0030, -0.0323],\n","        ...,\n","        [-0.1027,  0.0077, -0.0305,  ...,  0.0122,  0.0011, -0.0187],\n","        [-0.0305, -0.0333, -0.0078,  ...,  0.0902, -0.0444,  0.0043],\n","        [-0.0221,  0.0818,  0.0775,  ..., -0.0563, -0.0089, -0.0802]],\n","       device='cuda:0', requires_grad=True)\n","mlp.b_out: torch.Size([768])\n","Parameter containing:\n","tensor([ 4.5023e-02,  3.2263e-02, -8.8545e-02, -8.1625e-03,  1.1772e-01,\n","        -2.3888e-01, -7.5874e-02,  2.9564e-02,  4.6482e-02, -2.7773e-03,\n","        -3.8145e-03,  2.0843e-02,  9.2677e-03,  3.5888e-02, -1.4091e-01,\n","         6.1385e-02, -6.8962e-02, -1.2951e-02,  6.1896e-02, -1.7780e-02,\n","         2.1360e-02, -5.5017e-02,  2.1975e-02,  1.1830e-03,  4.9436e-02,\n","         4.1930e-02,  7.1898e-02, -2.0239e-02,  6.5098e-02,  1.0964e-01,\n","         4.0017e-02,  3.5822e-02,  6.4422e-02, -3.1552e-02,  2.0921e-02,\n","        -5.9030e-02,  1.9308e-02, -3.7585e-02,  4.7847e-02,  1.2950e-01,\n","         6.5660e-02,  1.6015e-01,  3.6072e-03,  1.3144e-02,  8.7157e-02,\n","        -5.1418e-02,  1.0630e-01, -4.2858e-02,  9.8618e-02, -2.9094e-02,\n","         9.4126e-02, -5.8661e-03, -2.9511e-02, -7.0213e-02, -2.4058e-03,\n","        -9.2266e-02,  5.3705e-02,  1.3925e-02, -1.0657e-02, -6.5181e-02,\n","         2.2841e-02,  1.2673e-01, -4.6832e-02, -3.9238e-02, -1.0288e+00,\n","         4.9528e-02,  1.0585e-02,  2.5042e-02,  6.0465e-03, -1.6819e-01,\n","         6.7637e-02, -5.6069e-02,  2.3984e-02, -8.1788e-02,  1.8519e-01,\n","        -5.3801e-02,  5.1166e-03, -3.4199e-02,  3.3593e-02,  9.6572e-03,\n","         7.0050e-02, -8.5121e-02,  1.3117e-01,  2.0365e-02, -9.6871e-02,\n","         1.3111e-02, -9.1116e-02, -2.2846e-01, -4.3093e-02, -5.2251e-02,\n","        -2.3870e-02, -9.1072e-02,  1.4825e-03,  2.0018e-02,  1.6285e-02,\n","        -1.8391e-01, -7.8575e-02, -1.5803e-01,  4.3354e-02,  8.2150e-02,\n","         8.9258e-02,  6.2411e-03, -5.0751e-03, -7.8197e-02, -4.1822e-02,\n","        -7.0752e-02, -6.2371e-02,  7.2956e-02, -2.9113e-02,  1.0280e-02,\n","         5.4623e-02, -5.4496e-02, -2.0813e-02,  2.7419e-02,  4.3915e-02,\n","        -1.1206e-01, -4.1483e-02,  4.4149e-02,  4.1488e-02,  3.3088e-02,\n","        -4.9593e-02,  2.5347e-02, -8.0750e-02,  3.5120e-02,  2.5000e-02,\n","         8.4420e-02,  3.9589e-03, -2.6386e-02,  4.6670e-02, -1.8601e-02,\n","        -2.7607e-02, -6.5403e-02, -5.8142e-02, -6.2748e-02,  5.5334e-03,\n","         1.0983e-01,  1.1807e-01,  8.8252e-03, -1.1783e-02, -4.1632e-02,\n","         2.2897e-02, -1.5753e-01,  5.2934e-02, -2.9923e-02, -4.5317e-02,\n","        -2.7485e-02,  1.2231e-02, -1.6446e-02, -1.1546e-01, -9.0706e-02,\n","         2.3194e-02,  8.7321e-02, -6.4447e-04, -4.7643e-02,  2.5382e-02,\n","         1.1230e-02, -1.1837e-02,  1.1483e-01,  6.2778e-02, -7.4322e-02,\n","         1.8604e-02,  3.5352e-02,  8.3046e-02, -3.2333e-02, -3.5075e-02,\n","        -5.6861e-02,  6.3852e-03, -3.5449e-02, -2.0108e-03, -2.9977e-03,\n","         1.8376e-01,  1.6517e-01,  4.6639e-02, -2.8841e-02,  9.5179e-03,\n","        -1.2773e-01,  3.6274e-02,  3.3075e-02,  6.7161e-02, -1.1401e-01,\n","        -1.0324e-01,  4.0848e-02,  6.9455e-04, -2.2487e-02, -1.4184e-01,\n","        -7.6204e-02,  4.8272e-02,  6.5127e-03, -2.4099e-04, -4.6942e-02,\n","        -1.0845e-02,  1.0996e-01, -1.9959e-02, -5.5883e-03,  1.5396e-02,\n","        -7.8590e-02,  9.2186e-02,  6.0335e-02, -2.3314e-02,  9.8412e-02,\n","         2.7981e-02,  2.4934e-02,  3.0177e-02,  6.3878e-03,  2.6812e-02,\n","         8.2178e-02, -3.1889e-02,  4.6658e-03,  1.1254e-01, -2.0472e-02,\n","        -1.9678e-02, -7.9651e-02,  4.4800e-02,  2.0878e-03,  1.0551e-02,\n","        -3.4646e-02, -5.8185e-02,  1.9808e-02, -3.0192e-02, -8.9304e-02,\n","         1.6887e-03, -4.5835e-02, -5.6149e-02,  4.1295e-02, -1.2998e-02,\n","        -8.9592e-03, -9.7501e-02,  8.6019e-04, -1.0314e-02, -2.9536e-02,\n","         8.8495e-02, -1.0251e-01, -7.5625e-02,  1.4877e-02, -8.9994e-02,\n","        -5.4272e-03, -1.3237e-02,  1.2560e-02,  4.1312e-02, -1.4846e-02,\n","        -2.3258e-03,  3.5059e-02,  5.3121e-02,  2.4269e-02, -2.6712e-02,\n","        -8.4159e-02, -2.0311e-02, -1.2856e-03,  7.9390e-02,  1.0080e-01,\n","        -4.2852e-02,  6.4158e-02, -1.5676e-01, -4.6177e-02, -8.5520e-02,\n","        -7.3629e-02, -4.1726e-03,  1.2724e-01,  8.0200e-02, -6.0142e-02,\n","         3.7472e-02, -4.8540e-02,  6.6447e-03, -5.5559e-02,  2.3945e-01,\n","         1.6573e-01, -2.7424e-01, -5.2924e-03, -3.5117e-02, -1.0445e-01,\n","        -4.9122e-02, -4.2225e-02, -7.1904e-02, -1.0075e-01,  1.0230e-02,\n","        -5.9576e-02,  2.8034e-03, -1.1119e-01,  5.6818e-02,  5.8964e-02,\n","        -1.3514e-01,  1.0375e-01,  6.1090e-02, -5.9418e-02, -1.2069e-02,\n","         1.5967e-02,  8.0903e-03,  8.0048e-02,  2.1895e-01, -1.0442e-01,\n","        -7.4534e-02,  4.0670e-02,  1.7061e-02,  4.5917e-02, -1.5722e-02,\n","        -6.0820e-02,  8.0987e-03,  9.1690e-02,  1.1977e-02,  4.8149e-02,\n","         1.2315e-01, -4.9318e-02,  1.2376e-01,  3.3778e-03, -6.3046e-02,\n","         1.5333e-01,  5.0951e-02, -8.9270e-02, -4.0724e-02, -4.0352e-02,\n","        -1.2391e-02, -1.6080e-01, -1.7766e-01,  7.5903e-02, -1.1405e-01,\n","        -9.3767e-02,  2.7890e-02, -8.6641e-03, -4.4354e-02,  1.0092e-02,\n","         1.6177e-02,  7.9481e-02, -2.1834e-02,  1.4273e-01,  9.5448e-02,\n","        -7.3992e-02,  2.5193e-01, -1.3582e-02, -4.1486e-02,  7.8391e-02,\n","         4.9195e-02,  1.4428e-02,  6.6614e-02, -6.7850e-03,  2.6350e-02,\n","        -2.2226e-02, -2.5074e-02,  3.0529e-02, -5.4314e-02,  2.5678e-03,\n","         2.1976e-02, -7.7988e-02, -8.7472e-02, -4.3832e-03, -5.6923e-03,\n","        -6.0136e-02,  2.3537e-02,  2.4781e-02,  1.1300e-01, -6.6311e-02,\n","         1.1406e-02, -2.0834e-02,  1.0654e-01, -5.8886e-02, -1.0436e-02,\n","        -3.5977e-02,  1.9855e-03, -1.5095e-02,  1.6664e-01,  3.8586e-02,\n","         7.3969e-04,  8.3391e-03, -4.6113e-02, -1.2392e-02,  8.4240e-02,\n","         1.9114e-02, -6.4050e-02,  1.2611e-02,  1.6068e-01, -6.8633e-02,\n","        -2.1504e-02,  3.9946e-03, -1.3237e-01, -7.7658e-01, -4.5846e-03,\n","        -2.8635e-02, -2.5182e-02,  4.0094e-02, -2.1614e-02,  5.9410e-02,\n","        -1.2508e-02, -3.8256e-02, -2.8660e-02,  6.3848e-02,  3.3284e-02,\n","         6.1880e-02, -8.7276e-03, -1.3498e-02, -2.2981e-02,  4.0298e-02,\n","         1.7356e-02, -4.0403e-02,  1.0129e-02,  1.9055e-01,  4.8645e-02,\n","         2.8901e-02,  4.3848e-02,  2.5438e-02, -4.6661e-02, -3.5847e-02,\n","         5.2495e-02, -6.3460e-02,  3.0081e-02, -2.2347e-02, -1.7123e-01,\n","         7.5116e-02, -5.7682e-02, -1.7896e-02,  1.3129e-01,  6.4119e-02,\n","        -3.3117e-02,  3.4110e-02,  2.3311e-02, -8.1768e-02, -7.8663e-03,\n","         7.2086e-03, -1.0913e-01, -6.0863e-02, -1.0291e-01,  7.0626e-02,\n","        -3.4457e-02, -6.6375e-03,  4.1267e-02,  1.0085e-01, -5.9672e-03,\n","         1.2186e-01,  3.2346e-02, -9.0074e-03, -3.6914e-02, -7.6526e-02,\n","        -9.9214e-02,  1.0725e-01,  1.4607e-01, -1.6410e-02, -1.6554e-01,\n","        -5.3178e-02, -2.0510e-02, -1.3013e-01,  7.0259e-02, -3.4697e-02,\n","        -4.4588e-02,  8.9730e-02, -4.3746e-02, -1.1891e-01, -3.7777e-03,\n","         4.7557e-02, -3.2944e-02,  1.4794e+00, -2.2029e-02,  2.4320e-02,\n","         2.6203e-02, -2.6522e-02,  1.9999e-01,  1.2335e-02,  3.7748e-02,\n","         1.0837e-01,  1.0647e-02,  2.6263e-02, -5.7881e-02,  6.4170e-02,\n","         1.3092e-01,  6.0774e-02,  1.5351e-01,  5.1787e-02, -1.6283e-02,\n","        -1.3189e-02, -4.0299e-02,  6.9897e-02,  5.6916e-02, -4.7023e-03,\n","         3.3006e-02, -2.1637e-02,  5.4445e-02, -1.1246e-02, -1.6313e-02,\n","        -9.7042e-02, -3.3673e-02, -3.1121e-01, -1.7338e-03, -6.5774e-03,\n","        -3.3948e-01, -1.0748e-02, -7.2840e-03,  3.4916e-02,  7.6206e-03,\n","        -9.0456e-03, -1.2918e-01, -4.1915e-02, -6.5605e-02,  5.6196e-03,\n","        -3.3288e-02,  9.6272e-03,  1.9119e-02,  7.9960e-03,  4.8949e-03,\n","        -1.0826e-01,  2.1244e-02,  6.2302e-02, -5.7631e-02, -4.0647e-02,\n","         1.1760e-01,  1.8409e-02,  9.1127e-02,  5.4443e-02,  4.0377e-02,\n","         5.2713e-02,  6.4445e-02,  4.3552e-02,  1.8278e-02, -2.7897e-02,\n","        -1.2969e-02,  7.3674e-02,  5.2346e-02, -3.1770e-02,  6.8897e-02,\n","         1.0820e-01, -7.0980e-02, -4.3594e-02,  5.8857e-02,  7.3827e-02,\n","        -6.0256e-02, -4.8512e-03,  5.1875e-02, -1.7978e-02, -9.7263e-02,\n","         1.0159e-01, -5.8648e-02,  3.3427e-02, -2.1911e-02,  6.3458e-02,\n","        -6.0518e-02, -1.5584e-02, -4.4891e-02,  1.2770e-01,  1.2310e-01,\n","        -1.0521e-02, -8.9975e-02,  5.1911e-02,  7.7123e-02,  5.4728e-02,\n","         2.9925e-02,  4.5541e-02, -6.9752e-02,  1.9429e-03,  1.3842e-01,\n","         3.2565e-02, -2.0783e-02, -8.2869e-02,  8.5544e-02,  3.7853e-02,\n","         7.7590e-03,  1.3680e-03,  6.4752e-03, -7.0810e-02, -1.1387e-01,\n","         9.5829e-02,  9.1051e-02, -6.5929e-02,  2.3231e-02,  6.6653e-02,\n","         1.0892e-01,  1.3683e-02, -2.4451e-01, -8.7208e-02,  4.0799e-02,\n","         1.2450e-02, -9.7876e-03, -8.4818e-02,  6.1542e-02, -2.1203e-02,\n","         7.5964e-03, -1.5272e-02,  2.2896e-02,  1.4737e-01, -6.7023e-02,\n","         4.8008e-02,  1.6407e-01,  5.9616e-02, -7.4996e-02,  3.7564e-02,\n","        -1.0317e-01, -2.8256e-02, -2.0282e-02,  4.1672e-02, -1.0623e-01,\n","         5.1083e-02,  2.4353e-02,  1.7573e-02,  1.3917e-03,  2.7037e-02,\n","         2.6375e-02, -3.1101e-02,  1.3591e-02, -3.4730e-02, -2.7803e-01,\n","        -2.8762e-02,  3.0337e-02, -3.2352e-02, -1.2179e-02, -1.3032e-02,\n","        -5.0929e-03,  8.4164e-02,  6.9907e-02, -2.9803e-02,  6.5644e-02,\n","        -8.0717e-02,  2.1697e-02,  9.6715e-02,  1.5086e-02,  1.1789e-02,\n","        -1.2883e-01,  2.4771e-02,  2.6497e-02,  5.5522e-02, -1.4012e-01,\n","        -6.6509e-03, -3.4700e-02,  8.4467e-03, -1.8842e-02, -1.1403e-02,\n","        -1.2643e-02,  5.0147e-02,  3.4162e-02, -5.4514e-02, -6.0217e-02,\n","        -1.3390e-01, -2.0140e-01, -1.5776e-03, -1.0785e-02, -1.5657e-02,\n","        -7.0327e-03,  6.0274e-02, -8.0423e-02,  8.7842e-02,  5.4633e-02,\n","         2.5239e-02, -2.8561e-02, -2.8283e-02, -7.0851e-02,  5.5545e-02,\n","         1.0581e-01, -5.1550e-03, -2.3810e-02, -1.4051e-01,  1.0330e-06,\n","        -6.2580e-02,  3.2829e-02,  2.0821e-03, -1.0545e-02, -2.0066e-02,\n","        -6.4922e-02,  7.5895e-02,  1.3187e-02,  7.5001e-02,  5.9478e-02,\n","         6.5165e-02, -3.2629e-02,  1.3688e-01, -6.0418e-02,  3.5761e-02,\n","         3.7931e-02, -7.2553e-02,  3.7288e-02,  7.7615e-03, -7.2981e-02,\n","         1.4384e-03, -3.2364e-02,  4.2222e-02,  7.6461e-02, -2.1868e-02,\n","         2.2159e-02, -5.3884e-02, -8.7562e-02, -2.1667e-02, -5.0475e-02,\n","         4.6042e-02, -2.1064e-01,  6.7564e-02, -7.4217e-02,  6.5668e-02,\n","         3.2803e-02,  2.8213e-02, -4.9096e-02, -1.6074e-02,  6.8048e-02,\n","        -8.2289e-02,  6.2946e-02,  2.0254e-02,  4.0095e-02,  7.4980e-02,\n","        -1.4052e-01,  1.1654e-01, -3.3523e-02, -5.1018e-02, -4.1743e-02,\n","        -8.4847e-02, -3.4367e-02,  1.6062e-02, -8.5649e-02,  1.0479e-02,\n","        -1.9157e-01, -3.0794e-03,  1.4401e-01,  2.4762e-02, -1.3440e-01,\n","         3.4516e-02,  6.9025e-02, -3.5945e-02,  1.5276e-02,  7.0170e-02,\n","        -1.4009e-02, -4.2377e-03, -7.8656e-02, -1.9765e-03, -1.1486e-01,\n","         8.5145e-02,  1.2174e-01,  1.1059e-01,  7.8198e-02,  5.9846e-02,\n","         7.9015e-03, -7.8730e-02, -2.8581e-02, -1.7287e-01,  1.4536e-01,\n","        -1.0344e-02,  3.2438e-02,  9.7084e-02,  4.5569e-02,  2.1417e-02,\n","         7.4727e-02, -5.2297e-02, -4.1671e-02,  1.0934e-02,  5.0398e-02,\n","         6.3046e-02,  6.9303e-02,  9.6004e-02,  1.1744e-03, -1.5224e-02,\n","         1.0817e-02,  5.7317e-02,  5.6077e-02,  2.4949e-02,  1.4738e-01,\n","        -1.8389e-01, -5.7228e-02, -1.6117e-01, -7.4940e-02,  5.0967e-03,\n","         2.2772e-02,  5.7293e-02, -8.3043e-02,  2.5825e-02, -1.9614e-02,\n","        -1.9872e-03, -7.1870e-02,  1.5372e-02, -1.3297e-01,  4.2593e-03,\n","         4.8105e-02, -4.9414e-02, -6.2924e-03, -4.0709e-02,  3.0459e-02,\n","         9.9903e-03,  9.6811e-02,  2.9624e-02], device='cuda:0',\n","       requires_grad=True)\n","Output shape (our layer): torch.Size([1, 35, 768])\n","Reference output shape (GPT-2): torch.Size([1, 35, 768]) \n","\n","93.41% of the values are correct\n","\n","=== Example Differences (First 10 Elements) ===\n","tensor([6.2883e-06, 8.7619e-06, 1.0669e-05, 8.0466e-06, 1.6332e-05, 9.0897e-06,\n","        3.4094e-05, 9.6560e-06, 1.1206e-05, 9.4175e-06], device='cuda:0',\n","       grad_fn=<SliceBackward0>)\n"]}]},{"cell_type":"markdown","metadata":{"id":"47Tq2M1OKW2o"},"source":["# Transformer - 5 баллов"]},{"cell_type":"markdown","metadata":{"id":"jkzg7NPuKW2o"},"source":["Собираем все в один большой трансформер.\n","1. Применяем эмбеддинги и позиционные эмбеддинги, складываем результаты\n","2. Прогоняем в цикле через все блоки трансформера\n","3. Применяем финальную нормализацию и lm_head"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HdbjvO9sVLrk"},"outputs":[],"source":["\"\"\"\n","class DemoTransformer(nn.Module):\n","    def __init__(self, cfg: Config):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.embed = Embed(cfg)\n","        self.pos_embed = PosEmbed(cfg)\n","        self.blocks = nn.ModuleList([TransformerBlock(cfg) for _ in range(cfg.n_layers)])\n","        self.ln_final = LayerNorm(cfg)\n","        self.unembed = Unembed(cfg)\n","\n","    def forward(self, input_ids: Int[Tensor, \"batch seq_len\"]) -> Float[Tensor, \"batch seq_len d_vocab\"]:\n","        pass\n","        # Ваш код здесь!\n","\n","\n","\n","rand_int_test(DemoTransformer, [2, 4])\n","load_gpt2_test(DemoTransformer, reference_gpt2, tokens)\n","\"\"\""]},{"cell_type":"code","source":["class DemoTransformer(nn.Module):\n","    def __init__(self, cfg: Config):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.embed = Embed(cfg)\n","        self.pos_embed = PosEmbed(cfg)\n","        self.blocks = nn.ModuleList([TransformerBlock(cfg) for _ in range(cfg.n_layers)])\n","        self.ln_final = LayerNorm(cfg)\n","        self.unembed = Unembed(cfg)\n","        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Устанавливаем устройство\n","\n","    def forward(self, input_ids: Int[Tensor, \"batch seq_len\"]) -> Float[Tensor, \"batch seq_len d_vocab\"]:\n","        # Пример выполнения форвард-прохода\n","        x = self.embed(input_ids) + self.pos_embed(input_ids)\n","        for block in self.blocks:\n","            x = block(x)\n","        x = self.ln_final(x)\n","        logits = self.unembed(x)\n","        return logits\n","\n","\n","\n","\n","rand_int_test(DemoTransformer, [2, 4])\n","load_gpt2_test(DemoTransformer, reference_gpt2, tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FxwlpQI-xzbr","executionInfo":{"status":"ok","timestamp":1726690323776,"user_tz":-180,"elapsed":6971,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}},"outputId":"1fa31090-51e2-4244-b939-3d5a50769e67"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mВыходные данные были обрезаны до нескольких последних строк (5000).\u001b[0m\n","         [-0.0124, -0.0680,  0.2146,  ..., -0.2448,  0.0900, -0.1793]],\n","\n","        [[ 0.2130, -0.2916,  0.0795,  ..., -0.1168, -0.0097, -0.0261],\n","         [-0.0096,  0.2111, -0.0177,  ...,  0.0671,  0.0581, -0.0806],\n","         [ 0.2191,  0.0818,  0.1152,  ...,  0.1655, -0.1392, -0.0276],\n","         ...,\n","         [ 0.1431, -0.1600, -0.1279,  ...,  0.0715, -0.1801, -0.2008],\n","         [-0.2247,  0.1478, -0.1812,  ..., -0.1859, -0.2295, -0.0560],\n","         [-0.1702,  0.1952, -0.1292,  ...,  0.0438, -0.0234,  0.1074]],\n","\n","        [[ 0.1193,  0.0102,  0.1173,  ...,  0.0137, -0.1608,  0.1247],\n","         [-0.1662,  0.0240, -0.1149,  ...,  0.1681, -0.0810, -0.0362],\n","         [-0.1547,  0.3312,  0.0170,  ..., -0.1551, -0.0597,  0.0701],\n","         ...,\n","         [ 0.0528, -0.0318, -0.0741,  ..., -0.0271, -0.1402,  0.1883],\n","         [ 0.0039, -0.1590,  0.0322,  ..., -0.0552,  0.2296, -0.1538],\n","         [ 0.0476, -0.2814, -0.1319,  ...,  0.1081,  0.0250,  0.2890]]],\n","       device='cuda:0', requires_grad=True)\n","blocks.8.attn.b_K: torch.Size([12, 64])\n","Parameter containing:\n","tensor([[-1.0223e-01,  1.3551e-01,  4.0884e-02, -2.3823e-02, -8.5786e-02,\n","          6.8314e-03,  1.7803e-02,  7.0603e-02,  1.9971e-01, -1.5140e-03,\n","         -9.0394e-02,  4.6559e-02, -9.5618e-02, -6.6414e-02, -1.9596e-02,\n","          1.0236e-01,  4.8351e-03, -3.2154e-02, -4.3726e-02, -2.6974e-01,\n","         -1.3746e-01, -1.7101e-01, -6.4744e-02, -7.2923e-02, -1.7448e-01,\n","         -3.6750e-02,  2.2505e-02,  1.8971e-02,  4.7198e-02, -9.0532e-03,\n","          9.5253e-02, -3.3146e-02, -8.6959e-02,  6.0353e-02,  1.1419e-01,\n","          8.8073e-02,  2.4877e-01,  1.2083e-01, -9.4962e-02,  4.0916e-02,\n","         -3.0110e-02,  1.3664e-01, -1.2353e-01, -3.3908e-02,  3.9682e-02,\n","         -3.9561e-02, -9.8951e-03, -1.1934e-02, -2.6388e-02,  2.2523e-02,\n","          2.8011e-02,  3.9704e-02,  7.3361e-02,  7.3603e-02, -1.0341e-01,\n","          3.3311e-02,  8.4127e-02, -5.4098e-02, -7.2578e-02,  3.6727e-02,\n","         -1.4622e-02, -2.7666e-02, -8.5565e-02,  4.3214e-02],\n","        [-9.6030e-02,  1.2748e-02,  1.3688e-01, -1.8239e-02, -9.8178e-02,\n","         -1.2023e-01, -4.0614e-03, -2.5235e-01, -1.9489e-02,  1.2491e-01,\n","         -8.4452e-04,  4.5327e-02,  1.0697e-01,  1.6522e-01,  9.0771e-02,\n","         -1.3803e-01, -1.6585e-01, -1.2662e-01, -1.4958e-02,  8.8082e-02,\n","         -5.5717e-02, -8.9664e-02,  1.1662e-01, -1.0398e-01, -1.3714e-01,\n","          9.9335e-02,  1.7627e-02,  1.8941e-02, -8.5592e-02, -1.2885e-01,\n","          1.3668e-01,  2.2488e-02, -1.0846e-01,  3.9924e-02, -1.3737e-01,\n","         -1.2944e-01, -6.9431e-02, -6.9896e-02, -5.0768e-02,  8.3969e-03,\n","          9.2611e-02,  5.7344e-02,  1.0084e-02,  1.3227e-01, -4.5001e-02,\n","          5.8472e-02, -7.8679e-03,  2.8252e-01, -1.2541e-01, -8.9854e-02,\n","         -2.0332e-02, -9.8447e-02, -3.0504e-02, -1.4708e-01,  1.7202e-02,\n","          7.3315e-02,  3.5188e-02, -7.4851e-02, -1.3170e-01, -1.0115e-01,\n","          1.9228e-01, -8.8856e-03,  6.2415e-02, -1.6044e-02],\n","        [-8.6171e-02,  2.0543e-04,  3.3191e-03, -9.4491e-02, -1.1750e-01,\n","         -7.2298e-02, -1.6911e-01,  4.4639e-02, -4.1597e-02,  8.1154e-02,\n","         -4.8889e-02,  4.8263e-02,  6.3225e-02,  3.8506e-02, -1.2673e-01,\n","          6.0718e-03, -1.5338e-01,  7.8601e-02, -5.0676e-02, -8.1432e-02,\n","          7.6762e-02, -1.3988e-01, -2.0803e-03, -9.8190e-02,  6.1577e-02,\n","          8.6730e-02, -9.0401e-02, -2.9228e-02, -1.4891e-01,  2.5679e-03,\n","          1.2062e-01,  2.5028e-03, -1.0103e-02, -7.2957e-02, -2.2161e-01,\n","         -9.3336e-02,  1.0910e-01, -1.3156e-01,  3.6275e-02,  3.3345e-02,\n","         -5.8987e-02,  7.9914e-02, -6.1204e-02,  6.9762e-02, -4.3099e-02,\n","         -7.8912e-03,  1.0143e-02,  8.0182e-02, -2.2478e-02,  5.1468e-02,\n","          1.4909e-02, -4.5318e-03,  6.3477e-02,  7.9696e-02,  1.7262e-02,\n","         -3.4212e-02,  8.8241e-02,  2.7554e-02,  2.3107e-02, -4.3298e-02,\n","         -4.9576e-02, -1.3998e-01, -7.1592e-02, -1.1386e-01],\n","        [-1.4748e-01, -9.4982e-02, -1.6516e-02,  7.1716e-02,  4.7184e-02,\n","          9.0344e-03,  1.3471e-01,  1.8089e-01,  2.5703e-01, -8.2924e-02,\n","         -4.6297e-02, -1.0803e-01,  3.6763e-03,  1.4049e-01,  1.2601e-01,\n","          5.8735e-02, -4.6786e-02,  3.2262e-02, -1.2931e-01,  1.0074e-02,\n","         -2.0093e-01,  3.2356e-03,  6.3368e-02, -1.3923e-01, -4.8688e-02,\n","          6.7522e-02, -1.8941e-03, -8.3352e-02,  1.5491e-01, -5.9128e-02,\n","         -1.5190e-02,  2.0398e-02,  5.0289e-02,  6.0609e-02, -4.7002e-02,\n","          1.2324e-01,  2.9864e-02,  8.8630e-02,  6.9911e-02,  2.3898e-01,\n","          3.2324e-02, -8.0567e-02, -1.0070e-01,  1.0303e-01, -1.5809e-02,\n","          8.6472e-02, -5.1466e-02,  5.4109e-03, -1.0257e-01,  3.3051e-02,\n","          1.0088e-01, -5.9766e-02,  2.6937e-02, -4.1589e-02,  3.7680e-02,\n","         -2.8821e-02, -7.0497e-02, -6.6438e-02, -7.9761e-02, -5.2233e-02,\n","         -1.2345e-01,  1.3494e-01,  9.2657e-02, -1.0533e-02],\n","        [-6.3088e-02,  1.2633e-02,  1.0252e-01, -7.2230e-02,  4.1083e-04,\n","         -9.3771e-02, -1.0057e-01,  3.3617e-02,  1.6473e-01, -5.6068e-02,\n","          2.2299e-02,  6.8179e-02, -8.7624e-02, -2.8762e-02,  3.3405e-02,\n","          6.2579e-03,  8.8717e-02,  1.3787e-02, -1.1133e-01, -8.7197e-02,\n","          1.0738e-01,  2.2573e-02, -8.3750e-02,  1.7418e-02, -7.4384e-03,\n","         -1.2019e-01, -1.3539e-01,  2.9010e-02, -6.1089e-02, -7.7143e-02,\n","         -7.5459e-02, -2.7559e-03, -2.1239e-02, -1.3173e-01, -4.9516e-02,\n","         -1.7961e-01,  7.6426e-02, -6.7209e-02,  1.7783e-01, -2.8335e-02,\n","          7.0171e-02, -7.5340e-02, -7.5617e-02, -1.2073e-02, -4.4806e-02,\n","         -6.7356e-03,  1.2292e-02,  1.1847e-01,  5.3332e-02, -9.7471e-02,\n","         -3.0271e-02,  3.6805e-02,  1.2097e-01,  1.0301e-01, -6.6776e-02,\n","         -5.8524e-02, -3.6231e-02, -1.0572e-01, -5.2993e-02,  6.0351e-02,\n","          1.5160e-02, -1.8709e-01,  3.9543e-02, -3.0980e-02],\n","        [-1.3393e-02, -5.9541e-02,  1.6930e-01, -1.0320e-01,  7.9425e-02,\n","         -1.7708e-01,  1.8838e-01, -8.6452e-02,  3.4791e-02, -7.3380e-02,\n","          1.3934e-01, -7.4141e-02, -6.9602e-02,  1.9657e-03, -4.9761e-02,\n","          8.4390e-02,  8.1290e-02, -7.8786e-02,  6.8494e-02, -1.3530e-01,\n","         -8.0245e-02, -2.6900e-02, -9.7733e-03,  2.1557e-01,  2.3463e-02,\n","          1.3171e-01, -4.4126e-02,  1.8368e-01,  2.7866e-02,  1.5622e-01,\n","         -9.0791e-03, -1.9220e-01,  5.8357e-02,  1.0008e-02, -1.4682e-01,\n","         -1.7219e-02, -1.5861e-01, -1.4894e-01,  1.2631e-01, -8.9347e-03,\n","          1.7782e-02, -5.5055e-03,  5.1111e-03,  6.8424e-04,  1.0668e-01,\n","         -9.0044e-02, -1.0457e-01,  1.5416e-02, -8.3791e-02,  8.4639e-02,\n","          1.4969e-02,  7.1834e-02, -1.2424e-01,  8.8402e-02, -1.9284e-01,\n","          1.1088e-01, -1.6146e-02,  2.5932e-01,  3.6491e-03, -1.0417e-01,\n","         -3.4639e-02, -4.3061e-02,  3.1173e-02, -2.0448e-01],\n","        [-1.1353e-02,  6.9813e-02,  4.2666e-02,  5.4720e-04, -6.0918e-02,\n","          3.5510e-02,  9.3479e-02,  7.5767e-04,  6.5440e-02,  1.7908e-01,\n","         -5.9046e-03,  2.5198e-02, -7.9102e-02,  1.2681e-02, -9.7410e-02,\n","          1.0956e-02,  9.6542e-02, -1.8632e-02, -9.2920e-02,  2.1774e-01,\n","         -1.4718e-01,  2.3893e-02,  2.1196e-01, -1.1269e-01,  6.2340e-02,\n","          3.5132e-02, -1.5425e-01,  2.0612e-01,  1.3082e-01, -3.5099e-02,\n","         -4.7199e-02, -7.4708e-02,  1.2987e-02, -7.2424e-02,  2.1794e-02,\n","          1.2685e-02, -6.4667e-02, -3.0078e-02,  6.2027e-03,  4.3833e-02,\n","         -1.3752e-01, -8.0484e-03, -1.6766e-02,  2.3362e-02, -4.6702e-02,\n","          3.8256e-02, -1.0689e-01,  6.1672e-03,  8.9948e-02,  3.2283e-02,\n","         -8.5576e-02,  1.1002e-01,  7.7839e-02, -1.2101e-01, -1.2992e-01,\n","         -1.5660e-01, -9.7521e-03, -2.7966e-01,  7.5568e-02,  9.7571e-03,\n","         -1.6646e-02,  4.8394e-02,  6.7330e-04,  6.4955e-03],\n","        [-1.5771e-02,  1.6469e-01, -6.2116e-02,  2.0442e-02, -1.4991e-01,\n","          1.2696e-01,  7.0565e-02,  1.1443e-01, -6.5446e-02,  2.1000e-01,\n","         -5.5566e-02, -3.5150e-01,  1.8036e-02, -2.3482e-01,  6.9834e-02,\n","          6.4044e-03, -1.9526e-01,  2.3888e-01, -1.9056e-01, -2.1119e-02,\n","          3.8505e-02,  2.3277e-01,  1.5378e-01,  7.2870e-02,  7.2132e-02,\n","          1.7797e-01, -2.1220e-02,  7.5709e-02, -7.5228e-02,  1.3469e-01,\n","         -8.4215e-02,  1.5231e-01, -1.9217e-01,  1.2750e-02,  7.4883e-02,\n","          1.3414e-01, -1.9132e-01, -3.9446e-02,  3.3230e-01,  6.1393e-02,\n","          2.0315e-02, -2.2844e-02, -1.9926e-01,  3.0178e-03, -1.7752e-01,\n","         -9.9418e-03, -1.7071e-01, -5.9599e-02, -2.2043e-01, -8.3854e-03,\n","          1.6461e-01,  6.6012e-02,  9.9212e-02,  8.9257e-02, -1.3990e-02,\n","         -1.3360e-02,  9.4860e-02,  3.6600e-02, -6.6143e-02,  1.4016e-01,\n","          6.9948e-02,  8.1209e-02, -4.7168e-02,  2.4129e-02],\n","        [ 5.2230e-02, -1.0379e-01, -7.4756e-02, -9.6847e-02, -4.4949e-02,\n","         -9.1215e-02, -1.2220e-01, -3.6544e-03, -2.1666e-02, -6.4127e-02,\n","          3.3714e-02, -7.6387e-02, -1.7881e-01, -2.1389e-01,  9.0744e-02,\n","          7.1557e-02, -1.3841e-01, -2.1211e-02, -8.1248e-02,  2.2823e-02,\n","         -5.2587e-02,  2.6031e-01, -1.0335e-01,  7.0517e-02, -1.0555e-01,\n","         -7.6895e-02, -1.2415e-01,  1.4071e-01, -4.5115e-02,  8.6829e-02,\n","         -1.8331e-03, -4.9369e-02,  1.3860e-01, -1.1770e-01, -7.4791e-02,\n","          8.3913e-02, -1.9824e-01, -8.6214e-02, -5.0124e-02,  4.8871e-02,\n","         -1.5867e-01, -6.7344e-02,  1.7815e-01,  1.6578e-02, -1.3324e-01,\n","         -6.4717e-02, -8.4600e-03, -3.1087e-02, -1.6134e-02, -6.3750e-02,\n","         -6.8864e-02, -2.1772e-02,  7.5677e-03,  1.0501e-01, -1.2398e-01,\n","          2.2218e-01,  1.5951e-02,  7.1277e-02, -6.1550e-03,  1.9305e-02,\n","          1.5787e-01, -6.5799e-02,  5.9684e-02, -1.2088e-01],\n","        [ 4.0756e-02, -1.9382e-01, -4.2866e-02,  3.7494e-02, -1.6230e-02,\n","         -1.6080e-01, -6.4395e-02,  2.4987e-02,  2.2784e-01,  9.3317e-02,\n","          1.0366e-03, -4.9245e-02, -1.4899e-01, -6.1615e-02,  5.0556e-02,\n","         -1.6845e-02, -1.1908e-02,  7.8362e-02,  5.9239e-02, -1.8221e-02,\n","          4.5840e-02, -5.6454e-03,  1.4018e-01,  1.2800e-02,  1.2425e-01,\n","         -8.4551e-02,  2.8327e-02,  7.2132e-02, -1.9699e-01, -2.8487e-02,\n","          1.4648e-02,  9.5522e-02, -1.6542e-01,  1.5805e-01, -6.9936e-02,\n","         -3.0191e-02,  5.1022e-02, -3.0965e-03, -3.9480e-02, -1.9985e-01,\n","         -7.0617e-02,  4.5373e-02, -7.4371e-02,  2.5018e-02, -1.0340e-02,\n","          1.9959e-01, -2.3156e-01,  2.1017e-01, -3.7919e-02, -1.3345e-01,\n","         -5.1857e-03,  2.0587e-01, -5.2825e-02,  2.5610e-02,  7.3741e-02,\n","         -1.4662e-01,  2.0725e-02,  7.0683e-02,  9.3513e-02,  4.1853e-02,\n","         -2.0906e-01,  8.7205e-02,  8.5486e-02, -6.9880e-02],\n","        [ 1.2036e-02,  6.7581e-02,  1.1727e-01,  1.1203e-01, -7.0258e-02,\n","          6.0133e-02,  1.3350e-01, -7.0318e-02,  1.2832e-01, -1.3536e-02,\n","          2.2360e-02,  2.5702e-03,  6.7676e-02, -2.4411e-02, -1.5724e-01,\n","          1.5086e-01, -1.3563e-02, -9.5992e-02,  2.5553e-02,  1.9625e-02,\n","         -3.1450e-02,  9.5146e-02,  2.1478e-01, -1.5908e-02,  4.2695e-02,\n","          1.5390e-02,  6.6571e-02,  3.5034e-02,  1.5538e-02,  1.8622e-01,\n","         -3.0397e-02,  6.4782e-02, -1.3577e-01,  8.4248e-02,  3.5940e-02,\n","          1.0833e-01, -5.9349e-02,  8.0788e-02,  5.3911e-02, -5.7571e-02,\n","          1.7422e-01,  1.8424e-03, -1.3160e-01,  1.8067e-02,  3.6823e-02,\n","          1.7618e-02, -1.1526e-01, -1.9440e-02, -1.3939e-01, -1.0413e-01,\n","         -1.4836e-02, -1.0446e-01,  1.0899e-01, -3.1098e-02,  1.2285e-01,\n","         -4.3499e-02,  9.6036e-02,  8.7673e-02, -5.2589e-02, -1.2884e-02,\n","          9.8708e-02, -4.4556e-02,  1.5902e-01, -1.6047e-01],\n","        [ 1.0701e-01,  2.2666e-02,  5.2785e-02, -1.5955e-02, -1.6505e-01,\n","         -5.6245e-02,  2.0795e-02,  2.6818e-02,  4.3986e-02, -1.0622e-01,\n","          8.9828e-02, -2.9886e-03,  9.0550e-02, -1.9871e-02,  1.5701e-01,\n","         -4.3353e-02,  3.5311e-02,  1.3137e-01, -8.8374e-03, -7.9146e-02,\n","         -3.3846e-02, -9.2017e-02,  1.7068e-02, -9.6807e-02, -2.8363e-02,\n","         -5.2100e-02, -1.6993e-01, -4.6985e-02,  1.7261e-02,  1.2924e-01,\n","          7.8902e-02,  1.7411e-01, -8.8855e-02, -4.4012e-02, -7.4182e-02,\n","         -4.8946e-02,  4.2007e-03, -4.9900e-02,  1.5272e-01,  2.7818e-02,\n","          2.3726e-01, -9.0605e-02, -1.8271e-02,  1.6916e-01,  2.9150e-02,\n","          1.0233e-01,  1.8241e-01,  3.9657e-02,  4.1858e-02,  2.3840e-02,\n","         -1.3189e-01, -4.4927e-02, -2.6617e-02,  1.5657e-01,  1.1691e-01,\n","         -8.1841e-02,  1.6037e-01,  1.2809e-01,  2.4404e-02, -1.4411e-01,\n","          2.2733e-02, -1.2562e-01, -1.8220e-01,  7.5837e-02]], device='cuda:0',\n","       requires_grad=True)\n","blocks.8.attn.b_V: torch.Size([12, 64])\n","Parameter containing:\n","tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n","       device='cuda:0', requires_grad=True)\n","blocks.8.mlp.W_in: torch.Size([768, 3072])\n","Parameter containing:\n","tensor([[ 0.0728,  0.2308,  0.0563,  ..., -0.1192, -0.0528, -0.0337],\n","        [-0.0764,  0.0445,  0.0396,  ..., -0.2856,  0.1121,  0.2754],\n","        [ 0.1191, -0.0931, -0.0249,  ...,  0.0714, -0.0871,  0.0389],\n","        ...,\n","        [-0.0853, -0.1365, -0.3167,  ..., -0.0099, -0.0647,  0.0631],\n","        [ 0.0910,  0.2691,  0.2102,  ..., -0.1966, -0.0822, -0.0785],\n","        [-0.1095,  0.0959,  0.1170,  ..., -0.1380,  0.1206,  0.1314]],\n","       device='cuda:0', requires_grad=True)\n","blocks.8.mlp.b_in: torch.Size([3072])\n","Parameter containing:\n","tensor([-0.1121, -0.1224, -0.1870,  ..., -0.0645, -0.0018, -0.1045],\n","       device='cuda:0', requires_grad=True)\n","blocks.8.mlp.W_out: torch.Size([3072, 768])\n","Parameter containing:\n","tensor([[-0.0882, -0.0182, -0.0571,  ...,  0.2254, -0.0706,  0.2501],\n","        [-0.2082, -0.1283, -0.0783,  ...,  0.0407,  0.1010,  0.0168],\n","        [-0.1802,  0.1600,  0.1066,  ..., -0.0362,  0.2725,  0.0956],\n","        ...,\n","        [ 0.1185,  0.1119, -0.1662,  ..., -0.0930, -0.0868,  0.0032],\n","        [ 0.1155, -0.1878,  0.1325,  ...,  0.0041, -0.0142, -0.0037],\n","        [-0.0738, -0.2040,  0.0523,  ..., -0.0662, -0.1873, -0.0498]],\n","       device='cuda:0', requires_grad=True)\n","blocks.8.mlp.b_out: torch.Size([768])\n","Parameter containing:\n","tensor([-5.8769e-02, -1.5128e-02, -1.2704e-01,  1.7183e-01,  2.2110e-02,\n","        -1.9016e-01,  3.3572e-02,  1.0734e-01,  1.4926e-01,  6.1738e-03,\n","        -1.5037e-01, -1.0702e-01,  1.3010e-01,  1.0654e-01, -4.7800e-02,\n","         4.2991e-02, -3.4297e-02,  2.1130e-01,  7.2358e-02, -8.7342e-02,\n","         1.0162e-03,  7.8567e-02, -5.9700e-02, -6.9859e-02, -1.6282e-01,\n","         7.4988e-03, -1.6893e-01,  3.9928e-02, -2.8615e-02,  1.3346e-01,\n","        -7.9313e-02, -7.9161e-02,  1.2042e-02, -1.9270e-01, -1.2865e-01,\n","        -1.9764e-02,  2.2606e-01, -6.7848e-02,  3.6736e-02, -1.0475e-01,\n","         2.3289e-02, -1.0270e-01,  2.7894e-02,  1.4310e-01, -1.0513e-01,\n","        -2.1978e-01,  1.3514e-01,  4.6547e-02, -1.4172e-01,  1.4714e-01,\n","         1.7424e-01,  3.4675e-02, -1.3016e-01, -1.0892e-01,  1.4502e-01,\n","         2.0394e-01, -1.5733e-01,  4.2240e-02, -1.1223e-01, -8.1955e-02,\n","        -9.8327e-03, -1.2808e-01,  3.5260e-02, -1.7828e-01, -1.9592e-01,\n","         1.1301e-01, -2.2965e-01,  2.5436e-02, -5.9254e-02,  2.7750e-02,\n","         1.2652e-01, -1.2888e-01,  5.9776e-02, -5.1973e-02,  1.2766e-01,\n","         7.0324e-02,  1.4374e-02, -1.2484e-01, -1.1273e-01,  4.2302e-02,\n","         7.7210e-02,  2.5129e-01,  1.0015e-01, -1.4621e-01, -9.2487e-03,\n","         5.8279e-02,  1.7071e-01, -3.1801e-02, -1.2636e-01,  1.8447e-02,\n","        -6.3903e-02,  1.7928e-01,  1.3434e-03, -9.4283e-02,  2.7342e-02,\n","         1.0053e-02,  1.8924e-02,  2.8742e-02,  1.9648e-01, -9.2325e-02,\n","        -9.9888e-02, -3.8376e-02,  2.1042e-01,  1.1169e-01,  1.8560e-02,\n","         2.1821e-02,  2.1615e-01, -6.4030e-02, -7.7317e-03,  1.6265e-01,\n","        -1.0447e-01, -5.0986e-03,  5.5824e-02,  2.0225e-01,  7.4229e-02,\n","         1.3156e-01,  4.1933e-02,  1.9266e-02,  4.4231e-02, -7.9142e-02,\n","         2.3100e-01,  1.1498e-01,  1.6480e-01,  1.1436e-01,  1.4813e-01,\n","         1.3108e-01, -1.1652e-01, -2.0515e-01,  1.2130e-02,  1.0260e-01,\n","        -1.4227e-01,  3.0950e-02, -2.6763e-02,  7.3041e-02,  1.8694e-02,\n","        -4.4567e-02,  1.2339e-01, -6.7681e-02, -2.8511e-01, -5.4403e-02,\n","         1.2565e-01,  9.3232e-03,  4.1351e-02, -9.5091e-02, -2.3921e-01,\n","         7.5710e-02, -2.2279e-03,  6.8768e-02, -2.1144e-01, -1.4405e-01,\n","        -5.8355e-02,  8.7306e-02,  9.1577e-02,  3.7639e-02, -9.9338e-03,\n","        -2.8254e-02,  5.8019e-02,  3.3767e-02,  1.9116e-02, -1.3632e-01,\n","         9.9828e-02, -2.4520e-03, -4.3158e-02,  1.8607e-01,  9.8838e-02,\n","         5.9011e-02, -1.6511e-01, -1.0553e-01,  5.0005e-02,  7.3320e-02,\n","        -1.7801e-01,  8.1211e-02,  5.9752e-02, -4.5913e-02,  5.0967e-03,\n","        -1.8042e-01,  5.3292e-02, -4.0537e-02,  5.6309e-03, -8.9632e-02,\n","        -3.9791e-02, -5.2643e-02,  4.8361e-02,  3.1825e-02,  2.6285e-03,\n","        -7.6144e-02,  3.0124e-02, -1.3679e-01, -9.1254e-02, -4.9735e-02,\n","         1.5186e-01, -6.8807e-02, -2.3222e-02, -1.0225e-01,  5.8105e-02,\n","        -1.2033e-01, -2.8751e-01,  5.3445e-04, -4.1134e-04, -1.6188e-02,\n","         7.6223e-02, -2.1538e-01, -4.2687e-02,  1.5292e-01,  2.4832e-02,\n","         8.9139e-02, -1.2599e-01,  1.2807e-03,  1.5907e-02, -1.5537e-01,\n","         1.3691e-02,  5.6071e-03, -1.0638e-02,  1.1626e-02,  5.7793e-02,\n","        -2.9137e-02, -2.2145e-02, -9.6289e-02,  7.5568e-02, -4.5294e-02,\n","         6.9269e-02, -1.7070e-02,  2.4163e-02,  8.9586e-02,  1.8388e-03,\n","         1.0287e-01,  1.2610e-02, -4.2420e-02,  9.7918e-02, -1.5377e-01,\n","         1.2005e-01, -7.7870e-02,  7.8147e-02, -5.4496e-02, -3.6114e-02,\n","         9.7898e-02,  8.9982e-02, -4.9528e-02,  3.0769e-02,  2.8650e-02,\n","         1.2046e-01,  2.3780e-02,  3.2855e-02, -2.1651e-01, -2.0946e-01,\n","         6.3724e-02,  1.7793e-02,  1.7407e-01,  8.5457e-04, -6.1269e-02,\n","        -2.4446e-02,  1.8557e-01,  7.3487e-02, -1.1203e-02, -4.3421e-02,\n","         7.5323e-02, -1.4780e-01, -1.3026e-01,  1.4440e-01,  1.8588e-02,\n","         7.0788e-02,  2.7552e-01, -1.1580e-01, -1.4875e-01, -2.3263e-01,\n","        -7.9815e-02,  2.2366e-01,  1.0123e-01, -8.9331e-02,  6.4436e-02,\n","        -2.7676e-01,  1.4556e-02, -5.3891e-02, -9.1036e-02,  1.3853e-01,\n","        -6.2024e-02,  1.1217e-01, -4.5253e-02,  2.4855e-03,  1.5327e-02,\n","         6.0593e-02, -1.8591e-01,  2.1779e-02, -1.0553e-01,  1.1848e-01,\n","         4.2643e-02, -8.5359e-02,  1.0735e-01,  6.5083e-02, -1.7322e-01,\n","         3.1246e-02,  5.3687e-02,  1.1827e-01,  1.9771e-02, -1.5053e-01,\n","         7.8057e-02,  1.5818e-01,  1.6076e-01, -1.0949e-01, -1.1212e-01,\n","         7.2905e-02, -2.0691e-01,  5.2617e-03,  1.0644e-01, -9.6805e-02,\n","        -1.2888e-01,  8.4566e-02, -1.2238e-04, -1.3740e-01,  1.9806e-01,\n","        -1.5793e-01, -1.3062e-01,  2.1061e-01,  5.2683e-02, -3.9564e-01,\n","        -1.2768e-01,  1.2843e-01,  7.4315e-02,  3.5640e-02, -6.6355e-02,\n","        -1.3406e-01, -4.1483e-02,  9.8421e-02, -3.1615e-02, -4.3813e-02,\n","         2.6276e-02,  1.2736e-01,  4.8799e-03, -4.7589e-02,  7.5080e-02,\n","         2.0391e-01, -3.3617e-02, -1.0929e-01,  3.3336e-02, -1.1807e-02,\n","        -1.5771e-02, -2.8418e-01, -1.1072e-02, -1.3586e-01,  2.4765e-02,\n","        -2.1580e-01,  2.8945e-02, -6.2606e-02, -7.5600e-02,  8.1372e-02,\n","        -8.9529e-02,  4.0484e-03, -4.0095e-03,  9.9999e-03, -1.3426e-01,\n","         1.1105e-01, -3.2715e-03,  2.9609e-02, -1.9708e-01, -9.8862e-02,\n","         5.7465e-02, -1.6699e-01,  1.8782e-01, -9.6659e-02,  1.4386e-01,\n","        -8.1090e-02,  1.6029e-01,  3.9859e-02,  2.1410e-01,  1.6743e-01,\n","         5.3262e-02, -2.8367e-02,  3.5335e-02, -1.6813e-02,  2.2281e-02,\n","        -5.3663e-02,  4.2385e-02, -4.6209e-02, -8.2678e-01, -9.2653e-02,\n","        -2.2728e-01, -8.0602e-02,  7.1655e-02,  3.4758e-01,  1.5232e-01,\n","        -1.2162e-01,  2.2559e-02, -1.0051e-01,  1.7072e-01, -1.2843e-01,\n","        -7.7123e-02,  2.3323e-04,  3.9672e-02, -5.8028e-02, -6.5995e-02,\n","        -5.4983e-02, -1.2149e-01, -6.0734e-02,  2.2569e-01, -3.7335e-02,\n","        -3.6775e-02,  1.8373e-01, -6.4585e-02,  1.6862e-01, -1.7038e-01,\n","         6.6172e-02,  8.0071e-02,  2.2189e-01,  1.6821e-02,  4.2798e-02,\n","         3.4852e-02, -6.8625e-02, -9.9195e-03,  2.2145e-01,  5.2885e-02,\n","        -8.4178e-02,  6.9827e-02, -4.3831e-02,  5.6738e-02,  1.8749e-01,\n","         9.7824e-02, -7.0215e-02, -2.8080e-02,  5.2072e-02,  1.4484e-01,\n","         9.4261e-03,  1.5601e-01, -2.6534e-02,  4.5197e-02,  8.7440e-02,\n","         1.6953e-01,  1.6529e-01,  1.1180e-01, -1.8141e-01, -7.9372e-02,\n","         1.6777e-01, -1.7279e-02, -2.1423e-01, -1.5037e-02,  8.5993e-02,\n","         3.3805e-03, -1.4001e-01,  6.6421e-02,  7.5586e-02,  1.0490e-02,\n","         1.0710e-01,  3.1776e-02, -1.1603e-01, -9.9434e-02, -8.2833e-02,\n","        -2.2401e-01,  1.1396e-01,  1.0330e+00,  3.6247e-02,  1.6486e-02,\n","         9.7572e-02, -1.4699e-02,  6.6007e-02, -1.3970e-01,  1.4905e-01,\n","         2.6190e-01,  2.6835e-02, -1.0719e-02, -8.0123e-02,  2.3901e-02,\n","        -1.3664e-02, -2.4460e-01,  6.0661e-02,  1.1666e-01, -2.0624e-02,\n","        -1.3970e-01,  1.1908e-03,  4.8883e-02, -1.2981e-02,  4.7476e-02,\n","        -2.4209e-02,  2.1890e-02, -3.0175e-02, -1.3388e-01, -2.0547e-01,\n","         3.7484e-02,  8.1212e-04,  1.7459e-01, -9.9870e-02,  4.9559e-02,\n","        -1.6083e-02,  1.2203e+00,  1.6643e-01, -1.0376e-01, -5.9933e-03,\n","         1.7347e-01, -3.6017e-05, -2.0671e-02, -7.4345e-03, -1.0151e-03,\n","        -3.5179e-03,  2.8466e-03,  1.0333e-02,  1.9522e-01,  2.0232e-01,\n","         6.2518e-02,  1.2624e-01, -9.7949e-02,  3.6485e-02, -8.6692e-02,\n","        -9.0188e-03, -3.6922e-02, -7.3783e-03,  7.9041e-02, -5.6468e-02,\n","        -1.7389e-02, -1.1945e-01, -5.5713e-02,  6.0973e-02,  1.1235e-01,\n","        -2.0326e-01, -9.5858e-02,  1.9016e-01,  5.2982e-02, -8.3206e-02,\n","         7.8478e-02, -6.5513e-02,  1.2287e-01,  4.3119e-02,  3.4426e-02,\n","        -2.3168e-02,  4.9700e-02,  1.1356e-01, -7.6832e-02,  2.5402e-03,\n","        -1.0767e-01, -1.1810e-01,  1.9055e-02,  1.3635e-01, -1.2282e-01,\n","         7.6642e-02,  1.4567e-02,  3.6925e-02, -6.5020e-02, -6.6345e-02,\n","         6.5961e-02, -6.4338e-02,  1.8772e-02, -2.6439e-02, -1.1596e-03,\n","         1.1295e-01,  1.6181e-02, -8.8827e-02, -1.2512e-01, -1.4308e-01,\n","         1.9660e-01,  5.8951e-02,  7.3752e-02, -1.2838e-01, -4.2147e-02,\n","        -9.8722e-02,  1.6849e-01, -6.8120e-02, -1.3341e-01, -1.5664e-01,\n","         8.2964e-04,  8.9524e-02,  7.0188e-02,  6.7071e-02, -8.7070e-02,\n","         1.4737e-01, -1.0557e-01, -1.8619e-01,  8.6352e-02,  2.2703e-01,\n","         1.1996e-02,  6.5522e-02, -1.9073e-02, -3.8538e-02, -2.5005e-02,\n","        -8.5968e-02,  6.1669e-02,  1.0926e-01, -7.2602e-02, -1.4800e-01,\n","         6.1748e-02, -2.2961e-01,  3.1679e-03, -5.6593e-02, -1.0661e-01,\n","        -3.9110e-02,  2.1421e-02,  6.3433e-02, -1.8626e-02,  1.2275e-01,\n","        -9.1002e-02,  1.9431e-02,  3.3327e-02, -4.6426e-02,  1.9181e-01,\n","        -1.4646e-01, -1.7366e-02,  1.0546e-01, -6.5218e-02,  1.8726e-01,\n","        -1.9612e-01,  2.9527e-02, -6.8297e-02, -7.1361e-02, -1.5687e-01,\n","         3.0408e-02, -9.0515e-02, -1.3739e-01,  2.1894e-01,  1.8688e-01,\n","        -5.7703e-02,  7.0457e-02, -2.5594e-01,  1.4262e-01,  7.7588e-03,\n","        -4.8228e-02, -3.6001e-02, -1.4824e-01,  3.6964e-02, -1.0511e-01,\n","        -1.9951e-03,  1.5784e-01, -7.6577e-02, -3.3761e-02,  1.0470e-01,\n","        -1.8986e-01, -9.9369e-02, -1.9494e-02, -2.3157e-01, -7.6811e-02,\n","        -1.2869e-01, -6.4331e-02, -1.0443e-01,  1.6667e-01,  8.2404e-02,\n","        -1.2334e-01,  2.6043e-01,  6.5064e-02, -8.1565e-02,  8.1645e-02,\n","         5.2301e-02, -2.2490e-02,  4.5627e-02,  5.1924e-02,  7.1152e-02,\n","         1.4725e-01, -1.5259e-02, -1.8378e-02, -2.1626e-01,  1.5326e-01,\n","        -7.2225e-02, -5.6951e-02, -7.5823e-03,  6.5243e-02, -6.1362e-02,\n","        -4.2306e-02,  4.9982e-02, -1.0694e-02, -2.2043e-01, -1.7961e-01,\n","         1.1751e-01, -5.6446e-02, -6.1906e-02,  3.9603e-02, -1.6048e-02,\n","         7.7821e-02,  6.5473e-02, -6.0150e-02,  1.4740e-01,  5.0661e-02,\n","         1.9010e-01,  9.6012e-02,  1.3314e-02,  6.3652e-02,  6.6090e-02,\n","        -2.2606e-02, -1.0447e-01, -1.3062e-01,  5.2569e-02,  1.0364e-01,\n","        -3.2097e-02,  2.2066e-01,  2.0202e-01,  5.8923e-02,  9.7096e-02,\n","        -5.2521e-02, -1.6751e-01,  1.0752e-01, -3.4350e-02, -2.1032e-01,\n","        -7.9709e-02, -6.1715e-02, -1.4369e-01, -5.0396e-02,  1.2141e-01,\n","         3.5349e-01,  5.0782e-02, -1.0906e-01,  1.7086e-01, -1.4661e-01,\n","        -5.9952e-02,  5.2228e-02,  9.7623e-02, -1.1827e-02, -5.3270e-02,\n","         1.4883e-02,  1.2638e-01, -2.0917e-02, -3.2632e-02,  1.4429e-01,\n","         5.4383e-02, -4.9807e-02, -1.8972e-02, -1.1839e-02,  5.4536e-02,\n","         7.2511e-03, -1.8759e-01, -1.6722e-02, -4.4381e-02, -1.1177e-01,\n","        -6.6807e-03, -2.1611e-01, -8.2291e-02,  1.2724e-01,  1.5376e-01,\n","         4.6422e-02, -1.1472e-01, -7.6445e-02,  2.6862e-02,  9.2872e-02,\n","         8.4951e-02, -3.2472e-02, -2.0463e-01, -6.3029e-02,  4.2306e-02,\n","         1.6564e-02, -2.1404e-01,  9.8362e-02, -1.1333e-01,  5.0958e-02,\n","         9.6867e-02, -1.1643e-01,  4.6737e-02, -3.6432e-02, -1.6969e-01,\n","        -1.4029e-01,  2.8366e-02,  1.9957e-02, -1.8196e-01,  7.6958e-02,\n","        -5.9995e-02, -1.5547e-01, -6.5749e-02, -8.4578e-02,  2.0553e-02,\n","         1.1013e-01, -1.1647e-01,  1.1296e-01,  1.3463e-02,  6.0956e-02,\n","         2.7034e-02, -5.5513e-02, -7.0310e-02,  6.3617e-02,  2.7610e-01,\n","        -7.2239e-02,  1.1893e-01,  4.4160e-03, -1.1407e-01, -3.6611e-02,\n","         3.2564e-02, -2.2657e-02, -5.9874e-02], device='cuda:0',\n","       requires_grad=True)\n","blocks.9.ln1.w: torch.Size([768])\n","Parameter containing:\n","tensor([0.3815, 0.3605, 0.3697, 0.3585, 0.3653, 0.3277, 0.4366, 0.3190, 0.3760,\n","        0.3174, 0.3975, 0.3641, 0.3470, 0.3779, 0.3925, 0.3663, 0.3564, 0.3584,\n","        0.3682, 0.3501, 0.3349, 0.3449, 0.3698, 0.3721, 0.3585, 0.3598, 0.3786,\n","        0.3364, 0.3586, 0.3547, 0.3510, 0.3606, 0.3541, 0.3366, 0.3623, 0.3904,\n","        0.3035, 0.3562, 0.3467, 0.3565, 0.3333, 0.3324, 0.3350, 0.3506, 0.3571,\n","        0.3667, 0.3467, 0.3370, 0.3564, 0.3545, 0.3442, 0.3410, 0.3603, 0.3587,\n","        0.3565, 0.3505, 0.3562, 0.3838, 0.3350, 0.3870, 0.3623, 0.3577, 0.3859,\n","        0.3485, 0.9022, 0.3349, 0.3387, 0.3671, 0.3486, 0.3438, 0.3759, 0.2744,\n","        0.3469, 0.3436, 0.3389, 0.3589, 0.3936, 0.3936, 0.3719, 0.3413, 0.3468,\n","        0.3408, 0.3602, 0.3486, 0.3457, 0.3838, 0.3643, 0.7337, 0.3350, 0.3663,\n","        0.3487, 0.3469, 0.3343, 0.3448, 0.3369, 0.3408, 0.3642, 0.3808, 0.3825,\n","        0.3819, 0.3486, 0.3291, 0.3740, 0.3694, 0.3543, 0.3478, 0.3838, 0.3876,\n","        0.3389, 0.3592, 0.3662, 0.3660, 0.3552, 0.3615, 0.3657, 0.3683, 0.3649,\n","        0.3624, 0.3414, 0.4054, 0.3696, 0.3387, 0.3447, 0.3508, 0.3739, 0.3779,\n","        0.3221, 0.3697, 0.3671, 0.3530, 0.3603, 0.3469, 0.3868, 0.3623, 0.3456,\n","        0.3430, 0.3506, 0.4079, 0.2555, 0.3272, 0.3617, 0.3630, 0.3604, 0.3369,\n","        0.3874, 0.3484, 0.3665, 0.3837, 0.3565, 0.3447, 0.3538, 0.3683, 0.4010,\n","        0.3994, 0.3744, 0.3564, 0.3624, 0.3584, 0.3365, 0.3858, 0.3955, 0.3488,\n","        0.3622, 0.3767, 0.3660, 0.3565, 0.3539, 0.4371, 0.3588, 0.3669, 0.3506,\n","        0.3650, 0.3585, 0.3670, 0.3701, 0.3445, 0.3613, 0.3428, 0.3722, 0.3489,\n","        0.3406, 0.3330, 0.3401, 0.3828, 0.3367, 0.3369, 0.3565, 0.3564, 0.3532,\n","        0.3642, 0.3508, 0.3213, 0.3459, 0.3510, 0.3545, 0.4010, 0.3243, 0.3330,\n","        0.3585, 0.3825, 0.3651, 0.3838, 0.3554, 0.3588, 0.3278, 0.3603, 0.3389,\n","        0.3115, 0.3885, 0.3493, 0.3467, 0.3863, 0.3818, 0.4068, 0.3487, 0.3373,\n","        0.3763, 0.3447, 0.2666, 0.3466, 0.3838, 0.3509, 0.3541, 0.3745, 0.3486,\n","        0.3332, 0.3441, 0.3486, 0.3428, 0.3447, 0.3190, 0.3577, 0.4276, 0.3402,\n","        0.3552, 0.3756, 0.3780, 0.3321, 0.3682, 0.3641, 0.3956, 0.3625, 0.3700,\n","        0.3506, 0.3231, 0.3559, 0.3381, 0.4075, 0.3448, 0.3510, 0.3291, 0.3699,\n","        0.3368, 0.3709, 0.3460, 0.3701, 0.3466, 0.3564, 0.3480, 0.3545, 0.3552,\n","        0.3561, 0.3705, 0.3431, 0.3274, 0.3257, 0.9450, 0.4037, 0.3624, 0.3708,\n","        0.4143, 0.4372, 0.3331, 0.3467, 0.3819, 0.3389, 0.3721, 0.3365, 0.3564,\n","        0.3526, 0.3429, 0.3174, 0.3507, 0.4689, 0.3877, 0.3799, 0.3668, 0.3406,\n","        0.5056, 0.4012, 0.3700, 0.3611, 0.3396, 0.3256, 0.3797, 0.3545, 0.3282,\n","        0.3525, 0.3468, 0.3598, 0.3465, 0.3683, 0.3759, 0.3486, 0.3423, 0.3311,\n","        0.3408, 0.3502, 0.3556, 0.3252, 0.3406, 0.4091, 0.3538, 0.3552, 0.2097,\n","        0.3390, 0.3916, 0.3664, 0.3680, 0.3651, 0.3425, 0.3427, 0.3624, 0.3733,\n","        0.3558, 0.3662, 0.4126, 0.3366, 0.3603, 0.3429, 0.3389, 0.3412, 0.3674,\n","        0.3389, 0.3333, 0.3720, 0.4006, 0.3489, 0.3447, 0.3940, 0.3479, 0.3368,\n","        0.3680, 0.3870, 0.3555, 0.3406, 0.3567, 0.3406, 0.3565, 0.3478, 0.3429,\n","        0.3595, 0.3624, 0.3468, 0.3542, 0.3603, 0.3574, 0.3644, 0.3643, 0.3524,\n","        0.3735, 0.3467, 0.3385, 0.3533, 0.3346, 0.3666, 0.3604, 0.3526, 0.3604,\n","        0.3460, 0.3625, 0.3351, 0.3556, 0.0780, 0.3381, 0.4179, 0.3800, 0.3751,\n","        0.2844, 0.3681, 0.3375, 0.3481, 0.3484, 0.3811, 0.3545, 0.3812, 0.3936,\n","        0.3408, 0.3507, 0.3513, 0.3448, 0.3290, 0.3536, 0.5866, 0.3418, 0.3365,\n","        0.3817, 0.3318, 0.3313, 0.3485, 0.3341, 0.3552, 0.3681, 0.3603, 0.3373,\n","        0.3615, 0.3640, 0.3290, 0.3252, 0.3378, 0.3311, 0.3416, 0.3273, 0.3428,\n","        0.3601, 0.3526, 0.3350, 0.3782, 0.3857, 0.3357, 0.2720, 0.3899, 0.3408,\n","        0.3605, 0.3521, 0.3213, 0.3623, 0.3506, 0.3332, 0.3364, 0.2724, 0.3419,\n","        0.3228, 0.3912, 0.3351, 0.3780, 0.3214, 0.3801, 0.3550, 0.3854, 0.3181,\n","        0.3565, 0.3681, 0.3362, 0.4030, 0.3581, 0.3371, 0.0696, 0.3506, 0.3514,\n","        0.3572, 0.3447, 0.3311, 0.3566, 0.3430, 0.3897, 0.3528, 0.3544, 0.3532,\n","        0.2775, 0.3450, 0.3899, 0.3232, 0.3721, 0.2646, 0.3682, 0.3729, 0.3506,\n","        0.3234, 0.3334, 0.3252, 0.3711, 0.3682, 0.3624, 0.3174, 0.3540, 0.3379,\n","        0.3330, 0.3490, 0.3623, 0.7363, 0.0733, 0.3589, 0.3309, 0.3545, 0.3339,\n","        0.3466, 0.3369, 0.3686, 0.3589, 0.3507, 0.3740, 0.3547, 0.3467, 0.3759,\n","        0.3364, 0.2742, 0.2803, 0.3714, 0.3544, 0.3592, 0.3527, 0.3550, 0.3838,\n","        0.3801, 0.3408, 0.3448, 0.3532, 0.3855, 0.3215, 0.3228, 0.3642, 0.3507,\n","        0.3681, 0.3586, 0.3863, 0.3740, 0.3482, 0.3277, 0.3486, 0.3489, 0.3509,\n","        0.3720, 0.3611, 0.3512, 0.3419, 0.4053, 0.3779, 0.3730, 0.3442, 0.3429,\n","        0.3666, 0.3508, 0.3447, 0.3334, 0.3758, 0.3427, 0.3603, 0.3745, 0.3589,\n","        0.3682, 0.3699, 0.3388, 0.3660, 0.3426, 0.3556, 0.3793, 0.3452, 0.3408,\n","        0.3903, 0.3449, 0.3797, 0.3525, 0.3647, 0.3727, 0.3624, 0.3504, 0.3681,\n","        0.3704, 0.3369, 0.3613, 0.3631, 0.3350, 0.3546, 0.3524, 0.3721, 0.3780,\n","        0.3527, 0.3878, 0.3737, 0.4132, 0.3779, 0.3334, 0.3481, 0.3469, 0.4131,\n","        0.3431, 0.3369, 0.3986, 0.3505, 0.3502, 0.3241, 0.3837, 0.3545, 0.3506,\n","        0.3781, 0.3294, 0.3884, 0.3534, 0.3603, 0.3389, 0.3566, 0.3413, 0.3624,\n","        0.3430, 0.3481, 0.3701, 0.3349, 0.3499, 0.3552, 0.3487, 0.3505, 0.3545,\n","        0.3680, 0.3510, 0.3370, 0.3685, 0.3565, 0.3878, 0.3740, 0.3543, 0.3623,\n","        0.3802, 0.3466, 0.3500, 0.3467, 0.3566, 0.3499, 0.3756, 0.3593, 0.3545,\n","        0.3432, 0.3623, 0.3694, 0.3556, 0.3389, 0.3519, 0.3432, 0.3565, 0.3630,\n","        0.3701, 0.3545, 0.3507, 0.3350, 0.3486, 0.3878, 0.3604, 0.3272, 0.3336,\n","        0.3994, 0.4226, 0.3667, 0.3428, 0.3672, 0.3860, 0.3682, 0.3408, 0.3858,\n","        0.3584, 0.3839, 0.3669, 0.4028, 0.4092, 0.3525, 0.3369, 0.3623, 0.3428,\n","        0.3565, 0.3370, 0.3992, 0.3566, 0.3937, 0.3557, 0.3523, 0.3682, 0.3760,\n","        0.3387, 0.3584, 0.3310, 0.3530, 0.3936, 0.3291, 0.3566, 0.3493, 0.3098,\n","        0.3291, 0.3213, 0.3349, 0.3802, 0.4131, 0.3428, 0.3386, 0.3705, 0.3483,\n","        0.3408, 0.3427, 0.3760, 0.3176, 0.3419, 0.3477, 0.3638, 0.3332, 0.3506,\n","        0.3705, 0.3350, 0.3603, 0.3470, 0.3428, 0.3368, 0.3940, 0.3294, 0.3897,\n","        0.3529, 0.4248, 0.3460, 0.3528, 0.3837, 0.3935, 0.3436, 0.3525, 0.3829,\n","        0.3629, 0.3619, 0.3381, 0.3447, 0.3502, 0.3420, 0.3525, 0.3818, 0.3328,\n","        0.3291, 0.3409, 0.3616, 0.3506, 0.3232, 0.3534, 0.3804, 0.3760, 0.3486,\n","        0.3585, 0.3571, 0.3488, 0.3408, 0.3543, 0.3678, 0.3691, 0.3465, 0.3447,\n","        0.3809, 0.3848, 0.3842, 0.3472, 0.3439, 0.3760, 0.3740, 0.2471, 0.3974,\n","        0.3565, 0.3870, 0.3537, 0.3526, 0.3455, 0.3397, 0.3350, 0.3818, 0.3760,\n","        0.2291, 0.3341, 0.3382, 0.3782, 0.3344, 0.3584, 0.3575, 0.3291, 0.3358,\n","        0.3428, 0.3293, 0.3525], device='cuda:0', requires_grad=True)\n","blocks.9.ln1.b: torch.Size([768])\n","Parameter containing:\n","tensor([ 3.0492e-02,  1.0873e-02,  4.3270e-02,  1.7420e-02, -2.5693e-04,\n","         1.3972e-02, -5.4081e-02,  2.8417e-02,  1.4311e-02,  6.1985e-03,\n","         7.1668e-03,  7.2782e-03,  2.5299e-02,  1.9724e-02,  3.7934e-02,\n","        -1.3185e-03,  3.1771e-02,  3.4832e-02,  6.9418e-03,  7.5766e-03,\n","         2.5131e-02,  2.4309e-02,  1.7464e-02,  2.8942e-02,  2.0046e-02,\n","         1.1927e-02,  4.9463e-03,  1.4933e-02,  3.1305e-02,  5.3658e-03,\n","         8.7908e-03, -1.3974e-02, -1.1042e-02,  1.4675e-02,  2.2177e-02,\n","         4.8724e-02, -3.8153e-03,  7.2784e-03,  2.8098e-02,  4.9011e-03,\n","         3.8378e-03,  4.4482e-03, -4.7649e-03,  1.7485e-02,  3.1325e-02,\n","         2.0469e-02,  1.5536e-02,  9.7983e-03,  5.5255e-03, -4.2110e-03,\n","         2.0810e-02, -9.2583e-04,  1.2394e-02, -5.3090e-03,  1.3071e-02,\n","        -1.4376e-02, -2.2310e-03,  2.1225e-02,  5.3781e-03,  1.9862e-02,\n","         2.2096e-02,  1.6833e-02,  2.8913e-02,  8.3504e-03,  1.2640e+00,\n","         1.1653e-02, -1.2745e-02, -6.7209e-03,  2.8282e-02,  1.9079e-02,\n","         5.7522e-03,  2.3886e-02,  1.8771e-02,  2.0131e-02,  1.9840e-02,\n","         2.2523e-02, -1.7576e-02,  1.6454e-02,  1.6718e-02,  2.6704e-02,\n","         4.2290e-02,  1.6274e-02,  1.9184e-02,  1.7019e-02,  4.9366e-02,\n","         1.6655e-02,  3.0581e-02, -4.8480e-03,  1.4291e-02,  1.7406e-02,\n","         4.8399e-03,  1.4267e-02,  3.2760e-02, -9.3008e-04,  1.6378e-02,\n","         9.3173e-03,  1.1932e-02,  2.2098e-02,  3.0984e-02,  4.8152e-02,\n","         1.5879e-02, -2.4991e-02, -2.9359e-02,  2.0413e-02,  2.3619e-02,\n","         1.5845e-02,  3.2071e-02,  1.5187e-02,  8.8350e-03,  1.6707e-02,\n","         1.1934e-02,  2.7053e-02,  1.4257e-02,  3.5153e-02,  1.1276e-02,\n","         2.8245e-04,  5.0559e-02,  1.4811e-02,  2.7672e-02,  3.8542e-02,\n","         3.5771e-02,  1.2524e-02,  7.9735e-03, -1.6752e-03,  4.0489e-03,\n","         3.3490e-02,  1.1014e-02,  4.2589e-02,  4.1177e-02,  2.3080e-02,\n","         1.9257e-02,  1.4621e-02,  1.2663e-02,  1.1382e-02,  1.2189e-02,\n","         1.4357e-02,  2.1875e-02,  3.8572e-02, -9.7851e-01,  1.8799e-04,\n","         5.6949e-03, -6.7323e-03,  2.7129e-02,  2.1288e-02,  5.6009e-03,\n","        -5.0546e-03, -1.0455e-02,  1.7738e-02,  9.5393e-03,  2.1756e-02,\n","         4.5037e-02, -2.6835e-02,  2.0255e-02,  1.2796e-02,  8.0672e-03,\n","         1.2271e-03,  1.1062e-02,  2.5293e-02,  9.0142e-03, -2.8360e-03,\n","        -3.4980e-02,  2.5504e-02,  8.1569e-03,  2.3866e-02,  1.9978e-02,\n","         4.5272e-02,  3.4002e-03,  1.1349e-01, -3.0909e-04,  2.4132e-02,\n","         1.5031e-02,  1.4289e-02,  2.4586e-02,  1.6743e-02,  2.6241e-02,\n","         1.8351e-02,  6.0749e-02,  1.3744e-02, -9.7299e-03,  8.2542e-03,\n","         1.5036e-02, -2.2009e-03,  2.9051e-02,  2.0967e-02,  4.4107e-02,\n","         1.0594e-02,  4.8096e-03,  1.3991e-02,  1.4999e-02, -5.2220e-03,\n","         1.1884e-02,  3.6578e-02,  3.0015e-02,  2.0630e-02,  2.6151e-02,\n","         8.1315e-02,  2.2292e-02,  3.0108e-02,  4.0327e-02,  1.6590e-02,\n","         9.0357e-03,  8.5139e-03,  1.9155e-02,  2.3388e-02,  5.4928e-03,\n","         1.1643e-02,  3.3528e-02,  1.9696e-02,  2.0762e-02,  6.7627e-03,\n","        -5.3330e-04,  3.8859e-02,  2.8078e-02,  3.3113e-02,  2.9168e-02,\n","         1.4322e-02,  1.4427e-02,  1.9223e-02,  3.2934e-02,  1.7911e-02,\n","         1.4826e-02,  2.7489e-02,  3.4255e-03,  4.4369e-03, -5.8271e-03,\n","         1.2655e-05,  9.8684e-03,  2.6706e-02,  3.1864e-02,  8.0583e-03,\n","         1.7587e-02,  1.7766e-02, -1.5736e-02,  2.1030e-02,  8.9753e-03,\n","         3.8633e-03,  1.6269e-02,  8.4637e-03,  1.9661e-02,  1.6015e-02,\n","         3.1092e-02,  1.2668e-02,  2.3572e-02,  4.7969e-03,  1.8475e-02,\n","         1.0278e-02, -3.5105e-03,  1.8962e-02,  1.6102e-02,  2.2042e-02,\n","         2.7791e-02,  3.3593e-02,  2.7364e-03,  9.1344e-03,  3.4546e-02,\n","        -2.0953e-02,  2.1569e-02,  2.2558e-02, -1.0549e-02,  2.4257e-02,\n","         9.5191e-03,  2.1621e-02,  2.3205e-02, -1.9487e-03,  2.4744e-02,\n","         1.5900e-02, -7.5825e-02, -7.0304e-03,  2.6699e-02,  1.7583e-02,\n","         3.3506e-02,  4.2919e-03,  1.7947e-02, -1.0324e-02, -4.9267e-03,\n","         1.7151e-02,  3.3310e-03,  2.4004e-02,  1.7828e-02,  4.2457e-03,\n","         1.3460e-02,  1.5531e-02,  4.2796e-04,  7.9273e-02,  1.6549e-02,\n","         1.1694e-02,  1.3224e-02,  2.4826e-02, -1.4099e-01,  5.9840e-02,\n","         1.5161e-02,  4.9515e-03,  3.1367e-02,  2.2476e-02,  2.7255e-02,\n","         1.9948e-02,  1.1058e-02,  2.1055e-02,  1.3075e-02,  2.7591e-03,\n","         1.2312e-02,  1.4495e-02, -8.9776e-03,  2.8881e-02,  1.0944e-02,\n","         4.6865e-03,  1.4001e-02,  1.5085e-02,  4.5588e-02,  3.0149e-02,\n","         3.7736e-03,  6.7782e-02,  2.4625e-02,  1.8980e-02,  1.3088e-01,\n","         1.1943e-02,  3.5017e-02, -2.8263e-03,  1.4576e-02,  1.9351e-02,\n","         3.4526e-02,  1.7707e-02,  9.2545e-03,  1.0294e-02, -1.5073e-03,\n","        -7.4645e-03, -2.1486e-01,  1.3212e-02,  1.6797e-02,  2.8523e-02,\n","        -1.9194e-03,  2.9378e-03,  3.3162e-03,  9.9875e-03,  1.2589e-02,\n","         1.8258e-02,  1.4405e-02,  2.0468e-02,  2.4215e-02,  8.1178e-03,\n","         8.9394e-03,  8.3687e-03, -1.6169e-03, -1.9501e-03,  1.3940e-02,\n","        -6.2043e-03, -9.2368e-03,  1.2015e-02, -4.0545e-03,  1.5354e-02,\n","         1.7631e-02, -3.1877e-03,  9.2731e-03,  1.9466e-03, -1.2600e-02,\n","         1.8434e-02,  3.5745e-02,  2.4432e-02,  3.5761e-02,  2.1524e-02,\n","         5.5862e-03,  3.2582e-02, -1.6921e-02,  2.2361e-02,  1.1903e-02,\n","         7.9036e-02,  1.3365e-02,  1.3526e-04, -8.3639e-04,  1.2128e-02,\n","         2.8013e-02, -2.0960e-03,  4.4792e-02,  2.1588e-01,  5.1534e-02,\n","         1.0282e-02,  3.5406e-02, -1.1957e-02,  6.3151e-02,  1.5547e-02,\n","         3.4978e-02,  7.6248e-03,  2.0230e-02,  9.5394e-03,  2.1975e-02,\n","        -2.1745e-02,  1.5206e-02,  2.4135e-02, -4.3635e-03,  3.2644e-02,\n","         2.7837e-02,  2.4270e-02, -1.3464e-02, -2.5990e-01,  4.3669e-02,\n","         1.1335e-02,  4.3247e-02,  1.0057e-02,  2.1309e-02,  1.0001e-02,\n","         2.7655e-02, -1.8995e-02,  1.5746e-02,  6.3277e-03,  1.1677e-04,\n","         2.3379e-02,  5.8150e-03,  2.5217e-02, -4.9475e-02,  1.8588e-02,\n","         2.3623e-02,  1.5584e-02,  2.3759e-02,  1.3985e-02,  2.8896e-02,\n","        -3.7939e-03,  1.8157e-02,  8.9940e-03,  1.9959e-02,  8.2681e-03,\n","         2.1788e-02,  2.7793e-02,  2.8309e-02,  1.6599e-02,  1.2845e-02,\n","         2.5146e-02,  1.4347e-02,  3.1225e-02,  7.0123e-03,  1.4993e-02,\n","        -6.3596e-02,  1.6489e-02,  1.7804e-02,  2.0980e-02,  2.8874e-02,\n","         1.1221e-02,  1.1360e-02,  1.4227e-02,  8.7227e-03, -1.2859e-03,\n","        -4.8777e-03,  7.4109e-03, -2.2111e-02,  2.2965e-02, -6.7598e-03,\n","         9.6770e-03,  3.7641e-02, -6.0150e-02,  3.3126e-02,  5.0289e-03,\n","         9.8868e-03,  5.3616e-03,  2.1815e-02, -4.6418e-03, -6.1248e-03,\n","         1.4572e-02,  3.7026e-02,  2.1172e-02,  1.0499e-02,  5.9143e-04,\n","         1.7518e-02,  7.9348e-04,  2.1479e-02,  1.6420e-02, -1.2433e-02,\n","         1.9114e-02,  1.3894e-02,  1.3655e-02,  1.8253e-02,  3.4881e-03,\n","         4.6841e-02,  1.8069e-02,  1.7672e-02,  2.6934e-02,  2.5695e-02,\n","         2.1822e-02,  2.6906e-02,  2.4229e-02,  2.0002e-02,  4.9879e-02,\n","         2.7866e-01, -6.3525e-02,  2.0515e-02,  1.8086e-02,  4.9788e-03,\n","         1.3468e-03,  2.1840e-02,  1.1516e-02, -1.6606e-02,  2.7777e-02,\n","         1.0955e-03,  3.3796e-02,  1.9485e-02,  2.0462e-02,  9.7305e-03,\n","         2.1445e-02, -5.0352e-02,  4.1499e-02,  1.0300e-02,  1.4353e-02,\n","        -6.8805e-03,  2.0569e-02,  1.2843e-02,  7.1495e-02,  3.1187e-02,\n","         3.4228e-02,  2.3727e-03, -1.0675e-02,  5.3816e-03,  1.1982e-02,\n","         6.9884e-03,  9.1350e-03,  2.6571e-02,  2.1772e-02,  2.0681e-02,\n","         3.1708e-02,  1.4879e-02,  2.2451e-02,  1.8890e-02,  6.7578e-03,\n","         2.0082e-02,  4.8951e-02,  1.7292e-02,  6.5108e-03, -8.2309e-04,\n","         2.0504e-02,  1.4999e-01,  5.3778e-02,  2.3666e-02,  2.1510e-02,\n","         1.0187e-02, -1.3285e-02,  1.3953e-02,  2.2537e-02,  3.3802e-02,\n","         2.6163e-02,  3.1887e-02,  1.0900e-03, -2.0444e-03,  4.8195e-02,\n","        -9.0014e-03,  1.0960e-02, -6.7787e-03,  2.5145e-02,  1.8359e-02,\n","         3.5667e-02,  1.9920e-02,  1.9106e-02,  2.1743e-02,  2.1916e-02,\n","         2.4789e-02,  1.2540e-02,  8.1938e-03,  1.3269e-02,  7.7007e-02,\n","         1.9964e-04,  2.1763e-02,  2.0351e-02,  2.2181e-02,  3.3092e-02,\n","         3.5036e-02,  1.6261e-02,  1.4645e-02,  4.0753e-03,  1.1995e-02,\n","         1.4290e-02,  4.7790e-03,  3.5958e-02,  1.4220e-02,  2.3047e-02,\n","         4.0370e-02,  2.0986e-02,  7.3956e-03,  3.1470e-02,  2.8259e-02,\n","        -2.3865e-02,  3.2087e-02,  1.3662e-02,  4.5868e-02, -8.7525e-03,\n","        -9.3848e-03,  9.0696e-04,  1.7263e-02,  2.6611e-02,  1.3995e-02,\n","        -1.1692e-02,  2.2815e-02,  1.4863e-02,  1.6093e-03,  1.1856e-02,\n","         1.7830e-03,  4.2211e-02,  7.4831e-03,  2.3812e-02,  1.2525e-02,\n","         3.4073e-03,  2.0428e-02, -1.1241e-03,  2.4105e-02,  1.4789e-02,\n","         4.2384e-02,  2.2830e-02,  1.6747e-02,  2.2657e-02,  2.7260e-02,\n","         6.4910e-03,  1.5120e-02,  5.6488e-03, -4.6249e-02, -7.4661e-04,\n","         3.7826e-02,  1.7944e-04,  4.4868e-03,  2.4641e-02,  2.1288e-02,\n","         2.9802e-02,  9.7515e-03,  3.2065e-02,  6.4750e-03,  2.2078e-02,\n","         4.9191e-02,  1.5626e-02,  2.3219e-02,  2.2685e-02,  1.7696e-02,\n","         1.8980e-02,  2.8285e-02,  7.6404e-02, -9.0878e-04,  2.8371e-02,\n","         1.9977e-02,  3.2796e-02,  1.4536e-02,  3.0808e-02, -7.2076e-04,\n","         3.3591e-02,  3.6848e-02,  1.1425e-02,  1.6014e-02,  3.4456e-02,\n","        -1.2892e-01, -9.3180e-03,  2.5703e-02,  2.5299e-02,  2.6678e-02,\n","         4.2309e-02,  2.0138e-02,  2.8523e-02,  5.0709e-03,  6.7703e-02,\n","        -5.5278e-03,  5.0000e-03,  6.7978e-03, -1.3550e-03,  1.7543e-02,\n","         1.5805e-02,  1.2147e-02,  1.3114e-02,  2.6474e-04,  7.2472e-03,\n","         1.2037e-02,  2.9629e-02, -2.3053e-03,  2.7027e-02,  2.8881e-02,\n","        -1.5761e-02,  1.3112e-02,  3.4166e-02,  7.2287e-03, -9.4476e-03,\n","         1.3837e-02,  2.8369e-02,  2.5705e-02,  2.5138e-04,  4.7979e-02,\n","         1.7487e-02,  3.9693e-03,  1.4923e-02,  6.3899e-03, -9.8940e-02,\n","         3.3000e-02, -6.6347e-03,  1.9614e-02,  1.9170e-03,  2.9230e-02,\n","         1.2570e-02,  9.5888e-03,  1.7076e-02,  2.9001e-03,  1.2286e-02,\n","         2.8301e-02,  1.2213e-02,  2.1222e-02, -2.1216e-03,  3.9754e-02,\n","         9.6394e-03,  1.1122e-03,  1.5532e-02, -5.7242e-03,  2.8465e-02,\n","         4.0302e-03,  2.0632e-02,  2.4541e-02,  4.3192e-02,  2.6073e-02,\n","         7.2233e-03,  9.4155e-03,  1.6505e-02,  1.8448e-02, -2.5170e-03,\n","         1.2000e-02,  6.8031e-03,  3.7981e-02,  2.5705e-02,  2.5174e-02,\n","        -7.0208e-03,  7.9762e-03,  1.8266e-02,  5.6669e-03,  1.4118e-02,\n","         2.4259e-03,  1.6194e-02, -1.9699e-03,  3.2739e-03, -1.7505e-02,\n","         1.3951e-02,  5.6820e-03,  1.2771e-03,  4.9013e-02,  2.9891e-02,\n","         7.0213e-03,  3.9604e-02,  4.9489e-02,  1.8771e-02,  3.1523e-02,\n","         3.4107e-02,  1.6705e-02,  6.5625e-03,  2.0344e-02,  5.2166e-02,\n","        -2.3815e-03,  1.9008e-02,  2.4418e-02,  2.8172e-02,  2.1597e-02,\n","         1.1870e-01,  4.4278e-02,  7.0442e-03,  2.6831e-02,  5.4814e-03,\n","         1.6737e-02,  5.6836e-03, -2.3425e-03,  3.3303e-02,  1.6783e-02,\n","         2.6404e-02,  6.4658e-02,  2.0041e-02,  2.8214e-02,  2.0244e-02,\n","         2.8213e-02,  5.7425e-03, -5.8249e-02,  2.1254e-02,  2.6269e-02,\n","         1.4840e-02,  4.4355e-03,  3.8794e-02], device='cuda:0',\n","       requires_grad=True)\n","blocks.9.ln2.w: torch.Size([768])\n","Parameter containing:\n","tensor([0.2713, 0.2568, 0.2734, 0.2627, 0.2627, 0.2588, 0.4197, 0.2268, 0.2705,\n","        0.2372, 0.2862, 0.2605, 0.2665, 0.2684, 0.2941, 0.2588, 0.2888, 0.2640,\n","        0.2666, 0.2755, 0.2319, 0.2568, 0.2588, 0.2529, 0.2618, 0.2575, 0.2686,\n","        0.2502, 0.2529, 0.2549, 0.2451, 0.2907, 0.2563, 0.2529, 0.2686, 0.3057,\n","        0.2409, 0.2465, 0.2368, 0.2626, 0.2446, 0.2475, 0.2397, 0.2612, 0.2686,\n","        0.2744, 0.2627, 0.2340, 0.2883, 0.2588, 0.2549, 0.2588, 0.2666, 0.2657,\n","        0.2666, 0.2969, 0.2744, 0.2803, 0.2466, 0.2800, 0.2803, 0.2549, 0.2642,\n","        0.2744, 0.1744, 0.2506, 0.2510, 0.2977, 0.3018, 0.2461, 0.2773, 0.1973,\n","        0.2532, 0.2666, 0.2387, 0.2725, 0.2822, 0.3336, 0.2763, 0.2626, 0.2822,\n","        0.2588, 0.2636, 0.2920, 0.2667, 0.2822, 0.2919, 0.0195, 0.2627, 0.2588,\n","        0.2622, 0.2588, 0.2694, 0.2568, 0.2588, 0.2465, 0.2744, 0.2666, 0.2500,\n","        0.2705, 0.2407, 0.2187, 0.3148, 0.2842, 0.2627, 0.2529, 0.2783, 0.3115,\n","        0.2517, 0.2495, 0.2646, 0.2529, 0.2623, 0.2705, 0.2667, 0.2713, 0.2861,\n","        0.2727, 0.2427, 0.2979, 0.2734, 0.2624, 0.2530, 0.2666, 0.2727, 0.2627,\n","        0.2607, 0.2718, 0.2880, 0.2560, 0.2666, 0.2421, 0.2783, 0.2580, 0.2568,\n","        0.2475, 0.2608, 0.3036, 0.9476, 0.2521, 0.2588, 0.2644, 0.3192, 0.2456,\n","        0.2839, 0.2832, 0.2626, 0.2803, 0.2588, 0.2607, 0.2666, 0.2703, 0.2879,\n","        0.2783, 0.2687, 0.2529, 0.2645, 0.2625, 0.2389, 0.2959, 0.3253, 0.2647,\n","        0.2805, 0.2764, 0.2745, 0.2646, 0.2700, 0.3496, 0.2510, 0.2764, 0.2627,\n","        0.2517, 0.2548, 0.2686, 0.2744, 0.2666, 0.2627, 0.2479, 0.2744, 0.2530,\n","        0.2529, 0.2488, 0.2577, 0.2822, 0.2483, 0.2459, 0.2447, 0.2686, 0.2607,\n","        0.2764, 0.2666, 0.2842, 0.2559, 0.2686, 0.2474, 0.3271, 0.2435, 0.2724,\n","        0.2646, 0.2869, 0.2764, 0.2918, 0.2568, 0.2647, 0.2494, 0.2685, 0.2588,\n","        0.2276, 0.2958, 0.2674, 0.2510, 0.2940, 0.2646, 0.2723, 0.2646, 0.2627,\n","        0.2979, 0.2645, 0.1781, 0.2585, 0.2665, 0.2679, 0.2414, 0.2811, 0.2803,\n","        0.2627, 0.2466, 0.2510, 0.2615, 0.2397, 0.2427, 0.2666, 0.3604, 0.2544,\n","        0.2485, 0.2700, 0.2700, 0.2510, 0.2844, 0.2678, 0.2900, 0.2936, 0.2607,\n","        0.2587, 0.2479, 0.2646, 0.2449, 0.2900, 0.2530, 0.2618, 0.2509, 0.2561,\n","        0.2529, 0.2723, 0.2586, 0.3070, 0.2724, 0.2688, 0.2587, 0.2659, 0.2584,\n","        0.2920, 0.2548, 0.2666, 0.2645, 0.2530, 0.0723, 0.2861, 0.2646, 0.2666,\n","        0.3213, 0.3172, 0.2456, 0.2626, 0.2968, 0.2417, 0.2549, 0.2514, 0.2456,\n","        0.2666, 0.2355, 0.2400, 0.2601, 0.3272, 0.2959, 0.2830, 0.2747, 0.2618,\n","        0.5215, 0.2717, 0.2647, 0.2588, 0.2549, 0.2446, 0.2802, 0.2454, 0.2416,\n","        0.2647, 0.2607, 0.2760, 0.2676, 0.2686, 0.2685, 0.2445, 0.2322, 0.2533,\n","        0.2666, 0.2446, 0.2685, 0.2369, 0.2549, 0.3267, 0.2705, 0.2585, 0.2052,\n","        0.2607, 0.2823, 0.2666, 0.2543, 0.2768, 0.2861, 0.2583, 0.2607, 0.2721,\n","        0.2529, 0.2607, 0.4808, 0.2510, 0.2612, 0.2549, 0.2646, 0.2495, 0.2705,\n","        0.2495, 0.2359, 0.2685, 0.2881, 0.2502, 0.2704, 0.2686, 0.2666, 0.2496,\n","        0.2744, 0.2803, 0.2720, 0.2686, 0.2800, 0.2597, 0.2705, 0.2524, 0.2588,\n","        0.2114, 0.2561, 0.2763, 0.2666, 0.2646, 0.2803, 0.2694, 0.2627, 0.2713,\n","        0.2744, 0.2435, 0.3374, 0.2549, 0.2466, 0.2842, 0.2702, 0.2531, 0.2507,\n","        0.2665, 0.2666, 0.2490, 0.2642, 0.0598, 0.2605, 0.2894, 0.2783, 0.2764,\n","        0.2261, 0.2744, 0.2510, 0.2568, 0.2493, 0.2974, 0.2744, 0.2725, 0.2795,\n","        0.2593, 0.2685, 0.2912, 0.2705, 0.2479, 0.2782, 0.4970, 0.2816, 0.2568,\n","        0.2727, 0.2476, 0.2568, 0.2469, 0.2547, 0.2744, 0.2803, 0.2627, 0.2354,\n","        0.2764, 0.2684, 0.2428, 0.2686, 0.2529, 0.2495, 0.2425, 0.2529, 0.2441,\n","        0.2588, 0.2661, 0.2476, 0.2668, 0.2568, 0.2686, 0.1892, 0.2842, 0.2588,\n","        0.2745, 0.2466, 0.2437, 0.2673, 0.2666, 0.2548, 0.2509, 0.2250, 0.2585,\n","        0.2476, 0.2684, 0.2495, 0.2979, 0.2510, 0.2744, 0.2701, 0.2920, 0.2932,\n","        0.2813, 0.2961, 0.2529, 0.2794, 0.2607, 0.2535, 0.0681, 0.2607, 0.2814,\n","        0.2627, 0.2559, 0.2452, 0.2666, 0.2685, 0.2978, 0.2764, 0.2485, 0.2444,\n","        0.1587, 0.2607, 0.2686, 0.2686, 0.2549, 0.1431, 0.2627, 0.2769, 0.2567,\n","        0.2510, 0.2549, 0.2417, 0.2764, 0.2783, 0.2549, 0.2290, 0.2646, 0.2464,\n","        0.2510, 0.2397, 0.3236, 0.0177, 0.0570, 0.2647, 0.2495, 0.2688, 0.2397,\n","        0.2529, 0.2646, 0.2778, 0.2510, 0.2606, 0.2856, 0.2446, 0.2568, 0.2680,\n","        0.2509, 0.1938, 0.1880, 0.2685, 0.2588, 0.2745, 0.2562, 0.2717, 0.3135,\n","        0.2779, 0.2438, 0.2485, 0.2861, 0.2764, 0.2475, 0.2399, 0.2705, 0.2548,\n","        0.2646, 0.2646, 0.2842, 0.2456, 0.2581, 0.2548, 0.2588, 0.2464, 0.2568,\n","        0.2686, 0.2645, 0.2622, 0.2647, 0.3784, 0.2762, 0.2869, 0.2463, 0.2646,\n","        0.2817, 0.2385, 0.2453, 0.2588, 0.2760, 0.2495, 0.2549, 0.2764, 0.2705,\n","        0.2897, 0.2666, 0.2666, 0.2979, 0.2549, 0.2725, 0.2646, 0.2607, 0.2493,\n","        0.3017, 0.2646, 0.2959, 0.2685, 0.2686, 0.3037, 0.2822, 0.2494, 0.2646,\n","        0.2627, 0.2530, 0.2762, 0.2744, 0.2627, 0.2549, 0.2568, 0.2607, 0.3076,\n","        0.2735, 0.2725, 0.2668, 0.2832, 0.2764, 0.2678, 0.2711, 0.2549, 0.2880,\n","        0.2549, 0.2596, 0.3005, 0.2607, 0.2495, 0.2405, 0.2881, 0.2529, 0.2510,\n","        0.2657, 0.2439, 0.2861, 0.2634, 0.2713, 0.2783, 0.2660, 0.2468, 0.2584,\n","        0.2602, 0.2532, 0.2706, 0.2479, 0.2549, 0.2491, 0.2679, 0.2607, 0.2704,\n","        0.2744, 0.2710, 0.2526, 0.2764, 0.2881, 0.3460, 0.2556, 0.2664, 0.2568,\n","        0.2665, 0.2512, 0.2660, 0.2822, 0.2860, 0.2568, 0.2641, 0.2721, 0.2610,\n","        0.2470, 0.2636, 0.2588, 0.2832, 0.2568, 0.2561, 0.2821, 0.2714, 0.2495,\n","        0.2526, 0.2601, 0.2446, 0.2510, 0.2594, 0.2917, 0.2627, 0.2472, 0.2599,\n","        0.2764, 0.4425, 0.2654, 0.2106, 0.2795, 0.2783, 0.2737, 0.2607, 0.2900,\n","        0.2627, 0.3018, 0.2376, 0.2936, 0.2476, 0.2744, 0.2510, 0.2705, 0.2579,\n","        0.2648, 0.2392, 0.3037, 0.2464, 0.2743, 0.2447, 0.2666, 0.2569, 0.2920,\n","        0.2510, 0.2555, 0.2568, 0.2801, 0.2705, 0.2586, 0.2705, 0.2548, 0.2414,\n","        0.2436, 0.2510, 0.2595, 0.2763, 0.3428, 0.2920, 0.2548, 0.2685, 0.2588,\n","        0.2410, 0.2560, 0.2803, 0.2398, 0.2626, 0.2623, 0.2529, 0.2495, 0.2646,\n","        0.2803, 0.2529, 0.2508, 0.2561, 0.2468, 0.2666, 0.2643, 0.2510, 0.2862,\n","        0.2588, 0.3344, 0.2591, 0.2761, 0.2927, 0.2825, 0.2476, 0.2818, 0.2800,\n","        0.2398, 0.2607, 0.2685, 0.2685, 0.2646, 0.2547, 0.2486, 0.2803, 0.2549,\n","        0.2398, 0.3056, 0.2446, 0.2568, 0.2627, 0.2764, 0.2783, 0.2803, 0.2777,\n","        0.2705, 0.2607, 0.2642, 0.2517, 0.2722, 0.2647, 0.2628, 0.2618, 0.2435,\n","        0.2685, 0.3240, 0.2783, 0.2529, 0.2549, 0.2744, 0.2763, 0.2075, 0.3051,\n","        0.2616, 0.2764, 0.2744, 0.2591, 0.2649, 0.2457, 0.2522, 0.2801, 0.2846,\n","        0.1321, 0.2588, 0.2510, 0.2782, 0.2372, 0.2744, 0.2854, 0.2475, 0.2445,\n","        0.2575, 0.2455, 0.2607], device='cuda:0', requires_grad=True)\n","blocks.9.ln2.b: torch.Size([768])\n","Parameter containing:\n","tensor([ 4.6359e-02,  1.3956e-02,  4.1969e-02,  5.9464e-02, -3.2730e-03,\n","        -1.5924e-02,  2.0831e-02,  4.2198e-02,  4.6790e-03, -2.2352e-03,\n","        -1.5116e-03,  3.8837e-02,  4.2359e-02,  4.3516e-04, -2.0616e-02,\n","         2.9114e-02, -1.4773e-02,  7.2373e-02,  2.4280e-02, -2.5719e-02,\n","         2.6464e-02,  2.5266e-03, -2.5735e-02,  5.4931e-02,  8.6198e-03,\n","         9.1083e-03, -9.7662e-03,  3.2609e-02,  7.6199e-03, -1.2238e-02,\n","        -3.5628e-03, -1.5776e-02, -8.7988e-03,  8.9751e-03,  3.6059e-04,\n","        -1.9238e-02, -1.6577e-02, -1.3442e-02, -9.9734e-03,  3.3466e-03,\n","         1.2651e-02, -1.7199e-03, -1.9708e-02,  5.0742e-02, -2.9713e-02,\n","        -1.1055e-02,  4.3423e-02, -6.5405e-03, -6.0137e-03, -1.8037e-02,\n","         3.8510e-02,  9.4927e-03,  4.7670e-03, -3.2339e-03,  3.0884e-02,\n","        -2.1922e-02, -2.6174e-02, -1.6103e-02,  6.0524e-03,  1.2656e-02,\n","         4.3455e-02,  1.0686e-02,  1.2142e-02, -2.0499e-02, -2.1240e-01,\n","         3.2852e-02, -2.6814e-02, -8.6224e-04,  1.9907e-02,  4.8420e-03,\n","         1.4650e-02,  5.9070e-03,  3.0817e-02,  2.5065e-03,  1.6111e-02,\n","         2.4625e-02, -1.6990e-02, -2.1809e-02,  3.2874e-02, -9.5611e-03,\n","        -3.5267e-02,  2.7005e-02,  1.9234e-02, -6.9227e-03,  7.1713e-02,\n","         3.7310e-02,  5.4099e-02, -2.0350e-02, -1.4198e-03,  1.2337e-02,\n","        -2.5822e-02,  2.3218e-02, -2.0248e-02,  3.6099e-02, -1.6097e-02,\n","        -9.4947e-04, -3.0887e-03,  5.2009e-03, -1.5644e-02,  3.4826e-02,\n","        -2.1911e-04, -5.9407e-02,  4.8287e-03,  4.3837e-02,  3.2372e-02,\n","        -1.4633e-02,  7.6709e-03,  2.9655e-02, -3.9969e-03,  3.3355e-03,\n","        -3.8935e-02,  1.8390e-02,  4.4255e-02,  5.0225e-02,  1.7208e-02,\n","         4.6327e-02,  5.5122e-02,  3.2269e-02,  2.0172e-02, -1.4916e-02,\n","         2.7309e-02,  5.0541e-03, -1.0247e-02,  2.0149e-02,  2.5397e-02,\n","         2.5361e-02, -1.5364e-02, -2.4828e-02, -1.7092e-02,  5.0636e-03,\n","         2.5888e-02,  2.0438e-02,  8.2908e-03,  1.6948e-02,  4.1886e-02,\n","         1.2966e-02,  1.2470e-03,  1.5099e-02,  1.9378e-01,  8.2823e-03,\n","        -4.7962e-03,  1.3489e-02,  4.3567e-03,  6.4663e-03, -3.8445e-02,\n","         9.7321e-04,  1.9274e-02,  2.6011e-02, -2.7832e-02,  1.3927e-02,\n","        -2.6986e-02, -2.0381e-02, -8.8528e-03,  4.6666e-02,  1.6820e-02,\n","        -1.0759e-02,  3.2214e-02, -2.7836e-02, -7.5690e-03, -3.1338e-02,\n","        -1.8618e-02,  3.8666e-02, -2.3154e-02,  3.3513e-02, -9.1068e-03,\n","         5.1771e-02, -2.4427e-02,  1.6266e-02, -5.2176e-03,  2.1431e-02,\n","        -2.6429e-02, -1.3502e-03, -1.5157e-02,  3.3783e-02, -1.2742e-03,\n","        -9.1661e-03,  5.5032e-02, -2.0955e-02,  4.3506e-02, -3.2580e-02,\n","        -5.1832e-03,  2.5456e-02,  4.8346e-02,  9.8867e-03,  1.5130e-02,\n","         2.2179e-02,  3.2472e-03, -2.4789e-02,  1.3605e-03,  3.0614e-02,\n","         2.8012e-02, -2.5684e-02,  2.1680e-02,  2.6460e-02,  2.0087e-03,\n","         6.1622e-03, -1.9493e-02, -1.3897e-02,  1.1777e-02, -2.8853e-02,\n","         3.4451e-02, -2.6946e-02,  3.0851e-02,  6.5116e-02,  1.1722e-02,\n","         4.3605e-02, -2.1370e-02,  2.4930e-02,  1.3708e-02, -3.7338e-02,\n","         1.9752e-02,  5.3699e-02,  2.7069e-02,  3.3175e-02,  6.1775e-03,\n","        -7.0276e-03, -9.9095e-03, -1.5216e-02, -3.3901e-02,  1.0711e-02,\n","         3.9820e-02, -3.4286e-02,  2.4851e-02,  2.6422e-02,  4.4120e-02,\n","         1.8298e-02,  3.0423e-03,  4.8683e-02,  4.1800e-02,  1.8543e-02,\n","         2.9380e-02,  2.0182e-02,  7.5888e-02, -1.3803e-02,  3.7292e-03,\n","         7.8018e-03,  2.4379e-02, -2.2781e-02,  1.7691e-02,  7.8380e-03,\n","         4.8310e-02,  1.2099e-02,  1.0327e-02, -4.3469e-02, -4.7232e-02,\n","        -1.0782e-02, -4.3969e-03,  3.5032e-02, -1.1166e-02,  9.2256e-03,\n","        -6.7484e-03,  2.3821e-02, -2.3077e-02, -1.0305e-02,  2.4358e-02,\n","         1.0538e-01, -1.2543e-02,  2.3935e-02, -1.5297e-02,  5.1612e-02,\n","         6.8340e-03,  9.5482e-02,  4.4886e-03, -1.3280e-02, -9.4018e-03,\n","        -1.9276e-02,  1.2387e-02,  4.0241e-02,  1.0192e-02,  8.8142e-03,\n","        -1.7780e-02, -8.2222e-03,  1.0885e-02, -2.4470e-02, -6.7068e-03,\n","         1.7433e-02, -5.6699e-03,  7.6062e-03,  2.3800e-02,  1.3672e-02,\n","         2.3269e-02, -1.4779e-02,  1.0775e-02,  4.6934e-02,  8.1263e-03,\n","         2.1176e-02,  1.1527e-02,  2.0063e-02, -1.1815e-01,  3.6538e-02,\n","         2.3737e-02,  1.3567e-02,  4.9459e-02,  2.9661e-02,  3.4450e-02,\n","         1.0566e-02,  2.0714e-02,  1.6877e-02, -5.5296e-02,  5.4029e-03,\n","         3.0143e-03, -2.0687e-02,  1.5221e-02,  2.2572e-02, -6.8964e-04,\n","        -4.0363e-03,  2.2592e-02,  1.1445e-02,  2.9604e-02,  2.5694e-02,\n","        -4.2649e-02,  8.3323e-03,  5.1442e-02, -3.5837e-02, -5.9444e-02,\n","         1.7270e-02,  7.4314e-02, -6.5124e-03,  1.6511e-02,  1.0761e-02,\n","         6.7955e-03, -6.8050e-03,  3.0290e-02, -2.0315e-02, -2.3744e-02,\n","         4.4000e-03, -2.7915e-01, -8.3837e-03, -6.0874e-03,  3.4702e-03,\n","         2.7941e-02, -3.7527e-02, -4.3679e-02, -4.5477e-03,  1.0540e-02,\n","        -1.9555e-02,  2.7929e-02,  2.4295e-03,  8.8084e-04,  1.1129e-02,\n","        -4.4063e-02,  1.8228e-02,  2.6457e-02, -6.1199e-03,  1.8750e-02,\n","         7.2018e-03,  3.1757e-02, -1.1687e-02,  1.0006e-02,  2.8961e-02,\n","         3.8352e-02,  2.2461e-03,  3.6023e-02, -3.1655e-02,  3.1976e-02,\n","         2.2143e-02, -1.8267e-02,  3.5434e-02, -2.9472e-02,  3.6890e-02,\n","        -5.0324e-02,  2.0068e-02,  1.9135e-02,  4.2284e-02,  3.8479e-02,\n","         1.8943e-02,  1.6805e-03,  4.3020e-02,  4.3138e-04,  6.2916e-02,\n","         1.4258e-02, -1.5524e-02, -4.3297e-03,  5.1373e-01,  5.3498e-04,\n","        -1.4394e-02, -3.6367e-02, -1.6451e-02, -5.1973e-02,  3.4127e-02,\n","        -2.0742e-02,  1.0771e-02,  1.1353e-02,  1.6064e-02,  1.9150e-02,\n","        -4.7783e-03,  2.6506e-02, -1.8528e-02,  2.5603e-02,  8.8883e-03,\n","         4.8920e-02,  1.7394e-02,  7.8051e-03, -1.2286e-01,  1.0118e-02,\n","         4.1234e-04,  2.7605e-02,  2.2310e-03,  3.0696e-02,  3.0611e-02,\n","        -3.3815e-02,  2.8696e-02,  2.0536e-02, -2.6363e-03,  5.5335e-03,\n","        -2.3168e-02,  9.2917e-03, -6.2566e-03, -5.5252e-02,  4.1969e-02,\n","        -1.3232e-02,  1.2184e-02, -1.4690e-02, -2.7277e-02,  3.4491e-02,\n","         3.8440e-02,  3.2278e-02,  2.2802e-02, -1.6364e-02,  4.9551e-02,\n","         7.3260e-03,  4.5073e-03,  3.3260e-02, -3.7166e-03,  1.0038e-02,\n","         3.6014e-02,  5.5558e-02,  3.7811e-04, -3.2413e-02, -2.9892e-02,\n","        -5.1771e-02,  3.2636e-02,  3.0849e-02,  9.7354e-03,  1.0504e-02,\n","         5.2117e-02, -1.8205e-02,  1.2379e-02,  1.2672e-02,  2.9560e-02,\n","         8.3178e-02,  2.9484e-02,  1.2231e-03,  2.3327e-02, -8.8367e-03,\n","        -4.9888e-02,  1.3511e-02, -1.6073e-01,  4.6437e-02,  6.8955e-02,\n","         6.5771e-03,  6.5913e-03,  1.0505e-02,  3.6031e-03,  3.5611e-03,\n","         3.4305e-02,  3.4872e-02,  1.1346e-02, -6.3544e-03,  6.1326e-03,\n","        -3.3602e-03, -4.5979e-04,  5.8058e-02,  1.2235e-02, -2.7755e-02,\n","         2.8681e-02,  3.5192e-02,  4.1441e-02, -3.7633e-03,  1.8175e-02,\n","         3.5060e-03,  1.7460e-02,  7.9820e-03,  3.2582e-02,  1.8512e-02,\n","         3.2931e-03,  2.3816e-02,  5.2062e-02,  1.4304e-03,  6.1383e-02,\n","        -5.1155e-01, -5.6101e-01,  1.1739e-02, -8.4377e-04, -3.0972e-02,\n","         4.3411e-03,  1.4292e-02,  1.2945e-02,  7.9660e-03,  1.6286e-02,\n","         4.8398e-03,  6.6507e-03,  1.1928e-02,  3.5266e-02,  2.1217e-03,\n","         4.0883e-02, -5.5675e-02,  5.2391e-02, -1.4916e-02,  2.3761e-03,\n","         6.1236e-03, -1.9336e-03,  4.3250e-03,  4.6581e-03,  4.3954e-03,\n","         5.3100e-03,  1.0387e-02,  7.5576e-03,  3.0202e-02,  2.0950e-02,\n","        -7.2719e-03, -3.3016e-02,  4.1409e-02,  2.4662e-02,  3.6624e-03,\n","         2.4028e-03, -1.4737e-03,  1.8640e-02, -1.7179e-02,  2.0110e-02,\n","         5.7687e-03,  4.1670e-02,  3.4698e-02,  7.0371e-03,  5.4823e-04,\n","        -3.2601e-02,  3.4001e-03,  5.9596e-02, -6.3127e-03, -9.3709e-03,\n","         3.9789e-02, -1.8381e-04, -1.3319e-02,  9.9240e-03, -1.3092e-03,\n","         4.8258e-03, -2.9932e-02, -2.5621e-02,  3.2499e-02,  1.8507e-02,\n","        -5.5692e-03, -1.5296e-02, -6.7538e-03, -1.1611e-02,  4.0821e-03,\n","         4.7750e-02,  2.5824e-02,  7.3968e-02,  1.0912e-02,  3.9996e-03,\n","        -1.2011e-02,  1.7074e-02, -1.3931e-03, -2.9334e-03,  3.4197e-02,\n","         3.2622e-03,  3.6016e-02,  2.5633e-02,  4.2825e-02,  4.8809e-03,\n","         7.3719e-03, -5.1014e-04,  1.6190e-02,  3.1836e-02,  1.3149e-02,\n","        -5.7841e-03, -7.2479e-03, -2.2626e-02,  2.7774e-02, -2.4598e-02,\n","        -7.7737e-03, -1.4708e-02,  2.2259e-02, -2.7018e-02,  1.2423e-03,\n","        -5.0729e-03, -7.2550e-03,  3.9393e-02, -1.6036e-02, -5.8190e-03,\n","         7.7902e-03,  2.7560e-03,  6.1637e-02,  5.5939e-04,  1.6815e-02,\n","        -3.7384e-02, -9.2474e-03, -2.3087e-02,  2.9745e-02,  3.5519e-02,\n","        -7.7708e-02,  1.2476e-02,  3.5081e-02,  4.4762e-03,  4.2720e-02,\n","        -2.6004e-02, -2.7662e-02, -1.0111e-02,  3.1815e-02, -6.0336e-03,\n","         1.0363e-02,  1.8858e-02,  5.2575e-03,  3.5614e-02,  2.9272e-02,\n","        -4.3823e-04,  2.4112e-02, -7.6850e-02, -2.0872e-02, -1.8476e-02,\n","        -6.7624e-03, -5.4782e-03, -2.2909e-02, -7.7881e-03, -2.6471e-02,\n","        -2.7177e-02, -7.7965e-03,  1.7534e-02, -1.0759e-02,  4.0409e-02,\n","         1.1255e-02,  9.2884e-03,  3.6359e-02, -5.9741e-03, -3.7481e-02,\n","         2.2945e-02, -4.8389e-03,  3.3000e-02,  3.6377e-02,  2.2267e-02,\n","         3.9006e-02,  2.3546e-02,  1.0590e-02, -6.7668e-03,  2.2654e-02,\n","         3.7816e-02,  3.3985e-02,  1.4320e-02, -2.0268e-02,  1.6213e-02,\n","        -7.5056e-02, -4.3580e-02, -1.1980e-02, -3.0683e-02,  4.1441e-02,\n","        -1.4618e-02, -8.9411e-03,  1.1536e-02,  1.9782e-02,  3.3240e-02,\n","         5.1114e-03,  1.0002e-02,  1.9953e-02, -3.9657e-02, -1.1193e-02,\n","         6.0912e-02, -2.4026e-02, -2.0804e-02,  7.9830e-03,  2.9038e-02,\n","         1.9761e-02,  6.9239e-03,  5.6124e-03,  6.1296e-02,  4.1832e-03,\n","         2.5818e-02,  2.2119e-03,  1.8062e-02,  6.6215e-02,  2.6332e-02,\n","         5.3421e-02, -1.4268e-02, -2.6278e-02, -6.9822e-03, -3.7129e-02,\n","        -2.2895e-03, -1.2351e-02,  5.5560e-03,  2.6927e-02, -1.1412e-03,\n","        -6.4117e-02, -2.3565e-02,  1.4585e-02,  3.2187e-02,  1.1488e-03,\n","         2.0908e-02, -1.3280e-02, -1.3430e-02,  1.4151e-02,  2.8581e-02,\n","         3.0495e-02,  2.7602e-02,  1.0433e-03,  5.2023e-03,  3.5873e-04,\n","         3.4250e-03,  2.4565e-02,  4.7433e-02, -1.8419e-03,  2.6846e-02,\n","        -3.3163e-03,  2.6491e-02, -1.6620e-02, -2.9514e-03,  4.6517e-02,\n","        -2.0178e-02, -3.7113e-02, -1.0680e-02, -2.5775e-03, -9.1360e-03,\n","         2.2367e-02, -3.3729e-02,  3.8603e-02,  4.2028e-02, -1.6116e-02,\n","         4.1367e-02, -5.0171e-02, -1.2311e-03, -1.4618e-02,  3.5920e-02,\n","        -3.0468e-03, -4.0911e-03,  1.6406e-02, -3.1169e-02,  2.4372e-02,\n","         2.9812e-02, -3.5397e-03, -2.5877e-02, -1.5602e-02, -6.3380e-03,\n","         3.1120e-03,  8.5625e-03,  3.9640e-02,  3.4653e-02, -2.0379e-03,\n","         1.5056e-02, -3.8181e-02,  1.2543e-02,  2.2661e-02, -1.5966e-02,\n","        -2.6374e-02,  1.2523e-02,  1.3684e-02,  2.1154e-02,  1.4626e-02,\n","         1.4217e-01, -2.0984e-03,  5.2391e-02,  7.0815e-03,  1.1418e-02,\n","         1.8310e-02, -2.7533e-02,  2.7060e-03,  3.7722e-03,  1.4289e-02,\n","         4.8819e-03,  7.8974e-02,  6.2292e-02,  1.1453e-02,  6.4543e-02,\n","        -8.8402e-04,  2.3291e-02, -2.1248e-02, -3.4555e-02, -2.6052e-02,\n","         7.3395e-03, -1.8713e-02,  9.1007e-03], device='cuda:0',\n","       requires_grad=True)\n","blocks.9.attn.W_Q: torch.Size([12, 768, 64])\n","Parameter containing:\n","tensor([[[ 0.0709, -0.1273,  0.1836,  ..., -0.0111,  0.1262,  0.0295],\n","         [ 0.2491, -0.3088,  0.1739,  ...,  0.1256,  0.0628, -0.0157],\n","         [ 0.1505,  0.0529, -0.1205,  ...,  0.0031,  0.0152, -0.1657],\n","         ...,\n","         [-0.0111, -0.0088,  0.0099,  ..., -0.2001,  0.1975, -0.0116],\n","         [ 0.0894,  0.2280, -0.1021,  ...,  0.0452,  0.0501, -0.1210],\n","         [-0.0792,  0.1721,  0.1188,  ..., -0.1258, -0.2983,  0.1159]],\n","\n","        [[-0.1792,  0.0274, -0.0267,  ..., -0.0285,  0.0195, -0.0844],\n","         [-0.1268,  0.1172, -0.0711,  ..., -0.0970,  0.0057, -0.0410],\n","         [ 0.0636,  0.0686,  0.0320,  ..., -0.0850, -0.0856, -0.2431],\n","         ...,\n","         [-0.0766, -0.2014, -0.0448,  ...,  0.0353,  0.2431, -0.0878],\n","         [ 0.1407,  0.0846, -0.0295,  ..., -0.0653,  0.0858,  0.1285],\n","         [ 0.0179, -0.2151, -0.2791,  ...,  0.0327,  0.1048,  0.1885]],\n","\n","        [[-0.0096, -0.1581, -0.1205,  ...,  0.1954,  0.1977, -0.0129],\n","         [ 0.0630,  0.1569,  0.2012,  ..., -0.1209,  0.0673, -0.2633],\n","         [-0.1822, -0.1295, -0.0911,  ..., -0.1273, -0.1596, -0.2635],\n","         ...,\n","         [ 0.0852, -0.0508,  0.1167,  ...,  0.0536,  0.1949, -0.0208],\n","         [-0.2720,  0.2506, -0.1746,  ...,  0.0176,  0.1888,  0.0992],\n","         [-0.2966, -0.1624, -0.2416,  ...,  0.0392, -0.2684, -0.1019]],\n","\n","        ...,\n","\n","        [[ 0.0193, -0.0092, -0.1726,  ...,  0.3009,  0.0141,  0.1545],\n","         [-0.0728,  0.0568,  0.0779,  ..., -0.1145, -0.0742, -0.0521],\n","         [ 0.2133, -0.0995, -0.0565,  ..., -0.0757, -0.0583,  0.1945],\n","         ...,\n","         [ 0.1910, -0.1430, -0.1714,  ...,  0.1117, -0.0057, -0.3405],\n","         [-0.2113, -0.2084,  0.0005,  ...,  0.0253, -0.0186,  0.0339],\n","         [ 0.1586,  0.0852, -0.0480,  ...,  0.0276, -0.0714,  0.0486]],\n","\n","        [[-0.1093,  0.0096, -0.2385,  ..., -0.0047,  0.0437,  0.1438],\n","         [ 0.0797, -0.0661, -0.1550,  ...,  0.1316, -0.0491,  0.0365],\n","         [-0.1766,  0.0971, -0.1563,  ...,  0.1564, -0.0648,  0.1024],\n","         ...,\n","         [-0.0269, -0.2144,  0.0073,  ..., -0.0469,  0.0561,  0.0580],\n","         [-0.1823,  0.1416,  0.2579,  ..., -0.0504,  0.1490, -0.2098],\n","         [ 0.1377,  0.0569, -0.0544,  ..., -0.1438,  0.0281,  0.0561]],\n","\n","        [[ 0.1302, -0.0453,  0.0352,  ...,  0.2043, -0.0231, -0.0547],\n","         [-0.1659,  0.0626,  0.1867,  ...,  0.0444,  0.0110,  0.0698],\n","         [ 0.1036, -0.0940,  0.0836,  ..., -0.2081, -0.1017, -0.0156],\n","         ...,\n","         [ 0.0327,  0.2405, -0.0508,  ...,  0.0932,  0.0735, -0.0983],\n","         [-0.0912,  0.0818, -0.2375,  ..., -0.2634, -0.1876, -0.0127],\n","         [-0.2829, -0.1783,  0.0185,  ..., -0.0576, -0.1289,  0.0923]]],\n","       device='cuda:0', requires_grad=True)\n","blocks.9.attn.W_O: torch.Size([12, 64, 768])\n","Parameter containing:\n","tensor([[[-1.3172e-01, -1.2784e-01,  1.6728e-02,  ..., -6.9881e-02,\n","          -4.8622e-02, -1.6810e-01],\n","         [ 2.0712e-01, -1.2212e-02,  1.0674e-01,  ...,  1.0493e-03,\n","           1.6741e-01,  4.7495e-02],\n","         [-3.4675e-02,  1.0992e-01,  1.8979e-01,  ..., -5.6727e-02,\n","           1.5662e-01,  7.9880e-03],\n","         ...,\n","         [-2.0485e-02, -5.3016e-02, -5.3119e-02,  ..., -4.4016e-03,\n","           2.2468e-01,  1.3387e-02],\n","         [ 3.3935e-02, -1.3033e-01, -6.2152e-02,  ...,  1.3131e-01,\n","           2.0846e-01, -1.0563e-01],\n","         [ 8.7767e-02, -1.1300e-01, -2.5242e-02,  ..., -4.4135e-02,\n","           1.0712e-02,  3.4247e-02]],\n","\n","        [[ 1.1268e-01,  1.7125e-01,  5.9871e-02,  ..., -1.4582e-01,\n","           3.3346e-02, -1.0682e-01],\n","         [-8.8271e-02, -1.2786e-01,  2.1686e-02,  ..., -1.3353e-01,\n","           2.0789e-01,  1.2406e-01],\n","         [ 5.3145e-02,  1.7318e-01, -1.7130e-02,  ...,  3.6534e-01,\n","          -5.5097e-02,  1.7416e-01],\n","         ...,\n","         [ 7.2027e-02, -1.8489e-01, -1.7436e-01,  ...,  1.2299e-01,\n","           3.1080e-01, -2.3148e-01],\n","         [ 1.9405e-01, -1.8980e-02, -4.7404e-02,  ..., -2.5181e-01,\n","          -1.1645e-01,  4.5141e-02],\n","         [ 1.4609e-01,  1.8492e-01,  8.9917e-03,  ...,  1.2548e-01,\n","           9.3582e-02, -2.2797e-01]],\n","\n","        [[ 1.4588e-01,  4.8574e-02, -1.3474e-01,  ...,  2.0857e-01,\n","          -2.2419e-01,  2.9867e-01],\n","         [-1.9288e-02,  4.3102e-03,  1.0248e-01,  ...,  3.2134e-02,\n","          -1.5450e-01, -1.3339e-01],\n","         [ 4.4738e-02, -1.6567e-01, -1.0812e-01,  ..., -4.2015e-04,\n","           1.7643e-02,  1.6139e-01],\n","         ...,\n","         [-5.0282e-02, -2.7932e-02, -5.4401e-02,  ...,  7.7194e-03,\n","          -6.2727e-02,  5.8490e-02],\n","         [ 5.6509e-02,  1.2029e-01,  1.2572e-01,  ..., -1.7284e-01,\n","           5.6434e-02, -6.9003e-02],\n","         [ 2.5311e-01,  2.9530e-02, -3.1206e-02,  ...,  5.4398e-02,\n","           1.3899e-01,  5.1022e-02]],\n","\n","        ...,\n","\n","        [[ 7.5803e-02, -5.7502e-02,  1.3462e-01,  ...,  8.6057e-02,\n","           4.2867e-01,  2.8751e-01],\n","         [-1.0525e-01,  1.4659e-01, -1.9598e-01,  ...,  1.4778e-01,\n","           3.3781e-01, -3.6546e-01],\n","         [-1.7165e-01, -1.9079e-01, -2.9681e-02,  ...,  3.4274e-02,\n","           2.2400e-01, -3.8269e-01],\n","         ...,\n","         [ 1.0770e-01, -1.7601e-01, -9.2965e-02,  ..., -1.1912e-01,\n","           2.0634e-01,  4.4303e-02],\n","         [-2.4843e-01, -7.8920e-02, -9.7844e-02,  ...,  4.8999e-01,\n","          -1.1289e-01, -1.6240e-01],\n","         [-1.2980e-01,  2.3478e-02,  1.8250e-01,  ...,  2.1335e-01,\n","           7.2622e-02,  6.8658e-02]],\n","\n","        [[ 1.8136e-01, -1.6917e-01,  8.2602e-02,  ...,  7.8381e-02,\n","          -2.4134e-01, -6.5317e-02],\n","         [-9.8892e-02, -4.8697e-02, -1.2324e-01,  ...,  9.8181e-02,\n","          -2.2809e-01,  3.9632e-02],\n","         [ 7.3203e-02, -6.3390e-02,  1.9302e-01,  ...,  1.4030e-01,\n","          -1.8091e-01, -1.8058e-01],\n","         ...,\n","         [ 1.1297e-01,  1.4612e-02, -2.7210e-02,  ...,  1.1585e-01,\n","           2.8840e-01,  1.2516e-01],\n","         [ 2.2420e-02,  3.4942e-02, -1.0965e-01,  ...,  3.1838e-02,\n","          -2.0573e-02,  1.0576e-01],\n","         [ 4.9332e-02,  5.9470e-02, -6.2286e-02,  ..., -3.5425e-02,\n","           7.8020e-02,  2.0894e-01]],\n","\n","        [[-2.9421e-02,  2.2383e-01, -1.8677e-01,  ...,  6.5724e-02,\n","           1.2430e-01, -7.0137e-02],\n","         [-2.3679e-01,  4.2551e-02, -2.1060e-01,  ..., -5.4285e-02,\n","           4.7639e-02,  2.9921e-02],\n","         [ 3.0297e-02,  1.0614e-01,  9.5798e-03,  ...,  6.6292e-02,\n","          -2.1502e-01, -7.0965e-02],\n","         ...,\n","         [ 2.2632e-01,  6.3675e-02, -2.8221e-01,  ..., -4.7043e-02,\n","          -1.3574e-01, -1.4783e-01],\n","         [-2.3770e-02, -2.3127e-01, -1.6676e-01,  ..., -2.1239e-01,\n","          -3.3118e-02,  1.0519e-01],\n","         [ 1.6765e-01, -3.9259e-02, -2.4877e-01,  ..., -9.7945e-02,\n","           1.7858e-03,  1.4449e-01]]], device='cuda:0', requires_grad=True)\n","blocks.9.attn.b_Q: torch.Size([12, 64])\n","Parameter containing:\n","tensor([[ 5.7074e-02,  3.5463e-02, -9.9121e-02,  1.3528e-01, -2.8422e-02,\n","         -2.5334e-02,  9.8002e-03,  3.8072e-03,  2.5879e-01, -2.7572e-01,\n","         -2.0595e-01, -1.0678e-01,  7.6633e-02,  1.0083e-01,  9.3127e-02,\n","          2.4570e-02, -2.3616e-02,  2.7036e-02, -1.7550e-01, -1.9422e-02,\n","          1.7457e-01, -2.7237e-01, -6.5788e-02,  7.4692e-01, -1.6401e-01,\n","         -4.0414e-02,  8.1384e-02,  2.2789e-01,  8.9813e-02, -1.2559e-01,\n","         -1.0622e-01, -1.6890e-01,  3.7665e-01,  1.2396e-01, -1.1711e-01,\n","          1.0037e-01,  3.6573e-01,  3.0290e-02,  5.0581e-02,  1.2993e-02,\n","          1.3841e-01, -1.2291e-01,  4.2085e-01, -6.4772e-03, -9.3395e-02,\n","         -2.6562e-01, -1.4917e-01, -5.0087e-02, -1.0742e-01, -2.9186e-01,\n","         -1.4620e-01,  1.4122e-03, -2.3633e-01,  2.5467e-01,  4.9421e-02,\n","          1.7729e-01,  1.3761e-01, -1.5750e-01, -1.3650e-01, -6.1484e-02,\n","          4.7041e-02,  2.2004e-01,  5.6221e-02,  1.5853e-01],\n","        [-5.2637e-02,  1.4195e-01,  4.8549e-02, -2.1931e-01, -1.0867e-02,\n","         -2.7047e-02,  2.1637e-01,  1.4524e-01,  9.3187e-02,  1.7555e-01,\n","          2.7973e-01,  2.4600e-02,  2.2460e-01,  1.6508e-01, -7.2249e-03,\n","          9.7198e-02, -1.7470e-01,  9.1957e-02,  1.5614e-01,  3.2872e-01,\n","         -5.2771e-01,  5.6571e-02,  1.2282e-02, -1.1158e-01,  2.0687e-03,\n","         -6.8593e-02,  5.4372e-02,  1.0111e-01, -2.0737e-01,  1.1546e-02,\n","         -4.2896e-01,  7.3717e-02, -7.6243e-02, -1.0126e-01, -1.2786e-01,\n","         -1.1375e-01, -5.1607e-03,  6.1398e-02,  1.9391e-01,  2.5910e-02,\n","          9.4551e-02, -2.4274e-02, -2.4386e-01,  2.2691e-01,  1.0224e-01,\n","          1.1643e-01, -8.4448e-02, -3.2174e-01,  3.0014e-01,  7.1704e-02,\n","         -9.9480e-02, -2.2650e-01,  4.8370e-01,  8.0386e-01, -8.0234e-02,\n","          7.5195e-02, -1.4446e-03,  4.0229e-01,  1.6163e-01, -7.1445e-01,\n","         -2.4943e-01, -2.9387e-02, -1.9359e-01, -2.3615e-02],\n","        [-1.9458e-01,  4.4346e-02,  8.5401e-02,  5.3924e-04,  4.6195e-02,\n","          5.8739e-02,  9.5837e-02, -4.7041e-02, -1.3435e-02,  1.2862e-01,\n","         -1.3864e-01, -5.2601e-01, -7.7959e-02,  6.6246e-02, -1.8906e-01,\n","          1.5870e-02,  2.5899e-02,  1.8146e-02,  8.7626e-02,  4.7506e-02,\n","         -1.3262e-01, -2.4413e-02, -6.1479e-02, -6.6239e-02, -7.8819e-02,\n","         -9.1357e-02, -2.2079e-02,  9.9384e-03,  1.3730e-01, -9.7057e-02,\n","          3.7242e-02,  7.9768e-02, -3.6995e-03,  6.4544e-02,  1.6252e-01,\n","         -5.6633e-01,  7.0603e-02,  1.8254e-01, -5.0029e-02,  3.5748e-02,\n","         -2.8263e-02,  2.2118e-01, -6.7719e-02,  4.8378e-02, -9.4150e-02,\n","          9.2493e-02, -1.5537e-01,  1.2006e-01,  1.3244e-01, -1.0050e-01,\n","         -1.2397e-01, -2.1506e-01, -4.0331e-02,  2.1948e-01,  1.1586e-01,\n","          1.4619e-02,  2.2081e-01,  3.7465e-02,  5.3100e-02,  3.5543e-03,\n","         -1.8932e-01, -9.3629e-02,  1.5423e-01,  1.4337e-03],\n","        [-7.1716e-04, -1.2575e-01,  1.1977e-01,  5.3910e-03, -1.2087e-01,\n","         -7.7837e-02, -1.6742e-01, -1.2112e-01,  5.3714e-01, -2.1373e-01,\n","          1.3820e-01,  9.5615e-02,  4.5491e-01, -1.1989e-02,  4.4180e-02,\n","         -1.4895e-01, -1.9132e-01,  1.5918e-02,  2.4728e-01, -1.2594e-02,\n","         -4.7311e-02,  1.5049e-01, -2.2955e-02,  8.4944e-02,  2.5916e-01,\n","         -1.5120e-01,  1.9091e-02,  9.5476e-03,  1.1138e-01, -1.3251e-01,\n","          1.1037e-01, -1.4690e-01, -8.1932e-02,  1.7285e-01,  1.6587e-01,\n","         -1.2540e-01,  2.9277e-02,  1.3795e-01, -1.3116e-01, -1.5876e-03,\n","          3.1076e-01,  2.1178e-01,  2.5174e-01, -1.0828e-01, -4.7227e-02,\n","          7.4769e-02, -1.0512e-01, -4.5343e-02, -3.7389e-01,  3.6630e-02,\n","          1.1814e-01, -1.3580e-01,  3.0903e-02, -5.2938e-02, -4.3874e-01,\n","         -1.5170e-01,  2.7484e-02, -1.4787e-01,  4.6263e-01,  1.2536e-02,\n","         -3.7789e-02, -5.0799e-02, -3.8134e-02,  1.0866e-01],\n","        [ 7.8102e-02, -1.8570e-01, -4.2875e-02,  2.4919e-01,  5.5768e-01,\n","         -1.1292e-01,  2.3260e-01,  2.0588e-01,  1.1570e-01,  3.0605e-01,\n","          7.0557e-01,  1.9255e-01, -2.5530e-02, -1.0501e-01, -1.6024e-01,\n","         -2.6526e-01, -5.1140e-02,  1.4268e-01, -9.4198e-03,  4.0079e-01,\n","          7.5270e-02,  3.1589e-02,  2.6088e-01, -1.8130e-02, -9.4628e-02,\n","         -8.9067e-02, -3.9743e-01,  1.0139e-01,  6.9045e-01, -5.3575e-02,\n","         -1.9310e-01,  1.0430e-01,  2.3206e-02,  4.4273e-01, -2.0319e-01,\n","         -1.0404e-01, -1.3866e-01,  2.9659e-02, -3.2835e-02,  4.1620e-02,\n","         -1.1524e-02, -6.6619e-02, -5.4350e-02,  5.1276e-02, -3.5213e-02,\n","          1.3291e-01,  2.2014e-01, -5.5311e-01, -1.0537e-01,  1.4620e-01,\n","          5.6365e-02,  3.9656e-02, -2.3892e-01,  8.5603e-02, -1.0408e-01,\n","          1.3278e-03, -1.8454e-01,  9.2079e-02, -1.8098e-01,  4.8143e-02,\n","          2.9896e-03,  1.1406e-01, -1.4427e-01, -6.6444e-02],\n","        [ 1.4895e-02, -1.6720e-01, -1.1055e-01,  5.0606e-03,  1.8262e-01,\n","         -1.2893e-01, -8.4389e-02,  1.2598e-01,  1.1776e-01,  3.5588e-01,\n","          9.4756e-02, -8.8650e-02,  2.7648e-01,  6.9914e-02, -6.2597e-03,\n","          6.7105e-02,  1.4272e-01,  3.6327e-01,  5.3713e-03,  2.6915e-01,\n","         -1.3292e-01,  9.7736e-02,  2.1095e-01,  4.9022e-02, -6.5248e-01,\n","          5.2391e-02,  1.1344e-01, -1.0692e-01, -2.3291e-02, -7.5322e-02,\n","         -1.7185e-01,  1.1696e-01,  8.5059e-02,  1.5434e-01,  1.0515e-01,\n","         -4.3035e-02, -2.7180e-01,  1.5770e-01,  2.0265e-01, -1.5432e-01,\n","          4.9608e-02,  7.9321e-03,  9.3903e-03, -1.1589e-01,  4.3969e-03,\n","         -6.6867e-02,  5.2130e-01, -3.0988e-02, -8.8235e-02,  8.3518e-02,\n","         -1.4894e-01, -1.6971e-01,  2.2868e-02, -1.4802e-01, -2.3518e-01,\n","         -2.8940e-01,  1.6685e-01, -4.1698e-02,  1.6098e-01,  1.7997e-01,\n","          1.1164e-01, -2.2289e-02, -6.6003e-02,  4.8448e-01],\n","        [-7.0148e-02,  1.6435e-01,  6.9743e-02,  2.8874e-02,  4.6843e-02,\n","          3.9946e-01,  6.6648e-01, -6.1398e-02,  2.0312e-01, -9.5904e-02,\n","         -3.6850e-02,  3.4240e-01,  2.6602e-02,  1.1585e-01,  7.4607e-02,\n","         -1.0258e-01,  3.6976e-01,  7.2039e-04,  3.1415e-01,  2.4332e-01,\n","          4.0497e-02, -1.5877e-02,  3.2559e-01, -2.5036e-01,  1.0233e-01,\n","          2.6216e-02, -6.3873e-02, -1.6078e-01, -9.5458e-01,  1.9849e-01,\n","          2.8209e-02, -2.8849e-01,  1.4068e-01, -2.2681e-01, -7.6936e-02,\n","          1.2754e-01, -6.5862e-01, -5.0509e-02,  9.9723e-02,  2.0384e-01,\n","          2.8792e-01, -2.4738e-01,  3.1081e-01,  1.9830e-02,  1.4843e-01,\n","          2.0929e-01,  1.5453e-01,  8.7745e-02, -5.6095e-01, -3.7143e-02,\n","         -4.9186e-02,  3.1797e-01,  9.0510e-02, -2.7632e-01, -1.2354e-01,\n","          5.8933e-01, -1.8258e-01, -2.1669e-01,  8.9886e-02,  1.1800e-01,\n","         -6.0623e-01, -2.9290e-01, -3.0700e-01,  3.8413e-01],\n","        [ 4.8331e-02, -7.8804e-02,  2.5990e-02,  2.6446e-02, -1.4976e-02,\n","         -7.3132e-02, -8.0456e-02,  4.2376e-02, -1.0572e-01,  1.1796e-01,\n","         -2.8371e-02, -5.0707e-02, -1.2905e-01, -1.1529e-01,  1.8531e-01,\n","         -3.3795e-02, -8.5811e-02,  1.9221e-02,  1.9442e-02, -3.5737e-02,\n","         -1.6715e-01, -3.7101e-01, -7.8585e-01, -6.3879e-03, -4.6763e-02,\n","         -9.9851e-02, -5.0698e-02, -1.0424e+00,  1.2314e-01,  3.4614e-02,\n","         -1.5441e-01,  1.3353e-01,  1.5258e-01, -5.2468e-02,  6.2385e-01,\n","         -2.4937e-02, -4.2742e-02,  2.0701e-02, -3.9589e-02,  3.1489e-02,\n","          1.6188e-01,  3.4280e-02, -1.3562e-01,  8.4052e-02, -2.8741e-02,\n","          1.7302e-01, -3.7079e-01,  8.1322e-03, -1.8048e-02,  1.8368e-01,\n","          1.1838e-01, -1.2267e-01, -3.4130e-02,  4.0627e-01, -1.4308e-01,\n","         -3.2507e-01,  5.8517e-02,  5.0607e-02, -2.7042e-02,  3.3995e-02,\n","          8.2532e-02,  1.3754e-02,  2.3150e-01,  1.9084e-02],\n","        [ 6.5757e-02,  1.4536e-01, -4.9662e-02, -4.3191e-01, -1.0705e-01,\n","          6.8613e-02, -1.3727e-01,  6.9246e-02,  2.9739e-01,  2.2016e-01,\n","          1.2797e-01, -1.3019e-01, -4.3577e-02, -1.7936e-02, -3.4890e-02,\n","         -4.2888e-02,  4.3293e-01, -1.3170e-01, -1.0961e-01, -5.4248e-02,\n","         -7.3161e-02,  9.3469e-02, -8.7502e-02, -2.7807e-01,  1.4107e-01,\n","          1.4657e-01,  5.0861e-02,  2.1897e-01,  6.6438e-02,  2.2622e-01,\n","          5.7460e-01, -2.4913e-01, -1.5914e-01, -7.0184e-02, -1.4763e-01,\n","          7.2991e-02, -7.9415e-02, -2.3018e-02, -2.8405e-01,  2.2391e-01,\n","          7.9231e-02,  2.7028e-02, -2.3288e-01,  1.8568e-02, -2.4934e-01,\n","          2.0197e-01, -3.6933e-02,  1.8619e-01, -9.5846e-02,  4.9751e-02,\n","          5.9332e-03,  5.8198e-02, -2.4285e-01,  3.8627e-02, -1.1272e-01,\n","          1.2285e-01,  1.7214e-01,  1.3582e-01,  1.0774e-01, -5.5506e-02,\n","          1.2224e-01, -1.5027e-01,  2.3148e-01, -1.4183e-01],\n","        [ 2.9769e-01, -1.4803e-01,  1.3640e-01, -3.4612e-01, -8.4603e-01,\n","          2.5875e-01,  1.5911e-01, -4.5314e-01,  1.7784e-01,  2.6576e-01,\n","          3.5878e-01,  2.7762e-02,  6.1659e-02,  9.7364e-02, -1.8165e-01,\n","         -3.1246e-01, -8.3470e-02,  7.9312e-02, -1.9353e-01,  3.0717e-01,\n","          2.9616e-02,  2.6655e-01, -3.3635e-01, -1.0241e-01, -6.2562e-01,\n","         -3.2587e-01,  1.8522e-01,  4.1067e-01, -8.1585e-02,  3.8573e-01,\n","         -3.9140e-01, -2.2413e-01,  2.0742e-02,  1.5300e-01, -4.7833e-01,\n","          5.7279e-01, -1.3537e-01,  7.0099e-02, -3.1953e-02,  2.1288e-02,\n","         -6.5350e-01,  6.5423e-01,  2.7860e-01, -3.5179e-01, -1.6620e-01,\n","          2.9720e-01,  2.3657e-01,  2.1409e-01,  1.2296e-01,  2.3078e-01,\n","         -2.3068e-01, -1.6008e-02, -1.5411e-01, -8.1096e-02,  3.1855e-01,\n","         -1.2312e-01, -1.7508e-01, -5.2888e-01, -5.7583e-01, -1.5481e-01,\n","         -3.7576e-01, -2.9719e-01, -6.7941e-02,  2.7358e-01],\n","        [-3.1143e-01,  4.3647e-01,  9.0008e-02, -2.0669e-01,  1.6565e-01,\n","         -5.0888e-02,  1.3777e-01,  1.3898e-01, -1.0420e-01, -1.3468e-02,\n","         -7.3687e-02, -1.2492e-02, -3.8214e-01, -1.0145e-01, -3.4204e-01,\n","          5.1721e-01,  3.0902e-01,  2.6899e-02,  1.4165e-01, -3.5779e-02,\n","         -1.8690e-01,  2.6732e-02,  3.3351e-01, -2.2418e-01,  3.4874e-01,\n","         -9.9663e-02, -2.2360e-01,  6.6217e-01,  4.9433e-01,  3.4153e-03,\n","         -4.5032e-01, -9.9349e-03, -2.7307e-02, -7.0137e-02, -4.8117e-02,\n","          4.0664e-01, -2.8933e-02,  5.3761e-02,  1.5314e-02,  3.5358e-02,\n","         -4.4744e-02,  1.4541e-01,  1.2457e-01, -1.3798e-01,  1.3941e-01,\n","         -1.8424e-02,  1.7156e-02,  3.2941e-02, -1.1481e-01, -2.7031e-01,\n","          1.1910e-01, -3.2040e-02, -3.1430e-01, -2.9038e-02,  1.5965e-01,\n","         -1.0942e-01,  8.4638e-02,  3.1557e-02, -1.7373e-01, -1.8982e-01,\n","         -3.6792e-01, -4.9307e-03,  4.1306e-01,  7.1446e-02],\n","        [-7.0113e-01, -2.2701e-01, -2.1436e-01, -1.8776e-01,  1.7995e-01,\n","         -9.6098e-02,  1.4566e-01,  2.3199e-01,  1.6248e-01,  1.2402e-01,\n","         -3.1905e-01, -2.0291e-01, -3.4448e-03, -3.6970e-02,  3.3076e-01,\n","         -2.6620e-02, -1.0011e-01,  2.7431e-01,  8.4240e-02,  2.8037e-01,\n","          6.7386e-02, -5.0578e-01, -1.2151e-01,  5.7576e-01,  6.2569e-01,\n","          6.1143e-03,  1.7854e-01,  2.1927e-01,  6.6790e-02, -4.3277e-02,\n","         -2.6398e-01, -1.9645e-02, -7.6256e-02, -9.7291e-02, -9.3345e-02,\n","          1.1609e-02, -8.3743e-02, -6.4095e-02, -1.7636e-01,  2.2074e-01,\n","         -5.6377e-02,  3.7314e-01,  7.9393e-01, -1.4373e-01,  4.3174e-02,\n","         -2.8679e-01,  2.3980e-02, -2.6634e-02,  1.4406e-01,  3.1414e-01,\n","         -2.8618e-01, -1.8983e-01,  1.1444e-01, -1.9469e-01, -1.5817e-01,\n","          2.7521e-01,  3.2967e-01,  1.5949e-01,  1.0450e-01,  1.8255e-03,\n","         -1.0599e-01, -6.0642e-02,  1.6229e-01,  8.7860e-02]], device='cuda:0',\n","       requires_grad=True)\n","blocks.9.attn.b_O: torch.Size([768])\n","Parameter containing:\n","tensor([-1.0005e-03,  9.5993e-02,  3.4501e-02, -1.4761e-01,  1.1975e-01,\n","        -9.4909e-03,  1.9088e-01,  2.2239e-02, -3.2487e-02,  1.2755e-01,\n","         1.2376e-01, -3.1138e-02,  3.9749e-02, -2.3691e-01, -6.4458e-02,\n","         2.1421e-02, -1.2262e-01, -3.1006e-01, -4.7585e-02,  5.3593e-02,\n","        -4.4442e-02, -4.1408e-02,  3.5029e-03, -1.0594e-01,  3.7362e-02,\n","        -8.0019e-02,  9.1027e-02, -2.1046e-01, -2.0122e-01,  9.4927e-02,\n","         1.2044e-01, -1.9729e-02,  9.4864e-03, -1.0730e-01,  4.1957e-02,\n","        -6.4850e-02,  4.2057e-01, -1.4497e-01, -1.2500e-01,  6.4674e-02,\n","         5.1348e-02,  1.1208e-01,  4.9831e-03,  3.0381e-02, -3.3060e-02,\n","         2.1400e-01, -3.7382e-02,  4.8530e-02, -3.6717e-03,  1.9135e-01,\n","        -8.3102e-02,  7.3350e-02, -3.1587e-02,  1.8331e-01, -3.2525e-02,\n","         7.4331e-02,  2.8908e-01, -1.7929e-01,  1.9495e-01, -1.3792e-01,\n","        -4.7677e-02,  5.7919e-03, -1.5315e-01,  7.5697e-02, -1.4035e-01,\n","         1.7261e-01,  1.9832e-01,  1.5351e-01, -7.3055e-02, -3.2967e-02,\n","        -1.4115e-01, -1.2803e-01, -2.4010e-01,  6.7038e-02,  1.9030e-02,\n","        -1.7719e-02, -1.7845e-03, -1.0121e-01,  1.7225e-02, -4.7546e-03,\n","         5.5694e-02, -1.9892e-01, -4.9911e-02, -6.9326e-02, -2.2070e-02,\n","         4.9257e-02, -1.5352e-01, -3.8931e-03, -5.2858e-02, -9.7673e-02,\n","         2.3435e-02,  1.4532e-01, -9.5513e-02, -4.4090e-02, -1.4344e-03,\n","        -1.2604e-01, -1.1235e-02, -1.3578e-01, -1.1435e-01,  1.8309e-01,\n","        -2.9828e-02,  1.6554e-01,  4.1181e-02, -2.2371e-01,  7.0045e-02,\n","         2.5238e-02, -5.9638e-02,  1.5013e-01,  3.1121e-01, -2.4069e-01,\n","        -9.8917e-02, -1.0276e-01, -1.6837e-01, -2.7254e-01,  1.9899e-01,\n","         1.0211e-02, -7.7833e-02,  2.7678e-01, -6.7535e-02, -6.4659e-02,\n","        -1.2307e-01,  6.6648e-02,  6.3239e-02,  2.6957e-01,  9.4086e-02,\n","        -2.8335e-01,  1.3667e-01, -7.7265e-02, -1.9066e-02,  1.0308e-01,\n","         7.3775e-02,  5.6707e-03, -5.8924e-02, -1.0653e-01, -1.7335e-01,\n","         1.2459e-01, -1.5065e-01, -1.0643e-01, -1.3459e-01,  1.3240e-01,\n","         9.2858e-02,  1.4212e-01, -2.9385e-02, -1.1062e-01, -4.8246e-04,\n","         1.3262e-01,  2.9519e-01, -4.4082e-02,  4.2516e-02,  7.6878e-02,\n","         1.4327e-02,  9.2325e-03, -3.2895e-01, -2.0640e-02, -8.7275e-02,\n","         4.2262e-02, -3.0082e-01, -2.2640e-02, -1.8639e-01,  1.9048e-01,\n","         1.9011e-01, -1.9901e-01,  1.5170e-01,  1.7618e-01, -8.0639e-02,\n","        -1.2521e-02, -1.2936e-01, -3.5029e-02, -1.9071e-01, -1.6720e-01,\n","         1.4190e-02,  1.8290e-01, -1.6370e-01,  4.7683e-03, -7.9428e-02,\n","         2.1009e-01, -1.9380e-01,  1.4456e-01, -5.4880e-02,  8.4819e-02,\n","        -1.2963e-01,  2.6540e-01, -1.3032e-01,  1.6548e-01, -5.7266e-02,\n","        -1.0563e-01,  1.1694e-01, -2.6814e-02,  9.2481e-02,  8.0029e-02,\n","        -6.7113e-02,  7.2601e-02, -7.9996e-02,  1.6769e-02, -1.5747e-02,\n","        -1.6023e-01,  2.9598e-02, -6.7216e-03, -3.4512e-01, -2.8054e-02,\n","        -6.1957e-02,  3.2586e-01, -4.3184e-02,  2.0215e-03,  2.1505e-01,\n","        -2.7534e-02, -8.3614e-03, -9.3718e-03, -2.0597e-01,  3.9377e-01,\n","         2.5447e-01, -1.1334e-01, -6.8208e-02, -1.3008e-01,  4.5430e-02,\n","        -5.7701e-02, -1.3399e-01,  2.0652e-02, -9.8158e-02,  5.3045e-03,\n","        -1.2142e-01, -1.0532e-01,  4.3265e-01,  8.2594e-02,  1.4842e-02,\n","         1.0201e-01, -1.1360e-01,  3.5444e-02, -6.0574e-02,  2.8448e-01,\n","         1.6165e-01, -3.4289e-01,  2.2572e-01,  1.0921e-01,  4.7368e-02,\n","        -4.4777e-02, -1.2993e-01, -4.4299e-02,  1.7362e-02, -4.8478e-02,\n","        -2.0229e-01,  2.3764e-01, -1.9047e-01,  1.0579e-01, -1.6418e-02,\n","         4.4134e-02,  1.5253e-01, -1.2111e-01,  1.5612e-01, -1.6585e-01,\n","        -1.6493e-01, -2.9386e-01,  1.5611e-01, -8.9699e-02, -2.9721e-01,\n","         2.0352e-02,  1.2643e-01,  1.1622e-01, -3.9367e-02, -6.1550e-02,\n","         3.9224e-02, -5.7595e-02,  9.0225e-03,  2.4582e-01, -1.8398e-01,\n","        -1.9251e-01,  1.8646e-01, -4.1993e-02, -1.2458e-01, -4.0027e-02,\n","         1.9608e-01, -1.4011e-01,  8.9569e-02,  4.1079e-01,  1.4199e-01,\n","         5.0294e-02,  3.0890e-04, -3.5362e-02, -1.3960e-01, -4.0158e-02,\n","         1.0712e-01,  2.7103e-02, -1.2405e-01,  2.2455e-02, -1.1622e-01,\n","         1.3122e-01,  3.3982e-02, -5.6686e-02, -1.3898e-02,  1.0154e-01,\n","         5.1606e-02, -7.0149e-03, -2.6959e-01, -7.0461e-02,  1.2894e-01,\n","        -3.1957e-01,  2.7698e-02, -2.1115e-02, -3.2452e-02,  2.6924e-02,\n","        -2.0698e-01,  9.2400e-03,  1.7714e-01, -1.4176e-02,  4.8795e-02,\n","         7.2114e-02,  1.2489e-03, -1.5839e-01, -2.8445e-01, -8.4842e-02,\n","         9.7669e-03,  1.9264e-01,  2.7074e-01, -3.8565e-02, -2.3105e-01,\n","        -5.0865e-02, -1.5973e-01,  1.2884e-01, -5.6029e-02,  2.1747e-01,\n","        -1.5123e-01,  2.3185e-02,  7.3693e-02, -3.0500e-01,  3.5836e-01,\n","         4.2776e-03, -4.8432e-02,  9.2827e-02,  9.7691e-02, -1.8790e-01,\n","         9.9901e-03,  5.2965e-02,  8.2231e-02,  4.6390e-02,  1.2003e-01,\n","        -7.5950e-02,  4.2294e-01, -8.7677e-02,  9.8521e-02, -3.1079e-02,\n","        -5.2664e-02, -8.6258e-02,  1.2731e-01,  3.6618e-02,  3.1462e-01,\n","         6.9042e-02,  1.1368e-01, -1.8659e-01,  5.1707e-02, -1.0138e-01,\n","        -1.2349e-01,  1.0031e-01, -1.1482e-01, -2.5861e-02,  1.4731e-01,\n","        -7.4221e-02,  1.8890e-01, -2.7002e-02, -1.3186e-01,  4.8430e-02,\n","         2.2101e-03,  3.9665e-03,  7.7497e-02, -1.2430e-01, -6.2076e-02,\n","        -4.1317e-01, -3.5394e-02, -1.3235e-01,  2.2161e-01,  9.9246e-02,\n","         9.7860e-02, -3.4942e-02,  1.9542e-01, -3.3049e+00, -9.7563e-02,\n","         6.2970e-02, -9.6682e-02,  1.3736e-01,  6.7789e-02,  9.9618e-02,\n","         9.3814e-04,  5.9127e-02, -1.5715e-01, -1.4323e-01,  7.7409e-02,\n","         2.1312e-01, -1.3827e-02, -9.0442e-02, -9.3988e-02,  2.1182e-01,\n","         2.3330e-01, -1.1546e-01,  1.4284e-01,  6.9150e-02, -2.0036e-01,\n","         7.6277e-02, -2.3945e-01,  1.7516e-01,  1.0337e-01,  1.2222e-01,\n","        -1.9500e-02, -1.0951e-01, -1.7932e-01, -1.0488e-01,  2.2560e-01,\n","        -6.2802e-02,  4.3388e-02, -1.5167e-01,  1.1736e-01, -9.1135e-02,\n","         6.2373e-02, -2.4069e-01,  1.5399e-02, -2.2656e-01, -1.5917e-01,\n","         4.3026e-02,  7.8077e-02, -9.7240e-03, -1.8445e-01,  2.3935e-01,\n","        -1.0824e-01,  3.8966e-02,  1.7314e-01,  1.3345e-01,  7.5741e-02,\n","        -6.2559e-02, -7.3733e-02, -3.7690e-02, -7.0425e-02, -7.8255e-03,\n","         3.5934e-01,  7.6155e-02,  6.1812e-02, -1.7249e-01, -2.5174e-01,\n","         8.6452e-02, -1.4091e-02,  3.5971e-02,  5.7271e-02,  7.4850e-02,\n","        -7.3503e-02,  5.8273e-02,  1.8705e-01, -9.5724e-02,  1.0906e-01,\n","         8.6684e-02, -2.0893e-01,  1.9867e+00, -8.6349e-02, -3.9603e-02,\n","        -2.0359e-01, -1.7040e-01,  1.2897e-01,  1.7317e-01,  1.1967e-01,\n","         2.7425e-02, -7.9455e-02, -6.1431e-02,  2.0631e-01,  1.4249e-01,\n","         1.9575e-01,  3.5862e-01,  1.1018e-01, -1.3140e-01,  1.1291e-02,\n","        -1.6184e-01, -1.6862e-01,  7.7261e-02,  2.1758e-02,  1.7043e-01,\n","        -9.7807e-02,  2.2926e-01,  5.3700e-02,  1.7612e-01, -2.0488e-02,\n","        -1.6440e-01,  1.7016e-02, -1.7554e-01,  1.0477e-01, -1.5647e-01,\n","        -1.1431e-02,  4.7458e+00, -2.9149e-02,  1.7026e-01,  1.9193e-01,\n","         1.7523e-02,  3.1422e-01, -1.1714e-01,  7.0314e-02, -2.7886e-01,\n","         2.4345e-01,  4.9604e-02, -6.4879e-02, -1.7644e-01, -1.7264e-02,\n","        -1.3335e-01,  5.6386e-01, -4.3467e-02,  1.5383e-02, -5.8325e-02,\n","         2.0165e-01, -4.2586e-02,  7.3204e-02,  1.6190e-01, -7.7363e-02,\n","        -2.3010e-01,  5.1491e-02, -1.6533e-02, -1.8095e-01, -9.4516e-02,\n","        -2.3332e-02, -1.3148e-01, -2.0431e-01, -4.7999e-02, -4.6228e-02,\n","        -2.0390e-01,  4.1767e-02, -1.4147e-01, -2.5862e-03,  8.1887e-02,\n","         9.9528e-02,  1.3560e-02,  2.4823e-01,  3.0752e-02,  8.7286e-02,\n","        -1.6199e-01, -8.0186e-02, -2.0965e-01,  1.1193e-01, -2.3824e-02,\n","         1.3561e-01,  1.8562e-01, -1.1484e-01,  1.3190e-01, -3.2144e-01,\n","         8.0633e-02, -1.3983e-01, -5.7238e-04,  1.2872e-02, -3.0570e-01,\n","         2.3090e-01, -4.4604e-04,  5.6499e-02,  3.8473e-02, -1.5076e-02,\n","        -3.3668e-02,  1.9393e-01, -1.4869e-01, -2.2445e-01,  2.6277e-02,\n","         1.7242e-01,  1.5932e-01, -1.3214e-01,  1.4428e-01,  4.2196e-02,\n","         2.0699e-01, -1.3374e-01,  2.1793e-01, -2.5093e-01, -1.7928e-01,\n","        -1.0566e-01,  1.9833e-01,  2.1984e-01, -1.2074e-01,  1.8485e-01,\n","        -1.7171e-01,  1.8523e-01,  2.6167e-02, -7.3133e-02, -2.1503e-01,\n","         1.9874e-01,  2.3330e-02, -1.3120e-02, -2.8102e-02, -8.6016e-02,\n","        -7.5960e-03, -4.3331e-02,  1.0317e-01, -8.1870e-02,  1.0311e-01,\n","         1.4059e-01,  2.7661e-02,  1.1439e-01,  2.5182e-02,  4.2873e-02,\n","         8.5013e-02, -2.6514e-02, -1.4918e-01,  2.3401e-01,  2.8750e-02,\n","        -8.7962e-02, -1.9412e-01,  1.6663e-01,  7.5823e-03, -1.1870e-01,\n","         2.7810e-01, -1.0625e-01,  1.9192e-01, -2.7437e-02,  1.9019e-01,\n","        -1.0117e-01,  1.7931e-01, -5.1552e-02, -1.7191e-01, -7.5452e-03,\n","         6.0231e-02, -1.2875e-01,  1.2142e-02,  1.4399e-01, -1.0505e-01,\n","         1.2820e-01,  1.1391e-01,  6.1981e-02,  3.8115e-02, -1.2773e-01,\n","        -1.6859e-01,  4.3273e-02, -1.5281e-01, -8.9525e-02, -3.7519e-02,\n","         9.5539e-02, -4.3028e-02,  2.8466e-01,  1.8738e-01, -1.4513e-01,\n","        -1.6912e-01,  2.2286e-02, -3.4257e-02,  3.6447e-02,  7.7477e-02,\n","         2.2335e-02, -1.3744e-01, -1.8407e-01, -7.7232e-02,  4.0740e-02,\n","         4.6692e-02, -2.4246e-01, -8.4338e-02,  6.8418e-02, -9.0801e-02,\n","        -9.2771e-02,  2.9303e-02, -1.6589e-01, -4.6258e-02,  1.0406e-02,\n","        -2.7218e-01,  1.2510e-01,  5.7916e-03,  2.4600e-03,  6.6378e-02,\n","         7.6192e-03, -2.7284e-01, -9.2966e-02, -1.5675e-01, -1.3880e-02,\n","         1.6427e-02,  1.4169e-01, -4.1856e-02,  1.3142e-01,  1.8531e-02,\n","        -3.0448e-02, -1.7331e-02, -1.2448e-01,  1.7558e-02, -2.3002e-01,\n","        -3.2871e-02, -1.8939e-02, -2.3697e-01, -1.4301e-03,  2.9953e-02,\n","        -6.7764e-02, -3.0404e-01, -1.1289e-01,  2.6506e-01, -2.4477e-01,\n","         1.2281e-01, -8.0204e-02,  2.0694e-02, -1.5638e-01, -3.1804e-02,\n","         2.7598e-02,  2.7641e-01, -3.1995e-01,  1.3425e-01, -6.1324e-02,\n","        -2.8552e-02,  2.8800e-01, -1.1180e-01,  1.7413e-01, -2.8480e-02,\n","        -2.2807e-01,  2.4679e-01,  1.9206e-01,  1.9522e-01,  1.4590e-02,\n","         1.6650e-01,  1.9537e-01,  1.5690e-01,  1.5964e-01, -9.0091e-02,\n","         8.8295e-02, -7.1991e-02,  1.1305e-01, -3.5595e-01, -1.9702e-01,\n","        -1.5869e-01,  2.1596e-01, -7.9471e-02, -1.5093e-01, -1.1289e-01,\n","        -1.1790e-01,  1.9021e-01, -1.5442e-01,  2.7321e-02, -8.4873e-02,\n","        -3.5578e-03,  1.4734e-01, -1.0126e-01,  1.2332e-02,  2.0186e-01,\n","        -1.7624e-02, -3.6107e-02,  1.3901e-01,  4.9322e-02, -1.2565e-01,\n","         1.6179e-01,  2.7376e-01,  3.4543e-01, -7.1094e-02, -7.7765e-02,\n","        -1.4745e-01,  8.5705e-02, -3.6763e-01,  7.1928e-03, -1.6851e-01,\n","         1.0933e-01,  3.8386e-01,  1.9200e-03,  1.1253e-01,  6.8387e-02,\n","         1.7860e-01,  6.2294e-02, -8.4302e-02,  2.2505e-01, -4.0318e-02,\n","        -1.7854e-01,  1.7508e-01, -5.8372e-02,  2.9933e-02,  1.6529e-01,\n","        -6.4162e-02, -8.3055e-02, -9.6228e-02,  4.7445e-02, -2.5413e-02,\n","         8.9628e-02, -4.4765e-02,  2.8292e-02, -6.0991e-02, -4.1795e-02,\n","        -3.0973e-01,  1.2029e-01,  2.5421e-01, -1.7003e-01,  8.7150e-02,\n","        -2.4163e-02,  5.8442e-03, -1.6609e-01], device='cuda:0',\n","       requires_grad=True)\n","blocks.9.attn.W_K: torch.Size([12, 768, 64])\n","Parameter containing:\n","tensor([[[ 9.4145e-02, -5.3496e-02, -9.3943e-02,  ..., -3.4193e-01,\n","          -2.3770e-02,  1.0545e-01],\n","         [ 1.5285e-01,  9.5173e-02,  2.1745e-02,  ..., -1.7279e-01,\n","           1.2958e-01,  9.8347e-02],\n","         [ 9.9024e-04, -5.5259e-02, -2.4611e-01,  ...,  2.7925e-03,\n","           8.8341e-02,  5.3160e-02],\n","         ...,\n","         [ 2.6154e-02,  3.6957e-01,  8.1458e-02,  ..., -3.4971e-01,\n","           3.3020e-02, -6.2888e-02],\n","         [ 5.6379e-02, -2.2004e-02, -3.9210e-02,  ...,  1.4980e-02,\n","          -2.4840e-02,  3.8601e-03],\n","         [ 3.7804e-02, -2.1265e-02, -5.6661e-03,  ...,  1.3488e-02,\n","          -3.4759e-01,  2.3772e-02]],\n","\n","        [[-4.6153e-02,  1.2378e-01, -2.7581e-02,  ..., -5.1874e-02,\n","          -3.6277e-02, -7.6499e-02],\n","         [ 1.4909e-02,  2.4272e-01,  1.3189e-01,  ...,  2.4428e-05,\n","          -6.1700e-02,  2.7235e-01],\n","         [-1.2985e-02, -2.8705e-02,  1.4543e-01,  ...,  7.8230e-02,\n","          -6.8932e-02,  9.2322e-02],\n","         ...,\n","         [ 5.5286e-02,  6.1294e-04, -6.2223e-02,  ..., -2.6524e-01,\n","           3.4521e-02, -1.5790e-01],\n","         [ 8.2569e-02,  2.1133e-01, -1.2963e-01,  ...,  1.0548e-01,\n","           2.8488e-02,  8.5266e-02],\n","         [ 8.6676e-02, -7.5268e-02,  8.9741e-02,  ..., -1.3114e-03,\n","           1.6764e-01,  2.7604e-01]],\n","\n","        [[-8.1481e-02,  8.1735e-02, -1.2206e-01,  ...,  1.2930e-01,\n","           1.9423e-01,  3.7175e-01],\n","         [ 1.7568e-01,  4.5024e-02,  5.4544e-02,  ...,  5.6012e-02,\n","           1.2601e-03, -3.9937e-02],\n","         [-2.0059e-02, -4.0676e-02,  1.0148e-01,  ..., -4.5590e-02,\n","          -4.9966e-02, -1.0142e-01],\n","         ...,\n","         [-3.9295e-02,  1.7572e-02,  7.4279e-02,  ...,  2.0608e-01,\n","           2.6710e-01, -2.8057e-03],\n","         [ 1.4299e-01,  7.0728e-02, -1.0828e-01,  ..., -1.8021e-01,\n","          -1.3090e-01, -8.1889e-02],\n","         [ 2.0223e-01, -1.2992e-01, -8.7976e-02,  ...,  1.1713e-01,\n","          -1.2327e-01,  1.4145e-01]],\n","\n","        ...,\n","\n","        [[ 9.2781e-02, -1.1319e-01,  5.6543e-02,  ...,  2.0488e-03,\n","          -9.1193e-03, -2.3978e-02],\n","         [-2.1108e-01,  1.3073e-02, -1.0329e-01,  ..., -1.1162e-01,\n","           1.6350e-01,  1.2513e-01],\n","         [ 5.4479e-02,  2.3772e-01,  4.8785e-03,  ..., -9.5702e-02,\n","          -7.9954e-02,  6.7852e-02],\n","         ...,\n","         [ 4.1018e-01, -9.6045e-02,  1.0990e-01,  ...,  7.7188e-03,\n","           7.2901e-02, -1.2807e-01],\n","         [ 6.5892e-02, -5.4596e-03, -2.4575e-01,  ...,  5.1451e-03,\n","          -2.5701e-01,  3.7122e-02],\n","         [ 3.5498e-02, -2.7176e-02,  7.8145e-02,  ..., -3.0772e-02,\n","          -6.2309e-02,  6.9498e-02]],\n","\n","        [[ 6.1206e-02,  1.3055e-01,  1.4109e-02,  ...,  6.3441e-02,\n","          -1.0065e-02, -1.1513e-02],\n","         [ 5.0221e-02,  1.1393e-01,  1.2709e-01,  ..., -1.6862e-01,\n","           3.0784e-02,  9.6974e-02],\n","         [ 1.9877e-02, -7.7984e-02,  7.7326e-02,  ..., -3.5420e-03,\n","          -1.5693e-01,  5.0432e-02],\n","         ...,\n","         [ 1.1988e-01,  6.4384e-02, -4.5254e-02,  ..., -2.1759e-03,\n","           4.4212e-02, -1.0332e-01],\n","         [ 7.7589e-03, -8.0984e-03, -1.1979e-01,  ...,  5.5994e-02,\n","          -9.1319e-02,  7.2040e-02],\n","         [-1.0848e-01,  4.1246e-02, -4.3207e-02,  ..., -4.0944e-03,\n","           2.5390e-01, -1.5975e-02]],\n","\n","        [[-3.5064e-02,  1.6179e-01, -3.0180e-02,  ..., -1.8651e-01,\n","           4.0982e-02, -4.4899e-03],\n","         [-7.5924e-02, -9.4095e-02, -9.1652e-02,  ...,  2.3108e-02,\n","           8.2284e-02,  5.0613e-02],\n","         [-3.8344e-02, -1.9574e-01, -5.7516e-02,  ..., -2.2230e-02,\n","           7.4682e-02, -1.0301e-01],\n","         ...,\n","         [ 1.2619e-01,  1.5655e-01, -1.4248e-01,  ...,  1.2178e-01,\n","          -9.3209e-02, -5.3340e-02],\n","         [-1.5569e-01,  9.9370e-03,  1.4729e-01,  ..., -8.4597e-02,\n","          -1.7131e-01,  3.8573e-02],\n","         [ 3.0411e-02, -1.0820e-01, -1.2622e-02,  ...,  2.7543e-02,\n","          -9.8972e-03,  3.8507e-01]]], device='cuda:0', requires_grad=True)\n","blocks.9.attn.W_V: torch.Size([12, 768, 64])\n","Parameter containing:\n","tensor([[[-0.0520,  0.1444, -0.0810,  ...,  0.0076, -0.0417,  0.0683],\n","         [ 0.1249,  0.0732,  0.1956,  ...,  0.0728, -0.1613,  0.0857],\n","         [-0.1725,  0.0639,  0.1837,  ...,  0.1417, -0.0786, -0.1313],\n","         ...,\n","         [-0.1725,  0.0344,  0.0454,  ...,  0.0972,  0.0054, -0.0929],\n","         [ 0.0849, -0.0514,  0.2248,  ..., -0.0555,  0.2565,  0.0645],\n","         [-0.2131,  0.1072, -0.1038,  ...,  0.1561, -0.0424,  0.0532]],\n","\n","        [[-0.2271, -0.2250, -0.2152,  ..., -0.0053, -0.0600, -0.0276],\n","         [ 0.0372, -0.1475,  0.1151,  ...,  0.0734, -0.1241,  0.1069],\n","         [ 0.4230,  0.1648, -0.0510,  ..., -0.1289, -0.2109,  0.1522],\n","         ...,\n","         [-0.0177,  0.0275,  0.0336,  ..., -0.1283, -0.0583,  0.2024],\n","         [ 0.0137, -0.0239,  0.0215,  ..., -0.0240, -0.1866, -0.0066],\n","         [ 0.0661,  0.0397,  0.1292,  ..., -0.1038,  0.0432, -0.1385]],\n","\n","        [[-0.0674, -0.1525, -0.1729,  ..., -0.0476, -0.2427,  0.0991],\n","         [ 0.0760, -0.1394, -0.1636,  ..., -0.0969,  0.0394, -0.0932],\n","         [ 0.0025, -0.0607,  0.0060,  ..., -0.0428,  0.1500,  0.1544],\n","         ...,\n","         [ 0.0854,  0.0021, -0.0378,  ..., -0.0026,  0.0597,  0.0332],\n","         [-0.2185, -0.1219,  0.2201,  ..., -0.1218,  0.1019,  0.1750],\n","         [ 0.0068, -0.0263,  0.1325,  ..., -0.0698, -0.0678,  0.0903]],\n","\n","        ...,\n","\n","        [[ 0.0598,  0.4108,  0.1641,  ..., -0.1320,  0.1498, -0.0062],\n","         [ 0.1638,  0.0006, -0.0571,  ...,  0.1000, -0.1151, -0.0489],\n","         [-0.1624,  0.0728,  0.0300,  ..., -0.1453,  0.1216,  0.0776],\n","         ...,\n","         [ 0.1901,  0.0605, -0.0070,  ..., -0.0045,  0.0090,  0.1576],\n","         [-0.1556, -0.0094,  0.0009,  ...,  0.0878,  0.2607,  0.1467],\n","         [-0.2276, -0.1729, -0.0424,  ..., -0.0215, -0.0770,  0.0369]],\n","\n","        [[ 0.1205, -0.0267,  0.0428,  ..., -0.0013, -0.1162,  0.1072],\n","         [-0.1359, -0.1173,  0.0054,  ..., -0.0968,  0.1004, -0.0869],\n","         [ 0.1845, -0.1658, -0.0823,  ..., -0.0706, -0.0665,  0.1110],\n","         ...,\n","         [-0.0183,  0.0574,  0.1805,  ...,  0.1434,  0.0977,  0.0364],\n","         [-0.2906, -0.1947, -0.0175,  ...,  0.3410, -0.1008,  0.0828],\n","         [ 0.0448,  0.0236, -0.1106,  ...,  0.0354,  0.0413,  0.1814]],\n","\n","        [[-0.3031,  0.1945, -0.0691,  ..., -0.0371,  0.0620,  0.0426],\n","         [-0.0672, -0.2072,  0.0826,  ...,  0.1014, -0.1325, -0.0619],\n","         [ 0.0301,  0.0182,  0.1837,  ...,  0.0655, -0.1282,  0.0375],\n","         ...,\n","         [ 0.0353, -0.0221,  0.0501,  ...,  0.0024, -0.0112, -0.0260],\n","         [-0.0768,  0.0588,  0.0312,  ...,  0.2506,  0.1025,  0.0781],\n","         [ 0.0313,  0.2603, -0.2040,  ...,  0.0140, -0.1682, -0.0827]]],\n","       device='cuda:0', requires_grad=True)\n","blocks.9.attn.b_K: torch.Size([12, 64])\n","Parameter containing:\n","tensor([[-0.1255,  0.2206,  0.0216, -0.0688, -0.1582, -0.0327,  0.0876, -0.0626,\n","          0.0811, -0.0644, -0.0199, -0.1491,  0.0267,  0.1105,  0.1203, -0.0348,\n","         -0.0688, -0.0639,  0.1043, -0.0693,  0.0045,  0.0290,  0.1264,  0.0626,\n","          0.0075, -0.0317,  0.0051,  0.1298,  0.0427, -0.0896, -0.0518, -0.0634,\n","          0.0265, -0.0019,  0.0692, -0.0828,  0.0287, -0.0489, -0.0420, -0.0596,\n","          0.0583,  0.1366, -0.0611,  0.0569,  0.0564,  0.0526, -0.0255,  0.0686,\n","          0.0258,  0.0516,  0.0732,  0.1113,  0.0053, -0.0742, -0.0705,  0.0175,\n","         -0.0987,  0.0456,  0.0729, -0.0077, -0.0798, -0.0756,  0.0055, -0.0332],\n","        [ 0.0030, -0.0390, -0.0831,  0.0223,  0.0725,  0.0654, -0.0171, -0.0059,\n","         -0.0044,  0.0392, -0.0521, -0.0376,  0.1254,  0.0559, -0.0117,  0.1854,\n","         -0.1344,  0.0412, -0.0968,  0.0319, -0.0834, -0.0132,  0.0216,  0.0100,\n","         -0.0510,  0.0055,  0.0237,  0.0758,  0.0447, -0.0553, -0.1178,  0.0300,\n","          0.0438, -0.0611, -0.0670,  0.0224, -0.1735, -0.2236, -0.0770,  0.0570,\n","          0.0093, -0.0689, -0.1845,  0.2155,  0.0832,  0.0287, -0.0957,  0.0006,\n","          0.1299, -0.0636,  0.0551, -0.0606,  0.1494,  0.1282, -0.0628, -0.1256,\n","         -0.1404,  0.1363,  0.1145, -0.2711, -0.1551, -0.0910, -0.0379,  0.0805],\n","        [-0.1277,  0.0374,  0.0509,  0.0381, -0.0083,  0.0432, -0.0236,  0.0160,\n","         -0.1329, -0.0132,  0.0797,  0.1162, -0.0792, -0.0100, -0.1731,  0.1729,\n","          0.0814,  0.0267,  0.0352,  0.0599, -0.0114, -0.0663, -0.0608, -0.0509,\n","          0.0919,  0.1067, -0.0545,  0.1557,  0.0640, -0.1485,  0.0293, -0.0251,\n","          0.0680,  0.0158, -0.0430,  0.0155,  0.0523,  0.1136,  0.0337,  0.0241,\n","         -0.0482,  0.0724, -0.1494, -0.0821, -0.0632, -0.1239,  0.0540, -0.0095,\n","         -0.0061, -0.0178,  0.0356, -0.0095,  0.0093,  0.0072,  0.0328, -0.1743,\n","          0.0981,  0.0292, -0.0631, -0.1329, -0.0223, -0.1139, -0.1433,  0.0083],\n","        [ 0.0401, -0.0902,  0.0472, -0.0482,  0.0471, -0.0441,  0.0032, -0.0329,\n","         -0.0447,  0.0276,  0.0385,  0.1291,  0.0525, -0.1432,  0.0207, -0.2047,\n","         -0.0799,  0.0879,  0.1140,  0.2115, -0.0057, -0.1172,  0.0591,  0.1517,\n","          0.1417,  0.0476, -0.1222, -0.0510, -0.0312,  0.2222,  0.0140, -0.1130,\n","          0.0648,  0.0484, -0.1820,  0.0310, -0.0893, -0.0548,  0.0590, -0.1759,\n","         -0.0411, -0.0135,  0.0960, -0.0123, -0.0173,  0.1311, -0.2086, -0.1125,\n","         -0.0221,  0.1350, -0.0325, -0.0989,  0.1220, -0.1368, -0.1308, -0.0261,\n","          0.0443, -0.0017,  0.1034, -0.0008, -0.0877, -0.0684, -0.0392, -0.1728],\n","        [-0.0240, -0.0719, -0.2233,  0.0978,  0.0647, -0.0481,  0.0633,  0.0149,\n","         -0.0814, -0.1094, -0.0934, -0.0609, -0.0068,  0.0770,  0.0417, -0.0316,\n","          0.0945, -0.0902, -0.1067,  0.0077,  0.0634, -0.0634,  0.0044, -0.0968,\n","          0.0370, -0.0613,  0.0617,  0.0037, -0.1369,  0.1051,  0.0227,  0.0117,\n","          0.1464, -0.0271,  0.1025,  0.0685, -0.0346,  0.0322,  0.0691, -0.0533,\n","         -0.0142,  0.0609, -0.0018, -0.1066, -0.0613,  0.0536,  0.1285,  0.0408,\n","         -0.0112,  0.0026, -0.1186, -0.1523,  0.0720,  0.0411,  0.1521,  0.0091,\n","         -0.0019,  0.0018, -0.1301, -0.0132, -0.0679, -0.0117, -0.0979,  0.0545],\n","        [ 0.0182, -0.0463,  0.0241, -0.0502,  0.0392,  0.0424, -0.1205, -0.1889,\n","          0.0215, -0.0120, -0.1430, -0.0477,  0.1129,  0.0159,  0.0662, -0.0431,\n","         -0.0446, -0.2192,  0.0520,  0.0566, -0.0353, -0.0032,  0.0538, -0.0225,\n","          0.0668,  0.0869, -0.0070, -0.0015, -0.0431, -0.0828, -0.1255, -0.0892,\n","         -0.0515,  0.1422, -0.2329,  0.0192,  0.1022,  0.0114,  0.0058,  0.0259,\n","          0.0752, -0.0840,  0.0451,  0.0202, -0.1189,  0.0620,  0.1103,  0.0710,\n","         -0.0240, -0.0156,  0.0250,  0.0551,  0.0169,  0.0848,  0.0929,  0.1276,\n","         -0.0127, -0.0541, -0.1338, -0.0281,  0.0262, -0.0618, -0.0107, -0.0707],\n","        [ 0.1936,  0.1006, -0.0497, -0.0812,  0.1146,  0.2048,  0.0354,  0.0161,\n","          0.1236, -0.1369, -0.0812,  0.0289, -0.0678, -0.0265, -0.0008,  0.0303,\n","          0.1055,  0.1704,  0.1421,  0.1223, -0.0543, -0.0537,  0.1398,  0.0473,\n","          0.0314,  0.1005,  0.0610,  0.0343, -0.2528, -0.0340, -0.0053, -0.1737,\n","          0.0729, -0.1808, -0.0874, -0.0493, -0.0833, -0.1081,  0.0743, -0.0902,\n","          0.0198,  0.0163, -0.1331, -0.1174,  0.0136,  0.0780,  0.1453, -0.0496,\n","         -0.1343, -0.0792,  0.1258,  0.0236,  0.0011, -0.1013,  0.1834,  0.0250,\n","         -0.0327, -0.0640, -0.0800,  0.1388,  0.0161, -0.1581,  0.0240,  0.0623],\n","        [-0.0209,  0.1246,  0.0193,  0.0368, -0.0014, -0.0428, -0.0251,  0.0278,\n","          0.0207, -0.0942,  0.1659, -0.0582, -0.2425, -0.0813, -0.0288,  0.1564,\n","         -0.1706, -0.0651, -0.0256, -0.0956,  0.0079, -0.0071,  0.1243, -0.1891,\n","         -0.1624,  0.0945, -0.0573,  0.0316, -0.0923,  0.0845,  0.0506, -0.1522,\n","          0.0542,  0.1385,  0.1617,  0.1236,  0.2003, -0.0508,  0.0573, -0.0890,\n","         -0.1273,  0.0624,  0.0409, -0.1029,  0.1334, -0.0643,  0.0730,  0.0948,\n","         -0.1132, -0.1136,  0.0451, -0.0124,  0.0162, -0.0813, -0.1171, -0.0333,\n","         -0.1172, -0.1160, -0.0450, -0.1540, -0.1172, -0.0400, -0.0715,  0.0813],\n","        [-0.0013, -0.0564,  0.0154,  0.0559,  0.0064, -0.0990,  0.1634, -0.1042,\n","          0.1244, -0.0345,  0.0449, -0.0153,  0.0619,  0.0100, -0.1985, -0.0666,\n","          0.1329,  0.0919,  0.0473,  0.1619, -0.0848, -0.0871,  0.0597, -0.0743,\n","          0.0605, -0.0721, -0.1160, -0.1217, -0.0850, -0.1356, -0.0775, -0.0825,\n","         -0.1217,  0.0606,  0.0476, -0.0383,  0.0933, -0.1239, -0.0393, -0.1217,\n","         -0.1321,  0.0375,  0.0023, -0.0377,  0.0386,  0.0209,  0.1063, -0.1485,\n","          0.1018, -0.0953, -0.0062,  0.0116,  0.0306, -0.1426,  0.0332,  0.1407,\n","          0.0421,  0.0019, -0.0367,  0.0365,  0.0690, -0.0325,  0.0039,  0.0302],\n","        [-0.0078, -0.0699, -0.0953, -0.0015, -0.1523,  0.0500, -0.0017, -0.1140,\n","          0.1138,  0.0453, -0.1191,  0.0207,  0.0959, -0.2418, -0.0065, -0.1666,\n","          0.0483,  0.1732,  0.1052,  0.2840, -0.0799,  0.0096, -0.0478,  0.0326,\n","         -0.0753, -0.0169, -0.2814,  0.0648,  0.0253,  0.0950, -0.0215,  0.0823,\n","          0.0245, -0.1445, -0.1361,  0.0634, -0.0389, -0.0765,  0.0535,  0.0050,\n","          0.0073,  0.1607, -0.0031,  0.0659,  0.1333, -0.0401,  0.0948, -0.1007,\n","         -0.0392, -0.0931, -0.1846, -0.0235,  0.0036, -0.0260, -0.0254,  0.0274,\n","         -0.1880, -0.1766, -0.2232, -0.0329,  0.0459, -0.0553, -0.0974, -0.0664],\n","        [-0.1912, -0.0770, -0.0069, -0.0680,  0.1358,  0.0140,  0.0339,  0.0270,\n","         -0.1214, -0.1417,  0.1516,  0.1173,  0.0953,  0.1671, -0.1319,  0.0396,\n","          0.2160,  0.1800, -0.1326, -0.0207, -0.0977,  0.0897, -0.0333, -0.2805,\n","          0.1455, -0.0197, -0.2215,  0.0341,  0.3492, -0.0611, -0.0934,  0.1339,\n","         -0.0987,  0.0366, -0.1223, -0.0775,  0.0543,  0.2306, -0.1063, -0.0301,\n","         -0.1709, -0.1352,  0.0787,  0.1328,  0.0218, -0.0267, -0.2936,  0.1577,\n","         -0.2909, -0.0100,  0.0078, -0.2154, -0.1283,  0.0276,  0.2323, -0.0767,\n","         -0.0893, -0.0072, -0.0190,  0.0100,  0.1073, -0.0219,  0.0914, -0.2090],\n","        [-0.0053, -0.0130, -0.1577, -0.0767,  0.0853,  0.0360,  0.0105,  0.0320,\n","         -0.1390,  0.0143,  0.0884, -0.0620, -0.0025, -0.0230,  0.1482,  0.1071,\n","         -0.1584,  0.1008, -0.1102,  0.0537, -0.2433, -0.0812, -0.0372,  0.0606,\n","          0.0308,  0.0337, -0.0666, -0.1019, -0.1692, -0.1300,  0.0559, -0.0399,\n","         -0.1213, -0.0511,  0.0150,  0.1218,  0.2077,  0.0753,  0.0415, -0.0302,\n","          0.0058, -0.1171,  0.1549,  0.0287, -0.0452, -0.1570, -0.0238, -0.1625,\n","         -0.0535,  0.0714, -0.0331, -0.0426,  0.1067,  0.0392, -0.0859,  0.1046,\n","          0.2720,  0.2062,  0.1160, -0.0629, -0.0293,  0.0842,  0.0225,  0.0506]],\n","       device='cuda:0', requires_grad=True)\n","blocks.9.attn.b_V: torch.Size([12, 64])\n","Parameter containing:\n","tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n","       device='cuda:0', requires_grad=True)\n","blocks.9.mlp.W_in: torch.Size([768, 3072])\n","Parameter containing:\n","tensor([[-0.1263,  0.1003,  0.0432,  ...,  0.2170,  0.0198, -0.1404],\n","        [-0.0915,  0.0872,  0.0615,  ...,  0.0048, -0.1113, -0.2263],\n","        [ 0.1290,  0.0250,  0.1792,  ..., -0.1480,  0.2844,  0.1908],\n","        ...,\n","        [ 0.1656,  0.1988, -0.1999,  ..., -0.0282, -0.0565,  0.1884],\n","        [-0.0513, -0.0398,  0.3159,  ..., -0.0569,  0.1251,  0.1349],\n","        [ 0.0052, -0.0937, -0.2332,  ...,  0.0320, -0.0762, -0.1115]],\n","       device='cuda:0', requires_grad=True)\n","blocks.9.mlp.b_in: torch.Size([3072])\n","Parameter containing:\n","tensor([-0.1567, -0.0586, -0.1862,  ..., -0.0808, -0.1747,  0.0605],\n","       device='cuda:0', requires_grad=True)\n","blocks.9.mlp.W_out: torch.Size([3072, 768])\n","Parameter containing:\n","tensor([[ 0.2813, -0.0430, -0.1807,  ..., -0.0268, -0.0099,  0.1054],\n","        [-0.1153, -0.1000, -0.1819,  ..., -0.5141, -0.0151, -0.3968],\n","        [-0.0404,  0.1570, -0.1183,  ..., -0.2827,  0.1967, -0.1631],\n","        ...,\n","        [-0.1986, -0.0699,  0.0277,  ..., -0.1114,  0.0991, -0.1837],\n","        [-0.0446,  0.1790, -0.0538,  ...,  0.1366, -0.1700, -0.0059],\n","        [ 0.1810,  0.1191, -0.1690,  ..., -0.1463, -0.1032,  0.0144]],\n","       device='cuda:0', requires_grad=True)\n","blocks.9.mlp.b_out: torch.Size([768])\n","Parameter containing:\n","tensor([-4.6645e-02, -1.0990e-01, -2.7257e-01,  1.5499e-01,  9.7615e-02,\n","        -2.4267e-01,  1.6664e-01,  1.7415e-01,  1.8233e-01,  7.1084e-02,\n","        -1.8766e-01, -4.9556e-02,  1.0335e-01,  2.1693e-01, -1.6183e-01,\n","         3.8626e-02, -3.9116e-02,  2.3063e-01,  1.5293e-01, -1.0322e-01,\n","         8.1140e-02,  1.3819e-02, -1.8062e-03, -2.9647e-02, -2.4134e-01,\n","        -1.3232e-02, -2.0712e-01,  9.7280e-02, -4.8264e-03,  1.3334e-02,\n","         2.5184e-02, -1.3851e-02,  1.5864e-01, -1.7938e-01,  4.9989e-03,\n","        -4.4017e-02,  2.1377e-01, -2.7572e-02,  2.3475e-02,  1.6258e-02,\n","         8.5390e-02, -1.3142e-01,  3.6655e-02,  6.3542e-02, -1.7329e-01,\n","        -3.1277e-01,  6.0763e-02,  1.5423e-01, -6.6386e-02,  1.4715e-01,\n","         2.4128e-01,  3.6907e-02, -6.8389e-02, -1.0475e-01,  1.4493e-01,\n","         8.3119e-02, -2.1339e-01,  3.3495e-02, -6.9378e-02, -6.9432e-02,\n","        -7.5200e-02, -1.0936e-02,  1.8573e-01, -2.1191e-01, -3.9096e-01,\n","         8.4828e-02, -1.5332e-01,  1.1962e-01, -1.9299e-01, -7.5922e-02,\n","         2.8689e-01, -1.0406e-01,  4.3814e-02, -8.8036e-02,  1.0242e-01,\n","         1.3584e-01,  1.9973e-02, -2.2582e-01, -1.9397e-01, -3.7615e-02,\n","        -4.3179e-03,  2.0579e-01,  3.5219e-02, -1.0143e-01,  1.6486e-02,\n","         6.2673e-02,  2.5071e-01, -1.5815e-02, -1.5148e-01, -2.1676e-03,\n","         7.3065e-03,  1.0322e-01, -7.1201e-02,  4.8543e-02, -7.6900e-02,\n","         6.1005e-03, -4.4881e-02,  1.0420e-01,  2.7540e-01, -1.3834e-01,\n","        -1.5979e-01,  2.1070e-02,  1.5638e-01,  1.5513e-01, -1.8610e-02,\n","         5.9736e-02,  2.6548e-01, -5.1591e-02, -1.9993e-01,  2.3214e-01,\n","         4.4893e-02,  4.5724e-02,  9.2505e-02,  1.7909e-01, -5.0144e-02,\n","         1.5815e-01,  2.4626e-02, -1.1860e-01,  1.0602e-01, -1.6652e-01,\n","         2.6053e-01,  1.2638e-01,  1.9932e-01,  1.7970e-01,  2.7137e-01,\n","         1.3657e-01, -2.9675e-02, -1.8606e-01, -1.2305e-01,  8.8590e-02,\n","        -2.4939e-02,  1.3136e-01, -5.0992e-02,  8.7640e-02,  2.7342e-01,\n","         1.5242e-02,  1.4187e-01, -1.2874e-01, -2.3542e-01,  1.0312e-02,\n","         1.2333e-01,  5.5724e-02,  7.8074e-02, -1.3216e-01, -2.8968e-01,\n","         6.1413e-02, -5.1442e-03,  1.4312e-01, -2.2536e-01, -1.4487e-01,\n","        -1.3377e-01,  1.2375e-01,  2.0242e-01,  1.8884e-01,  7.4498e-02,\n","        -3.0417e-02,  1.0066e-01, -1.4598e-02,  1.6901e-01, -1.9318e-01,\n","         3.1864e-02,  8.5186e-02, -4.9956e-02,  8.5447e-02,  6.0868e-02,\n","         5.8474e-02, -5.4050e-02, -1.4979e-01,  3.8467e-02,  9.8465e-02,\n","        -2.3694e-01,  1.1825e-02,  5.2717e-02, -1.8730e-02,  1.2019e-02,\n","        -9.4906e-02, -1.5321e-01,  5.6207e-02,  2.0627e-02, -5.7167e-02,\n","        -1.5878e-02, -3.7366e-02,  7.0670e-02, -1.9443e-02, -1.2266e-01,\n","        -4.2204e-02, -1.3531e-01, -9.4064e-02, -9.0040e-02,  2.9191e-02,\n","         2.0907e-01, -2.3428e-01, -1.2359e-01, -1.4506e-01,  1.8681e-01,\n","        -8.5629e-02, -2.9228e-01, -6.9232e-03,  1.5759e-01,  5.3033e-02,\n","         1.5142e-01, -8.3449e-02,  1.7208e-02,  1.3312e-01,  1.2606e-01,\n","         5.0882e-02, -2.2798e-01, -1.9043e-03,  5.1293e-02, -1.7704e-01,\n","        -5.4751e-02,  3.8875e-03,  5.6078e-02,  7.9638e-02,  7.3502e-02,\n","        -1.3192e-01,  6.5902e-02, -6.1788e-02,  2.0751e-01,  2.9838e-02,\n","         5.9709e-02, -5.8736e-02,  9.6689e-02,  6.3798e-02,  1.1788e-01,\n","        -3.5596e-03,  1.1808e-01,  5.4177e-03,  1.5647e-01, -1.2298e-01,\n","         2.0457e-01,  2.7301e-02,  2.1531e-01, -1.1098e-01,  1.2113e-01,\n","         1.8815e-02,  1.4313e-01, -3.5198e-02,  1.4577e-01,  1.2122e-02,\n","         2.0972e-01, -7.5843e-03,  1.2801e-01, -1.8500e-01, -9.0361e-02,\n","         1.1041e-01,  8.3758e-02,  1.7638e-01, -1.4093e-01, -4.4593e-02,\n","        -8.7552e-03,  2.0834e-01,  1.5022e-01, -8.1232e-02, -6.9706e-02,\n","         1.5197e-01, -1.3750e-01, -8.6779e-02,  2.3159e-01, -7.7275e-02,\n","         2.2492e-02,  1.7563e-01, -1.5183e-01, -1.1455e-01, -2.8734e-01,\n","        -1.2182e-01,  1.4882e-01,  1.0653e-01, -1.2947e-01,  1.1363e-01,\n","        -3.6037e-01,  8.9070e-02,  1.1562e-02, -1.0585e-01,  1.1428e-01,\n","         2.8572e-02,  1.7015e-01, -5.6327e-02,  4.8283e-02,  1.6017e-01,\n","        -7.6671e-02, -1.1675e-01,  1.5664e-01, -2.1910e-01,  1.1274e-01,\n","        -2.0155e-02, -1.4090e-01,  2.3459e-01,  6.4530e-02, -6.0280e-02,\n","        -1.2191e-01, -6.3197e-02,  6.2332e-02,  1.1732e-03, -3.3251e-01,\n","         1.3410e-01,  1.0073e-01,  2.4873e-01, -1.4790e-01, -1.2361e-01,\n","         1.2249e-01, -2.4586e-01,  7.7483e-02,  1.1315e-02, -9.8362e-02,\n","        -2.0711e-01, -6.6671e-02,  1.7929e-01, -2.8183e-01,  7.2839e-02,\n","        -1.8233e-01, -2.0555e-01,  1.1689e-01, -7.1077e-02, -4.5069e-01,\n","        -1.8665e-01,  2.2080e-01,  1.2884e-01,  3.5437e-02, -7.1610e-02,\n","        -3.2340e-01, -4.6526e-02,  1.4190e-01,  9.2176e-02,  4.4605e-02,\n","         9.8919e-02,  1.8468e-01,  8.4106e-02, -1.7906e-02,  3.9992e-02,\n","         1.4725e-01,  8.5672e-02, -1.4753e-02,  6.3064e-03,  7.6518e-03,\n","        -1.2123e-02, -2.3181e-01, -3.4100e-02, -2.1264e-02,  7.2029e-03,\n","        -2.2954e-01, -4.0891e-02, -8.7613e-03, -6.9527e-02,  4.1800e-02,\n","        -1.3394e-01, -1.5761e-02,  9.2174e-02, -9.0727e-04, -2.1286e-01,\n","         9.6180e-02,  3.4437e-02,  1.0252e-01, -2.6328e-01, -6.3576e-02,\n","         1.6987e-02, -3.2421e-01,  2.8497e-01, -2.2376e-01,  5.3744e-02,\n","        -2.1846e-01,  7.2129e-02,  2.6935e-01,  2.3953e-01,  2.6346e-01,\n","         5.1689e-02,  3.1074e-02,  1.9459e-02, -3.6945e-02, -1.5042e-02,\n","        -1.7358e-01,  1.3155e-01, -1.4216e-01, -1.2830e+00, -1.8172e-01,\n","        -2.1910e-01, -1.4435e-01,  1.3411e-01,  2.6381e-01,  8.8686e-02,\n","        -1.3577e-01, -3.0493e-04, -1.3565e-01,  2.2613e-01, -1.7768e-01,\n","        -1.1167e-01,  2.5651e-02,  8.4247e-02,  4.7100e-02, -1.4081e-01,\n","         2.8840e-03, -1.9117e-01,  6.2996e-02,  2.0388e-01, -2.1876e-02,\n","        -1.2601e-01, -2.1485e-02, -7.1363e-02,  2.0348e-01, -1.2332e-01,\n","         7.6071e-02,  1.9128e-01,  2.7049e-01,  6.0912e-02,  7.4316e-02,\n","         1.5869e-02, -8.8610e-02,  3.8557e-02,  4.3029e-01,  1.5355e-02,\n","        -1.1744e-01,  2.2373e-01, -5.0764e-02,  1.6264e-01,  1.5239e-02,\n","         2.1836e-02, -1.3108e-01, -3.0124e-02, -4.8933e-03,  2.2778e-01,\n","        -1.1355e-01,  6.0990e-02, -9.9982e-02, -1.5382e-01,  7.5107e-02,\n","         3.0128e-01,  3.1461e-02,  5.1018e-02, -1.5052e-01, -2.4927e-01,\n","         2.1779e-01,  1.7069e-02, -1.9073e-01,  8.2023e-02,  1.7980e-01,\n","         5.8830e-02, -7.8000e-02,  1.5013e-02,  1.1365e-01,  1.3778e-02,\n","         1.4144e-01,  6.3252e-02, -1.2104e-01, -8.6013e-02, -3.5023e-02,\n","        -3.0819e-02,  7.0698e-02,  1.1305e+00,  6.6620e-02,  1.2980e-02,\n","         1.5430e-01,  1.1084e-01, -3.1931e-02, -2.2845e-01,  1.5752e-01,\n","         3.1179e-01,  1.1690e-02, -1.1666e-01,  6.6314e-02, -1.4804e-02,\n","        -1.0173e-01, -2.0323e-01,  3.8088e-02,  1.5078e-01,  4.4971e-02,\n","        -2.7317e-01,  3.9841e-02,  3.8331e-02,  4.6648e-02, -8.5646e-02,\n","        -1.1726e-01, -8.1172e-02, -1.3430e-01, -2.2710e-01, -1.2536e-01,\n","        -7.4126e-02,  1.5675e-02,  1.3557e-01, -1.4051e-01, -1.5143e-01,\n","        -4.9571e-02,  1.4896e+00,  4.2735e-02, -4.1363e-02, -2.0904e-02,\n","         6.3417e-02, -1.4033e-01, -6.3794e-02,  1.7028e-01,  3.8541e-02,\n","        -1.2516e-01, -9.4359e-02,  8.2163e-02,  1.2015e-01,  1.7628e-01,\n","         9.5908e-02,  1.2566e-01, -1.9221e-01,  1.1375e-01,  5.1612e-02,\n","         1.2616e-01,  3.8993e-02,  8.8228e-02, -1.0839e-01, -1.4850e-01,\n","         6.6314e-05, -7.7564e-02, -6.3030e-03,  1.5601e-01,  1.8852e-01,\n","        -1.6829e-01, -8.9566e-02,  2.7002e-01, -1.1344e-01, -5.9498e-02,\n","         8.8728e-02,  4.1073e-02,  1.1490e-01,  1.0474e-01, -3.9621e-02,\n","         4.2453e-02, -1.3514e-01,  1.4181e-01,  5.7557e-02,  4.7732e-02,\n","        -1.8116e-01, -1.6362e-01, -2.6371e-01,  1.0961e-01, -1.2800e-01,\n","         4.5317e-02,  3.7697e-02,  3.9600e-03, -3.5139e-02, -1.5755e-01,\n","         8.7411e-03, -9.2033e-02, -5.7770e-02,  1.2038e-02, -1.2095e-02,\n","         1.9991e-01,  1.2894e-01, -1.0110e-01, -2.2756e-01, -1.5150e-01,\n","         1.7469e-01, -2.8941e-02,  7.0995e-02, -1.7859e-01, -1.4882e-01,\n","        -1.8845e-01,  1.6607e-01,  3.2358e-02, -1.8974e-01, -2.4711e-01,\n","         1.0224e-01, -3.4859e-02, -4.4967e-02,  1.4403e-01,  1.6580e-02,\n","         8.2170e-02, -9.8024e-02, -2.9623e-01,  1.5860e-01,  7.1731e-02,\n","         2.8512e-02,  1.8698e-02, -2.0622e-02, -7.5021e-02,  2.5783e-02,\n","        -7.0775e-02,  2.1523e-02,  2.2910e-01, -8.6382e-02, -1.2866e-01,\n","         1.1657e-01, -1.9386e-01,  1.1100e-01, -5.9276e-02, -1.6057e-01,\n","         1.7637e-02,  1.6796e-02, -4.7407e-02, -1.0866e-01,  1.8590e-01,\n","        -7.7290e-02, -6.0036e-02,  1.3764e-02, -2.3848e-02,  1.2234e-01,\n","        -1.6364e-01, -1.1911e-01, -3.4663e-02, -9.7506e-02,  3.1605e-01,\n","        -1.6558e-01,  3.2261e-02, -1.0310e-01, -8.4768e-02, -1.9401e-01,\n","        -2.0051e-02, -2.2758e-01, -1.2467e-01,  1.8934e-01,  1.5265e-01,\n","        -1.2989e-01,  3.5823e-02, -2.3359e-01,  2.1274e-01,  1.4823e-01,\n","        -1.5298e-01, -2.4177e-02, -1.2925e-01, -2.5155e-02, -8.6855e-02,\n","         1.7696e-02,  1.9299e-01, -2.6344e-01, -8.2949e-02,  1.9863e-01,\n","        -2.5698e-01, -9.6519e-02, -1.8943e-01, -2.2586e-01, -1.2087e-01,\n","        -1.3587e-01, -1.5572e-01, -1.5387e-01,  1.3237e-01,  1.3065e-01,\n","        -1.7808e-01,  1.9847e-01,  1.2240e-01, -9.0830e-02,  7.8478e-03,\n","        -6.0225e-02, -1.4847e-01,  2.2021e-01,  3.8675e-02,  1.0557e-01,\n","         2.0231e-01,  1.0333e-02, -3.9311e-02, -2.5853e-01, -5.2108e-03,\n","        -8.4177e-02, -9.7600e-02,  5.6339e-02,  2.3896e-01, -9.7650e-02,\n","        -7.5705e-02,  2.6809e-01, -3.0667e-02, -2.0390e-01, -1.5002e-01,\n","         1.1131e-01, -6.1663e-02,  9.7560e-02, -2.2336e-02,  5.3332e-02,\n","         1.3491e-01,  3.6292e-02,  3.3832e-02,  7.0793e-02, -2.2014e-03,\n","         2.5348e-01,  1.7549e-02, -9.4112e-02,  1.4941e-01,  2.5454e-01,\n","        -7.3731e-02, -5.2944e-02, -2.0348e-01, -7.6453e-03,  8.4055e-02,\n","        -5.7725e-02,  1.9312e-01,  3.9951e-01,  1.0299e-01,  2.2905e-01,\n","        -1.0512e-01, -1.7754e-01,  1.2691e-01, -3.4129e-02, -3.1649e-01,\n","        -1.3639e-01, -7.3219e-02, -2.7001e-02,  4.1069e-02,  1.1430e-02,\n","         2.0258e-01,  1.6231e-01, -7.7365e-02,  3.0301e-01, -5.8596e-02,\n","        -5.9156e-02,  4.5032e-02, -2.9409e-02,  9.6740e-02, -8.4039e-02,\n","         1.5169e-01,  5.2729e-02, -6.4264e-02, -1.3393e-01,  1.3587e-01,\n","         1.7235e-02, -1.4441e-01,  3.5125e-02,  3.2920e-02,  8.8476e-03,\n","         8.5842e-02, -1.7053e-01, -1.0479e-01, -3.4624e-02, -3.5924e-02,\n","         5.6040e-02, -1.7124e-01, -4.1189e-02,  2.0853e-01,  1.0226e-01,\n","         1.5869e-01, -1.5678e-01, -9.4734e-02, -5.8940e-02,  2.2240e-01,\n","         2.2156e-01, -1.9327e-02, -1.2897e-01, -2.2394e-01, -4.4447e-02,\n","         7.5848e-02, -2.4911e-01,  1.3489e-01, -1.3736e-01,  8.6539e-02,\n","         5.9652e-03, -1.8353e-01, -5.8970e-02, -7.3803e-02, -3.1374e-01,\n","        -1.7683e-01,  8.5927e-02,  1.8984e-02, -1.9906e-01, -2.5258e-02,\n","        -1.9547e-01, -1.4445e-01, -4.0224e-02, -5.2308e-02,  1.1811e-02,\n","         1.2978e-01, -5.4838e-02,  1.8505e-01,  1.0740e-01, -1.0936e-02,\n","        -7.7379e-02,  1.4461e-03, -1.2349e-01,  2.4152e-02,  2.1144e-01,\n","        -1.5100e-01,  1.2033e-01,  2.1154e-01, -7.1171e-02,  5.5354e-02,\n","         1.4147e-02,  4.3370e-02, -1.8958e-01], device='cuda:0',\n","       requires_grad=True)\n","blocks.10.ln1.w: torch.Size([768])\n","Parameter containing:\n","tensor([0.4269, 0.3799, 0.3893, 0.3629, 0.3722, 0.3487, 0.5020, 0.3584, 0.3821,\n","        0.3207, 0.4149, 0.3587, 0.3574, 0.3838, 0.4463, 0.3977, 0.3977, 0.3702,\n","        0.3779, 0.3975, 0.3311, 0.3544, 0.3800, 0.4131, 0.3798, 0.3877, 0.4171,\n","        0.3595, 0.3612, 0.3603, 0.3588, 0.4113, 0.3604, 0.3545, 0.3667, 0.4339,\n","        0.3249, 0.3704, 0.3545, 0.3721, 0.3368, 0.3487, 0.3353, 0.3564, 0.3506,\n","        0.3993, 0.3607, 0.3410, 0.4021, 0.3760, 0.3486, 0.3444, 0.3885, 0.3701,\n","        0.3740, 0.3779, 0.3729, 0.4284, 0.3385, 0.4539, 0.3883, 0.3629, 0.4170,\n","        0.3713, 0.9214, 0.3348, 0.3570, 0.4068, 0.4061, 0.3641, 0.3857, 0.3037,\n","        0.3584, 0.3480, 0.3252, 0.3683, 0.4444, 0.4629, 0.3827, 0.3628, 0.3694,\n","        0.3467, 0.3526, 0.3801, 0.3851, 0.4228, 0.4093, 0.7403, 0.3598, 0.3877,\n","        0.3584, 0.3423, 0.3475, 0.3584, 0.3424, 0.3330, 0.3847, 0.4186, 0.4209,\n","        0.4701, 0.3586, 0.3724, 0.4209, 0.3873, 0.3735, 0.3428, 0.4019, 0.3808,\n","        0.3334, 0.3721, 0.3839, 0.3805, 0.3675, 0.3779, 0.3794, 0.3740, 0.4325,\n","        0.3949, 0.3448, 0.4574, 0.3780, 0.3578, 0.3412, 0.3506, 0.4140, 0.3799,\n","        0.3388, 0.4181, 0.3878, 0.3740, 0.3879, 0.3373, 0.4092, 0.3597, 0.3545,\n","        0.3415, 0.3582, 0.4604, 0.2745, 0.3591, 0.3707, 0.3878, 0.4010, 0.3506,\n","        0.4058, 0.3760, 0.3916, 0.3913, 0.3663, 0.3670, 0.3782, 0.3946, 0.4417,\n","        0.4209, 0.3869, 0.3525, 0.3730, 0.3864, 0.3505, 0.4150, 0.4600, 0.3799,\n","        0.3870, 0.4170, 0.3722, 0.3547, 0.3877, 0.5442, 0.3619, 0.3896, 0.3617,\n","        0.3643, 0.3731, 0.3980, 0.3877, 0.3663, 0.3780, 0.3408, 0.4256, 0.3529,\n","        0.3271, 0.3438, 0.3584, 0.4188, 0.3390, 0.3503, 0.3532, 0.3881, 0.3629,\n","        0.3963, 0.3746, 0.3604, 0.3701, 0.3977, 0.3623, 0.4951, 0.3287, 0.3498,\n","        0.3665, 0.4218, 0.3889, 0.4014, 0.3759, 0.3662, 0.3255, 0.3897, 0.3525,\n","        0.3092, 0.4251, 0.3579, 0.3555, 0.4457, 0.3956, 0.4703, 0.3759, 0.3488,\n","        0.4288, 0.3623, 0.2928, 0.3678, 0.3938, 0.3628, 0.3643, 0.4017, 0.3761,\n","        0.3565, 0.3459, 0.3525, 0.3604, 0.3486, 0.3274, 0.3842, 0.4756, 0.3351,\n","        0.3486, 0.3936, 0.3776, 0.3408, 0.4105, 0.3850, 0.4303, 0.4073, 0.3716,\n","        0.3623, 0.3284, 0.3761, 0.3558, 0.4561, 0.3662, 0.3891, 0.3492, 0.3952,\n","        0.3525, 0.4122, 0.3604, 0.4110, 0.3520, 0.3603, 0.3528, 0.3653, 0.3701,\n","        0.3705, 0.3632, 0.3702, 0.3464, 0.3315, 0.9082, 0.4844, 0.3878, 0.4224,\n","        0.4873, 0.5058, 0.3504, 0.3468, 0.4508, 0.3556, 0.4170, 0.3428, 0.3680,\n","        0.3494, 0.3252, 0.3216, 0.3488, 0.5176, 0.4359, 0.4386, 0.4021, 0.3604,\n","        0.6687, 0.4509, 0.3995, 0.3760, 0.3447, 0.3291, 0.4286, 0.3506, 0.3464,\n","        0.3728, 0.3721, 0.3877, 0.3631, 0.3889, 0.4053, 0.3542, 0.3467, 0.3470,\n","        0.3740, 0.3438, 0.3880, 0.3232, 0.3345, 0.4736, 0.3486, 0.3643, 0.2282,\n","        0.3596, 0.4405, 0.3682, 0.3545, 0.4109, 0.3877, 0.3549, 0.3821, 0.4138,\n","        0.3649, 0.3937, 0.4467, 0.3380, 0.3823, 0.3390, 0.3613, 0.3486, 0.3947,\n","        0.3479, 0.3369, 0.3642, 0.4576, 0.3565, 0.3604, 0.4678, 0.3507, 0.3409,\n","        0.3938, 0.4287, 0.3874, 0.3395, 0.3938, 0.3597, 0.3819, 0.3784, 0.3355,\n","        0.4237, 0.3854, 0.3697, 0.3742, 0.3560, 0.4006, 0.3878, 0.3462, 0.3679,\n","        0.4106, 0.3858, 0.4077, 0.3658, 0.3292, 0.4183, 0.3876, 0.3637, 0.3541,\n","        0.3504, 0.3995, 0.3469, 0.3624, 0.0751, 0.3525, 0.4702, 0.3971, 0.4287,\n","        0.2670, 0.3829, 0.3473, 0.3740, 0.3528, 0.4322, 0.3682, 0.4757, 0.4069,\n","        0.3330, 0.3643, 0.3799, 0.3565, 0.3373, 0.3736, 0.7194, 0.3672, 0.3409,\n","        0.3674, 0.3385, 0.3377, 0.3506, 0.3413, 0.3721, 0.4098, 0.3594, 0.3478,\n","        0.3721, 0.4006, 0.3331, 0.3447, 0.3565, 0.3330, 0.3424, 0.3428, 0.3373,\n","        0.3643, 0.3677, 0.3486, 0.4034, 0.4038, 0.3532, 0.3037, 0.4288, 0.3565,\n","        0.3787, 0.3585, 0.3193, 0.3662, 0.3684, 0.3512, 0.3473, 0.2831, 0.3468,\n","        0.3501, 0.3975, 0.3371, 0.4131, 0.3237, 0.3936, 0.3959, 0.4275, 0.3546,\n","        0.3813, 0.3963, 0.3406, 0.4351, 0.3786, 0.3426, 0.0793, 0.3633, 0.3564,\n","        0.3762, 0.3504, 0.3385, 0.4036, 0.3662, 0.4053, 0.3807, 0.3608, 0.3440,\n","        0.3097, 0.3402, 0.4296, 0.3451, 0.3604, 0.2707, 0.3778, 0.3840, 0.3506,\n","        0.3514, 0.3593, 0.3371, 0.4033, 0.3897, 0.3751, 0.3271, 0.3663, 0.3678,\n","        0.3529, 0.3464, 0.4229, 0.7445, 0.0817, 0.3701, 0.3506, 0.4114, 0.3385,\n","        0.3502, 0.3604, 0.3820, 0.3760, 0.3740, 0.4229, 0.3527, 0.3547, 0.3826,\n","        0.3491, 0.2555, 0.3135, 0.3976, 0.3545, 0.3741, 0.3881, 0.3794, 0.4218,\n","        0.4206, 0.3507, 0.3447, 0.3866, 0.4392, 0.3490, 0.3339, 0.3701, 0.3780,\n","        0.3899, 0.3635, 0.4133, 0.3878, 0.3506, 0.3316, 0.3702, 0.3428, 0.3724,\n","        0.3866, 0.3740, 0.3621, 0.3695, 0.5004, 0.4188, 0.4083, 0.3567, 0.3604,\n","        0.3875, 0.3604, 0.3508, 0.3427, 0.4058, 0.3494, 0.3581, 0.3841, 0.3709,\n","        0.3975, 0.3938, 0.3547, 0.3913, 0.3528, 0.3857, 0.4092, 0.3637, 0.3604,\n","        0.4512, 0.3335, 0.4250, 0.3740, 0.3817, 0.4403, 0.3930, 0.3623, 0.3752,\n","        0.3800, 0.3534, 0.3797, 0.3926, 0.3470, 0.3711, 0.3545, 0.3976, 0.4579,\n","        0.3926, 0.3929, 0.4056, 0.4692, 0.4213, 0.3706, 0.3444, 0.3660, 0.4895,\n","        0.3365, 0.3584, 0.4805, 0.3617, 0.3545, 0.3374, 0.4227, 0.3780, 0.3525,\n","        0.4015, 0.3311, 0.4190, 0.3645, 0.3760, 0.3750, 0.3546, 0.3500, 0.3741,\n","        0.3622, 0.3557, 0.3994, 0.3468, 0.3529, 0.3643, 0.3603, 0.3565, 0.3712,\n","        0.3629, 0.3825, 0.3493, 0.3762, 0.3700, 0.4971, 0.3995, 0.3662, 0.3802,\n","        0.3957, 0.3652, 0.3694, 0.3959, 0.4159, 0.3516, 0.4100, 0.3723, 0.3806,\n","        0.3580, 0.3900, 0.3955, 0.3956, 0.3434, 0.3506, 0.3741, 0.3774, 0.3721,\n","        0.3769, 0.3700, 0.3580, 0.3467, 0.3721, 0.4273, 0.3748, 0.3468, 0.3407,\n","        0.4152, 0.5294, 0.3857, 0.3896, 0.4077, 0.4439, 0.3799, 0.3541, 0.4308,\n","        0.3727, 0.4526, 0.3488, 0.4519, 0.4253, 0.3896, 0.3559, 0.3797, 0.3531,\n","        0.3832, 0.3592, 0.4759, 0.3464, 0.4093, 0.3818, 0.3389, 0.3770, 0.4151,\n","        0.3417, 0.3628, 0.3565, 0.3741, 0.4168, 0.3625, 0.3644, 0.3720, 0.3192,\n","        0.3486, 0.3301, 0.3642, 0.4055, 0.5101, 0.3756, 0.3604, 0.3867, 0.3780,\n","        0.3490, 0.3807, 0.4044, 0.3124, 0.3692, 0.3579, 0.3563, 0.3252, 0.3525,\n","        0.3859, 0.3624, 0.3754, 0.3485, 0.3446, 0.3584, 0.4422, 0.3619, 0.4193,\n","        0.3468, 0.4541, 0.3491, 0.3587, 0.4319, 0.4347, 0.3656, 0.4070, 0.4190,\n","        0.3837, 0.3899, 0.3525, 0.3579, 0.3858, 0.3467, 0.3527, 0.4534, 0.3567,\n","        0.3506, 0.4093, 0.3447, 0.3662, 0.3467, 0.3721, 0.4247, 0.4153, 0.4012,\n","        0.3857, 0.3780, 0.3708, 0.3316, 0.3564, 0.3564, 0.3896, 0.3534, 0.3613,\n","        0.4041, 0.4477, 0.4032, 0.3485, 0.3692, 0.4135, 0.3936, 0.2861, 0.4619,\n","        0.3525, 0.4006, 0.3798, 0.3356, 0.3679, 0.3562, 0.3254, 0.3975, 0.4228,\n","        0.2575, 0.3506, 0.3588, 0.3804, 0.3326, 0.3760, 0.4110, 0.3343, 0.3214,\n","        0.3534, 0.3275, 0.3462], device='cuda:0', requires_grad=True)\n","blocks.10.ln1.b: torch.Size([768])\n","Parameter containing:\n","tensor([ 3.0510e-02,  6.0018e-03,  4.8768e-02,  1.1650e-02,  5.8796e-03,\n","         1.0598e-02, -6.7249e-02,  2.5557e-02,  1.3905e-02,  6.4351e-04,\n","         7.5819e-03,  1.2247e-02,  2.6726e-02,  2.7891e-02,  4.7979e-02,\n","        -4.1496e-03,  4.0992e-02,  3.4726e-02, -1.0701e-03,  1.3254e-02,\n","         3.3631e-02,  2.3287e-02,  2.1054e-02,  2.5587e-02,  2.0324e-02,\n","         6.3015e-03, -1.6431e-03,  1.5146e-02,  2.8475e-02,  6.5443e-03,\n","         1.0149e-02, -6.4570e-03, -9.9454e-03,  2.3009e-02,  2.5093e-02,\n","         5.7307e-02, -2.3542e-02,  5.4855e-03,  3.6255e-02,  6.7605e-05,\n","         3.6737e-03, -2.2789e-03, -6.6622e-03,  1.3133e-02,  3.4681e-02,\n","         1.6549e-02,  1.7798e-02,  9.1896e-03,  7.5546e-03,  5.7225e-03,\n","         3.0501e-02, -7.7824e-03,  1.6269e-02, -1.4698e-02,  1.7723e-02,\n","        -1.2181e-02, -3.4919e-03,  2.8184e-02,  5.7460e-04,  1.9307e-02,\n","         2.8484e-02,  2.0697e-02,  3.4364e-02,  5.2619e-03,  1.0895e+00,\n","         8.9252e-03, -1.7973e-02, -2.6218e-02,  4.1295e-02,  1.5583e-02,\n","         4.8572e-03,  2.7360e-02,  2.5208e-02,  2.6618e-02,  2.2383e-02,\n","         3.0180e-02, -2.0396e-02,  1.3613e-02,  1.3994e-02,  3.2356e-02,\n","         4.5118e-02,  1.0150e-02,  1.5576e-02,  2.3248e-02,  6.8681e-02,\n","         2.1442e-02,  3.6212e-02, -1.7378e-03,  1.6896e-02,  2.0278e-02,\n","         1.5742e-03,  1.2599e-02,  4.4826e-02, -8.9105e-04,  1.5220e-02,\n","         1.0788e-02,  6.8030e-03,  2.6381e-02,  3.6601e-02,  6.5487e-02,\n","         3.1313e-03, -2.7101e-02, -3.9119e-02,  1.7792e-02,  2.0577e-02,\n","         2.1596e-02,  3.7847e-02,  1.0212e-02,  7.9026e-03,  1.4136e-02,\n","         1.0731e-02,  2.6045e-02,  1.9629e-02,  5.3064e-02,  1.7490e-02,\n","        -7.8047e-03,  5.6762e-02,  1.0151e-02,  3.9767e-02,  4.1502e-02,\n","         2.9220e-02,  1.8263e-02,  3.7876e-03, -2.8561e-03,  4.4087e-03,\n","         3.1142e-02,  1.5206e-02,  4.4540e-02,  4.8803e-02,  2.2513e-02,\n","         1.9234e-02,  2.6071e-02,  1.8358e-02,  1.0985e-02,  1.7072e-02,\n","         1.1037e-02,  2.7748e-02,  4.3213e-02, -6.5276e-01, -1.0676e-03,\n","         4.7908e-03, -5.9358e-03,  4.9437e-02,  2.0611e-02,  1.2362e-02,\n","        -1.6437e-02, -1.2943e-02,  7.8778e-03,  7.7959e-03,  2.8179e-02,\n","         4.6312e-02, -3.7110e-02,  1.7228e-02,  2.0611e-02,  2.1190e-03,\n","         6.7950e-04,  1.7173e-02,  2.7729e-02,  9.7434e-03, -1.8524e-02,\n","        -4.4523e-02,  1.8437e-02,  1.0640e-02,  2.7398e-02,  2.5514e-02,\n","         4.5742e-02,  1.2592e-03,  1.3448e-01,  1.7151e-03,  3.0443e-02,\n","         1.3813e-02,  2.7351e-02,  3.7165e-02,  2.1619e-02,  3.5051e-02,\n","         3.2485e-02,  7.6267e-02,  1.8186e-02, -6.8216e-03,  1.6186e-02,\n","         2.4216e-02, -2.9053e-03,  3.0967e-02,  3.0941e-02,  4.1112e-02,\n","         1.6433e-02,  6.9999e-03,  1.0342e-02,  1.1311e-02, -1.0954e-02,\n","         1.7435e-02,  4.8904e-02,  2.9742e-02,  1.6672e-02,  3.0743e-02,\n","         9.5988e-02,  2.1865e-02,  4.1136e-02,  4.5287e-02,  2.8203e-02,\n","         6.6434e-03,  7.2262e-03,  2.5223e-02,  2.5595e-02,  1.0206e-02,\n","         1.4698e-02,  3.6713e-02,  2.1287e-02,  2.7897e-02,  8.4845e-03,\n","        -3.1251e-03,  4.7961e-02,  3.6884e-02,  4.4813e-02,  3.6081e-02,\n","         2.1300e-02,  1.9595e-02,  1.8230e-02,  4.9084e-02,  1.8052e-02,\n","         8.8896e-03,  2.7559e-02,  3.0454e-03,  8.2039e-03, -1.0471e-02,\n","        -2.6374e-04,  5.2323e-03,  2.1517e-02,  3.4661e-02,  5.8228e-03,\n","         2.0718e-02,  6.4387e-03, -2.5122e-02,  1.8809e-02,  7.2337e-03,\n","         7.7876e-03,  1.5827e-02,  1.1656e-02,  2.1921e-02,  1.4640e-02,\n","         3.8638e-02,  1.1814e-02,  2.4043e-02,  1.2504e-02,  2.3457e-02,\n","         8.9652e-04,  4.5214e-03,  2.9194e-02,  2.6070e-02,  2.9030e-02,\n","         3.8022e-02,  4.5631e-02,  5.0841e-03,  8.6518e-03,  3.4771e-02,\n","        -2.9929e-02,  2.8767e-02,  2.6812e-02, -6.3973e-03,  2.6378e-02,\n","         1.7356e-02,  2.4563e-02,  2.6616e-02, -1.5714e-03,  3.1854e-02,\n","         1.7033e-02, -9.0867e-02, -8.8382e-03,  3.5924e-02,  2.0487e-02,\n","         3.1361e-02, -6.6589e-03,  2.1889e-02, -8.9931e-03,  1.0533e-03,\n","         2.1037e-02,  5.5251e-03,  2.7291e-02,  1.7257e-02,  4.9234e-03,\n","         1.4868e-02,  1.6623e-02,  2.9330e-03,  1.0793e-01,  1.2949e-02,\n","         1.7930e-02,  1.3331e-02,  2.7704e-02, -1.5497e-01,  6.9195e-02,\n","         1.6382e-02,  3.6435e-03,  3.6038e-02,  2.4597e-02,  2.9102e-02,\n","         2.8022e-02,  1.9410e-02,  2.1548e-02,  2.6269e-02,  4.4157e-03,\n","         1.2594e-02,  1.5880e-02, -1.2743e-02,  3.1621e-02,  5.0564e-03,\n","         3.8002e-03,  1.7110e-02,  2.5296e-02,  4.4084e-02,  2.9926e-02,\n","         8.9388e-03,  8.0685e-02,  2.9842e-02,  2.0275e-02,  1.8288e-01,\n","         1.2359e-02,  4.6401e-02, -2.3895e-03,  4.8557e-03,  1.7429e-02,\n","         4.1916e-02,  1.8273e-02,  2.0372e-02,  2.2133e-02,  3.2574e-03,\n","        -1.3338e-02, -1.8723e-01,  1.0802e-02,  1.8939e-02,  2.5256e-02,\n","         3.1490e-03,  9.3702e-03,  4.4415e-03,  7.3213e-03,  7.3003e-03,\n","         2.9991e-02,  1.6974e-02,  2.8924e-02,  2.9901e-02, -5.3843e-04,\n","         6.7884e-03,  1.4092e-02, -1.5407e-03, -4.1260e-03,  1.0127e-02,\n","        -3.5204e-03, -5.3762e-03,  2.0368e-02,  1.2082e-03,  2.2934e-02,\n","         1.5206e-02, -1.4959e-02,  1.2037e-02,  1.2362e-02, -1.2875e-02,\n","         1.6643e-02,  4.5399e-02,  3.3174e-02,  4.1726e-02,  2.6364e-02,\n","         1.2428e-02,  4.2257e-02, -3.1136e-02,  2.2604e-02,  8.6213e-03,\n","         9.7748e-02,  6.5618e-03, -2.5439e-03,  2.5821e-03,  1.2533e-02,\n","         3.2014e-02, -5.8792e-03,  3.8993e-02,  2.9207e-01,  6.5573e-02,\n","         3.7718e-03,  3.6122e-02, -8.5052e-03,  3.5195e-02,  1.1074e-02,\n","         4.3378e-02,  3.2003e-03,  2.5859e-02,  1.2299e-02,  2.2928e-02,\n","        -2.3925e-02,  1.5934e-02,  2.9323e-02, -3.9099e-03,  5.1672e-02,\n","         3.0027e-02,  2.3198e-02, -1.1945e-02, -2.1119e-01,  5.8699e-02,\n","         1.6626e-02,  4.8430e-02,  1.1477e-02,  2.9299e-02,  1.2431e-02,\n","         3.2892e-02, -2.4925e-02,  1.2931e-02,  6.6905e-03,  5.6148e-03,\n","         3.2051e-02, -3.6190e-03,  2.8784e-02, -7.4883e-02,  1.3950e-02,\n","         2.6382e-02,  1.3927e-02,  3.2732e-02,  1.0389e-02,  3.6522e-02,\n","         3.8695e-03,  1.8970e-02,  8.8188e-03,  2.5616e-02,  1.8713e-02,\n","         2.5290e-02,  3.0087e-02,  3.5146e-02,  1.6163e-02,  1.6035e-02,\n","         3.4702e-02,  1.7713e-02,  4.2986e-02,  1.5878e-02,  1.5618e-02,\n","        -6.7364e-02,  1.6589e-02,  2.3507e-02,  2.9140e-02,  3.2753e-02,\n","        -3.6422e-03,  1.5391e-02,  8.8451e-03,  1.6420e-02, -2.5854e-03,\n","        -1.1436e-02,  4.4180e-03, -3.5285e-02,  3.6272e-02, -1.3829e-02,\n","         1.0876e-02,  4.2532e-02, -3.6222e-02,  3.4925e-02,  1.0801e-03,\n","         1.1326e-02,  1.0099e-02,  3.1453e-02, -6.8046e-03,  3.5503e-03,\n","         1.5443e-02,  4.0166e-02,  2.1864e-02,  4.5181e-05,  5.6395e-03,\n","         2.1827e-02, -1.5863e-03,  1.7870e-02,  1.5306e-02, -1.4041e-02,\n","         2.0903e-02,  1.7877e-02,  1.4547e-02,  1.1389e-02,  5.7616e-03,\n","         5.5374e-02,  2.1508e-02,  2.7936e-02,  3.7233e-02,  3.0709e-02,\n","         2.0045e-02,  2.4502e-02,  3.2306e-02,  2.4381e-02,  5.7804e-02,\n","         2.6354e-01, -3.4994e-02,  1.7011e-02,  1.8178e-02,  1.3185e-02,\n","         1.8638e-03,  1.6515e-02,  7.2046e-03, -2.0771e-02,  3.0423e-02,\n","        -1.0573e-02,  4.3190e-02,  2.9087e-02,  2.3918e-02,  1.8108e-02,\n","         2.2516e-02, -7.7928e-02,  4.8908e-02,  1.2752e-02,  9.5487e-03,\n","        -1.3659e-02,  1.6999e-02,  1.3089e-02,  1.0188e-01,  3.1624e-02,\n","         4.4236e-02,  2.6660e-03, -2.2002e-02,  9.4993e-03,  1.6732e-02,\n","         6.7471e-03,  1.0948e-02,  3.9674e-02,  2.4001e-02,  2.6092e-02,\n","         4.9369e-02,  1.8497e-02,  3.0572e-02,  3.1680e-02,  1.5310e-02,\n","         1.7420e-02,  5.5267e-02,  2.0003e-02,  9.6060e-03, -6.1582e-04,\n","         1.8077e-02,  1.8408e-01,  6.8998e-02,  3.1370e-02,  1.9246e-02,\n","         1.1786e-02, -1.2548e-02,  9.0407e-03,  2.3702e-02,  4.8123e-02,\n","         2.7501e-02,  3.3255e-02,  7.5798e-03, -1.2386e-03,  4.6698e-02,\n","        -6.0752e-03,  6.5236e-03, -4.5752e-03,  3.1878e-02,  2.2800e-02,\n","         4.0039e-02,  1.9241e-02,  1.9338e-02,  3.4379e-02,  3.2265e-02,\n","         2.6210e-02,  1.1994e-02,  1.2377e-02,  2.0400e-02,  8.6980e-02,\n","         2.9149e-03,  2.9756e-02,  2.5734e-02,  3.5196e-02,  5.1832e-02,\n","         3.8598e-02,  1.5860e-02,  9.6417e-03,  6.9731e-03,  1.0494e-02,\n","         7.7392e-03,  1.3177e-02,  4.7104e-02,  2.4319e-02,  3.4188e-02,\n","         5.6501e-02,  3.2135e-02,  1.6710e-02,  3.8981e-02,  3.1749e-02,\n","        -2.5556e-02,  2.8888e-02,  1.9070e-02,  5.1650e-02, -1.5914e-02,\n","        -1.2977e-02,  6.6083e-03,  1.7860e-02,  3.1013e-02,  1.8371e-02,\n","        -2.1300e-02,  2.5543e-02,  1.6410e-02, -6.5174e-03,  1.3495e-02,\n","         8.7851e-03,  4.6246e-02,  1.8821e-03,  2.9014e-02,  1.1800e-02,\n","         5.9435e-04,  3.8069e-02, -1.1412e-03,  2.3119e-02,  1.1591e-02,\n","         4.3060e-02,  3.3098e-02,  2.1665e-02,  1.8575e-02,  3.6334e-02,\n","         4.9192e-03,  1.9173e-02,  5.5739e-03, -4.8481e-02, -3.4651e-03,\n","         4.6214e-02, -9.8203e-03,  1.5743e-02,  3.0009e-02,  1.9906e-02,\n","         4.1677e-02,  8.9290e-03,  3.6726e-02,  1.1614e-02,  3.5722e-02,\n","         5.2057e-02,  1.4911e-02,  1.7501e-02,  2.3691e-02,  2.0107e-02,\n","         1.6700e-02,  3.2877e-02,  9.7055e-02,  7.1827e-04,  3.3868e-02,\n","         2.0839e-02,  3.9532e-02,  1.3293e-02,  3.6185e-02,  2.6945e-03,\n","         5.1187e-02,  5.1772e-02,  1.7860e-02,  1.9585e-02,  3.2763e-02,\n","        -1.5987e-01, -1.0280e-02,  2.8637e-02,  2.1631e-02,  3.6269e-02,\n","         4.1857e-02,  1.4414e-02,  3.6165e-02,  9.4467e-03,  7.0197e-02,\n","        -1.2440e-02,  2.1275e-03,  1.5799e-03, -1.6614e-04,  1.1726e-02,\n","         1.7327e-02,  1.7329e-02,  2.2099e-02, -4.4030e-03,  1.4518e-02,\n","         1.3263e-02,  3.3477e-02,  4.7591e-04,  3.0322e-02,  2.9178e-02,\n","        -1.4136e-02,  1.3277e-02,  3.4933e-02, -1.6847e-03, -2.2079e-03,\n","         1.9391e-02,  3.5811e-02,  3.1967e-02,  3.7433e-03,  4.5169e-02,\n","         2.0756e-02,  7.0152e-03,  2.5443e-02,  3.5833e-03, -1.0657e-01,\n","         4.4172e-02, -9.5086e-04,  1.4159e-02, -3.8349e-03,  3.2159e-02,\n","         1.5454e-02,  1.0590e-02,  1.9344e-02,  7.1228e-03,  1.7016e-02,\n","         2.7252e-02,  1.0541e-02,  2.8562e-02, -7.8883e-03,  4.8528e-02,\n","         9.2735e-03, -4.7732e-04,  1.3732e-02, -1.8557e-03,  2.5011e-02,\n","         9.9024e-04,  2.0201e-02,  1.6506e-02,  5.9075e-02,  4.0285e-02,\n","         6.5056e-03,  2.1686e-02,  1.7892e-02,  2.1786e-02,  3.1710e-03,\n","         1.0477e-02,  1.5669e-03,  4.0309e-02,  2.2216e-02,  3.4789e-02,\n","        -3.0456e-03,  6.2019e-03,  2.2039e-02,  9.4936e-03,  2.4101e-02,\n","         1.6185e-03,  1.7310e-02, -5.9819e-03,  7.8453e-03, -2.8414e-03,\n","         7.8690e-03,  4.5540e-03,  3.1039e-03,  4.9698e-02,  3.7590e-02,\n","        -8.4337e-04,  5.3732e-02,  5.3245e-02,  2.3421e-02,  3.3265e-02,\n","         3.5699e-02,  1.9311e-02, -7.2357e-05,  9.5435e-03,  7.3847e-02,\n","         2.7004e-04,  2.7659e-02,  2.8465e-02,  2.6450e-02,  2.4385e-02,\n","         1.3997e-01,  5.8820e-02,  1.8040e-03,  2.9881e-02,  9.1413e-03,\n","         1.3223e-02,  1.0460e-02,  2.1818e-03,  4.4793e-02,  2.0962e-02,\n","         3.1776e-02,  6.9040e-02,  1.6514e-02,  3.4750e-02,  1.9679e-02,\n","         3.2600e-02,  1.8007e-03, -4.3986e-02,  2.1791e-02,  3.6372e-02,\n","         2.4327e-02,  5.0891e-03,  3.7223e-02], device='cuda:0',\n","       requires_grad=True)\n","blocks.10.ln2.w: torch.Size([768])\n","Parameter containing:\n","tensor([0.2976, 0.2666, 0.2978, 0.2740, 0.3013, 0.2871, 0.5526, 0.2613, 0.2840,\n","        0.2607, 0.2947, 0.2736, 0.2764, 0.2916, 0.3057, 0.2851, 0.3029, 0.2802,\n","        0.2998, 0.3194, 0.2549, 0.2699, 0.2869, 0.2764, 0.2822, 0.2803, 0.2859,\n","        0.2704, 0.2784, 0.2747, 0.2725, 0.3135, 0.2933, 0.2725, 0.2881, 0.3330,\n","        0.2535, 0.2802, 0.2626, 0.2842, 0.2744, 0.2588, 0.2627, 0.2859, 0.2897,\n","        0.2822, 0.2789, 0.2646, 0.3172, 0.2881, 0.2787, 0.2839, 0.2794, 0.2920,\n","        0.2900, 0.3467, 0.2915, 0.3166, 0.2666, 0.3272, 0.3092, 0.2781, 0.2900,\n","        0.3012, 0.1870, 0.2705, 0.2763, 0.3206, 0.3549, 0.2705, 0.2959, 0.2180,\n","        0.2725, 0.2929, 0.2627, 0.2920, 0.2958, 0.3896, 0.3016, 0.2939, 0.2998,\n","        0.2686, 0.2780, 0.3057, 0.3236, 0.3111, 0.3226, 0.0201, 0.2874, 0.2666,\n","        0.2783, 0.2679, 0.2900, 0.2904, 0.2789, 0.2607, 0.2795, 0.2881, 0.2705,\n","        0.2946, 0.2607, 0.2395, 0.3780, 0.3029, 0.2822, 0.2788, 0.3033, 0.3589,\n","        0.2764, 0.2685, 0.2932, 0.2761, 0.2814, 0.2951, 0.2826, 0.2872, 0.3173,\n","        0.2856, 0.2469, 0.3256, 0.2900, 0.2794, 0.2705, 0.2959, 0.3114, 0.2873,\n","        0.2725, 0.2822, 0.3213, 0.2803, 0.2837, 0.2725, 0.2956, 0.2833, 0.2898,\n","        0.2704, 0.2822, 0.3363, 1.0951, 0.2872, 0.2915, 0.2899, 0.3654, 0.2666,\n","        0.2900, 0.3300, 0.2971, 0.2979, 0.2725, 0.2896, 0.2921, 0.2955, 0.3170,\n","        0.3057, 0.2888, 0.2728, 0.2887, 0.2931, 0.2737, 0.3213, 0.3665, 0.2842,\n","        0.3056, 0.3076, 0.2900, 0.2894, 0.2917, 0.4131, 0.2704, 0.3154, 0.2783,\n","        0.2791, 0.2780, 0.3042, 0.2998, 0.2739, 0.3017, 0.2607, 0.3018, 0.2835,\n","        0.2820, 0.2705, 0.2744, 0.2998, 0.2588, 0.2607, 0.2686, 0.2822, 0.2801,\n","        0.2939, 0.2725, 0.3172, 0.2822, 0.2959, 0.2686, 0.3595, 0.2616, 0.2958,\n","        0.2777, 0.3174, 0.3146, 0.2980, 0.2783, 0.2823, 0.2764, 0.2897, 0.2725,\n","        0.2407, 0.3135, 0.2763, 0.2816, 0.3184, 0.2839, 0.3071, 0.2881, 0.2760,\n","        0.3230, 0.2842, 0.1939, 0.2666, 0.2752, 0.2725, 0.2586, 0.3012, 0.3156,\n","        0.2803, 0.2705, 0.2705, 0.2829, 0.2608, 0.2645, 0.2968, 0.4358, 0.2705,\n","        0.2750, 0.3017, 0.2955, 0.2705, 0.2968, 0.3001, 0.3099, 0.3223, 0.2822,\n","        0.2664, 0.2646, 0.2881, 0.2762, 0.3076, 0.2840, 0.2921, 0.2861, 0.2764,\n","        0.2744, 0.2861, 0.2761, 0.3478, 0.3037, 0.2957, 0.2861, 0.2859, 0.2815,\n","        0.2979, 0.2784, 0.2958, 0.2824, 0.2595, 0.0720, 0.3310, 0.2822, 0.2901,\n","        0.3643, 0.3545, 0.2743, 0.2810, 0.3217, 0.2705, 0.2782, 0.2666, 0.2621,\n","        0.2715, 0.2568, 0.2526, 0.2979, 0.3584, 0.3213, 0.2979, 0.2950, 0.2666,\n","        0.5094, 0.3096, 0.2885, 0.2807, 0.2761, 0.2607, 0.3096, 0.2600, 0.2646,\n","        0.2920, 0.2725, 0.2979, 0.2900, 0.2920, 0.2978, 0.2646, 0.2588, 0.2782,\n","        0.2800, 0.2641, 0.3124, 0.2627, 0.2646, 0.3487, 0.2858, 0.2798, 0.2509,\n","        0.2780, 0.3033, 0.2900, 0.2724, 0.3086, 0.3528, 0.2744, 0.2687, 0.2897,\n","        0.2719, 0.2822, 0.5527, 0.2822, 0.2822, 0.2803, 0.2920, 0.2781, 0.2862,\n","        0.2842, 0.2666, 0.2972, 0.3071, 0.2764, 0.2861, 0.3059, 0.2752, 0.2685,\n","        0.3044, 0.3034, 0.3036, 0.3057, 0.2822, 0.2863, 0.2959, 0.2689, 0.2803,\n","        0.2529, 0.2737, 0.2979, 0.3076, 0.2822, 0.2975, 0.2810, 0.2822, 0.2822,\n","        0.2930, 0.2706, 0.4616, 0.2686, 0.2659, 0.3373, 0.2996, 0.2702, 0.2659,\n","        0.3018, 0.2951, 0.2725, 0.2783, 0.0522, 0.2702, 0.3266, 0.2979, 0.3172,\n","        0.2367, 0.2881, 0.2851, 0.2697, 0.2802, 0.3057, 0.3096, 0.3252, 0.3017,\n","        0.2763, 0.2801, 0.3233, 0.2890, 0.2574, 0.3055, 0.6621, 0.3052, 0.2707,\n","        0.2900, 0.2734, 0.2735, 0.2657, 0.2707, 0.2920, 0.3076, 0.2959, 0.2631,\n","        0.3017, 0.3112, 0.2585, 0.3474, 0.2744, 0.2567, 0.2625, 0.2796, 0.2646,\n","        0.2978, 0.2822, 0.2654, 0.2978, 0.2847, 0.2861, 0.2133, 0.3018, 0.2741,\n","        0.2998, 0.2704, 0.2604, 0.2847, 0.2862, 0.2805, 0.2554, 0.2232, 0.2705,\n","        0.2806, 0.2833, 0.2666, 0.3174, 0.2666, 0.2900, 0.2901, 0.3153, 0.3271,\n","        0.3017, 0.3501, 0.2744, 0.3037, 0.2783, 0.2694, 0.0606, 0.2783, 0.2876,\n","        0.2889, 0.2801, 0.2744, 0.3054, 0.3021, 0.3090, 0.2940, 0.2783, 0.2687,\n","        0.1821, 0.2900, 0.2822, 0.2867, 0.2744, 0.1579, 0.2822, 0.2959, 0.2722,\n","        0.2702, 0.2863, 0.2749, 0.2895, 0.2939, 0.2764, 0.2575, 0.2992, 0.2686,\n","        0.2705, 0.2685, 0.3664, 0.0253, 0.0485, 0.2920, 0.2743, 0.2920, 0.2666,\n","        0.2803, 0.2817, 0.3225, 0.2725, 0.2842, 0.3001, 0.2606, 0.2725, 0.2751,\n","        0.2722, 0.1523, 0.2143, 0.2899, 0.2790, 0.2978, 0.2764, 0.2939, 0.3815,\n","        0.3144, 0.2643, 0.2773, 0.3252, 0.3054, 0.2705, 0.2705, 0.2969, 0.2782,\n","        0.2811, 0.2828, 0.3013, 0.2744, 0.2783, 0.2795, 0.2665, 0.2525, 0.2822,\n","        0.2998, 0.2939, 0.2803, 0.2842, 0.4467, 0.3174, 0.3037, 0.2666, 0.2981,\n","        0.2963, 0.2602, 0.2685, 0.2859, 0.2900, 0.2744, 0.2861, 0.3075, 0.2900,\n","        0.3075, 0.2861, 0.2830, 0.3485, 0.2764, 0.2959, 0.3012, 0.2761, 0.2744,\n","        0.3428, 0.2783, 0.3252, 0.2939, 0.2919, 0.3531, 0.2986, 0.2744, 0.2910,\n","        0.2782, 0.2803, 0.2978, 0.2854, 0.2900, 0.2860, 0.2682, 0.2803, 0.3389,\n","        0.3076, 0.3000, 0.3048, 0.3253, 0.2978, 0.3037, 0.2904, 0.2842, 0.2998,\n","        0.2653, 0.2777, 0.3346, 0.2948, 0.2725, 0.2593, 0.3174, 0.2900, 0.2705,\n","        0.2947, 0.2705, 0.2958, 0.2920, 0.2842, 0.2900, 0.2832, 0.2646, 0.2777,\n","        0.2764, 0.2764, 0.2872, 0.2800, 0.2659, 0.2567, 0.3003, 0.2918, 0.3047,\n","        0.2959, 0.2928, 0.2789, 0.3037, 0.2911, 0.4346, 0.2738, 0.2914, 0.2822,\n","        0.2879, 0.2961, 0.2955, 0.3057, 0.3271, 0.2803, 0.2918, 0.2892, 0.2971,\n","        0.2803, 0.2836, 0.2807, 0.2959, 0.2744, 0.2805, 0.3561, 0.2825, 0.2822,\n","        0.2788, 0.2781, 0.2734, 0.2715, 0.2822, 0.3328, 0.2842, 0.2760, 0.2779,\n","        0.2881, 0.5528, 0.2979, 0.2447, 0.3029, 0.3114, 0.2920, 0.2842, 0.3193,\n","        0.2916, 0.3604, 0.2567, 0.3252, 0.2745, 0.2900, 0.2704, 0.2938, 0.2756,\n","        0.2881, 0.2666, 0.3292, 0.2606, 0.2939, 0.2722, 0.2764, 0.2725, 0.3154,\n","        0.2680, 0.2979, 0.2881, 0.3272, 0.3076, 0.2762, 0.2916, 0.2725, 0.2553,\n","        0.2725, 0.2802, 0.2818, 0.3076, 0.3946, 0.3193, 0.2741, 0.2982, 0.2897,\n","        0.2699, 0.2761, 0.2977, 0.2671, 0.2959, 0.2803, 0.2686, 0.2636, 0.2861,\n","        0.3090, 0.2861, 0.2803, 0.2803, 0.2607, 0.2920, 0.3017, 0.2744, 0.3099,\n","        0.2685, 0.4283, 0.2766, 0.2939, 0.3325, 0.3111, 0.2700, 0.3934, 0.3037,\n","        0.2571, 0.2720, 0.2800, 0.2669, 0.3043, 0.2543, 0.2744, 0.3115, 0.2728,\n","        0.2686, 0.3563, 0.2704, 0.2750, 0.3076, 0.3057, 0.3115, 0.2978, 0.2994,\n","        0.2975, 0.2900, 0.2979, 0.2825, 0.2920, 0.2861, 0.2979, 0.2718, 0.2673,\n","        0.2981, 0.3635, 0.3018, 0.2875, 0.2801, 0.2958, 0.2864, 0.2470, 0.3422,\n","        0.2744, 0.3037, 0.2861, 0.2752, 0.2782, 0.2822, 0.2684, 0.3010, 0.3135,\n","        0.1586, 0.2822, 0.2784, 0.2958, 0.2578, 0.2937, 0.3352, 0.2654, 0.2607,\n","        0.2770, 0.2644, 0.2911], device='cuda:0', requires_grad=True)\n","blocks.10.ln2.b: torch.Size([768])\n","Parameter containing:\n","tensor([-1.0358e-02,  1.3820e-02,  2.8260e-02,  4.6557e-02,  5.9956e-03,\n","         1.1307e-02,  6.8819e-02,  3.6446e-02,  4.8702e-03,  4.9763e-03,\n","         2.8531e-02,  4.7327e-02,  1.5152e-02,  2.8607e-02,  2.5593e-02,\n","         5.2164e-02,  4.8066e-02,  5.3223e-02,  3.4451e-02, -2.9055e-02,\n","         1.6824e-02, -6.3294e-03,  3.0100e-03,  4.8100e-02,  2.2632e-02,\n","         2.3483e-02,  5.6872e-03,  4.2506e-02,  1.2199e-02, -2.9102e-02,\n","         4.8205e-02, -3.0327e-02,  3.2885e-02,  5.2018e-02,  1.3616e-02,\n","         1.7174e-02, -6.2414e-03,  1.4992e-02,  1.5188e-02,  8.3957e-03,\n","         3.4247e-02,  2.9624e-02,  1.7826e-02,  1.4083e-02,  1.6533e-02,\n","         2.2324e-02,  3.2677e-02,  2.0053e-02,  9.4957e-03, -1.7382e-02,\n","         6.3748e-02,  4.1355e-02,  3.2904e-02,  3.2447e-02,  4.0435e-02,\n","        -2.8565e-03,  2.0369e-02, -1.4023e-02,  2.0943e-02,  6.2948e-03,\n","         2.9956e-02,  2.6207e-02,  3.2395e-02,  1.6449e-02, -1.4525e-02,\n","         2.8430e-02,  1.6217e-02, -4.6950e-03,  5.2596e-02,  3.7110e-02,\n","         1.3538e-02,  4.7081e-02,  2.6471e-02,  1.7197e-02,  3.4794e-02,\n","         1.3930e-02, -1.8007e-02,  2.2802e-03,  6.4147e-02,  1.4225e-02,\n","         8.2972e-04,  1.7301e-02,  1.5907e-02,  3.9303e-02,  4.9839e-02,\n","         3.9953e-02,  4.5833e-02,  1.3956e-01,  1.6589e-02,  1.9164e-02,\n","         2.9428e-02,  1.8867e-02,  3.5480e-02,  3.4520e-02,  2.5352e-02,\n","        -1.6986e-03,  3.1963e-03,  1.0863e-02, -1.9798e-02,  4.9423e-02,\n","         1.1976e-02, -2.8248e-02, -3.1719e-02,  2.6163e-02,  1.4126e-02,\n","         4.0976e-03, -8.0332e-04,  6.1240e-02,  2.2650e-02,  2.2354e-02,\n","         2.0694e-02,  4.3690e-02,  3.0244e-02,  3.6898e-02,  1.8719e-02,\n","         1.1135e-02,  3.0766e-02,  5.8322e-03,  5.2236e-02,  3.1649e-02,\n","         3.5989e-02,  7.6593e-03, -4.7919e-04,  3.2370e-02,  3.6766e-02,\n","         2.4986e-02,  6.0303e-04,  4.1531e-02, -2.0416e-02,  3.6249e-02,\n","         3.8137e-02,  5.3390e-02,  2.8590e-02,  4.0459e-02,  5.7189e-02,\n","         3.0323e-02,  2.6251e-02,  4.2108e-02,  3.3788e-01,  2.4742e-02,\n","        -2.1341e-02,  2.5394e-02,  2.5185e-02,  3.4734e-03,  1.8485e-02,\n","         7.6756e-03,  1.0611e-02,  1.4992e-02,  7.9128e-03,  1.0905e-02,\n","        -3.9157e-03, -2.0122e-02,  1.0011e-02,  3.0892e-02,  2.4538e-03,\n","         1.5397e-02,  5.3747e-02, -1.5423e-02,  3.6599e-02, -7.1308e-03,\n","         6.1582e-03,  3.8073e-02, -6.4656e-03,  3.2223e-02, -3.0139e-03,\n","         3.1230e-02, -1.3427e-02,  2.2051e-02,  3.4040e-03,  2.8121e-02,\n","         2.0565e-02,  4.5798e-02,  1.1976e-02,  1.4449e-02,  3.0251e-02,\n","         2.6776e-02,  8.5797e-02,  2.5977e-04,  4.7272e-02, -1.0841e-03,\n","         1.8195e-02,  1.8218e-02,  2.8540e-02,  6.7993e-03,  3.5639e-02,\n","         2.9599e-02,  2.4892e-02, -2.8580e-03,  2.1860e-02,  1.8337e-02,\n","         8.1896e-03,  7.1606e-03,  1.7517e-02,  1.8818e-02,  1.2455e-02,\n","         5.0942e-02,  1.0982e-02,  2.1877e-02,  6.7266e-03,  4.9079e-03,\n","         2.9072e-02,  2.0166e-02,  1.8988e-02,  6.0607e-02,  3.5498e-02,\n","         3.9689e-02,  1.1732e-02,  3.2019e-02, -7.8117e-03,  1.3688e-02,\n","         2.1697e-02,  5.7341e-02,  4.0743e-02,  6.6843e-02,  3.4915e-02,\n","         1.8039e-02,  8.2446e-03,  1.6047e-02,  3.0304e-02,  4.3722e-02,\n","         1.4338e-02,  1.5648e-02,  3.0412e-02,  8.0503e-04,  4.4321e-02,\n","         3.2069e-02,  2.9099e-03,  3.4809e-02,  3.7059e-02,  3.0682e-02,\n","         4.4311e-02,  3.7483e-02,  2.7851e-02,  2.5533e-02,  2.6303e-02,\n","         2.0085e-02,  4.1493e-02,  8.9645e-03,  3.0944e-03,  2.6097e-02,\n","         6.6764e-02,  2.7084e-03,  2.6569e-02,  3.2081e-02,  2.9702e-03,\n","         1.3219e-02,  2.0836e-02,  1.3685e-02,  3.5987e-03,  1.0517e-02,\n","         1.4312e-02,  1.2074e-02, -1.0478e-02,  2.5274e-02,  2.6911e-02,\n","         1.0097e-01,  9.9682e-03,  1.8130e-02,  4.0114e-02,  4.3335e-02,\n","         3.2085e-03,  4.3071e-02,  3.3993e-02,  3.3701e-02,  2.5201e-03,\n","        -1.5116e-02, -7.2455e-02,  4.2337e-02,  4.0797e-02,  2.2369e-02,\n","         2.2718e-02,  1.6584e-02, -1.3213e-02,  1.1772e-02,  1.1397e-02,\n","         2.9617e-02,  2.3913e-02,  1.8444e-02,  3.3094e-02,  3.8922e-02,\n","         4.6575e-02,  1.2183e-02,  2.6243e-02,  6.8510e-02,  2.2780e-03,\n","         1.0124e-02,  2.2449e-02,  8.6296e-03, -1.6431e-01,  4.9237e-02,\n","         4.8695e-02, -3.1594e-03,  3.1461e-02,  2.8214e-02,  1.3456e-02,\n","         1.9882e-02,  3.4631e-02,  2.4248e-02, -3.5280e-03,  2.1640e-02,\n","         1.2597e-02,  7.1220e-03,  1.1988e-02,  2.5425e-02,  1.4709e-03,\n","         5.3826e-03,  3.6498e-02,  2.5552e-02,  3.3139e-02,  2.6447e-02,\n","        -1.1497e-02,  5.5716e-02,  1.3308e-02, -6.7223e-03,  2.4045e-02,\n","         2.2624e-02,  3.7223e-02,  2.6761e-02,  5.4413e-02,  1.4670e-02,\n","         2.1103e-02,  2.0297e-02,  2.5275e-02, -2.4169e-03,  1.0851e-02,\n","         1.0792e-02, -2.5108e-01,  1.5956e-02,  3.9030e-02, -5.4340e-03,\n","         1.4072e-02, -1.2481e-02,  1.9383e-02,  2.3584e-02,  5.8051e-02,\n","         3.7730e-03,  4.6452e-02,  1.5874e-02,  3.9195e-02,  2.8941e-02,\n","        -8.1308e-03,  2.4481e-02,  2.6067e-02,  9.3105e-03,  3.3713e-02,\n","         3.7100e-02, -1.2273e-02, -1.6410e-02,  2.4022e-02,  4.7408e-02,\n","         3.4378e-02,  4.3000e-02,  2.5137e-02,  4.4269e-03,  4.9077e-02,\n","         3.1481e-02,  1.0652e-02,  2.6449e-02, -1.4687e-02,  1.4857e-02,\n","        -3.2030e-06,  3.4278e-02,  4.2626e-02,  4.3518e-02,  5.9497e-02,\n","         3.0237e-02,  4.7823e-02,  2.2643e-02,  2.5692e-02,  7.3306e-02,\n","         3.6672e-02,  1.4671e-02,  2.3230e-02,  6.9136e-01,  6.4758e-02,\n","         5.6275e-02, -8.1179e-03,  1.2797e-02, -5.9154e-02,  2.2879e-02,\n","         4.0809e-02,  1.1079e-02,  2.3431e-02,  1.9926e-03,  2.5910e-02,\n","         3.1874e-02,  5.4008e-03,  1.6043e-02,  1.9226e-02,  3.7281e-02,\n","         5.1407e-02,  1.7173e-02,  1.5955e-02, -5.9317e-02,  1.2196e-02,\n","         1.0802e-02,  3.0468e-03,  5.8788e-03,  2.2304e-02,  3.2142e-02,\n","         1.3249e-02,  2.8839e-02,  3.7375e-02,  3.6929e-02,  1.7584e-02,\n","         1.9938e-02,  1.0190e-02,  3.5776e-02,  1.7384e-02,  3.5547e-02,\n","         2.4908e-03,  3.4021e-02, -5.4762e-03, -8.3075e-03,  1.9333e-02,\n","         3.5979e-02,  1.6277e-02,  2.9949e-02,  3.6957e-02,  3.3667e-02,\n","         3.0161e-02,  1.7595e-02,  4.1365e-02,  1.5934e-02,  2.7179e-02,\n","         5.5548e-02,  7.0083e-02, -2.4011e-03,  1.1384e-02,  1.8920e-03,\n","        -1.1522e-01,  2.5727e-02,  1.6895e-02,  8.3255e-03,  2.3962e-02,\n","         6.0353e-02,  1.7068e-02,  4.7377e-02,  2.7464e-02,  4.8743e-02,\n","         7.5937e-02,  3.4020e-02,  5.8768e-02,  5.1526e-02,  1.9177e-02,\n","         1.2255e-02,  1.7058e-02, -3.0584e-01,  5.3723e-02,  5.2641e-02,\n","         7.4931e-03,  8.0473e-03,  5.1533e-02,  2.6815e-02,  1.6538e-02,\n","         7.7585e-03,  3.7131e-02,  2.8426e-02,  1.6543e-02,  3.0388e-02,\n","        -9.6813e-03,  2.6446e-02,  5.9391e-02,  3.3866e-02, -1.3877e-02,\n","         5.0415e-02, -7.9023e-03,  3.6284e-02,  1.2733e-02,  2.2542e-02,\n","         3.6630e-02,  9.2280e-03,  3.8719e-02,  4.1514e-02,  4.8284e-02,\n","        -1.4673e-02,  3.9955e-02,  3.1786e-02,  2.8342e-02,  6.0084e-02,\n","        -5.6054e-03, -6.0051e-01,  1.3674e-02,  5.3414e-03,  2.1680e-02,\n","         1.7339e-02,  1.7631e-02,  2.5795e-02,  5.4288e-02,  4.1404e-03,\n","         1.6550e-02,  2.0046e-02,  1.2296e-02,  1.9723e-02,  9.6581e-03,\n","         3.0429e-02, -9.5211e-02,  5.8852e-02,  2.3260e-02,  7.0863e-03,\n","         3.1864e-02,  4.1533e-02,  3.8262e-02,  2.9270e-03, -2.4406e-03,\n","        -7.0459e-04,  2.0805e-02,  3.1979e-02,  8.6200e-03,  4.7225e-02,\n","         1.0877e-02,  6.8129e-03,  4.8274e-02,  2.1957e-02,  2.3721e-02,\n","         3.3818e-02,  1.1655e-02,  4.6021e-02,  1.8045e-02, -1.3827e-02,\n","        -3.9979e-03,  2.9055e-02,  7.4535e-02,  1.1002e-02,  2.0955e-02,\n","        -3.2250e-02,  9.2323e-02,  6.0631e-02,  4.8247e-02,  2.5260e-02,\n","         3.8033e-02,  2.6952e-02,  1.2707e-02,  2.3304e-02, -6.8546e-03,\n","         2.3727e-02,  9.9788e-03, -7.4584e-04,  4.4504e-02,  3.0539e-02,\n","         2.0200e-02,  4.6410e-03, -5.3424e-03,  2.6282e-03,  1.8000e-02,\n","         2.2171e-02,  5.0755e-02,  5.0623e-02,  2.8502e-02, -6.8178e-03,\n","         2.2921e-03,  3.9287e-02,  8.1652e-03,  1.6192e-02,  4.5056e-02,\n","         1.9333e-02,  9.0636e-03,  1.0507e-02,  2.5045e-02,  3.0355e-02,\n","         3.2846e-02,  4.5357e-02,  2.5181e-02,  4.5486e-02,  1.5991e-02,\n","         9.1249e-03, -1.6159e-03, -3.3242e-03,  5.0166e-03, -1.1907e-02,\n","         2.4148e-02,  1.4709e-02,  6.0083e-02, -5.4288e-03,  1.1880e-02,\n","        -1.2682e-02,  9.9845e-03,  3.1314e-02,  5.4775e-02,  2.1177e-02,\n","         3.4766e-02,  2.6360e-02,  5.2954e-02,  2.3196e-02,  2.8086e-02,\n","        -1.5350e-02,  3.5632e-03,  2.0230e-02, -2.5101e-03,  3.2721e-02,\n","        -5.2974e-03,  2.7180e-03,  4.6001e-02,  2.1882e-02,  2.3802e-02,\n","        -3.7108e-03, -8.5181e-03,  2.8182e-02,  2.7818e-02,  2.3665e-02,\n","         2.7919e-02,  7.8592e-04,  3.3945e-02,  2.3061e-02,  2.6832e-02,\n","         4.5391e-02,  1.1655e-02,  2.3164e-03,  5.1892e-02,  1.2260e-02,\n","         8.7936e-03, -1.3305e-02, -4.6087e-04,  3.5252e-02, -1.0717e-02,\n","         5.9545e-03,  2.4296e-02,  3.2646e-02,  1.7622e-03,  6.5688e-02,\n","         2.3266e-02,  2.1682e-02,  3.1347e-02,  2.6992e-02,  4.4732e-02,\n","         4.2366e-02, -1.2863e-03,  7.0720e-03,  4.3547e-03,  2.3147e-02,\n","         4.1584e-02,  5.8816e-03,  4.4269e-02,  2.1353e-03,  6.1128e-02,\n","         6.8275e-02,  4.4310e-02,  4.5049e-02,  3.3080e-02,  8.5815e-03,\n","        -5.4939e-02, -7.2536e-04, -2.6956e-03,  1.9162e-02,  4.3828e-02,\n","         1.7810e-02,  1.5744e-02,  1.9663e-02,  9.2914e-03,  2.1843e-02,\n","         1.8821e-02,  2.9652e-02,  5.2211e-03, -3.3464e-03,  1.2501e-02,\n","         3.5486e-02,  7.3340e-03, -1.1261e-02,  2.0094e-02,  1.5204e-02,\n","         1.0204e-02,  4.1609e-02,  1.3557e-02,  6.7135e-02,  1.2011e-02,\n","         2.5460e-02,  6.1166e-03,  1.5924e-02,  4.5425e-02,  8.7188e-02,\n","         3.5348e-02,  3.0157e-02, -2.1819e-02,  2.8529e-02, -1.4283e-02,\n","         2.1892e-02,  1.8951e-02,  4.7751e-02,  2.6668e-02,  2.9404e-02,\n","         1.0511e-02,  1.5914e-02, -1.1116e-02,  3.7344e-02,  2.0180e-02,\n","         2.2825e-02,  3.1746e-02,  2.1207e-02,  2.7221e-02,  4.5675e-02,\n","         4.1321e-02,  2.7240e-02,  2.8394e-02,  6.6000e-02,  2.5427e-02,\n","         3.3961e-02,  9.0295e-03,  3.4376e-02,  1.4984e-02,  8.0904e-03,\n","         1.6822e-02,  2.2855e-03,  9.1259e-03, -9.2325e-03,  5.7467e-02,\n","         2.9218e-03, -2.2570e-02,  1.7161e-02,  1.2237e-02, -2.6738e-02,\n","         1.0197e-03,  5.3789e-03,  3.9366e-02,  5.4971e-02,  8.0899e-03,\n","         3.5850e-02,  4.6131e-03,  2.0722e-02, -3.1729e-02,  2.9270e-02,\n","         3.3209e-02,  3.2098e-02,  6.1395e-02, -1.2445e-02,  7.2913e-02,\n","         2.4019e-02,  2.5712e-02,  3.7966e-02, -1.0105e-02,  2.5099e-02,\n","         1.4116e-02,  1.3625e-02,  2.1187e-02,  1.3063e-02,  4.3473e-04,\n","         1.3430e-02,  1.5159e-02,  1.6721e-02,  3.1475e-02,  2.6737e-02,\n","        -1.0435e-02,  2.5066e-02,  3.9083e-02,  2.1112e-02,  2.4588e-02,\n","         1.3874e-01,  3.0582e-02,  4.4362e-02,  3.6819e-02,  2.8616e-02,\n","         1.3359e-02,  1.4427e-02,  4.7326e-03,  9.0515e-03,  3.2625e-02,\n","         3.0964e-02,  7.8371e-02,  3.4118e-02,  3.3910e-02,  2.2646e-02,\n","         1.4631e-02,  1.8085e-02, -1.1369e-02, -1.4955e-02,  1.8636e-02,\n","         3.3812e-02,  2.1553e-02,  6.5092e-04], device='cuda:0',\n","       requires_grad=True)\n","blocks.10.attn.W_Q: torch.Size([12, 768, 64])\n","Parameter containing:\n","tensor([[[ 0.2200,  0.2637,  0.0422,  ..., -0.0100,  0.0229,  0.1244],\n","         [-0.1269, -0.0215, -0.0951,  ..., -0.0238, -0.0919, -0.0484],\n","         [ 0.0709, -0.0726, -0.0253,  ...,  0.1592,  0.0695,  0.1500],\n","         ...,\n","         [ 0.0642, -0.0317,  0.1332,  ...,  0.1985, -0.0517,  0.0423],\n","         [-0.1892, -0.1039,  0.0752,  ..., -0.1074,  0.0164,  0.0596],\n","         [ 0.1380,  0.1194, -0.1244,  ...,  0.1841, -0.0604, -0.0981]],\n","\n","        [[-0.0765, -0.1113,  0.1435,  ...,  0.0153, -0.1537, -0.0328],\n","         [ 0.0463, -0.1467, -0.0673,  ...,  0.0624,  0.0853, -0.0662],\n","         [-0.1213,  0.1115,  0.0357,  ..., -0.0174,  0.0236, -0.1195],\n","         ...,\n","         [ 0.0249,  0.2000, -0.1319,  ..., -0.1060, -0.0321,  0.0502],\n","         [ 0.0601,  0.1222, -0.1190,  ..., -0.1016,  0.0171, -0.2672],\n","         [ 0.1605,  0.0015,  0.0065,  ..., -0.0933, -0.0285,  0.0155]],\n","\n","        [[ 0.1425,  0.2155, -0.1524,  ..., -0.0028,  0.0502,  0.0291],\n","         [-0.1617, -0.0914, -0.0738,  ..., -0.1944, -0.0872, -0.0436],\n","         [ 0.0806, -0.2056, -0.0654,  ...,  0.1500, -0.0903,  0.0127],\n","         ...,\n","         [-0.1754,  0.0643, -0.1351,  ..., -0.0142, -0.3574, -0.0644],\n","         [ 0.0676, -0.0624,  0.2015,  ..., -0.1612, -0.0308, -0.0512],\n","         [-0.1013,  0.0320, -0.1363,  ..., -0.1610, -0.1384,  0.0637]],\n","\n","        ...,\n","\n","        [[-0.0199, -0.0897,  0.1129,  ..., -0.2492, -0.0565,  0.0807],\n","         [ 0.0050, -0.1440,  0.0100,  ..., -0.0550,  0.1736, -0.0079],\n","         [-0.0808, -0.1348, -0.0364,  ...,  0.1271, -0.0790,  0.1002],\n","         ...,\n","         [-0.1067, -0.0611, -0.1239,  ..., -0.1006,  0.1367, -0.0111],\n","         [-0.2251,  0.0723, -0.1131,  ..., -0.0526,  0.1332,  0.1147],\n","         [-0.0625, -0.1345, -0.2477,  ...,  0.0449, -0.1780,  0.0022]],\n","\n","        [[-0.2002,  0.1511,  0.0206,  ...,  0.0910, -0.1158,  0.0121],\n","         [ 0.1242,  0.0504,  0.0026,  ..., -0.0627,  0.0148,  0.0211],\n","         [ 0.0245,  0.1400, -0.1313,  ...,  0.1615, -0.0483,  0.0261],\n","         ...,\n","         [-0.0446, -0.1071,  0.0934,  ..., -0.1901, -0.2228,  0.0121],\n","         [ 0.0344, -0.0911, -0.1433,  ..., -0.0080, -0.0333,  0.1243],\n","         [ 0.0215,  0.1775,  0.0883,  ..., -0.0610, -0.2030,  0.1285]],\n","\n","        [[-0.0077, -0.1363, -0.0670,  ..., -0.1334, -0.1148, -0.1825],\n","         [-0.0151, -0.1537,  0.0065,  ..., -0.0347, -0.1109,  0.2518],\n","         [-0.0780,  0.3635, -0.2179,  ...,  0.0263,  0.0509, -0.0924],\n","         ...,\n","         [ 0.0546,  0.1110, -0.1063,  ...,  0.0938,  0.2521, -0.1901],\n","         [ 0.0958,  0.0310,  0.0837,  ..., -0.0465,  0.1195, -0.2375],\n","         [ 0.2510, -0.1558, -0.2973,  ..., -0.1719,  0.1303, -0.1872]]],\n","       device='cuda:0', requires_grad=True)\n","blocks.10.attn.W_O: torch.Size([12, 64, 768])\n","Parameter containing:\n","tensor([[[-0.0077, -0.5188,  0.0783,  ..., -0.0935, -0.1252,  0.1297],\n","         [-0.3012,  0.2455, -0.0883,  ...,  0.0785,  0.2385, -0.1301],\n","         [-0.3693,  0.1506,  0.2052,  ..., -0.0831, -0.2656, -0.1792],\n","         ...,\n","         [ 0.1153, -0.0813,  0.1218,  ...,  0.3249, -0.0634,  0.1293],\n","         [-0.1063, -0.1416,  0.0132,  ..., -0.0017, -0.5232,  0.0840],\n","         [ 0.0200, -0.1195, -0.2656,  ...,  0.0729, -0.1169, -0.1342]],\n","\n","        [[ 0.2660,  0.0350, -0.2831,  ..., -0.0161,  0.1360,  0.0719],\n","         [ 0.0263,  0.0338, -0.0409,  ..., -0.2518,  0.2495, -0.1730],\n","         [ 0.0214,  0.0437,  0.0099,  ..., -0.0856,  0.1213,  0.2009],\n","         ...,\n","         [-0.0480, -0.1880,  0.1275,  ..., -0.0818,  0.0978,  0.0796],\n","         [ 0.1071, -0.0367,  0.1860,  ..., -0.1182,  0.3157,  0.0321],\n","         [ 0.0392, -0.2088,  0.0315,  ..., -0.1526, -0.0884,  0.0783]],\n","\n","        [[-0.0209,  0.1301, -0.0140,  ..., -0.0115, -0.1701, -0.0440],\n","         [-0.0608, -0.0744,  0.2311,  ..., -0.0946,  0.0612,  0.0693],\n","         [-0.1900, -0.1826, -0.0996,  ...,  0.0716,  0.0307,  0.1650],\n","         ...,\n","         [ 0.0424, -0.0648,  0.0120,  ...,  0.0143,  0.1360, -0.1949],\n","         [ 0.2429,  0.0626, -0.0698,  ..., -0.0720, -0.2912, -0.1587],\n","         [ 0.0481, -0.0372, -0.0765,  ..., -0.2128,  0.0314, -0.0730]],\n","\n","        ...,\n","\n","        [[-0.1116,  0.0277,  0.0313,  ..., -0.1234, -0.0324,  0.1160],\n","         [-0.1027,  0.0335,  0.2151,  ..., -0.2044,  0.0290, -0.0519],\n","         [ 0.0079,  0.1392, -0.0701,  ...,  0.1662, -0.1189, -0.1023],\n","         ...,\n","         [-0.1372,  0.0608, -0.1012,  ...,  0.0834, -0.0020, -0.0089],\n","         [ 0.1847,  0.1163, -0.0010,  ...,  0.0498,  0.0754,  0.1044],\n","         [ 0.0678, -0.0306, -0.0335,  ...,  0.1549,  0.1286, -0.0872]],\n","\n","        [[-0.0506, -0.0364,  0.1871,  ...,  0.0805, -0.0824,  0.1450],\n","         [-0.0422, -0.0946, -0.1733,  ...,  0.1871,  0.1567, -0.1503],\n","         [-0.0558,  0.0276, -0.1010,  ...,  0.0012, -0.0896, -0.0139],\n","         ...,\n","         [-0.2137, -0.1092,  0.0068,  ..., -0.0357,  0.2068,  0.4457],\n","         [ 0.0240, -0.2505, -0.0401,  ..., -0.2360, -0.2356,  0.2198],\n","         [ 0.1742, -0.2265, -0.0196,  ..., -0.1815, -0.3166,  0.0151]],\n","\n","        [[-0.0632,  0.0016, -0.1548,  ...,  0.0224, -0.0912,  0.1171],\n","         [ 0.0601,  0.0183, -0.0175,  ...,  0.0848,  0.0581,  0.0125],\n","         [-0.1431,  0.1826,  0.1990,  ...,  0.1664, -0.2114,  0.1073],\n","         ...,\n","         [ 0.2251,  0.0240, -0.0106,  ..., -0.1443, -0.0599, -0.1167],\n","         [ 0.0778, -0.1356,  0.0710,  ...,  0.1302,  0.1659,  0.0141],\n","         [ 0.0468,  0.1248,  0.0349,  ...,  0.2004,  0.0141, -0.1468]]],\n","       device='cuda:0', requires_grad=True)\n","blocks.10.attn.b_Q: torch.Size([12, 64])\n","Parameter containing:\n","tensor([[-3.0123e-02,  1.3602e-01, -3.8416e-01,  3.3694e-01, -1.7341e-01,\n","         -1.5653e-01,  3.4522e-01, -1.3852e-02, -1.3725e-01, -1.9261e-01,\n","          1.9387e-02, -2.5850e-01, -2.1981e-01,  1.4822e-01,  3.3675e-01,\n","          7.7637e-03, -3.5762e-02,  7.3605e-01,  3.3085e-02, -3.1454e-02,\n","         -3.5582e-01, -1.6558e-01, -3.7846e-01, -1.0992e-01, -1.7854e-01,\n","         -1.0493e-01,  1.6315e-01,  1.1452e-01, -1.9253e-02,  4.6498e-01,\n","         -3.0453e-02,  2.8298e-01, -1.6969e-01, -5.0411e-01, -8.3478e-04,\n","         -1.2855e-01,  1.6586e-01, -1.4920e-01, -1.6881e-01,  2.5217e-01,\n","         -2.6585e-02,  3.0624e-01,  1.8588e-01, -1.7441e-01,  7.8861e-02,\n","         -1.3175e-01,  1.8460e-02,  1.0425e-01, -6.3471e-03, -6.7023e-02,\n","          3.3427e-02, -9.2746e-02,  1.2539e-01,  1.7525e-01,  3.0557e-01,\n","         -1.1556e-01, -1.5145e-01, -1.3279e-01, -1.2822e-01, -1.1879e-01,\n","         -1.6065e-02, -1.8621e-01, -3.1030e-01,  1.4419e-02],\n","        [ 3.2336e-01, -5.6805e-01,  1.6553e-01,  1.9435e-01, -3.3608e-01,\n","          6.7831e-01, -8.2142e-02,  3.1068e-01, -8.1936e-02,  4.3770e-01,\n","         -2.2056e-01, -3.3023e-01, -2.5596e-01,  1.0788e-01,  5.5037e-01,\n","         -1.2635e-01, -3.1608e-01, -1.2489e-01, -2.0516e-01, -1.1313e-01,\n","         -2.6113e-01,  1.0401e-01, -3.6134e-01,  2.6062e-01, -1.4910e-01,\n","         -3.1019e-01, -8.6061e-02,  1.4763e-01, -1.1878e-01,  1.7804e-01,\n","         -8.8062e-03,  8.5499e-02,  2.5822e-02, -2.0229e-02, -2.2241e-01,\n","          1.2736e-01,  5.3231e-01,  8.5405e-03,  2.6103e-01,  9.3588e-02,\n","          1.5144e-01,  2.0460e-01, -2.1693e-01,  7.4516e-02,  3.5391e-01,\n","         -4.9676e-03,  1.4308e-01,  3.0912e-01,  1.8003e-01,  2.9422e-01,\n","          1.0522e-01,  3.2590e-01, -4.1141e-01, -7.2757e-03, -2.9784e-01,\n","         -4.1902e-01, -1.4096e-01,  2.9099e-03, -7.6510e-01, -1.2501e-01,\n","         -3.7473e-01, -3.6066e-02, -6.6852e-01, -2.2426e-01],\n","        [ 3.0670e-01,  2.7726e-01, -3.5746e-02, -6.6571e-02, -1.8040e-01,\n","         -1.4455e-02, -2.8488e-01,  1.1973e-01, -1.0813e-01, -2.9574e-02,\n","          1.4813e-01,  2.3262e-01,  1.8313e-01,  1.5721e-01,  1.1551e-01,\n","         -9.4007e-03, -2.2056e-01,  1.3182e-01,  1.3524e-01, -2.4638e-03,\n","         -7.9404e-02,  1.1329e-01, -1.9826e-01,  3.2735e-01,  1.6909e-01,\n","          1.1703e-01, -1.4846e-01,  1.7037e-01,  2.2204e-01,  4.5190e-01,\n","         -1.3694e-01,  9.4014e-02,  1.3372e-01,  9.0555e-02,  1.7607e-01,\n","         -3.2086e-01, -1.6044e-01,  2.9353e-02,  1.2123e-01, -4.7298e-02,\n","         -1.9941e-01, -7.5615e-02,  5.3019e-01,  4.9601e-02, -8.5767e-02,\n","         -1.3318e-01,  1.9001e-01,  3.3301e-01, -9.1623e-01, -1.8152e-02,\n","         -2.4504e-01, -1.3247e-01, -9.2963e-02,  7.2941e-02,  1.7319e-01,\n","          1.7309e-01, -4.6604e-01,  1.9697e-01, -2.6153e-01,  1.3301e-01,\n","          1.9059e-02, -1.7204e-01, -4.2370e-01,  1.1790e-02],\n","        [ 1.6573e-01, -9.2918e-02,  1.7689e-01,  2.9540e-01,  1.9618e-01,\n","          2.3690e-01,  1.0554e-01, -1.7553e-01, -7.4050e-02, -1.6920e-01,\n","         -7.1313e-02,  1.3076e-01, -6.0497e-02, -5.3230e-03, -4.0768e-01,\n","         -3.4618e-02, -1.0846e-01, -8.3831e-02, -2.3979e-02, -4.6495e-02,\n","         -1.9391e-02, -5.6780e-01,  1.9127e-01, -2.7112e-01,  1.5138e-01,\n","         -3.5411e-02, -1.8129e-02, -2.2363e-02,  2.1977e-01,  1.4437e-01,\n","          8.2205e-02, -1.5124e-01,  8.5538e-02,  2.0063e-01,  7.1086e-02,\n","          5.5811e-02,  4.8766e-02, -1.0142e-01, -2.3918e-01,  1.7465e-02,\n","         -1.7654e-02,  9.5229e-02,  2.1134e-01, -7.4745e-02, -1.6410e-02,\n","          7.1783e-01, -6.9806e-02, -3.4746e-02, -7.6417e-02,  1.7063e-01,\n","         -1.1323e-01, -2.0004e-02,  1.7884e-01, -1.6039e-01,  1.0098e-01,\n","         -9.6320e-03, -1.9244e-01, -4.7037e-01, -2.3088e-01,  2.6880e-01,\n","          1.0193e-01, -1.7237e-01,  2.8451e-02,  2.5470e-01],\n","        [ 5.7807e-02, -8.0783e-02, -1.7955e-01,  4.7289e-02, -1.7469e-01,\n","         -1.5648e-01, -1.6603e-01,  4.0933e-01,  1.4869e-01, -8.4099e-02,\n","          3.9806e-01,  7.9139e-02,  2.3833e-01, -7.5232e-03, -1.0050e-01,\n","         -6.0363e-02,  3.5878e-01,  4.0598e-02, -1.1177e-02,  2.1930e-01,\n","         -1.5621e-03,  2.1587e-02,  1.3994e-01, -3.3742e-02, -5.6713e-02,\n","          1.9469e-01, -1.2251e-01,  1.5201e-01,  4.6036e-01, -2.7384e-02,\n","         -2.8247e-01,  2.2679e-01, -3.7193e-02, -1.5851e-01,  8.5526e-02,\n","          6.7080e-01,  4.0681e-02,  1.2934e-01,  2.5086e-01, -2.5848e-01,\n","          1.3640e-01, -1.1105e-01,  3.7087e-03,  2.3662e-01, -1.1396e-01,\n","          3.7388e-02,  1.8426e-01,  5.4101e-02,  1.6549e-01, -1.6190e-02,\n","          2.6202e-01,  2.0808e-01, -8.1524e-02,  8.2696e-02, -8.5221e-02,\n","         -1.5549e-01, -1.6144e-01, -1.6774e-01,  2.7503e-01, -6.5406e-02,\n","         -1.4697e-01, -4.2654e-02, -2.7495e-01,  2.0262e-02],\n","        [-3.4260e-01, -2.3431e-02,  7.4462e-02, -5.0874e-02, -4.1342e-01,\n","         -2.4041e-01,  7.8618e-02,  4.2597e-03, -3.9149e-02,  3.1275e-02,\n","          4.3142e-02,  3.8456e-01,  2.3098e-01,  1.2162e-01,  2.6502e-01,\n","          3.9123e-01, -2.7914e-02, -7.4858e-02, -3.5179e-02, -4.9480e-01,\n","         -2.4047e-01, -7.5461e-02, -5.2049e-02,  3.4696e-01,  3.4176e-01,\n","         -2.4190e-02, -1.2849e-01,  7.3825e-01, -4.9214e-01,  2.6630e-01,\n","          1.0520e-01,  8.3582e-02, -8.2958e-02, -2.3379e-02, -2.9904e-01,\n","          8.9989e-02,  5.5421e-02, -7.8586e-02, -2.3359e-02, -4.5906e-01,\n","         -2.8271e-02,  2.9993e-01,  7.3759e-01,  2.6639e-01,  7.8228e-02,\n","         -3.5436e-01, -1.6673e-01,  1.1166e-01,  2.0798e-01,  3.6008e-01,\n","          8.6032e-02,  3.2023e-01, -5.7319e-02,  3.3350e-02,  4.8435e-02,\n","          7.1719e-03,  3.7614e-01, -5.0349e-02,  6.3670e-02,  2.1166e-02,\n","         -2.0407e-02, -5.0323e-02,  3.6483e-02, -4.6407e-02],\n","        [ 6.6423e-01, -3.4330e-01,  2.7236e-01,  1.0080e-01,  2.6146e-01,\n","         -1.2223e-01,  1.0168e-02,  3.9059e-02, -1.3374e-01,  1.1016e-01,\n","         -2.4258e-01, -3.6628e-01, -1.8596e-01, -8.3891e-02, -2.7699e-01,\n","          3.3513e-01, -1.2085e-01, -2.4310e-01,  8.1227e-02,  4.7663e-03,\n","          4.5216e-02,  1.8800e-01,  9.1009e-02, -4.4565e-01, -4.6175e-03,\n","          1.8649e-01,  1.7874e-01,  5.1177e-02,  2.4121e-01,  7.6263e-02,\n","         -2.4174e-01,  4.7941e-01,  2.5366e-02,  1.0680e-02, -1.4270e-01,\n","          1.8863e-01, -5.5274e-01, -3.2207e-02,  1.6730e-01, -1.8025e-01,\n","         -3.8638e-01,  1.0791e-01, -2.8317e-01,  3.4959e-02, -2.1794e-02,\n","          3.3955e-01,  7.4866e-02, -1.9866e-04,  3.9255e-02,  6.7143e-03,\n","         -3.5282e-01, -1.1582e-01, -5.3339e-01, -1.4976e-01, -5.3786e-02,\n","         -8.0359e-02, -1.2614e-01,  2.7754e-01,  3.7940e-02,  9.0583e-02,\n","         -2.9057e-02,  1.5832e-01,  1.5367e-01, -1.5008e-01],\n","        [-1.3314e-01, -3.4548e-03, -3.1673e-01, -2.8690e-02,  7.5536e-02,\n","          6.0555e-02, -1.8786e-02,  5.8156e-02,  2.7954e-01, -2.0821e-03,\n","          1.5358e-01,  3.9629e-02,  3.6476e-02, -2.6028e-01,  4.4187e-02,\n","         -4.1662e-02, -1.6517e-01, -3.9428e-02,  1.9538e-01,  3.5013e-02,\n","          2.0071e-01, -3.5046e-01,  9.0652e-02,  2.4818e-01, -6.7363e-02,\n","          1.6524e-01, -3.2464e-02, -7.6461e-02,  9.8651e-03,  8.2810e-02,\n","         -5.8788e-02, -1.8099e-01, -1.3864e-01,  2.3018e-01, -1.2891e-02,\n","          8.3856e-03, -4.0206e-01,  1.3831e-01, -2.2848e-01,  7.9650e-02,\n","          2.8299e-02,  1.7920e-01,  1.7552e-01, -9.6515e-02, -3.1170e-02,\n","         -1.4932e-01, -7.6143e-02,  4.0943e-01, -8.5522e-02, -1.0464e-01,\n","         -7.0688e-02, -9.4753e-02, -1.4565e-01, -1.2436e-01, -1.4906e-01,\n","         -2.7994e-01,  8.9925e-03, -2.3814e-02, -1.3242e-01,  1.2647e-01,\n","          9.0779e-02,  2.1219e-01,  1.4251e-02,  3.1764e-01],\n","        [-2.6386e-01, -4.6624e-01, -1.3946e-01, -2.9113e-01,  1.8327e-01,\n","         -2.2915e-01, -1.3431e-01,  9.2101e-02,  7.7100e-01,  8.6268e-02,\n","          3.4373e-02, -9.2637e-02,  8.7659e-02,  2.0009e-01,  6.1495e-02,\n","         -8.4341e-03, -1.4733e-02,  6.9567e-02,  2.2556e-02, -1.7362e-02,\n","          2.1109e-01,  5.4569e-02,  2.2487e-01,  2.4846e-01,  1.1048e-01,\n","          3.8328e-01, -2.9622e-01, -7.4607e-02,  1.1078e-01, -5.6308e-02,\n","          1.3126e-01, -1.0648e-01, -5.8257e-01, -9.3389e-02, -1.0492e-01,\n","         -1.0355e-01,  7.3085e-02, -2.0369e-01,  2.4469e-01,  4.3889e-02,\n","         -3.6401e-01, -7.0297e-02,  2.7228e-01,  7.5697e-02, -4.3272e-02,\n","         -2.5266e-01,  9.3861e-02,  5.7585e-01,  1.2477e-01, -1.6433e-02,\n","          9.4834e-02, -2.8133e-01, -4.3836e-02,  6.7955e-02, -1.9849e-01,\n","          1.1305e-01, -2.6484e-01, -1.1692e-01, -1.9514e-01,  1.1510e-01,\n","          2.7042e-02,  1.3889e-01, -8.7538e-02, -4.2816e-02],\n","        [ 1.0123e-01, -1.2715e-01,  1.7090e-02, -4.1021e-02, -1.3334e-01,\n","          1.2492e-01, -3.4841e-01, -1.5253e-01,  3.4907e-01, -8.3802e-02,\n","          4.5930e-04, -2.8797e-01, -7.5842e-02,  3.5990e-01, -5.3601e-01,\n","          1.0825e-01,  1.7082e-01, -9.4759e-02, -6.8271e-02,  2.5095e-01,\n","         -4.6936e-01,  3.4593e-01,  1.9105e-01,  1.5189e-01,  3.2542e-01,\n","          1.6826e-01,  2.2123e-01, -1.7550e-02,  2.4126e-02, -3.8289e-01,\n","          1.3111e-01,  1.9947e-01, -1.2816e-01,  1.2801e-02,  1.5380e-01,\n","         -1.0072e-01,  3.8776e-02, -1.0659e-01,  2.7618e-01, -5.9442e-03,\n","          9.3314e-03, -1.1100e-01, -2.1771e-01, -1.8497e-01,  5.4491e-01,\n","          1.1301e-01, -5.3555e-01, -1.2774e-01, -1.0334e-01,  7.5742e-02,\n","         -3.4792e-02, -9.3824e-02, -2.4960e-01, -1.2880e-01, -2.2386e-01,\n","          6.7761e-02, -2.3432e-01, -5.4757e-02,  1.1834e-01,  9.6907e-02,\n","          2.7172e-03, -1.1264e-01,  2.0810e-01, -2.2508e-02],\n","        [ 2.5917e-01,  4.1514e-01,  3.1884e-01, -2.2309e-01, -3.8306e-01,\n","         -1.4299e-01,  1.9778e-01,  2.0938e-01,  2.2597e-01, -5.4538e-02,\n","          1.8792e-01,  2.3519e-01,  1.0911e-02,  3.8372e-01,  1.8559e-01,\n","          2.5174e-01,  3.8684e-01, -6.2342e-02, -3.5415e-01, -5.8255e-02,\n","         -3.2187e-02, -2.4554e-01, -1.0832e-01,  3.1419e-01,  4.7324e-01,\n","         -5.0839e-01, -6.4546e-01,  6.6059e-02,  3.9169e-02, -1.1323e-01,\n","          3.6230e-01,  2.2373e-01, -2.2472e-01,  2.0258e-01,  9.4489e-02,\n","          7.8462e-02,  3.4755e-01,  3.3308e-01,  1.7111e-01,  2.5708e-01,\n","          4.6361e-01,  1.4691e-01, -3.3250e-01,  1.8182e-01,  1.6906e-01,\n","          4.5256e-02,  2.2282e-01, -2.6774e-02,  4.5942e-01, -1.8142e-01,\n","         -1.8363e-02, -2.5842e-01, -1.0456e-01,  1.9713e-01,  2.0192e-01,\n","          2.8451e-01, -2.3377e-01, -2.7875e-02,  5.6174e-01, -1.0759e-01,\n","          6.7322e-02,  1.1305e-01, -3.4908e-01, -1.9306e-02],\n","        [-5.3976e-02,  1.7750e-01, -2.9783e-01,  1.9763e-01,  1.4506e-01,\n","         -4.1781e-01,  6.9924e-02, -1.5619e-01,  2.7054e-01,  4.3899e-02,\n","          6.9901e-02,  1.5524e-01, -1.4151e-02,  3.4420e-01,  3.7932e-01,\n","         -1.6599e-01,  1.4620e-01, -4.7354e-02, -4.7243e-02,  3.0928e-01,\n","          5.8092e-02,  3.3537e-01,  4.9582e-01,  2.5782e-01,  8.2108e-04,\n","         -3.6974e-01,  2.3269e-01, -1.8757e-01, -4.3676e-01, -5.9062e-02,\n","         -2.8126e-01,  1.9963e-01,  1.1785e-01,  2.9632e-02, -4.5260e-02,\n","         -1.7040e-01,  1.2824e-01,  6.4427e-02, -1.8088e-01,  4.1791e-02,\n","         -6.9801e-02,  4.5488e-01, -2.2003e-01, -1.3967e-01, -4.7346e-01,\n","          2.4016e-02,  6.7736e-01,  1.8737e-01,  4.0143e-02, -5.8746e-01,\n","          6.4271e-02, -2.6761e-01, -2.2386e-01, -1.5010e-01, -1.6765e-01,\n","          2.1310e-02,  1.4503e-01, -2.6396e-02,  9.4649e-02,  3.2541e-01,\n","         -1.4509e-01, -7.2613e-02,  7.2879e-02, -2.5346e-01]], device='cuda:0',\n","       requires_grad=True)\n","blocks.10.attn.b_O: torch.Size([768])\n","Parameter containing:\n","tensor([ 4.7937e-02, -3.1588e-02, -5.5813e-02,  1.5831e-02,  7.9644e-02,\n","         5.4199e-02,  2.2304e-01,  1.5857e-01,  1.6212e-02,  8.7711e-02,\n","         2.3944e-01,  1.2179e-01,  2.6832e-02, -2.9524e-02,  9.1278e-03,\n","         4.6827e-02, -2.1363e-01, -7.5650e-02,  6.7583e-02, -7.0388e-02,\n","        -8.2164e-02,  4.7564e-02, -1.0019e-02, -2.4580e-02,  8.3130e-02,\n","        -3.1600e-02, -3.0950e-02, -1.7740e-02,  2.5806e-02,  9.7704e-02,\n","        -5.4576e-02, -4.4918e-02, -2.7341e-03, -1.5207e-01,  3.7182e-02,\n","        -1.2179e-01,  5.1144e-01, -3.2758e-02, -7.0350e-02,  1.0358e-01,\n","        -1.0174e-01, -1.1064e-02,  3.6645e-02, -1.4911e-01,  4.8826e-02,\n","         1.3557e-01,  1.2574e-04,  1.2123e-02, -2.9050e-02,  1.5527e-01,\n","         8.6084e-03,  2.7225e-02, -3.8675e-02,  9.7560e-02,  1.5169e-01,\n","         1.9880e-01,  1.0015e-01, -1.6542e-01,  1.0381e-02,  2.2829e-02,\n","        -4.6071e-02,  1.1734e-01, -7.5738e-02,  1.2981e-01, -2.7963e-01,\n","         9.2118e-02,  1.6833e-01,  7.8993e-02, -7.2420e-02, -8.4600e-02,\n","         4.6709e-02, -1.1569e-01, -1.9673e-01,  5.5477e-02,  3.9599e-02,\n","        -2.0853e-02, -3.0665e-02,  3.1019e-02, -3.6241e-02,  1.6613e-02,\n","        -3.5343e-02,  1.0857e-01, -6.9708e-02, -1.2507e-01, -1.1330e-01,\n","         9.8706e-02, -6.1470e-02, -6.9282e-01,  1.8552e-01, -1.0347e-01,\n","        -1.6407e-02,  7.8168e-02, -5.4766e-02,  1.0888e-03, -8.5360e-03,\n","         3.1690e-02,  1.3761e-01,  4.6803e-02,  3.7858e-02,  5.3966e-02,\n","         7.0715e-02,  1.3657e-01,  2.2666e-01, -1.5802e-01,  8.6463e-02,\n","         3.8259e-02,  1.1012e-02,  1.1827e-01,  1.0691e-01, -1.7779e-01,\n","        -2.2092e-02,  2.3585e-02, -7.4207e-02, -2.0405e-01,  4.3805e-03,\n","         1.6590e-01,  6.3301e-02,  1.5828e-01, -6.4452e-02,  1.3357e-02,\n","         7.6930e-02,  7.2073e-02,  5.0408e-02,  2.9214e-01,  1.9529e-01,\n","        -1.9358e-01,  1.3167e-01, -5.9751e-02,  3.8664e-03,  3.1661e-02,\n","         3.5332e-02, -1.3900e-02, -5.6890e-02,  1.8373e-01,  8.3392e-02,\n","         1.2190e-01, -1.8956e-01, -9.0826e-02, -2.0872e-01,  7.7108e-02,\n","         9.1274e-02, -1.8480e-02, -1.5327e-01, -1.2498e-01, -1.1931e-01,\n","         9.5322e-02,  1.2761e-01,  5.1300e-03,  9.8440e-02,  6.9930e-02,\n","        -4.9191e-02,  4.3527e-02, -1.8803e-01, -4.5674e-02, -1.6852e-01,\n","         1.5070e-01, -1.3489e-01, -1.0053e-01, -6.2539e-02,  1.2798e-01,\n","         2.2494e-01, -3.1419e-02,  5.8586e-02,  1.0528e-01, -1.0922e-01,\n","        -1.0378e-01, -6.0511e-02, -1.3783e-01, -2.3716e-01, -1.9155e-01,\n","        -1.0309e-01,  2.2602e-02, -1.3592e-01,  1.7917e-01, -7.3952e-03,\n","        -4.3551e-03, -1.3310e-01,  6.2222e-02,  1.0593e-01,  9.1266e-02,\n","        -1.2636e-01,  2.9490e-01, -4.2028e-02, -5.2721e-03,  1.2662e-01,\n","        -7.9044e-03,  7.2558e-02,  3.5874e-03, -3.5116e-02,  6.9390e-02,\n","         3.1368e-02, -9.0066e-02, -5.7947e-02, -2.1587e-02, -1.2224e-01,\n","        -9.7884e-02,  3.9194e-02, -1.1906e-01, -4.1468e-02, -1.1932e-01,\n","        -1.7761e-02,  1.3867e-01,  2.4053e-02, -1.1533e-01,  1.1941e-01,\n","        -8.4960e-02, -8.9286e-02,  1.4932e-01, -9.6569e-02,  1.0428e-01,\n","         1.4615e-01,  9.0860e-03, -1.1936e-01, -8.3104e-02, -1.1557e-01,\n","        -1.3101e-01,  2.7457e-02, -3.6647e-02, -1.3184e-01,  4.3613e-02,\n","        -5.4241e-03, -7.5222e-02,  1.0976e-01,  9.5867e-02,  2.4106e-03,\n","         2.6423e-02,  1.4131e-01,  2.5239e-02, -5.5699e-02,  9.3297e-02,\n","         1.5433e-01,  3.4010e-03,  2.1518e-01, -1.7513e-03,  1.1967e-02,\n","         9.1820e-03,  1.3097e-01, -1.1063e-01,  9.8834e-02,  6.5788e-02,\n","        -7.7950e-02, -3.4329e-03, -3.1718e-02, -7.1343e-02, -1.7819e-01,\n","         1.8926e-02, -6.1608e-02, -8.6230e-02,  8.9410e-02, -1.4653e-01,\n","        -1.4126e-01, -1.6717e-01,  4.0580e-02,  7.8045e-02, -4.4155e-02,\n","         1.5847e-01,  7.2593e-02,  3.1912e-02,  2.1329e-02,  4.8976e-02,\n","         9.2007e-02, -3.9620e-02,  1.8473e-03,  6.4812e-02, -2.8528e-01,\n","        -1.5045e-01,  3.6618e-01, -8.6848e-02, -6.5474e-02,  4.3282e-02,\n","         5.7840e-02, -8.7303e-02,  4.4423e-02,  9.6521e-02,  2.1719e-02,\n","         6.0572e-02,  1.0382e-02, -1.4153e-01,  1.0285e-01,  7.5118e-02,\n","         1.0097e-01,  9.3333e-03, -1.1885e-01,  2.5006e-02,  6.3195e-02,\n","         4.7567e-02,  1.6035e-02, -9.7946e-02, -9.2009e-02, -3.4955e-02,\n","         5.1831e-03,  8.1484e-02, -1.2654e-01, -1.4697e-03,  1.1377e-01,\n","        -1.3410e-01,  2.0093e-02, -4.1324e-02,  7.7281e-02,  5.0051e-02,\n","        -4.8703e-02, -5.3925e-02,  6.1276e-02, -4.1822e-02,  4.9155e-02,\n","         7.5054e-02,  1.0769e-01, -1.0651e-01, -1.3932e-01, -1.8701e-02,\n","         2.6587e-02, -4.6411e-02,  3.1994e-01, -5.2711e-02, -4.7204e-01,\n","         3.8954e-02, -8.8885e-02,  3.4420e-02,  6.5038e-02,  1.9525e-01,\n","        -1.7640e-01,  7.1568e-02,  1.5165e-01, -7.3206e-02,  3.4461e-02,\n","         1.9498e-03, -1.8609e-01,  7.0690e-02,  1.8639e-02, -7.2433e-02,\n","        -2.9556e-02, -7.9434e-03,  8.9064e-02,  8.1119e-02,  2.1466e-02,\n","        -1.8293e-01,  2.7735e-01, -5.7738e-02,  8.0091e-02, -5.2167e-02,\n","        -7.0607e-02, -7.1579e-02,  1.9567e-01, -2.9619e-02,  2.8869e-01,\n","         1.0083e-01,  3.4755e-02, -8.4485e-02, -3.2696e-02, -5.4374e-02,\n","        -1.0799e-01,  1.4155e-01, -9.3129e-02, -1.0156e-01,  1.2757e-01,\n","         3.6797e-02, -3.1515e-02, -8.1485e-02, -1.7040e-01, -8.4086e-03,\n","         1.4829e-02, -1.8263e-02,  7.8528e-02,  8.3676e-02,  6.6276e-02,\n","        -2.7869e-01, -9.5947e-02,  1.1749e-02,  4.1306e-02,  8.6926e-03,\n","         7.7652e-02,  3.2255e-02,  1.3834e-01, -4.4486e+00, -3.6275e-01,\n","        -1.1963e-03, -8.9503e-02,  9.5880e-02,  2.2324e-01,  1.3193e-01,\n","        -7.6890e-02,  3.2911e-01, -6.3174e-02,  4.1791e-02, -1.2502e-02,\n","         1.7100e-01,  5.7489e-02, -2.0299e-01,  3.3243e-02, -8.3129e-02,\n","         3.4224e-01,  5.8200e-02,  1.4775e-01,  2.5619e-02, -1.4317e-01,\n","         1.4941e-01, -6.7741e-02,  8.4692e-02,  1.2604e-02, -2.1257e-02,\n","        -1.4093e-03,  8.4536e-02,  8.5240e-02, -5.1753e-02,  5.5997e-02,\n","        -7.7187e-02,  4.0158e-02, -6.9392e-02,  1.6538e-01, -1.6555e-02,\n","        -1.4952e-01, -1.2920e-01, -1.7886e-01, -9.6314e-03, -1.5353e-01,\n","         7.0691e-02,  9.2308e-02,  6.3373e-02, -1.5767e-01,  1.6187e-02,\n","        -1.9705e-01,  3.6078e-03,  1.6092e-01,  1.4987e-01, -4.1497e-02,\n","        -8.4000e-02, -7.0798e-02,  6.7229e-03, -1.3929e-01, -8.5196e-02,\n","         8.1472e-01,  8.5920e-03,  1.3420e-01, -1.3269e-01,  2.0686e-02,\n","         1.1995e-01,  9.0166e-02,  8.6618e-02,  5.4837e-02,  6.4329e-02,\n","        -1.7084e-02, -5.2210e-02,  2.2888e-01, -2.0424e-01,  1.2421e-01,\n","         1.3959e-01, -1.7688e-01,  2.6165e+00, -2.4519e-02,  1.7078e-01,\n","        -1.6223e-01,  3.7752e-02,  7.3862e-02,  6.0872e-02,  1.4170e-01,\n","         5.4109e-03, -1.1420e-01, -4.5449e-02,  6.8409e-02, -2.7813e-02,\n","         1.0659e-01,  2.0718e-01, -5.1880e-02, -1.0829e-01,  2.4777e-03,\n","        -2.9447e-02, -8.3015e-02, -7.2505e-02,  6.0554e-02,  8.2812e-02,\n","         1.6464e-02, -2.0826e-02, -3.1241e-02,  3.6609e-02, -1.6010e-01,\n","        -6.5573e-02, -6.8162e-02, -9.1021e-02, -3.3068e-02, -1.7318e-01,\n","        -3.3457e-01,  4.6834e+00,  2.7113e-02,  6.6056e-04, -6.7889e-02,\n","         4.4123e-02,  1.4383e-01, -1.5809e-01,  6.5069e-02, -1.1325e-01,\n","         3.6116e-02, -1.1768e-01, -5.8807e-02, -2.3403e-02, -5.5750e-02,\n","         1.4230e-02,  1.4241e+00, -1.1635e-01,  3.0558e-02,  2.1962e-02,\n","         1.7043e-01, -6.8005e-02,  5.2645e-02, -1.6300e-01, -6.0929e-02,\n","        -4.1334e-02,  4.1170e-02,  5.6959e-02, -3.1584e-02, -9.3887e-02,\n","        -1.5808e-04, -2.1193e-02, -1.2077e-01, -1.9837e-02, -8.7391e-02,\n","        -2.1372e-01, -8.2095e-02, -1.1554e-01,  5.3607e-02, -1.9404e-02,\n","         2.8743e-02, -1.5096e-01,  1.4700e-02,  8.7140e-02, -4.5549e-02,\n","        -2.6920e-02, -2.6464e-01, -2.8392e-01,  1.3871e-01,  1.7658e-02,\n","         1.5385e-01,  1.6090e-01,  1.9427e-02,  7.3656e-02, -2.0961e-01,\n","        -9.1527e-02, -8.4891e-02, -7.9264e-02,  3.0269e-03, -1.3221e-01,\n","         2.5468e-02, -4.4904e-02,  1.4309e-02, -8.0060e-02, -2.1336e-01,\n","         2.4848e-02,  2.4713e-02, -1.4904e-01, -6.4384e-02, -5.1738e-02,\n","        -2.5781e-02,  1.1272e-01, -1.0571e-01,  4.9443e-02,  3.9466e-02,\n","         3.0738e-02,  2.6485e-02,  1.4342e-01, -6.0364e-02, -2.3401e-01,\n","        -8.1766e-02,  1.4937e-01,  1.6887e-01, -1.0792e-03,  6.8753e-02,\n","         5.5594e-02,  7.0374e-02, -6.4380e-02, -9.1701e-02, -1.6403e-01,\n","         1.1248e-01, -5.4219e-02,  8.2941e-02, -3.3527e-01, -1.5606e-01,\n","         1.2022e-02, -2.1029e-02,  1.5834e-01, -9.5233e-03,  1.2413e-01,\n","         3.3597e-02, -3.4894e-02,  1.4954e-01, -6.8731e-02, -7.6407e-02,\n","         2.9327e-02, -6.8078e-02, -1.0464e-02,  2.1457e-01,  1.1778e-01,\n","        -9.2129e-02, -1.2972e-01,  2.3873e-01,  2.4697e-02, -5.3823e-02,\n","         6.3148e-02, -1.0659e-01,  7.2561e-02,  2.2318e-02,  6.0357e-02,\n","        -1.6966e-03,  9.3696e-02, -1.5331e-01, -6.6596e-03, -4.8424e-02,\n","         2.4525e-02, -1.6852e-01,  1.8566e-02, -2.1786e-02,  1.3239e-01,\n","        -1.0280e-01,  9.7453e-02, -1.0113e-01, -5.5575e-02, -1.0286e-01,\n","        -2.9138e-01,  2.6702e-02, -1.5618e-01, -7.0946e-02, -6.1069e-03,\n","         3.3646e-02,  1.6360e-02,  1.6209e-01, -1.0523e-02, -1.2743e-01,\n","        -9.9509e-02, -7.4020e-02, -1.5319e-01,  1.5190e-01, -4.6028e-02,\n","         1.0621e-01, -1.3951e-01, -1.5880e-02, -1.0535e-01, -1.9153e-02,\n","        -1.4352e-01, -1.8297e-01, -1.3212e-01, -9.6779e-03,  1.0565e-02,\n","         1.1169e-01, -8.2262e-02, -1.6700e-01,  2.4313e-02,  1.4730e-01,\n","         6.5713e-03,  1.4872e-01,  4.1170e-02,  1.1148e-01, -1.7808e-02,\n","         1.2893e-01, -1.2949e-01, -4.1430e-02, -1.7634e-01,  3.4733e-02,\n","        -2.3353e-02,  5.9309e-02,  3.1180e-02,  6.1073e-03,  1.9395e-01,\n","        -6.7231e-02,  3.1482e-02,  7.5942e-03, -2.5190e-02, -7.0729e-02,\n","         7.8313e-02,  8.4934e-03, -7.1392e-02,  6.4572e-02, -1.0761e-01,\n","        -4.1903e-02, -2.1715e-01, -2.9286e-01,  1.1623e-01, -3.5466e-02,\n","        -2.1299e-02, -1.5950e-01, -5.6319e-02, -2.3003e-02,  1.8329e-01,\n","        -5.5407e-02,  1.2235e-01, -7.4341e-02,  9.6844e-02, -8.4257e-02,\n","        -1.0470e-01,  1.3006e-01, -1.9883e-01,  1.0290e-01, -6.8469e-02,\n","         4.1534e-03,  2.6223e-01,  5.9830e-02,  2.9934e-01, -1.0090e-01,\n","         1.3055e-01,  1.6457e-01,  8.9949e-02,  4.5198e-02,  1.6215e-01,\n","         1.5733e-01, -6.3827e-02, -9.5586e-02, -1.9934e-01, -4.3034e-02,\n","         5.9373e-02,  7.5643e-02,  1.0851e-01, -8.1194e-02,  1.1950e-01,\n","        -4.4552e-02,  5.1804e-02, -1.4952e-01, -1.1100e-01, -4.9647e-02,\n","        -3.1114e-02,  5.9411e-02, -5.8479e-02,  6.2311e-02,  1.0563e-01,\n","         4.7962e-02,  3.7451e-02,  3.6913e-02,  2.1047e-02, -1.0449e-02,\n","        -3.3659e-02,  5.1748e-02,  8.7565e-02, -1.3298e-01, -3.7727e-02,\n","        -5.4857e-02, -3.7765e-02, -2.7018e-01,  9.9005e-02, -1.1593e-01,\n","         6.1492e-03,  3.3974e-02, -2.8060e-02,  3.3017e-02,  1.1789e-02,\n","         1.2295e-01, -5.7900e-02,  8.5595e-02,  1.1952e-01,  1.0527e-02,\n","        -8.3716e-02, -5.8298e-02, -1.1706e-02, -3.5549e-02,  4.7443e-02,\n","        -1.3783e-01, -1.8967e-02, -4.3700e-02, -1.5655e-02, -4.1889e-02,\n","        -9.8287e-03,  9.8394e-02, -2.5409e-02,  2.6745e-02, -1.9559e-02,\n","        -1.7901e-01,  9.6560e-02,  2.9094e-01, -9.3618e-02, -5.0036e-02,\n","         6.2974e-02, -1.1955e-02, -7.7004e-02], device='cuda:0',\n","       requires_grad=True)\n","blocks.10.attn.W_K: torch.Size([12, 768, 64])\n","Parameter containing:\n","tensor([[[ 1.4899e-01,  4.0719e-02, -6.1197e-02,  ...,  8.6335e-02,\n","          -9.1365e-02, -6.2707e-02],\n","         [ 2.8456e-02, -1.9467e-01,  3.8142e-03,  ...,  3.9168e-02,\n","          -3.3435e-03,  8.9742e-02],\n","         [ 6.5835e-02, -1.6945e-02, -1.0595e-02,  ...,  3.7114e-02,\n","          -3.5403e-02,  8.5406e-02],\n","         ...,\n","         [-1.3835e-01,  4.3756e-02,  5.7773e-02,  ...,  8.7522e-02,\n","          -1.7569e-01,  9.4440e-02],\n","         [ 1.9414e-02,  1.3590e-01,  5.1458e-02,  ..., -5.3100e-02,\n","           5.0195e-02, -7.8129e-02],\n","         [-3.1103e-02, -6.5926e-02,  1.4603e-01,  ...,  5.5265e-02,\n","           8.6715e-02,  2.4448e-01]],\n","\n","        [[ 2.0949e-01, -5.7649e-02,  1.3669e-02,  ..., -2.1519e-02,\n","          -1.9019e-01, -2.3519e-01],\n","         [ 4.4483e-02, -1.5558e-01, -3.1744e-02,  ...,  2.0628e-01,\n","           1.1652e-01,  2.1740e-01],\n","         [-1.6377e-01,  1.0866e-01, -7.9240e-02,  ...,  1.7547e-02,\n","           1.3203e-02,  2.9588e-02],\n","         ...,\n","         [-1.3132e-01, -9.9630e-02, -8.6718e-02,  ..., -1.0303e-01,\n","           6.1592e-02, -2.4515e-02],\n","         [-1.9981e-04,  4.2929e-02, -1.3723e-01,  ..., -5.4818e-02,\n","           1.5920e-02, -2.8745e-05],\n","         [-9.4270e-02,  1.1597e-01,  9.4899e-02,  ..., -4.4925e-02,\n","          -2.6543e-02, -2.2308e-01]],\n","\n","        [[ 7.8110e-03,  1.4494e-01, -2.5136e-01,  ...,  9.1028e-03,\n","          -1.2136e-01, -1.0187e-01],\n","         [-1.7098e-01, -1.0189e-01,  5.4635e-02,  ..., -8.9965e-02,\n","           2.2935e-02,  8.5610e-02],\n","         [ 5.9034e-02,  8.5637e-02, -2.2683e-02,  ..., -1.2856e-02,\n","          -1.2147e-01,  1.3224e-01],\n","         ...,\n","         [-7.4931e-02,  1.0073e-01, -1.3730e-01,  ..., -1.3577e-01,\n","           2.9199e-02, -3.5981e-02],\n","         [ 1.0396e-01, -2.3111e-02, -2.8135e-01,  ..., -3.1781e-02,\n","          -9.4206e-02,  7.1996e-03],\n","         [-4.7553e-02,  2.4214e-02, -1.0230e-01,  ..., -3.1475e-02,\n","          -2.3651e-01, -8.1435e-02]],\n","\n","        ...,\n","\n","        [[ 6.7738e-02, -4.1528e-02,  2.7653e-01,  ..., -1.1385e-01,\n","           1.5962e-01, -1.9448e-01],\n","         [-2.4945e-02, -6.8333e-02,  4.5379e-02,  ..., -6.6308e-02,\n","           3.4119e-02, -1.9457e-01],\n","         [ 1.5683e-01, -8.2802e-02,  5.9025e-02,  ..., -4.4520e-02,\n","          -3.4189e-03,  3.0698e-01],\n","         ...,\n","         [-1.3213e-01, -2.3835e-02,  9.0141e-02,  ..., -2.2527e-02,\n","          -1.5434e-01,  1.4390e-01],\n","         [-2.8954e-02,  5.2212e-02,  5.1452e-02,  ...,  2.2362e-01,\n","          -1.4996e-02,  5.7010e-02],\n","         [ 4.1662e-02,  4.4734e-02,  8.9494e-03,  ..., -5.6905e-02,\n","          -3.1331e-02,  2.0039e-01]],\n","\n","        [[ 4.4463e-02, -5.7257e-02, -9.3569e-02,  ..., -1.8667e-01,\n","          -1.8870e-01,  4.0083e-02],\n","         [ 7.9195e-02, -7.8978e-02, -1.2453e-01,  ..., -5.8864e-02,\n","          -5.7910e-02,  3.1454e-02],\n","         [ 3.0748e-01,  1.0332e-01, -7.6085e-02,  ...,  1.3571e-01,\n","          -6.6587e-02, -2.5773e-02],\n","         ...,\n","         [-1.1332e-01,  1.4779e-01, -1.0429e-01,  ..., -1.1464e-01,\n","          -1.4787e-01,  1.3347e-01],\n","         [-4.8410e-02,  1.1310e-01, -1.3474e-01,  ...,  1.8403e-01,\n","          -1.4686e-01,  2.5373e-02],\n","         [-1.3367e-01,  6.4444e-02,  8.7424e-02,  ..., -4.3135e-02,\n","          -4.0451e-02,  2.6351e-02]],\n","\n","        [[ 5.2266e-03,  1.6101e-01, -9.2400e-02,  ...,  7.2835e-02,\n","          -1.8465e-02, -1.7027e-01],\n","         [-1.0954e-01,  2.4147e-01,  1.0622e-01,  ..., -2.1062e-02,\n","           1.6349e-01,  1.3848e-01],\n","         [-1.4739e-01,  5.6957e-02, -9.2679e-02,  ...,  1.0056e-01,\n","           5.2361e-03, -3.4092e-01],\n","         ...,\n","         [ 1.3822e-01, -1.5591e-01, -1.0345e-02,  ..., -3.9752e-02,\n","           3.7690e-02, -5.6212e-02],\n","         [ 8.3212e-03,  1.7887e-01, -1.2826e-02,  ...,  2.7974e-01,\n","           1.5496e-01,  9.6960e-02],\n","         [-2.9811e-02, -1.2530e-01,  5.1095e-02,  ...,  1.1558e-01,\n","           1.2377e-01, -1.5381e-01]]], device='cuda:0', requires_grad=True)\n","blocks.10.attn.W_V: torch.Size([12, 768, 64])\n","Parameter containing:\n","tensor([[[-1.5074e-01, -4.6779e-02,  1.1546e-01,  ..., -2.3277e-01,\n","          -1.9039e-01,  5.9375e-02],\n","         [-5.8850e-02,  9.9473e-02, -4.5606e-02,  ..., -1.1648e-02,\n","          -2.3275e-01, -4.3250e-01],\n","         [ 4.5909e-02, -1.9528e-01,  1.6882e-01,  ...,  8.8048e-02,\n","           2.8475e-02, -3.0144e-01],\n","         ...,\n","         [ 5.8380e-02,  4.4380e-02, -3.8236e-02,  ...,  3.5870e-02,\n","          -6.7227e-02, -1.6883e-01],\n","         [-2.5440e-01,  8.5196e-02, -2.1427e-02,  ..., -1.2591e-01,\n","          -6.3482e-02,  6.3841e-02],\n","         [-8.7249e-02, -1.7700e-01, -1.3602e-01,  ...,  3.1904e-02,\n","           2.1719e-01,  2.0035e-01]],\n","\n","        [[-1.8560e-01,  2.7754e-02, -6.9768e-02,  ..., -4.9350e-02,\n","          -1.2275e-02, -2.3076e-01],\n","         [-5.5050e-02,  2.9557e-02, -1.9690e-02,  ..., -6.6557e-02,\n","           1.0794e-01, -1.1712e-01],\n","         [ 6.1300e-02, -2.4302e-03,  1.4218e-02,  ..., -2.8681e-01,\n","          -8.0277e-02,  5.0794e-02],\n","         ...,\n","         [ 5.7601e-02, -1.1363e-01,  5.8755e-02,  ..., -4.3441e-02,\n","          -2.1052e-01,  4.0587e-02],\n","         [-3.7411e-02, -2.1720e-01, -3.1690e-02,  ...,  2.5813e-01,\n","           8.6106e-02,  2.4563e-01],\n","         [ 2.8949e-02,  1.9387e-02, -1.3116e-01,  ..., -1.7265e-01,\n","           1.0564e-01, -7.3948e-02]],\n","\n","        [[ 4.6468e-02, -2.0646e-02,  4.9744e-02,  ..., -9.5929e-02,\n","           5.4720e-02,  2.7672e-02],\n","         [-1.2282e-01, -1.0671e-01, -1.6822e-01,  ...,  1.1918e-04,\n","           6.1973e-02, -2.4429e-02],\n","         [-2.2148e-01, -1.5694e-01, -1.1182e-01,  ...,  3.3269e-02,\n","           1.1036e-02, -2.1086e-01],\n","         ...,\n","         [ 6.2584e-02, -1.9561e-01,  8.9076e-03,  ...,  2.6470e-01,\n","          -2.3828e-01, -3.1200e-01],\n","         [-4.4580e-02, -2.1727e-01,  1.0556e-01,  ...,  3.6692e-02,\n","          -4.4688e-03,  6.2632e-02],\n","         [ 2.6283e-01,  2.3252e-01, -9.8796e-02,  ...,  9.6104e-02,\n","          -3.2174e-01, -6.0486e-02]],\n","\n","        ...,\n","\n","        [[-1.3776e-02,  8.0900e-03, -1.0017e-01,  ..., -1.1507e-01,\n","           9.6012e-02,  9.9860e-02],\n","         [-1.0794e-01, -1.4128e-02,  8.7863e-02,  ...,  5.4176e-02,\n","           7.7932e-02, -8.1609e-02],\n","         [ 8.0955e-02,  9.5608e-04, -3.1508e-02,  ..., -4.8216e-02,\n","          -5.6228e-02, -1.1200e-01],\n","         ...,\n","         [-3.7840e-02, -1.0250e-01,  2.6431e-01,  ...,  2.5967e-03,\n","           2.1642e-01,  8.3631e-02],\n","         [-2.9287e-03,  5.8890e-03, -6.7077e-02,  ..., -1.3691e-01,\n","           2.1113e-01,  7.1717e-03],\n","         [-1.2091e-02, -1.0574e-01, -2.1533e-01,  ..., -6.4982e-02,\n","           8.7455e-02, -3.3683e-02]],\n","\n","        [[ 2.4528e-02, -1.3108e-01,  2.3588e-01,  ..., -1.1603e-01,\n","          -5.1892e-02, -1.8815e-01],\n","         [-4.8176e-02,  8.9550e-02,  3.3610e-01,  ...,  1.5608e-01,\n","          -5.5524e-02,  2.6046e-01],\n","         [ 6.3243e-02,  5.7707e-02, -1.1547e-01,  ..., -3.0177e-01,\n","          -1.8319e-01, -2.6870e-01],\n","         ...,\n","         [-6.5555e-02, -1.4013e-01,  1.5921e-01,  ..., -1.8274e-01,\n","           1.5317e-01, -2.4122e-01],\n","         [-4.8341e-01, -8.1534e-02, -3.5653e-02,  ...,  1.1006e-01,\n","          -9.6652e-02, -9.1596e-02],\n","         [-1.8985e-01,  8.8578e-02,  7.2554e-02,  ..., -1.3718e-01,\n","           1.6001e-01,  2.9593e-02]],\n","\n","        [[-1.7106e-02,  6.1350e-02, -2.0698e-01,  ...,  1.7253e-01,\n","           3.4188e-01,  6.6182e-02],\n","         [ 4.0686e-02,  3.5153e-02, -4.8502e-02,  ..., -5.4341e-02,\n","          -2.4065e-01, -2.3886e-02],\n","         [-1.2070e-01,  1.1891e-01,  1.7259e-01,  ...,  2.0054e-01,\n","          -4.5362e-02,  6.9270e-02],\n","         ...,\n","         [ 6.4464e-02,  1.8407e-02,  1.1204e-01,  ..., -1.0374e-01,\n","           2.9582e-01,  8.6741e-02],\n","         [ 1.8405e-02, -3.3106e-02, -2.8296e-01,  ..., -2.2252e-02,\n","           8.3467e-02, -4.1667e-02],\n","         [ 1.6589e-01, -1.6319e-01,  1.1848e-01,  ..., -2.3251e-01,\n","          -4.0154e-02, -1.1683e-02]]], device='cuda:0', requires_grad=True)\n","blocks.10.attn.b_K: torch.Size([12, 64])\n","Parameter containing:\n","tensor([[-1.7624e-02, -2.5813e-02,  2.0685e-01, -6.4040e-02,  1.4593e-01,\n","          1.8508e-02,  3.4194e-02,  1.1235e-01,  8.6779e-02, -5.4940e-02,\n","          2.1903e-02,  5.3193e-02,  4.6690e-02, -4.3763e-03, -8.0620e-02,\n","          1.1295e-01,  4.9861e-02, -1.1693e-01, -1.0350e-01, -2.9186e-02,\n","          1.0329e-02, -1.7235e-02, -1.3372e-01,  1.8671e-01,  2.1759e-01,\n","          5.9848e-02, -3.2222e-02,  2.9476e-02,  2.3832e-01,  1.7801e-02,\n","          8.0869e-02, -2.3244e-02,  1.1356e-01, -1.4652e-01,  5.6394e-02,\n","          3.4816e-02,  5.7098e-02,  1.5263e-02, -8.2426e-02,  1.7275e-01,\n","          5.4765e-03, -5.8977e-02,  1.6485e-01, -1.4054e-01,  4.0822e-02,\n","         -8.4992e-02, -1.1393e-01,  2.8356e-02, -1.7442e-02, -1.1882e-01,\n","         -3.5511e-04, -1.3152e-01,  6.9256e-02, -1.7519e-01, -2.0577e-01,\n","          1.8529e-01,  1.1511e-01,  7.2765e-02, -8.4090e-02,  3.0063e-02,\n","          8.2283e-03, -8.1258e-02, -6.0634e-02,  1.0149e-01],\n","        [ 7.5925e-02, -2.4899e-01, -6.2538e-02,  1.9679e-01,  1.8955e-02,\n","          1.0694e-01,  1.3352e-02,  2.0407e-01,  1.1840e-01,  5.8519e-02,\n","          1.2158e-02,  1.2770e-03,  4.3734e-02,  9.5757e-02,  1.3466e-01,\n","         -1.0144e-01, -7.6927e-02, -5.2446e-02, -3.1351e-02,  6.2792e-02,\n","         -5.6919e-02, -1.1778e-01, -3.7628e-02,  1.9980e-03, -8.8481e-02,\n","         -7.0486e-02, -5.6220e-02,  6.7488e-02, -4.3301e-02,  1.0609e-01,\n","         -6.3798e-02,  1.8915e-01,  1.3614e-02,  7.3511e-02, -7.4426e-02,\n","          6.1905e-02, -8.0094e-03,  7.6608e-02, -7.2767e-02,  2.4660e-01,\n","          8.0332e-02, -4.9080e-02, -1.0075e-02,  1.0685e-01,  9.6899e-02,\n","         -1.0323e-02,  1.4254e-01, -8.7809e-02,  2.9834e-02,  1.1016e-01,\n","          3.1033e-02,  1.9623e-01, -1.4311e-01, -7.7999e-02,  1.4022e-01,\n","         -1.9453e-01, -1.0641e-01, -7.2444e-02, -1.9280e-01, -3.9770e-02,\n","         -2.3553e-03,  8.0888e-02, -2.9094e-01, -1.4176e-01],\n","        [-7.7889e-03, -4.6288e-02, -4.3639e-02,  5.3244e-02,  5.9077e-02,\n","          9.6297e-02, -2.2566e-01,  6.2995e-02,  9.2169e-02,  1.9931e-02,\n","          1.0819e-01,  6.9214e-02,  2.3559e-01, -8.4981e-02, -2.1855e-02,\n","         -4.8203e-02, -7.5733e-02,  1.8002e-01,  2.4011e-02,  8.1671e-02,\n","          5.2422e-02,  1.8039e-03, -7.0654e-02,  8.4335e-02,  3.8190e-02,\n","          4.5373e-02,  7.2867e-02,  1.3453e-02,  1.5159e-01,  1.3647e-01,\n","         -6.4683e-02, -1.5061e-01, -1.1711e-02, -3.2802e-03,  1.0167e-01,\n","         -3.7029e-02, -9.7525e-02,  2.9126e-02,  4.5457e-02, -8.7102e-02,\n","         -5.4907e-02,  6.0122e-03,  6.5975e-02, -5.1541e-03, -3.2260e-03,\n","         -1.7610e-02,  5.0468e-02,  1.7796e-01, -5.2174e-02, -3.4848e-02,\n","         -1.7726e-01, -1.0931e-01, -5.4763e-02,  1.2336e-01,  5.4363e-02,\n","          1.2668e-01, -1.5151e-02,  1.3855e-01, -1.8864e-01,  5.3631e-02,\n","         -1.0473e-01, -1.6813e-01,  1.2805e-01, -1.7528e-02],\n","        [-2.6551e-03,  6.8320e-02,  1.6368e-02,  1.0004e-01, -3.6730e-02,\n","          6.2298e-02,  4.3649e-02, -4.3487e-02,  1.2568e-01, -3.4401e-02,\n","         -2.1926e-01,  1.5089e-01, -9.0290e-02,  1.4911e-01, -5.0608e-02,\n","          2.2512e-02,  4.9103e-03, -9.8689e-02, -4.7740e-02,  6.2645e-03,\n","          2.1458e-02, -1.1679e-01,  1.1978e-01, -3.6190e-02,  5.5664e-02,\n","         -2.1212e-02, -2.4674e-02, -7.6079e-02,  8.7593e-02, -9.2781e-02,\n","         -7.6152e-02, -9.6186e-03, -6.8367e-02,  5.3864e-02,  4.7991e-02,\n","         -3.9279e-02, -7.2092e-02, -6.3545e-02, -1.1511e-01, -3.0095e-01,\n","         -1.4015e-02, -6.7589e-02,  6.5185e-02,  7.4409e-02, -6.0777e-02,\n","          2.5421e-01,  1.3505e-01, -5.5494e-02,  4.7875e-02, -3.7973e-02,\n","          5.4389e-02,  1.6999e-01,  1.7292e-02,  8.3308e-02,  1.0889e-01,\n","          1.3996e-01,  2.7829e-02, -2.2557e-01, -1.7959e-01, -4.6587e-02,\n","         -1.8309e-02, -1.5050e-01,  5.7129e-02,  4.9436e-02],\n","        [-2.5143e-02, -8.1833e-02, -7.2841e-02,  5.7981e-02, -1.3533e-01,\n","         -3.5975e-02, -9.3555e-03, -1.6360e-02, -1.3627e-02, -2.1082e-01,\n","          3.7897e-02,  1.6790e-02, -2.5749e-02, -7.3683e-02,  3.6662e-02,\n","         -6.5850e-03,  1.0200e-02,  5.0100e-02, -5.6466e-02, -5.6916e-02,\n","         -5.5798e-02, -1.3270e-01,  8.9432e-02,  7.0924e-02,  2.0312e-02,\n","         -8.8184e-02, -1.3527e-02,  5.9329e-02,  1.2589e-01, -4.3357e-02,\n","          1.6626e-02, -9.1214e-02, -3.7791e-03, -3.0436e-03, -9.1100e-02,\n","          8.3169e-02, -5.6191e-02, -3.7781e-02, -5.4072e-02, -3.4669e-02,\n","         -2.1502e-03, -7.2721e-02,  1.0577e-01, -3.5183e-02, -8.9126e-02,\n","         -3.2443e-02,  1.0641e-02,  4.1230e-02, -8.7105e-02,  1.2190e-02,\n","          1.2875e-01, -1.0346e-01, -1.6996e-01,  9.9585e-02,  9.7976e-02,\n","          9.9899e-02, -7.4136e-02, -1.0342e-02, -6.6939e-02, -4.6358e-02,\n","         -4.6230e-02,  5.0591e-02,  5.3961e-02, -1.2359e-01],\n","        [-3.8795e-02,  5.2974e-02,  2.0342e-01, -2.8446e-02,  1.2781e-01,\n","          3.5726e-02, -5.8569e-02, -3.8150e-02, -2.0568e-02, -1.0880e-01,\n","         -3.0861e-02, -1.0981e-01,  1.0991e-02, -1.1891e-01, -1.0098e-02,\n","         -8.2715e-02, -7.9770e-02, -1.1729e-01,  1.1052e-01,  1.2485e-01,\n","          9.3856e-02, -1.2185e-01, -8.5278e-02,  2.7466e-02, -1.3334e-02,\n","         -4.7405e-02,  5.3908e-02, -1.2398e-01,  1.2022e-02,  1.3266e-03,\n","         -8.3203e-02, -1.1451e-01,  1.1699e-01, -3.3573e-02, -5.6308e-02,\n","          1.0727e-01,  2.5836e-02, -2.7661e-02, -1.6600e-01,  4.7473e-02,\n","          1.0346e-01, -3.4814e-02,  1.3952e-01, -3.1699e-02,  9.1469e-02,\n","         -6.4855e-02,  3.7475e-02, -1.0149e-02,  3.2322e-03,  5.5055e-02,\n","         -1.0459e-01, -5.0283e-02,  2.2607e-01, -4.1631e-02, -9.8427e-02,\n","          9.4283e-02, -1.5683e-02, -1.4944e-02, -6.6599e-02, -8.5687e-02,\n","          1.3117e-01, -2.3163e-02,  8.8719e-02,  3.9808e-02],\n","        [ 1.5033e-01, -9.1544e-03,  8.6027e-02, -1.5528e-02, -8.4528e-02,\n","         -3.6937e-02, -1.5199e-01,  7.1221e-02,  3.1541e-02, -3.7440e-02,\n","         -3.4657e-02, -2.6432e-02, -2.8941e-01, -3.9230e-02,  9.3477e-02,\n","          1.0931e-01, -1.8465e-02, -6.2963e-02,  1.7143e-02, -1.3523e-01,\n","          1.0824e-01,  2.5357e-02, -1.1334e-01, -1.2599e-01, -6.6301e-02,\n","         -8.7935e-02, -1.4219e-01, -1.1878e-01,  5.2626e-03,  7.6757e-04,\n","         -4.1406e-03,  6.3765e-02,  3.9758e-04, -7.9146e-02,  4.7199e-02,\n","          1.5427e-01, -4.0953e-01, -1.5874e-01, -7.6805e-02, -2.0944e-02,\n","         -1.6723e-01,  1.1122e-01, -4.7909e-02,  1.1836e-01,  4.2937e-02,\n","          4.7551e-02,  3.5807e-02,  5.0640e-02, -4.6935e-02,  1.8810e-01,\n","         -8.0394e-02, -1.3143e-01, -1.3406e-01, -2.7348e-01, -1.1507e-01,\n","         -1.7645e-02,  1.2278e-01,  4.9965e-02, -1.1362e-01, -4.2854e-02,\n","         -3.9152e-02, -2.0589e-03,  1.2624e-01, -2.0098e-01],\n","        [ 2.4635e-02,  4.7322e-02,  3.8901e-02,  5.3916e-02,  2.2082e-02,\n","          1.7613e-01,  1.8130e-01,  1.4991e-01, -1.6001e-01, -1.5974e-01,\n","          2.4074e-02, -2.2108e-02, -7.9141e-02,  1.9526e-01,  1.1658e-02,\n","         -4.6535e-02,  8.0326e-02, -7.4497e-02,  2.6525e-02, -1.2711e-01,\n","          9.8974e-03,  1.4840e-01, -1.2415e-01,  3.3669e-02,  1.6965e-01,\n","         -1.7046e-01, -7.4396e-03,  1.2458e-01,  4.6845e-02, -7.0517e-02,\n","          3.7368e-02,  1.2094e-01,  2.1636e-01,  3.2418e-02,  4.8276e-02,\n","         -3.0550e-02,  3.0073e-02,  8.8765e-02,  1.5151e-01, -1.0519e-01,\n","         -2.1992e-02,  2.7907e-02,  1.1266e-01, -1.3772e-02, -1.3272e-01,\n","         -1.1143e-01,  1.2591e-01,  1.8125e-02, -2.8575e-02, -7.5479e-02,\n","         -1.4759e-02, -1.7622e-01,  8.2102e-02, -9.0938e-02,  2.3174e-01,\n","         -1.5901e-02, -1.1258e-02,  1.4217e-01,  2.2692e-02,  6.4820e-02,\n","         -2.8464e-01,  1.1252e-02, -1.2269e-01,  4.9764e-02],\n","        [ 3.7575e-02,  2.0636e-01, -4.9876e-02,  8.5013e-02, -2.8248e-02,\n","         -1.7278e-02,  5.6059e-02,  5.9047e-02, -6.5777e-02,  8.8205e-02,\n","          1.2203e-02, -1.2226e-01, -5.5032e-02, -3.9672e-03,  1.4482e-02,\n","          2.0450e-02, -1.3621e-02, -6.6305e-02, -2.0690e-02, -2.1199e-03,\n","          1.7669e-01, -7.0545e-02,  7.0407e-02,  4.4832e-02, -8.7985e-03,\n","          3.7761e-02, -8.1812e-02, -6.5397e-02,  9.0263e-02,  7.2655e-02,\n","          1.2480e-01,  5.0615e-02,  4.1890e-02,  1.3384e-01, -1.4744e-01,\n","         -1.1728e-01,  5.0167e-02, -5.4865e-02,  1.6716e-02,  1.1848e-01,\n","          2.8475e-02,  5.8505e-02,  1.5414e-02, -4.1325e-02, -7.0796e-02,\n","          1.0194e-01, -6.7400e-02,  9.7703e-03, -1.0207e-02, -1.4984e-01,\n","         -2.6578e-02, -1.2107e-01,  6.8181e-02,  1.0347e-02,  9.4448e-02,\n","          1.5780e-03, -1.8433e-01, -7.5693e-02, -6.0374e-03,  5.6049e-02,\n","          2.4044e-02, -5.7675e-02, -1.4260e-01,  3.1729e-02],\n","        [ 3.6948e-02,  1.6921e-01,  6.2030e-02, -5.9590e-02, -1.4411e-01,\n","         -4.7375e-02, -1.4800e-01,  6.3543e-04,  2.1273e-02,  2.4926e-02,\n","         -1.8055e-02, -5.1928e-02,  9.9054e-02, -2.4069e-02, -3.2470e-01,\n","          1.3627e-02,  1.3238e-01,  1.3183e-01, -4.4960e-02, -5.6949e-02,\n","         -1.4600e-01, -2.9472e-02,  1.0150e-03,  8.5254e-02,  2.7522e-02,\n","          6.3163e-02,  2.5545e-02, -1.7246e-01,  6.0683e-02,  2.0779e-02,\n","          1.4020e-02,  3.7930e-02, -2.0716e-02, -7.7837e-02,  5.9336e-02,\n","         -1.5149e-03,  7.3858e-02,  9.8819e-02,  1.3462e-01,  7.9377e-03,\n","          8.3360e-02, -9.3081e-02,  1.2559e-01,  4.1611e-02,  1.0634e-01,\n","          1.9791e-01, -2.3783e-01, -8.5273e-04,  4.7685e-02, -6.8938e-02,\n","          3.9645e-02,  7.7749e-02, -2.1447e-01, -3.2404e-02, -1.2238e-01,\n","          4.0503e-02, -1.6697e-02,  4.7267e-02, -1.5963e-01, -1.1048e-01,\n","          2.8873e-02,  2.5857e-02,  1.3109e-01, -2.9223e-02],\n","        [-2.2739e-02,  5.5996e-02, -7.4476e-02, -9.2364e-02,  1.4886e-01,\n","          3.1740e-02,  1.7316e-02,  2.5754e-02,  3.6505e-02, -1.0856e-01,\n","         -4.6535e-02, -1.1976e-01,  9.7579e-02, -8.3303e-03, -9.7458e-02,\n","         -1.5488e-01, -2.2956e-01, -3.5622e-02, -9.3476e-02, -8.8416e-02,\n","         -2.1059e-01, -2.9490e-02,  5.1991e-02,  1.2048e-02,  1.3119e-01,\n","          8.1288e-02, -1.3284e-01, -3.3801e-02, -1.2457e-01, -5.9899e-02,\n","         -5.1326e-02, -1.0688e-01,  7.2927e-02, -9.7861e-02,  5.4201e-02,\n","         -2.5810e-02, -5.3953e-02,  1.5483e-01, -5.6107e-02, -8.1820e-02,\n","          1.2366e-01,  5.1857e-03,  5.3522e-02, -1.3855e-01, -1.8540e-01,\n","          2.1259e-02, -1.2347e-01,  5.6678e-02, -1.0802e-02,  4.7820e-02,\n","          9.5739e-02, -8.0236e-02,  1.2089e-01, -1.1096e-01, -5.2377e-02,\n","          9.9155e-02, -9.6960e-02, -5.9884e-02, -1.1613e-01,  8.3398e-02,\n","          9.1056e-03,  6.6448e-02, -6.6887e-02,  1.6537e-01],\n","        [-4.1878e-02,  3.8294e-03, -1.8312e-01,  2.0171e-01,  2.2563e-01,\n","         -1.6782e-01,  1.3118e-01, -4.4852e-02,  5.3316e-02,  2.8155e-02,\n","          9.0862e-03,  3.7953e-02,  3.7173e-02,  3.4851e-02, -9.5943e-02,\n","         -7.1076e-04,  1.8335e-02, -2.7461e-02,  4.0641e-04, -1.4002e-01,\n","         -4.3318e-02, -7.1720e-02,  1.2296e-01,  7.3424e-05,  8.8623e-02,\n","         -5.4769e-02,  3.1950e-02, -3.0042e-02, -1.5413e-01, -1.2647e-01,\n","         -1.4453e-01,  3.3081e-02,  7.4916e-02,  7.0325e-02,  7.3154e-02,\n","          1.0621e-01,  4.6588e-02, -6.9586e-02,  1.9194e-01,  7.4478e-02,\n","         -5.7261e-02,  4.9902e-02, -1.6441e-01, -1.0525e-01, -3.0928e-02,\n","          4.5563e-03,  3.1098e-01,  7.4927e-02, -9.9836e-02,  9.8246e-02,\n","          3.6473e-02, -1.9020e-01, -1.8551e-01, -4.6230e-02, -1.6482e-01,\n","          3.3003e-02,  1.2695e-01, -1.0058e-01,  4.8174e-02,  6.5242e-02,\n","         -1.9277e-01,  1.1271e-01, -6.5022e-02,  1.2815e-02]], device='cuda:0',\n","       requires_grad=True)\n","blocks.10.attn.b_V: torch.Size([12, 64])\n","Parameter containing:\n","tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n","       device='cuda:0', requires_grad=True)\n","blocks.10.mlp.W_in: torch.Size([768, 3072])\n","Parameter containing:\n","tensor([[-0.0470, -0.1844,  0.0954,  ..., -0.1219,  0.0784,  0.0695],\n","        [ 0.0465, -0.2866, -0.0475,  ..., -0.1587,  0.0991,  0.0961],\n","        [ 0.1747, -0.0565, -0.0819,  ...,  0.0196,  0.0371,  0.0941],\n","        ...,\n","        [ 0.0594, -0.0186, -0.2675,  ..., -0.1615,  0.0099, -0.2356],\n","        [-0.0591,  0.0056,  0.0860,  ..., -0.0222, -0.0652, -0.1163],\n","        [-0.1588,  0.0426, -0.0066,  ..., -0.0767,  0.0009, -0.0639]],\n","       device='cuda:0', requires_grad=True)\n","blocks.10.mlp.b_in: torch.Size([3072])\n","Parameter containing:\n","tensor([-0.0678,  0.0492, -0.1440,  ..., -0.0373, -0.3087, -0.1231],\n","       device='cuda:0', requires_grad=True)\n","blocks.10.mlp.W_out: torch.Size([3072, 768])\n","Parameter containing:\n","tensor([[ 0.0526,  0.2037, -0.2281,  ...,  0.0285,  0.0621,  0.0854],\n","        [ 0.1654, -0.2038,  0.0162,  ..., -0.0902, -0.0277, -0.1632],\n","        [ 0.1352,  0.1129, -0.0354,  ...,  0.0646,  0.0649, -0.1546],\n","        ...,\n","        [ 0.4044,  0.2177, -0.1393,  ...,  0.1725,  0.0065,  0.1030],\n","        [ 0.0533,  0.0962, -0.4815,  ..., -0.0038, -0.1052,  0.1185],\n","        [ 0.1796, -0.1290,  0.1392,  ...,  0.0440,  0.2462, -0.1688]],\n","       device='cuda:0', requires_grad=True)\n","blocks.10.mlp.b_out: torch.Size([768])\n","Parameter containing:\n","tensor([-3.8143e-02,  2.5599e-02, -2.0104e-01,  1.4348e-01,  1.7296e-01,\n","        -1.0449e-01,  2.3975e-01,  3.1738e-01,  2.6895e-01, -3.7742e-02,\n","        -2.1719e-01, -1.3379e-01, -1.6686e-02,  1.1986e-01, -4.6542e-02,\n","        -3.7086e-02, -6.1694e-02,  3.7257e-01,  2.7303e-01, -2.3525e-01,\n","         4.0211e-02,  1.3741e-02,  1.4994e-01, -8.7482e-03, -2.8816e-01,\n","        -4.8289e-02, -1.4627e-01,  1.3170e-01,  5.7696e-02,  7.8080e-02,\n","         1.6892e-01,  1.4323e-01,  1.9676e-01, -2.7084e-01, -1.7095e-02,\n","        -2.2893e-01,  3.7549e-01, -6.1329e-02,  1.2292e-02, -1.4345e-04,\n","         4.6832e-03, -1.4181e-01,  1.1796e-01, -1.0276e-01, -1.2250e-01,\n","        -2.5222e-01,  9.4139e-02,  2.4413e-01,  8.8424e-02,  2.8009e-01,\n","         2.0151e-01, -5.7480e-03, -1.8841e-02,  4.0198e-02,  5.7171e-02,\n","         1.8770e-01, -4.3182e-02,  7.2363e-02, -8.2459e-02,  9.9696e-03,\n","        -1.8823e-01,  7.0356e-02,  3.1884e-01, -2.3913e-01, -7.5639e-01,\n","         1.2948e-01,  7.3434e-02, -1.2257e-02, -2.5637e-01, -9.4662e-02,\n","         1.3555e-01, -2.5064e-02,  1.0826e-01, -1.2222e-01,  6.5764e-02,\n","         6.0241e-03, -8.9593e-02, -3.5348e-01, -1.7470e-01, -1.1654e-01,\n","         1.2474e-02,  1.2593e-01, -5.3945e-02, -9.4816e-02, -2.0751e-01,\n","         1.1186e-02,  2.5762e-01, -5.1091e-01, -6.1145e-02, -5.4759e-02,\n","        -4.2531e-03,  9.5853e-02, -1.2925e-01,  2.4003e-01, -1.2552e-03,\n","         4.7027e-02, -2.4122e-01,  1.9284e-01,  1.5343e-01, -1.4140e-01,\n","        -1.2101e-01,  1.5099e-01,  3.2635e-01,  2.5328e-01, -1.4151e-01,\n","         8.5708e-02,  2.3137e-01,  1.3640e-01, -1.4373e-01,  1.2222e-01,\n","         9.3257e-02,  4.6817e-02,  7.6846e-02,  8.2065e-02, -1.8397e-01,\n","         8.8908e-02, -9.8975e-02,  1.0629e-01,  2.4419e-02, -1.4808e-01,\n","         2.3604e-01,  1.1292e-01,  1.7406e-01,  7.7582e-02,  4.3627e-01,\n","        -7.5567e-02, -8.8554e-02, -1.1853e-01, -1.1230e-01,  7.6000e-02,\n","        -3.1416e-02,  5.9794e-02, -1.9011e-01,  3.0470e-01,  4.3425e-01,\n","         1.6238e-02,  7.3720e-03, -1.9312e-01, -2.5405e-01,  8.1005e-02,\n","         1.3216e-01,  1.8647e-01, -1.5464e-01, -1.7287e-01, -3.6527e-01,\n","         1.5677e-01, -3.1230e-02,  1.5665e-01, -3.5846e-02, -1.6030e-02,\n","        -2.4349e-01,  2.4982e-01,  4.3248e-01,  2.1962e-01,  1.8951e-01,\n","         1.3434e-01,  1.9932e-01,  1.6355e-01,  2.7505e-01, -2.3918e-02,\n","         3.0964e-01, -7.3299e-02, -1.6255e-01, -7.1651e-02,  1.2032e-01,\n","        -6.8780e-02,  5.6922e-02, -1.7021e-01,  1.2268e-01,  1.2964e-01,\n","        -1.4666e-01,  8.4830e-02,  1.5973e-01, -1.0504e-01, -7.7611e-02,\n","         8.3413e-02, -3.7759e-01,  1.8042e-01,  1.2408e-01, -1.7245e-02,\n","         9.2364e-02,  1.3709e-01,  1.1227e-01, -9.1766e-02, -1.3294e-01,\n","         9.1459e-02, -1.3241e-01, -1.1060e-01, -6.8468e-02,  1.0740e-01,\n","         2.2344e-01, -4.6891e-01, -6.7498e-02, -8.1809e-02,  2.2811e-01,\n","        -1.6033e-01, -2.6327e-01, -1.9903e-01,  3.2382e-01,  3.5482e-02,\n","         2.1925e-01, -3.4115e-02,  8.7567e-02,  7.3009e-02,  1.3954e-01,\n","        -1.0720e-01, -1.9729e-01, -7.7086e-02, -1.4805e-02, -2.0860e-01,\n","         6.7832e-02, -2.2851e-03,  1.4290e-01,  1.0806e-01,  1.3177e-01,\n","        -2.1775e-01,  6.9232e-02, -1.3349e-01, -8.3663e-02, -7.0714e-02,\n","        -6.5278e-02, -2.1721e-01,  1.4354e-01, -9.2345e-02,  1.2621e-01,\n","         1.5472e-01,  1.9213e-01,  1.6357e-01,  1.9801e-02, -1.2216e-01,\n","         2.1403e-02,  2.0315e-01,  2.8329e-01, -1.6874e-01,  1.7956e-01,\n","        -1.5323e-01,  6.5958e-02, -1.4719e-01,  1.3041e-01,  4.6650e-02,\n","         1.7008e-01, -1.3723e-01, -4.5214e-02, -1.8821e-01,  3.7930e-02,\n","         1.0018e-01,  4.8997e-02,  8.2434e-02, -2.5882e-01, -2.0671e-01,\n","        -2.0532e-02,  6.6051e-02,  3.0145e-02,  4.8899e-02,  1.3834e-01,\n","         2.6462e-02, -2.9981e-01,  1.1138e-01,  3.3417e-01, -3.5646e-02,\n","        -3.0519e-02,  1.5504e-01, -3.4763e-01, -1.4912e-01, -3.2172e-01,\n","        -1.4177e-01,  5.4598e-01,  1.0665e-01, -2.4090e-01,  4.6356e-02,\n","        -4.4664e-01,  7.1574e-02,  2.0512e-02, -1.9377e-01, -1.6301e-02,\n","        -2.6721e-02,  2.4572e-01, -1.4274e-01,  7.2313e-02,  6.1251e-02,\n","         6.5675e-02, -1.1732e-01,  1.6584e-01, -3.4024e-01,  2.0874e-01,\n","        -3.1980e-02,  1.4726e-02,  2.1803e-01,  4.7385e-02, -1.2282e-01,\n","        -1.4817e-01,  6.5807e-02,  3.3150e-01, -1.6795e-02, -4.9827e-01,\n","         4.5978e-02,  8.4362e-02,  9.1172e-02,  2.0120e-03, -1.1323e-01,\n","         1.6160e-01, -3.7206e-01,  1.2649e-01,  6.5695e-02, -2.6316e-02,\n","        -2.2873e-01, -9.1453e-02,  2.1830e-01, -3.3229e-01,  7.2913e-02,\n","        -6.5246e-02, -3.0352e-01,  6.7573e-02, -1.9244e-01, -4.4533e-01,\n","        -1.0069e-01,  4.8872e-01,  8.0938e-02, -7.3544e-02, -8.3964e-02,\n","        -2.0925e-01, -5.8470e-03,  2.6306e-01,  1.2856e-01, -1.3729e-01,\n","        -5.3144e-02,  4.6033e-01,  2.5003e-02,  8.2404e-02, -1.3840e-02,\n","         1.2217e-01, -3.6007e-02, -6.4687e-02,  7.5287e-02, -1.9078e-01,\n","         7.7334e-03, -2.5034e-01, -8.9020e-02, -1.1531e-01,  4.8968e-02,\n","        -1.8849e-01,  5.2834e-02,  1.7361e-01,  8.8387e-02, -9.5664e-02,\n","         5.0541e-02,  2.1083e-01,  1.2897e-01,  7.9816e-02, -1.6714e-01,\n","        -4.0522e-02,  3.7384e-02,  6.0570e-02, -1.2221e-01,  1.8752e-01,\n","        -2.1690e-02, -5.0092e-01,  1.9677e-01, -5.0628e-01,  1.5160e-01,\n","        -2.7060e-01, -8.4371e-02,  2.5535e-01,  1.5280e-01,  1.8634e-01,\n","        -1.0199e-01, -5.7972e-03,  2.4652e-01, -5.5806e-02, -1.5157e-01,\n","        -1.0008e-01, -1.9642e-02, -2.2094e-01, -1.0768e+00, -2.9864e-01,\n","        -4.2762e-01, -1.1246e-01,  3.9854e-01,  2.4553e-01,  1.9120e-01,\n","         5.4409e-02,  1.8443e-01, -4.2112e-02,  1.1395e-01, -4.3893e-02,\n","         6.0759e-02, -1.1300e-02,  3.4083e-02,  2.1713e-01, -1.8448e-01,\n","         2.0593e-02, -1.9448e-01,  1.4154e-01,  3.2273e-01, -6.9914e-02,\n","        -5.7180e-02, -1.0634e-01, -2.7934e-02,  1.4282e-01, -1.3052e-01,\n","         2.3706e-01,  1.2440e-01,  1.8414e-01,  6.2075e-02, -5.1292e-02,\n","         8.3658e-02, -1.5651e-01, -1.0092e-02,  4.0387e-01,  1.6928e-01,\n","        -1.3300e-01,  3.1057e-01, -5.5125e-02,  2.1672e-01,  4.2086e-03,\n","         1.2447e-01,  7.0247e-02, -5.1777e-02,  8.1937e-02,  2.8656e-01,\n","         4.6151e-03,  1.8913e-01, -2.2937e-01, -1.9747e-01, -2.5782e-01,\n","         1.8636e-01,  5.8540e-02,  4.5639e-02, -1.3394e-01,  6.5096e-03,\n","         4.4221e-01, -7.2945e-02, -5.5352e-03,  1.5902e-01,  3.3598e-01,\n","         2.1134e-01, -3.1201e-02,  1.4178e-01, -1.1607e-01, -1.0096e-01,\n","         2.5346e-01,  1.4458e-01,  7.2361e-02, -1.2401e-02, -3.2370e-01,\n","        -2.0378e-02,  9.1925e-02,  1.3404e+00,  7.8867e-02,  2.6674e-02,\n","         2.0070e-01,  1.6535e-02, -7.3361e-02, -2.4295e-01,  2.9986e-01,\n","         2.5448e-01,  1.2613e-01, -3.9061e-02,  1.1476e-01, -1.2231e-01,\n","        -2.0507e-01, -1.1872e-02,  1.9056e-01,  5.2914e-02,  1.2171e-01,\n","        -2.1321e-01,  1.8319e-01, -7.9405e-02,  5.5996e-02, -5.7639e-02,\n","        -3.2464e-01, -2.7739e-02, -9.1723e-02, -9.4535e-02, -1.4464e-01,\n","        -1.2075e-01,  2.2768e-01,  1.8153e-01, -1.9708e-01, -2.7437e-01,\n","        -5.2851e-01,  1.1129e+00,  7.4122e-02, -1.6188e-01, -1.3519e-02,\n","         1.4743e-01, -9.2692e-02, -4.2594e-02,  1.4096e-01,  2.1862e-01,\n","        -9.8956e-02, -1.5609e-01,  1.0342e-01,  1.8255e-01,  1.4976e-01,\n","        -2.7884e-02,  7.6394e-01, -1.4906e-01,  8.2581e-02,  7.3296e-02,\n","         1.5545e-01,  1.7724e-01, -1.0694e-01, -4.1212e-01, -3.0346e-01,\n","        -2.0468e-01,  1.1816e-02,  1.8647e-01,  2.0743e-01,  1.7826e-01,\n","        -1.3123e-01, -2.0936e-01,  3.1381e-01, -1.2333e-01, -5.8601e-02,\n","         1.4561e-01,  1.2455e-02, -7.0780e-02,  1.2439e-01,  1.9909e-01,\n","        -9.7549e-02, -2.4073e-01,  8.4320e-02,  1.9366e-01,  5.8192e-02,\n","        -2.4837e-01, -3.9474e-01, -3.3803e-01,  1.1430e-01,  2.6951e-02,\n","         5.5158e-02,  9.9056e-02, -1.1751e-01, -5.1982e-02,  6.7939e-02,\n","        -1.4831e-01, -9.2635e-02, -6.9334e-02,  2.3419e-02, -1.3666e-01,\n","         1.6781e-01,  1.1838e-01, -1.0927e-01, -1.3770e-01,  1.3135e-02,\n","         1.3371e-01, -2.7289e-02,  5.5254e-02, -9.8559e-03, -2.1324e-01,\n","        -7.3178e-02,  1.2287e-01, -4.1111e-02, -1.8449e-01, -3.2350e-01,\n","         2.1753e-01,  1.5151e-01,  1.6217e-01,  9.0199e-02, -3.7094e-02,\n","         8.9493e-02, -6.4128e-02, -2.3840e-01,  2.7410e-01,  6.7423e-02,\n","         1.0561e-01, -2.1592e-03, -1.2679e-01, -1.2053e-01,  1.5938e-02,\n","        -3.2527e-01,  4.0235e-02,  2.4296e-01, -1.3199e-01, -1.4000e-01,\n","         1.3745e-01, -7.9453e-02,  8.5562e-02, -9.1363e-02,  1.0521e-02,\n","         1.1684e-01, -1.3988e-01,  4.3998e-02,  1.7960e-02,  1.7531e-01,\n","         1.2315e-01, -1.0354e-01,  9.5456e-03,  1.0831e-01,  4.9891e-03,\n","        -1.4330e-01, -1.2944e-01, -1.4552e-02, -1.2529e-01,  1.0417e-01,\n","        -6.7777e-02,  3.6176e-02, -1.0470e-01, -1.4965e-02, -1.3677e-01,\n","        -2.4409e-01, -2.3566e-01, -1.5233e-01,  3.3304e-01,  4.6872e-02,\n","         1.5761e-03,  2.5426e-01, -3.7104e-01,  3.9172e-01,  1.5297e-01,\n","        -2.3011e-01, -6.7894e-02,  4.3814e-02, -2.0516e-01,  4.7039e-03,\n","        -1.5345e-01,  1.1341e-01, -2.2237e-01,  2.9436e-02,  3.5200e-01,\n","        -2.7242e-01, -1.5071e-01, -2.4958e-01, -6.1204e-02, -2.8815e-01,\n","        -8.7968e-02, -3.6116e-01, -2.8994e-01, -1.9701e-02, -9.4269e-02,\n","        -1.6828e-01,  1.7895e-01,  3.0548e-01, -1.0286e-01, -7.8868e-03,\n","        -1.8351e-01, -2.7882e-01,  1.9623e-01, -2.5421e-02,  2.1852e-01,\n","         4.5399e-01, -4.7588e-03, -5.4432e-02, -5.0468e-02,  5.9853e-02,\n","        -3.3782e-02, -1.2641e-01,  8.0825e-02,  1.2883e-01, -1.6844e-01,\n","         3.6612e-02,  1.4562e-01,  2.2725e-01, -1.8357e-01, -2.7564e-01,\n","         1.2676e-01,  1.8689e-02,  1.1199e-01, -2.4423e-01,  6.6204e-02,\n","         1.6659e-01, -9.4392e-02,  5.8944e-02, -5.7070e-02,  7.3812e-02,\n","         4.0672e-01, -6.2068e-02, -1.2242e-01,  2.2239e-01,  3.8539e-01,\n","         8.9461e-02, -6.2826e-02, -3.5134e-02, -8.7834e-02,  3.4615e-02,\n","         8.4902e-02,  2.8439e-01,  2.1722e-01,  1.0903e-01,  1.2715e-01,\n","        -3.8421e-01, -1.5105e-01,  2.1808e-01, -9.2623e-02, -4.4051e-01,\n","        -3.1955e-01, -2.3065e-01, -5.6844e-02,  2.4761e-01, -5.1167e-02,\n","         2.1335e-01,  1.0087e-01, -2.9482e-01,  1.6396e-01, -6.2869e-02,\n","         3.2561e-02,  1.4373e-01, -2.1226e-01,  1.4838e-01,  3.9979e-02,\n","         1.4560e-01,  1.9304e-02, -1.1265e-01, -4.0770e-01,  3.6567e-02,\n","         6.0423e-02, -2.0730e-01,  1.0954e-01,  5.1026e-02, -3.8509e-02,\n","         1.3629e-01, -3.5795e-01, -1.9559e-01, -4.1739e-02, -2.7428e-02,\n","         2.3496e-01, -2.0647e-01, -6.6377e-02,  1.5882e-01,  7.0732e-02,\n","         1.9729e-01, -2.1172e-01, -5.7085e-02, -1.0428e-02,  2.6602e-01,\n","         2.2054e-01, -1.2878e-01, -1.7998e-01, -9.4714e-02, -4.6447e-02,\n","         6.1832e-02, -2.1316e-01,  9.9077e-02, -1.0367e-01,  9.9358e-02,\n","        -6.2603e-02, -3.2249e-01, -2.1392e-02, -4.3291e-02, -2.7536e-01,\n","        -1.6295e-01,  1.5185e-01,  8.4377e-02, -2.6299e-01, -1.9028e-01,\n","        -3.3593e-01, -1.1183e-01,  8.0995e-02, -2.0961e-01,  7.2705e-02,\n","         3.2803e-02, -9.3140e-02,  2.2211e-01, -5.9392e-02, -1.7534e-01,\n","        -9.2621e-02,  2.6030e-02, -1.9912e-01,  6.9357e-02,  1.6677e-01,\n","        -1.2446e-01,  2.8240e-01,  2.3896e-01, -1.0167e-01, -1.0009e-01,\n","        -1.7404e-01, -5.3099e-02, -3.0209e-01], device='cuda:0',\n","       requires_grad=True)\n","blocks.11.ln1.w: torch.Size([768])\n","Parameter containing:\n","tensor([0.5293, 0.4873, 0.4876, 0.4451, 0.5023, 0.4219, 0.6223, 0.4727, 0.4855,\n","        0.3994, 0.5006, 0.4326, 0.4446, 0.4954, 0.5684, 0.4873, 0.5110, 0.4770,\n","        0.4800, 0.5028, 0.4305, 0.4465, 0.4676, 0.5020, 0.4779, 0.4815, 0.5058,\n","        0.4319, 0.4606, 0.4597, 0.4503, 0.5015, 0.4644, 0.4600, 0.4737, 0.5642,\n","        0.2939, 0.4514, 0.4382, 0.4821, 0.4389, 0.4400, 0.4259, 0.4432, 0.4658,\n","        0.4676, 0.4579, 0.4594, 0.4813, 0.4803, 0.4268, 0.4382, 0.4854, 0.4424,\n","        0.4617, 0.5292, 0.4639, 0.5421, 0.4238, 0.5645, 0.4863, 0.4618, 0.5047,\n","        0.5129, 0.9577, 0.4206, 0.4549, 0.5187, 0.4986, 0.4544, 0.4862, 0.3916,\n","        0.4398, 0.4457, 0.4036, 0.4561, 0.5565, 0.6833, 0.5306, 0.5027, 0.4672,\n","        0.4366, 0.4272, 0.4912, 0.5289, 0.5412, 0.5283, 0.5840, 0.4498, 0.4879,\n","        0.4640, 0.4443, 0.4497, 0.4653, 0.4559, 0.4337, 0.4816, 0.4994, 0.5012,\n","        0.5786, 0.4335, 0.4677, 0.5763, 0.4838, 0.4600, 0.4327, 0.5185, 0.5376,\n","        0.4644, 0.4731, 0.4836, 0.4498, 0.4585, 0.4873, 0.4912, 0.4796, 0.5660,\n","        0.4793, 0.4165, 0.5690, 0.5058, 0.4597, 0.4429, 0.4528, 0.5333, 0.4813,\n","        0.4445, 0.5057, 0.5059, 0.4984, 0.4998, 0.4315, 0.5264, 0.4685, 0.4813,\n","        0.4208, 0.4639, 0.5840, 0.7327, 0.4568, 0.4828, 0.4793, 0.5626, 0.4443,\n","        0.5001, 0.5023, 0.5089, 0.4907, 0.4643, 0.4796, 0.4808, 0.5058, 0.5501,\n","        0.5238, 0.4877, 0.4293, 0.4819, 0.4991, 0.4462, 0.5287, 0.6151, 0.4736,\n","        0.5077, 0.5142, 0.4588, 0.4370, 0.4760, 0.6720, 0.4742, 0.5088, 0.4589,\n","        0.4517, 0.4652, 0.4962, 0.4837, 0.4637, 0.5056, 0.4205, 0.5339, 0.4565,\n","        0.4262, 0.4287, 0.4488, 0.5273, 0.4149, 0.4341, 0.4779, 0.4897, 0.4736,\n","        0.4993, 0.4816, 0.4638, 0.4659, 0.4846, 0.4561, 0.6387, 0.4033, 0.4405,\n","        0.4777, 0.5189, 0.5188, 0.4950, 0.4766, 0.4617, 0.4184, 0.4890, 0.4435,\n","        0.3828, 0.5182, 0.4447, 0.4619, 0.5570, 0.5137, 0.5719, 0.4732, 0.4483,\n","        0.5617, 0.4618, 0.3757, 0.4681, 0.4930, 0.4481, 0.4468, 0.5103, 0.4912,\n","        0.4525, 0.4365, 0.4329, 0.4409, 0.4335, 0.4012, 0.4912, 0.6562, 0.4271,\n","        0.4536, 0.5092, 0.4904, 0.4261, 0.5152, 0.4893, 0.5436, 0.5141, 0.4594,\n","        0.4443, 0.4049, 0.4575, 0.4367, 0.5801, 0.4606, 0.4950, 0.4429, 0.4988,\n","        0.4482, 0.5186, 0.4404, 0.5419, 0.4614, 0.4595, 0.4389, 0.4627, 0.4773,\n","        0.4809, 0.4482, 0.4871, 0.4359, 0.4278, 0.9190, 0.6210, 0.4953, 0.5255,\n","        0.6088, 0.6097, 0.4459, 0.4310, 0.5774, 0.4542, 0.5124, 0.4287, 0.4636,\n","        0.4390, 0.4221, 0.4212, 0.4472, 0.6115, 0.5656, 0.5719, 0.5019, 0.4529,\n","        0.7936, 0.5785, 0.4756, 0.4531, 0.4454, 0.4209, 0.5486, 0.4319, 0.4247,\n","        0.4862, 0.4574, 0.5064, 0.4630, 0.4990, 0.5282, 0.4411, 0.4286, 0.4581,\n","        0.4557, 0.4307, 0.5343, 0.4092, 0.4246, 0.5971, 0.4371, 0.4667, 0.3040,\n","        0.4433, 0.5722, 0.4823, 0.4425, 0.5254, 0.5252, 0.4677, 0.4741, 0.5332,\n","        0.4543, 0.4642, 0.5376, 0.4225, 0.4716, 0.4149, 0.4786, 0.4326, 0.4869,\n","        0.4404, 0.4340, 0.4788, 0.5604, 0.4311, 0.4468, 0.5996, 0.4510, 0.4185,\n","        0.5097, 0.5365, 0.4697, 0.4467, 0.4830, 0.4521, 0.4816, 0.4524, 0.4267,\n","        0.5970, 0.4875, 0.4762, 0.4894, 0.4586, 0.5005, 0.4907, 0.4331, 0.4583,\n","        0.5274, 0.4894, 0.5485, 0.4696, 0.4261, 0.5317, 0.4849, 0.4600, 0.4389,\n","        0.4685, 0.5379, 0.4535, 0.4578, 0.1187, 0.4391, 0.6078, 0.5135, 0.5879,\n","        0.2744, 0.4769, 0.4455, 0.4489, 0.4458, 0.5529, 0.4678, 0.5972, 0.5059,\n","        0.4266, 0.4561, 0.4814, 0.4669, 0.4281, 0.4953, 0.9317, 0.4722, 0.4209,\n","        0.4524, 0.4444, 0.4225, 0.4406, 0.4235, 0.4591, 0.4853, 0.4637, 0.4504,\n","        0.4642, 0.5058, 0.4289, 0.4291, 0.4463, 0.4140, 0.4330, 0.4322, 0.4306,\n","        0.4794, 0.4659, 0.4409, 0.5254, 0.5101, 0.4507, 0.4061, 0.5355, 0.4323,\n","        0.4559, 0.4404, 0.4176, 0.4405, 0.4655, 0.4411, 0.4118, 0.3210, 0.4576,\n","        0.4527, 0.4892, 0.4306, 0.5184, 0.4035, 0.5020, 0.4958, 0.5528, 0.4676,\n","        0.4952, 0.5254, 0.4504, 0.5292, 0.4736, 0.4404, 0.1061, 0.4434, 0.4561,\n","        0.4873, 0.4567, 0.4288, 0.5304, 0.4697, 0.5293, 0.4756, 0.4716, 0.4578,\n","        0.3921, 0.4383, 0.5300, 0.4485, 0.4519, 0.3259, 0.4898, 0.4969, 0.4307,\n","        0.4698, 0.4460, 0.4182, 0.4883, 0.4991, 0.4624, 0.4173, 0.4679, 0.4384,\n","        0.4406, 0.4349, 0.5596, 0.5996, 0.1229, 0.4562, 0.4205, 0.5098, 0.4432,\n","        0.4326, 0.5029, 0.4789, 0.4491, 0.4556, 0.5175, 0.4594, 0.4405, 0.5006,\n","        0.4490, 0.1710, 0.4160, 0.4987, 0.4371, 0.4660, 0.4756, 0.4729, 0.5201,\n","        0.5414, 0.4285, 0.4491, 0.4963, 0.5488, 0.4394, 0.4248, 0.4877, 0.4795,\n","        0.4916, 0.4680, 0.5136, 0.4834, 0.4823, 0.4463, 0.4558, 0.4228, 0.4693,\n","        0.4797, 0.4736, 0.4620, 0.4799, 0.6637, 0.5415, 0.4999, 0.4428, 0.4829,\n","        0.4832, 0.4533, 0.4573, 0.4419, 0.5020, 0.4248, 0.4558, 0.4984, 0.4798,\n","        0.5068, 0.4912, 0.4503, 0.5133, 0.4563, 0.5059, 0.5042, 0.4716, 0.4463,\n","        0.5996, 0.4250, 0.5530, 0.4726, 0.4718, 0.5959, 0.4943, 0.4764, 0.4763,\n","        0.4873, 0.4510, 0.4658, 0.4990, 0.4331, 0.4704, 0.4542, 0.5159, 0.5961,\n","        0.4922, 0.5097, 0.5278, 0.5784, 0.5472, 0.4692, 0.4304, 0.4894, 0.5963,\n","        0.4253, 0.4408, 0.6025, 0.4503, 0.4552, 0.4364, 0.5411, 0.4932, 0.4394,\n","        0.5185, 0.4328, 0.5410, 0.4660, 0.4878, 0.4641, 0.4372, 0.4333, 0.4633,\n","        0.4407, 0.4518, 0.4989, 0.4488, 0.4346, 0.4287, 0.4614, 0.4354, 0.4999,\n","        0.4840, 0.4658, 0.4478, 0.4930, 0.4792, 0.6373, 0.4660, 0.4541, 0.4917,\n","        0.4987, 0.4892, 0.4619, 0.4773, 0.5501, 0.4483, 0.5065, 0.4659, 0.4688,\n","        0.4694, 0.5024, 0.4865, 0.5183, 0.4337, 0.4346, 0.4956, 0.4671, 0.4561,\n","        0.4873, 0.4698, 0.4682, 0.4364, 0.4568, 0.5755, 0.4677, 0.4407, 0.4429,\n","        0.5294, 0.7360, 0.5131, 0.4851, 0.4973, 0.5924, 0.4814, 0.4514, 0.5488,\n","        0.4561, 0.6118, 0.4444, 0.5795, 0.5293, 0.5134, 0.4549, 0.4883, 0.4465,\n","        0.5133, 0.4344, 0.5952, 0.4465, 0.5254, 0.4596, 0.4432, 0.4608, 0.5336,\n","        0.4381, 0.4785, 0.4640, 0.4728, 0.5273, 0.4503, 0.4440, 0.4667, 0.3861,\n","        0.4444, 0.4432, 0.4485, 0.4883, 0.6555, 0.4988, 0.4495, 0.4934, 0.4862,\n","        0.4268, 0.4811, 0.5175, 0.4166, 0.4756, 0.4495, 0.4481, 0.4239, 0.4514,\n","        0.4697, 0.4673, 0.4716, 0.4287, 0.4426, 0.4699, 0.5173, 0.4361, 0.5411,\n","        0.4439, 0.6517, 0.4154, 0.4723, 0.5388, 0.5332, 0.4764, 0.5463, 0.5298,\n","        0.4879, 0.4615, 0.4382, 0.4326, 0.5024, 0.4483, 0.4398, 0.5745, 0.4242,\n","        0.4513, 0.5801, 0.4287, 0.4717, 0.4860, 0.4756, 0.5410, 0.5058, 0.4797,\n","        0.4805, 0.4929, 0.4519, 0.4281, 0.4575, 0.4454, 0.4912, 0.4442, 0.4685,\n","        0.5173, 0.5708, 0.5002, 0.4499, 0.4622, 0.5004, 0.4697, 0.3664, 0.5574,\n","        0.4660, 0.5103, 0.4735, 0.4250, 0.4697, 0.4541, 0.4111, 0.5176, 0.5579,\n","        0.3154, 0.4581, 0.4233, 0.4931, 0.3961, 0.5139, 0.5885, 0.4229, 0.4179,\n","        0.4334, 0.4053, 0.4559], device='cuda:0', requires_grad=True)\n","blocks.11.ln1.b: torch.Size([768])\n","Parameter containing:\n","tensor([ 5.0957e-02,  5.3063e-03,  7.1952e-02,  8.0110e-03, -5.2961e-03,\n","         2.0654e-02, -6.2158e-02,  3.0118e-02,  1.2816e-02,  9.8522e-04,\n","         1.6810e-02,  1.2260e-02,  2.7738e-02,  2.4473e-02,  4.4720e-02,\n","        -1.4659e-02,  4.0943e-02,  5.4175e-02,  4.4375e-03,  1.7207e-02,\n","         4.6662e-02,  1.7263e-02,  2.2401e-02,  3.1221e-02,  3.1871e-02,\n","         1.2152e-02,  1.0185e-02,  8.7086e-03,  4.1242e-02,  5.7700e-03,\n","         1.3230e-02, -8.9628e-03, -1.3103e-03,  3.1224e-02,  1.6118e-02,\n","         8.2979e-02, -1.0721e-02,  2.1484e-02,  3.6444e-02,  8.1267e-03,\n","         1.0690e-02,  1.3654e-02, -5.5075e-03,  2.1584e-02,  5.1625e-02,\n","         1.7856e-02,  2.0120e-02,  1.0978e-02,  6.0289e-03,  2.0345e-02,\n","         2.7132e-02, -4.6660e-03,  2.9875e-02, -1.5385e-02,  9.8566e-03,\n","        -2.3851e-02, -9.7068e-03,  3.8797e-02,  9.1246e-03,  1.1499e-02,\n","         2.9524e-02,  1.5283e-02,  3.0904e-02,  1.6801e-02,  1.0039e+00,\n","        -3.9770e-03, -2.0498e-02, -2.6763e-02,  4.8049e-02,  1.5009e-02,\n","         1.1894e-02,  3.7270e-02,  2.4164e-02,  4.3461e-02,  2.4629e-02,\n","         3.5908e-02, -2.6629e-02,  1.5446e-02,  1.7674e-02,  3.5629e-02,\n","         5.2871e-02,  1.3978e-02,  2.7208e-03,  1.0042e-02,  7.7910e-02,\n","         2.4433e-02,  3.4675e-02,  5.0479e-02,  7.2109e-03,  1.0557e-02,\n","        -2.2817e-03,  1.9000e-02,  4.9565e-02, -3.7963e-03,  1.4423e-02,\n","         1.9411e-02, -6.5769e-04,  3.5342e-02,  5.9354e-02,  7.5214e-02,\n","         1.0060e-02, -2.1077e-02, -6.1407e-02,  1.5284e-02,  1.1639e-02,\n","         1.3788e-02,  3.6969e-02, -2.2341e-03,  2.4030e-03,  1.8866e-02,\n","         1.2834e-02,  2.9768e-02,  3.2467e-02,  7.7260e-02,  1.7921e-02,\n","        -4.7416e-04,  6.4844e-02,  1.0180e-02,  3.8227e-02,  5.6682e-02,\n","         4.4469e-02,  1.2040e-02,  8.9668e-03, -3.1936e-03,  5.6808e-03,\n","         5.2600e-02,  2.2292e-02,  5.5553e-02,  4.8951e-02,  3.8977e-02,\n","         3.0935e-02,  1.8790e-02,  1.6160e-02,  1.4637e-02,  2.0357e-02,\n","         1.8181e-02,  3.9977e-02,  6.2379e-02,  1.8506e-01, -6.5573e-03,\n","         9.0801e-05, -1.3945e-02,  7.3753e-02,  2.7668e-02,  2.1038e-02,\n","        -2.4017e-02, -8.7805e-03,  2.0046e-02,  1.2135e-02,  2.7661e-02,\n","         6.6024e-02, -3.8745e-02,  5.4349e-02,  1.8484e-02,  1.7913e-02,\n","        -7.3669e-03,  1.8720e-02,  3.8781e-02,  1.5830e-02, -1.9952e-02,\n","        -6.2685e-02,  3.0598e-02,  1.0478e-02,  2.7016e-02,  1.4616e-02,\n","         5.5668e-02,  1.2246e-02,  1.3508e-01,  8.0952e-03,  3.9600e-02,\n","         2.2827e-02,  2.2268e-02,  4.6019e-02,  3.9591e-02,  4.9705e-02,\n","         4.1706e-02,  9.5053e-02,  1.7695e-02, -1.1952e-02,  3.1691e-02,\n","         3.8168e-02, -5.4378e-03,  3.7782e-02,  3.3950e-02,  3.4515e-02,\n","         1.8987e-02,  6.6384e-03,  2.4832e-02,  1.8379e-02, -2.5390e-03,\n","         2.4340e-02,  4.9642e-02,  4.6158e-02,  2.4274e-02,  3.9715e-02,\n","         1.1038e-01,  3.7134e-02,  5.0341e-02,  5.5456e-02,  3.5168e-02,\n","         1.8050e-02,  4.9509e-03,  3.3701e-02,  1.8843e-02,  1.0105e-02,\n","         1.3632e-02,  4.6892e-02,  2.4525e-02,  4.2187e-02,  1.8528e-02,\n","        -4.2850e-03,  6.6331e-02,  4.5478e-02,  5.2797e-02,  5.4549e-02,\n","         3.2139e-02,  3.5647e-02,  2.4004e-02,  3.4777e-02,  2.5018e-02,\n","         2.8822e-02,  2.8432e-02, -1.7858e-03,  1.3994e-03, -1.3365e-02,\n","        -1.8895e-03,  6.6490e-06,  2.5608e-02,  5.2495e-02,  1.0492e-02,\n","         2.6109e-02,  1.6537e-02, -2.1540e-02,  8.5378e-03,  1.5619e-02,\n","         5.4355e-03,  2.3590e-02, -1.5666e-03,  8.0263e-03,  1.3107e-02,\n","         4.3238e-02,  5.6620e-03,  2.4307e-02,  2.0592e-02,  2.9497e-02,\n","         6.1229e-03, -2.3683e-03,  4.7138e-02,  3.3529e-02,  4.1300e-02,\n","         2.9701e-02,  5.2470e-02,  6.3698e-03,  1.5438e-02,  3.8697e-02,\n","        -3.8382e-02,  4.8096e-02,  3.7726e-02, -1.8360e-02,  2.7203e-02,\n","         1.1250e-02,  2.4300e-02,  3.0776e-02, -1.3539e-03,  4.4676e-02,\n","         3.5066e-02, -9.3037e-02, -1.3574e-02,  3.9665e-02,  2.7291e-02,\n","         2.0355e-02,  2.6238e-03,  2.6837e-02, -5.2640e-03,  1.8386e-02,\n","         1.9248e-02,  1.4710e-02,  2.2621e-02,  1.2412e-02,  1.0830e-02,\n","         2.1292e-02,  1.4871e-02, -2.8636e-03,  1.0733e-01,  9.5934e-03,\n","         1.6910e-02,  6.8564e-03,  3.6940e-02, -1.6670e-01,  8.6902e-02,\n","         2.8393e-02, -8.1292e-03,  4.1394e-02,  3.3285e-02,  3.9317e-02,\n","         2.4998e-02,  1.3664e-02,  2.8197e-02,  2.6113e-02,  9.3119e-03,\n","         1.2897e-02,  2.7539e-02, -2.3538e-02,  3.9144e-02,  6.1638e-03,\n","        -3.4978e-03,  2.0548e-02,  2.8477e-02,  6.3878e-02,  5.3916e-02,\n","         2.2018e-02,  1.0583e-01,  2.4699e-02,  2.3762e-02,  2.0352e-01,\n","         3.7326e-04,  3.8613e-02, -1.2637e-02, -1.9754e-04,  2.2293e-02,\n","         7.2443e-02,  1.8414e-02,  2.6822e-02,  1.5175e-02, -5.4359e-04,\n","        -2.2947e-02, -2.3131e-01,  1.5446e-02,  3.3034e-02,  3.0253e-02,\n","         1.2617e-02, -3.3467e-03,  1.5273e-02,  9.1112e-04,  4.8214e-03,\n","         4.7554e-02,  2.0570e-02,  3.2138e-02,  4.2291e-02,  4.1480e-03,\n","         2.7088e-02,  1.0571e-02,  3.6714e-03, -7.9611e-03,  7.3115e-03,\n","        -1.1383e-02, -3.0560e-04,  1.6278e-02, -3.5650e-03,  2.9043e-02,\n","         7.7314e-03, -2.1310e-02,  2.1684e-02,  6.4216e-03, -2.0624e-02,\n","         5.5431e-03,  6.2225e-02,  4.4014e-02,  4.4378e-02,  2.8018e-02,\n","         1.0435e-02,  5.0297e-02, -3.2931e-02,  3.3166e-02,  1.7612e-02,\n","         1.2097e-01,  1.0688e-02,  2.4633e-03, -2.8974e-04,  1.6454e-02,\n","         3.8218e-02, -2.9897e-03,  5.6215e-02,  6.9348e-01,  7.9867e-02,\n","         1.5494e-02,  4.6085e-02, -1.1732e-02, -1.1142e-02,  1.4511e-02,\n","         4.4982e-02,  6.2679e-03,  4.4799e-02,  1.6038e-02,  2.5119e-02,\n","        -3.1447e-02,  3.0128e-02,  4.2842e-02, -1.0291e-02,  6.0887e-02,\n","         4.5069e-02,  3.6916e-02, -2.5139e-02, -1.8924e-01,  8.3298e-02,\n","         2.8021e-02,  4.2369e-02,  1.6348e-02,  3.1837e-02,  1.8270e-02,\n","         4.0213e-02, -5.0850e-02,  2.3217e-02,  1.1167e-02,  2.6715e-02,\n","         4.0778e-02,  5.4969e-04,  3.0089e-02, -8.4385e-02,  1.0244e-02,\n","         4.2933e-02,  2.5352e-02,  4.1581e-02,  1.1688e-02,  3.6082e-02,\n","         4.1435e-03,  2.4003e-02,  8.9933e-03,  4.6167e-02,  2.3125e-02,\n","         3.3026e-02,  3.8576e-02,  4.5442e-02,  1.0487e-03,  5.1951e-03,\n","         4.4943e-02,  1.0819e-02,  5.5210e-02,  1.2000e-02,  8.7799e-03,\n","        -7.7286e-02,  2.2174e-02,  3.1687e-02,  2.8004e-02,  3.9422e-02,\n","        -4.7354e-03,  2.8495e-02, -6.6421e-04,  1.4732e-02, -2.4696e-03,\n","        -5.5900e-03,  1.3079e-02, -4.3705e-02,  4.3596e-02, -6.0020e-03,\n","         1.7634e-02,  5.1057e-02, -1.9464e-01,  2.6633e-02, -6.0991e-03,\n","         1.0957e-02,  2.3551e-02,  3.3113e-02, -8.9708e-03, -1.6450e-02,\n","         1.0284e-02,  5.5322e-02,  2.3560e-02, -2.3596e-03,  7.6222e-04,\n","         2.5959e-02, -1.1411e-02,  2.0281e-02,  9.5009e-03,  8.9934e-03,\n","         3.0496e-02,  3.3500e-02,  1.4519e-02,  1.9551e-02, -4.9068e-04,\n","         6.8704e-02,  1.3335e-02,  2.8515e-02,  3.4738e-02,  5.0567e-02,\n","         3.1887e-02,  3.5825e-02,  3.3924e-02,  3.1144e-02,  7.3384e-02,\n","         2.3091e-01, -3.3036e-01,  3.0756e-02,  1.5327e-02,  2.2457e-02,\n","         2.1233e-05,  2.8833e-02,  1.1720e-02, -3.0866e-02,  4.7714e-02,\n","        -1.3484e-02,  6.8443e-02,  4.3676e-02,  1.2389e-02,  1.8265e-02,\n","         2.4049e-02, -1.2239e-01,  5.8566e-02,  1.7970e-02,  1.9080e-02,\n","        -3.0296e-02,  2.4286e-02,  1.0882e-02,  1.2097e-01,  4.1308e-02,\n","         4.6045e-02,  4.9006e-04, -1.7907e-02,  1.1065e-02,  2.3567e-02,\n","         2.2479e-02,  1.5298e-02,  3.4759e-02,  2.0883e-02,  3.7868e-02,\n","         6.4718e-02,  3.0103e-02,  3.7694e-02,  2.2847e-02,  1.9909e-03,\n","         2.2214e-02,  7.7449e-02,  2.6877e-02,  1.9288e-02,  9.6510e-03,\n","         3.2660e-02,  1.8836e-01,  8.4367e-02,  2.8365e-02,  1.9982e-02,\n","         1.0146e-02, -1.3098e-02,  1.7307e-02,  2.6276e-02,  4.4956e-02,\n","         2.3670e-02,  3.7691e-02,  9.8237e-04, -4.6224e-03,  6.0462e-02,\n","         8.2662e-03,  5.6737e-03,  2.8288e-04,  4.5995e-02,  2.5901e-02,\n","         5.1017e-02,  2.5754e-02,  2.0236e-02,  5.7405e-02,  4.5540e-02,\n","         2.9086e-02,  1.4166e-02,  1.3228e-02,  1.6824e-02,  1.0283e-01,\n","         5.4618e-03,  4.5689e-02,  2.7555e-02,  3.7490e-02,  5.6699e-02,\n","         5.6567e-02,  1.5029e-02,  3.5641e-03,  4.9401e-03,  1.7776e-02,\n","         1.6170e-02,  2.3552e-02,  5.5054e-02,  2.7596e-02,  4.9509e-02,\n","         6.4583e-02,  3.2221e-02,  1.2051e-02,  5.8318e-02,  5.0492e-02,\n","        -1.4628e-02,  4.0570e-02,  3.2298e-02,  6.2228e-02, -3.0772e-02,\n","        -2.1065e-02, -8.8901e-03,  2.5310e-02,  4.8362e-02,  2.8058e-02,\n","        -2.2063e-02,  3.3480e-02,  2.2386e-02, -4.8698e-03,  1.3463e-02,\n","         1.3649e-02,  5.0538e-02,  7.1241e-04,  4.0128e-02, -8.6229e-03,\n","        -7.0127e-04,  3.4726e-02,  3.6150e-03,  3.6542e-02,  4.5401e-03,\n","         6.8923e-02,  4.9333e-02,  3.3838e-02,  3.3999e-02,  3.5740e-02,\n","         4.5290e-03,  3.1268e-02,  9.5061e-03, -5.9600e-02, -9.8969e-03,\n","         5.6834e-02, -4.3476e-03,  1.2993e-02,  4.8145e-02,  3.5426e-02,\n","         5.4175e-02,  2.1451e-02,  2.8698e-02,  1.0663e-02,  4.5487e-02,\n","         6.2039e-02,  2.1544e-02,  1.9286e-02,  3.2572e-02,  2.2322e-02,\n","         2.9439e-02,  2.9981e-02,  1.1712e-01, -1.7359e-02,  4.1106e-02,\n","         1.8854e-02,  4.6597e-02,  1.7579e-02,  3.1545e-02, -6.6590e-03,\n","         5.1507e-02,  5.6321e-02,  1.4981e-02,  2.5548e-02,  4.9258e-02,\n","        -1.7790e-01, -1.4513e-02,  4.2589e-02,  3.0097e-02,  3.7793e-02,\n","         4.5283e-02,  2.2917e-02,  5.2134e-02,  1.4361e-02,  1.0005e-01,\n","        -9.3145e-03,  2.5116e-02,  2.0576e-02,  5.7131e-03,  1.9714e-02,\n","         3.1945e-02,  1.1784e-02,  2.8085e-02, -1.9708e-03, -1.0446e-04,\n","         8.5335e-03,  3.5670e-02, -4.4857e-03,  4.3353e-02,  3.2958e-02,\n","        -2.1877e-02,  1.8200e-02,  5.0236e-02,  1.3450e-02, -2.2938e-02,\n","         2.4351e-02,  5.0065e-02,  4.5189e-02,  8.6591e-03,  1.4151e-02,\n","         2.2256e-02,  1.3457e-02,  2.4722e-02,  8.1260e-04, -1.2190e-01,\n","         3.8085e-02,  4.6660e-03,  1.3899e-02,  8.3363e-04,  5.0650e-02,\n","         2.4335e-02,  1.3921e-03,  2.7870e-02,  9.3660e-03,  1.2715e-02,\n","         3.0842e-02,  1.1119e-02,  2.7882e-02, -1.0453e-02,  8.1021e-02,\n","         7.6485e-03, -3.0892e-03,  6.1935e-03, -1.6860e-02,  3.2387e-02,\n","        -2.4258e-03,  2.2655e-02,  1.2742e-02,  6.9285e-02,  4.2078e-02,\n","        -1.5552e-03,  2.6525e-02,  2.3013e-02,  3.1496e-02,  2.1559e-02,\n","         1.7584e-02,  7.9644e-03,  3.9832e-02,  2.6944e-02,  4.6912e-02,\n","        -8.7033e-03, -2.6287e-04,  5.0110e-02,  5.8330e-03,  1.2196e-02,\n","         1.6277e-02,  2.5659e-02, -8.4874e-03,  1.4163e-02,  1.3904e-02,\n","         1.5085e-02,  1.6424e-02, -5.6042e-03,  6.5207e-02,  4.9513e-02,\n","         1.2180e-02,  6.1905e-02,  7.0399e-02,  3.3701e-02,  3.2892e-02,\n","         4.2671e-02,  2.3416e-02, -3.4286e-03,  1.1502e-02,  8.5592e-02,\n","        -1.1950e-03,  3.0507e-02,  4.6810e-02,  3.5387e-02,  2.7330e-02,\n","         1.3511e-01,  7.3659e-02,  5.6895e-03,  3.4639e-02,  1.3703e-02,\n","         7.2090e-03,  1.3613e-02,  1.7626e-03,  4.3984e-02,  1.2186e-02,\n","         3.7943e-02,  5.4879e-02,  1.0607e-02,  3.7307e-02,  1.1190e-02,\n","         3.8651e-02, -5.1515e-03, -6.4129e-02,  2.0797e-02,  5.1854e-02,\n","         3.5310e-02,  1.3200e-02,  5.6112e-02], device='cuda:0',\n","       requires_grad=True)\n","blocks.11.ln2.w: torch.Size([768])\n","Parameter containing:\n","tensor([0.4990, 0.4716, 0.5410, 0.4644, 0.5254, 0.5017, 1.0595, 0.4707, 0.4814,\n","        0.4365, 0.5332, 0.4696, 0.4661, 0.4984, 0.5215, 0.5182, 0.5209, 0.4834,\n","        0.5254, 0.5836, 0.4540, 0.4819, 0.5059, 0.4736, 0.5015, 0.4698, 0.4984,\n","        0.4490, 0.4737, 0.4697, 0.4592, 0.5558, 0.4990, 0.4869, 0.5059, 0.5762,\n","        0.0720, 0.4642, 0.4500, 0.5059, 0.4814, 0.4744, 0.4701, 0.4893, 0.5019,\n","        0.4839, 0.4772, 0.4680, 0.5472, 0.5249, 0.4654, 0.4949, 0.4722, 0.5293,\n","        0.4813, 0.7329, 0.4975, 0.5252, 0.4658, 0.5527, 0.5091, 0.4972, 0.5141,\n","        0.5491, 0.0399, 0.4730, 0.4746, 0.5819, 0.6503, 0.4840, 0.4904, 0.3916,\n","        0.4638, 0.4930, 0.4696, 0.5019, 0.5177, 0.7329, 0.5215, 0.5354, 0.5135,\n","        0.4577, 0.4853, 0.5367, 0.6689, 0.5325, 0.5869, 0.0278, 0.4912, 0.4829,\n","        0.4890, 0.4717, 0.5293, 0.5098, 0.4872, 0.4508, 0.4869, 0.5137, 0.4736,\n","        0.5436, 0.4521, 0.4305, 0.8135, 0.5349, 0.5019, 0.4716, 0.5284, 0.6564,\n","        0.4932, 0.4684, 0.5092, 0.4712, 0.4907, 0.4951, 0.4895, 0.5331, 0.5865,\n","        0.4944, 0.4385, 0.5680, 0.5017, 0.5036, 0.4696, 0.5020, 0.5543, 0.4795,\n","        0.4790, 0.4873, 0.5317, 0.4876, 0.5098, 0.4676, 0.5059, 0.4930, 0.5020,\n","        0.4683, 0.4804, 0.5865, 0.2131, 0.5370, 0.5017, 0.5059, 0.7085, 0.4658,\n","        0.5056, 0.6473, 0.5099, 0.5266, 0.4777, 0.4912, 0.5176, 0.5215, 0.5371,\n","        0.5254, 0.5101, 0.4773, 0.4936, 0.4733, 0.4780, 0.6129, 0.7321, 0.4774,\n","        0.5097, 0.5371, 0.4853, 0.5176, 0.5215, 0.7473, 0.4619, 0.5478, 0.4871,\n","        0.4736, 0.4951, 0.5254, 0.5136, 0.5056, 0.6329, 0.4560, 0.4917, 0.4890,\n","        0.4924, 0.4831, 0.4794, 0.5369, 0.4606, 0.4617, 0.4691, 0.4890, 0.4850,\n","        0.5137, 0.4773, 0.6262, 0.4874, 0.5165, 0.4712, 0.6191, 0.4393, 0.5370,\n","        0.4980, 0.5410, 0.5446, 0.5032, 0.4752, 0.4815, 0.4695, 0.4773, 0.4788,\n","        0.4287, 0.5410, 0.4754, 0.4737, 0.5488, 0.4990, 0.5105, 0.5057, 0.4811,\n","        0.5449, 0.4892, 0.3505, 0.4559, 0.4834, 0.4812, 0.4465, 0.5215, 0.5410,\n","        0.4775, 0.4714, 0.4775, 0.4966, 0.4406, 0.4494, 0.5098, 0.8515, 0.4752,\n","        0.4815, 0.5332, 0.4961, 0.4694, 0.5215, 0.4912, 0.5214, 0.5866, 0.4912,\n","        0.4467, 0.4671, 0.4828, 0.4890, 0.5449, 0.4888, 0.5019, 0.4892, 0.4951,\n","        0.4712, 0.5019, 0.4951, 0.5801, 0.5215, 0.4927, 0.5063, 0.4896, 0.4765,\n","        0.5291, 0.4696, 0.5019, 0.5059, 0.4544, 0.0344, 0.5734, 0.4979, 0.5020,\n","        0.6336, 0.6387, 0.4803, 0.5176, 0.5488, 0.4694, 0.4580, 0.4618, 0.4403,\n","        0.4717, 0.4461, 0.4403, 0.5235, 0.6152, 0.5527, 0.5292, 0.5030, 0.5019,\n","        0.8330, 0.5403, 0.4951, 0.4821, 0.4853, 0.4514, 0.5549, 0.4660, 0.4625,\n","        0.5062, 0.4932, 0.5447, 0.4990, 0.4962, 0.5231, 0.4518, 0.4521, 0.4775,\n","        0.4736, 0.4823, 0.5873, 0.4577, 0.4463, 0.6160, 0.4909, 0.4831, 0.4503,\n","        0.4760, 0.5644, 0.4774, 0.4638, 0.5137, 0.6960, 0.4957, 0.4717, 0.5308,\n","        0.4989, 0.4852, 0.9818, 0.4812, 0.4950, 0.4895, 0.5019, 0.4766, 0.4951,\n","        0.4907, 0.4841, 0.5254, 0.5254, 0.4619, 0.4836, 0.5293, 0.4809, 0.4763,\n","        0.5137, 0.5137, 0.5019, 0.5254, 0.4990, 0.4816, 0.5059, 0.4814, 0.4776,\n","        0.4753, 0.4770, 0.4774, 0.5488, 0.4941, 0.5098, 0.4770, 0.5019, 0.4726,\n","        0.5059, 0.4732, 0.9469, 0.4580, 0.4497, 0.6468, 0.5018, 0.4509, 0.4658,\n","        0.5135, 0.5215, 0.4836, 0.4851, 0.0680, 0.4038, 0.6074, 0.5133, 0.5762,\n","        0.3465, 0.4951, 0.4792, 0.4825, 0.4852, 0.5254, 0.5137, 0.5566, 0.5250,\n","        0.4806, 0.4695, 0.5606, 0.4912, 0.4872, 0.5254, 1.2330, 0.5371, 0.4747,\n","        0.5020, 0.4873, 0.4689, 0.4423, 0.4717, 0.5337, 0.5293, 0.5098, 0.4631,\n","        0.5134, 0.5410, 0.4636, 0.7518, 0.4814, 0.4473, 0.4412, 0.4716, 0.4717,\n","        0.5176, 0.4813, 0.4641, 0.5059, 0.5073, 0.4698, 0.3935, 0.5051, 0.4853,\n","        0.5215, 0.4774, 0.4541, 0.4807, 0.4779, 0.4949, 0.4442, 0.0980, 0.4765,\n","        0.5083, 0.4948, 0.5096, 0.5605, 0.4618, 0.5188, 0.4862, 0.6028, 0.5293,\n","        0.5320, 0.5332, 0.4834, 0.5254, 0.4791, 0.4826, 0.0860, 0.4795, 0.4894,\n","        0.5058, 0.5019, 0.4807, 0.5118, 0.5585, 0.5563, 0.5098, 0.4752, 0.4610,\n","        0.3428, 0.4941, 0.4951, 0.4760, 0.4679, 0.2861, 0.5092, 0.5215, 0.4699,\n","        0.4912, 0.5137, 0.5063, 0.4909, 0.5132, 0.4587, 0.4889, 0.5018, 0.4873,\n","        0.4910, 0.4535, 0.7715, 0.0319, 0.0899, 0.4834, 0.4741, 0.5019, 0.4639,\n","        0.4671, 0.5020, 0.5566, 0.4714, 0.4854, 0.5176, 0.4600, 0.5086, 0.4731,\n","        0.4786, 0.0600, 0.4071, 0.4952, 0.5020, 0.5110, 0.4990, 0.5209, 0.7588,\n","        0.5215, 0.4677, 0.4951, 0.5762, 0.5449, 0.4552, 0.4638, 0.5135, 0.5059,\n","        0.4920, 0.4965, 0.5293, 0.5059, 0.5059, 0.4895, 0.4853, 0.4599, 0.5097,\n","        0.5137, 0.5449, 0.4763, 0.5212, 0.7698, 0.6255, 0.5025, 0.4697, 0.5137,\n","        0.5252, 0.4623, 0.4721, 0.4947, 0.4774, 0.4600, 0.4691, 0.5019, 0.5081,\n","        0.5350, 0.5059, 0.4908, 0.5996, 0.4946, 0.5438, 0.4948, 0.4852, 0.4892,\n","        0.5996, 0.5000, 0.6121, 0.5172, 0.5058, 0.6152, 0.5488, 0.4709, 0.5137,\n","        0.4677, 0.4891, 0.5182, 0.4970, 0.4953, 0.4873, 0.4781, 0.4834, 0.6116,\n","        0.5099, 0.5137, 0.5099, 0.5839, 0.5137, 0.5254, 0.4912, 0.4941, 0.5254,\n","        0.4824, 0.4886, 0.5839, 0.5019, 0.4679, 0.4521, 0.5254, 0.5001, 0.4574,\n","        0.5059, 0.4724, 0.4952, 0.5254, 0.4852, 0.5017, 0.4845, 0.4540, 0.4956,\n","        0.4893, 0.4541, 0.4953, 0.4753, 0.4597, 0.4555, 0.5436, 0.5019, 0.5521,\n","        0.4990, 0.4954, 0.4891, 0.5098, 0.4964, 0.9004, 0.5022, 0.5059, 0.5176,\n","        0.4873, 0.5210, 0.5277, 0.5618, 0.6152, 0.4825, 0.5019, 0.5215, 0.5176,\n","        0.4723, 0.5152, 0.4736, 0.5175, 0.4778, 0.5057, 0.6895, 0.4930, 0.4890,\n","        0.4929, 0.4950, 0.4883, 0.4751, 0.4873, 0.5879, 0.5060, 0.4874, 0.4717,\n","        0.5059, 1.0140, 0.5676, 0.4248, 0.5158, 0.5876, 0.5045, 0.4989, 0.5371,\n","        0.4950, 0.6682, 0.4579, 0.5745, 0.4678, 0.5234, 0.4774, 0.5253, 0.4716,\n","        0.5113, 0.4698, 0.5918, 0.4734, 0.5058, 0.4817, 0.4767, 0.4834, 0.5849,\n","        0.4715, 0.5332, 0.5100, 0.5958, 0.5213, 0.4790, 0.4731, 0.4696, 0.4502,\n","        0.4709, 0.4794, 0.4697, 0.5358, 0.7235, 0.5772, 0.4913, 0.5176, 0.4951,\n","        0.4775, 0.4905, 0.5059, 0.4614, 0.5137, 0.4717, 0.4670, 0.4521, 0.4773,\n","        0.5208, 0.5163, 0.4814, 0.4862, 0.4632, 0.5122, 0.5232, 0.4714, 0.5487,\n","        0.4814, 0.7279, 0.4934, 0.5098, 0.5643, 0.5091, 0.4677, 0.8153, 0.5215,\n","        0.4561, 0.4773, 0.4697, 0.4579, 0.5176, 0.4424, 0.4951, 0.5836, 0.4734,\n","        0.4717, 0.6929, 0.4521, 0.4930, 0.5234, 0.5345, 0.5371, 0.5095, 0.5364,\n","        0.5131, 0.5332, 0.5767, 0.4947, 0.4987, 0.4871, 0.4976, 0.4639, 0.4638,\n","        0.5176, 0.6423, 0.5020, 0.4949, 0.4937, 0.5254, 0.4812, 0.5403, 0.5840,\n","        0.4821, 0.5097, 0.5059, 0.4795, 0.4993, 0.4717, 0.4699, 0.5215, 0.5293,\n","        0.2910, 0.4928, 0.4746, 0.5136, 0.4484, 0.4969, 0.7114, 0.4759, 0.4435,\n","        0.5096, 0.4678, 0.5139], device='cuda:0', requires_grad=True)\n","blocks.11.ln2.b: torch.Size([768])\n","Parameter containing:\n","tensor([-1.9770e-03,  2.0055e-02,  3.8334e-02,  3.0216e-04,  2.0649e-02,\n","         3.2326e-03,  5.0893e-02,  2.7662e-02, -1.2057e-02, -1.1368e-02,\n","        -9.0342e-03,  2.6782e-02, -9.7410e-03,  1.2047e-02,  1.8908e-02,\n","         1.8763e-02,  4.2725e-02,  2.3068e-02, -1.0570e-02, -3.0680e-02,\n","        -1.0966e-02,  2.6101e-03,  1.0864e-02,  2.6391e-02, -2.8683e-03,\n","         4.9588e-03,  1.6695e-02,  2.0488e-02, -2.1496e-03, -3.3820e-02,\n","         6.1461e-03,  9.1776e-03,  9.8818e-03,  4.5791e-02,  9.9177e-03,\n","         4.3567e-03,  2.9751e-02, -1.8786e-02,  3.3473e-02, -3.1499e-02,\n","         1.5754e-02,  4.2623e-02, -7.8693e-03,  1.4216e-02,  1.8168e-02,\n","         2.6067e-03,  3.1309e-02, -1.0033e-03, -8.8638e-03, -3.5221e-02,\n","         3.8618e-02,  3.7020e-03,  3.2937e-02,  1.8482e-02, -1.4815e-02,\n","        -7.7805e-03,  5.2594e-03,  4.0192e-03,  9.9007e-03,  2.7639e-02,\n","         1.4332e-02,  4.2406e-02,  1.0204e-03,  2.6425e-02,  3.9371e-01,\n","         2.1459e-02,  2.9602e-02, -8.6012e-03,  5.8604e-02,  2.1422e-02,\n","        -3.7243e-02,  2.7898e-02,  1.7380e-02, -5.8365e-03, -9.1360e-04,\n","         1.3917e-02, -3.7961e-02, -1.0985e-02,  8.1267e-02,  3.4247e-02,\n","        -9.9419e-04,  7.8471e-04,  1.1363e-02,  4.6394e-02,  1.7662e-02,\n","         2.2832e-02, -6.8747e-03,  3.1664e-01,  2.3674e-02, -4.0318e-04,\n","        -5.4163e-03,  1.9663e-02, -2.3600e-03, -2.3344e-02, -4.4659e-03,\n","        -1.1295e-02,  1.6962e-02,  1.3828e-02, -2.2617e-02,  9.2670e-03,\n","         1.2624e-02, -3.0522e-02, -1.0299e-03, -3.9346e-03, -2.6422e-03,\n","        -7.2173e-03, -4.9170e-02,  2.1837e-02,  2.8134e-02,  1.2505e-02,\n","        -2.0111e-03, -8.5863e-03,  3.7535e-02,  3.7699e-03,  2.5194e-02,\n","         4.1117e-02, -8.1272e-03, -4.1117e-02,  5.9965e-03,  1.9486e-02,\n","        -1.1550e-03, -1.2193e-04, -3.6460e-02,  2.9326e-03, -3.2782e-02,\n","        -1.1985e-02, -1.3821e-02,  2.4435e-02,  1.7244e-04, -7.9792e-03,\n","        -8.3180e-03,  1.0637e-02,  3.0221e-02,  4.3739e-02,  9.4321e-03,\n","        -7.3731e-03, -7.4633e-03,  1.7020e-02,  3.5540e-02,  2.2817e-02,\n","        -1.5388e-02,  2.4447e-02, -1.1352e-02,  5.4107e-03, -6.6506e-04,\n","        -2.1653e-02, -1.8482e-02,  2.5981e-02,  1.4639e-03,  1.6672e-02,\n","         2.1895e-02, -1.9042e-02, -3.1044e-02, -6.2862e-03, -2.3009e-02,\n","         2.8817e-02,  4.0952e-02,  1.2868e-02,  1.4308e-02,  7.9704e-03,\n","        -1.6250e-02, -2.1372e-02, -1.7181e-02, -3.0238e-02, -2.6150e-03,\n","         2.5429e-02,  2.2134e-02,  4.1403e-02,  2.2501e-02, -2.6282e-02,\n","         3.9950e-02,  4.5368e-02,  3.5637e-02, -1.9180e-02,  4.4481e-03,\n","        -1.1992e-02,  2.5781e-02,  3.5772e-03, -1.9244e-02, -1.4046e-02,\n","         1.7489e-02,  8.9664e-03, -1.1940e-02,  1.2796e-03,  5.1954e-02,\n","         2.5120e-02,  9.8478e-03, -4.8570e-03,  2.4748e-02, -3.6122e-02,\n","        -2.8339e-03, -2.1125e-02, -1.1487e-02, -1.3704e-03,  1.4018e-02,\n","         6.3674e-02,  3.0747e-02,  2.0225e-03,  2.3836e-02, -1.2392e-02,\n","        -2.9209e-02, -1.8785e-02,  1.8295e-02,  3.0047e-02, -4.3826e-04,\n","         9.2962e-03,  2.8898e-02,  8.7810e-03, -7.3327e-03,  2.1819e-02,\n","        -7.7978e-03, -1.2293e-02,  3.4295e-02,  2.4645e-02, -9.0532e-03,\n","         1.1065e-03,  1.1084e-02,  5.0188e-04,  3.4106e-02, -8.2423e-03,\n","        -2.7834e-02,  1.0577e-02, -2.0528e-03,  8.4717e-04,  1.5029e-02,\n","         2.0727e-02, -1.9540e-02,  1.7994e-02, -7.7041e-03,  1.4030e-02,\n","        -2.1543e-02, -2.4718e-04, -1.6450e-02,  1.1755e-02, -5.6980e-03,\n","         3.3711e-02, -1.5150e-02,  9.1014e-03, -5.6491e-03,  1.9425e-02,\n","         7.9497e-03,  3.0760e-02,  2.4050e-02,  3.6260e-02,  1.9766e-02,\n","        -4.6812e-02,  1.4090e-02,  2.7172e-02,  6.4448e-04,  1.1674e-02,\n","        -1.0521e-04, -6.5295e-03, -6.1248e-02,  7.4147e-03, -2.7313e-03,\n","        -2.7356e-02,  2.3763e-02, -1.1479e-02, -1.4240e-02,  6.7913e-03,\n","        -2.8976e-02,  2.1050e-02,  4.2040e-02,  2.6469e-02, -2.9035e-04,\n","         4.1420e-03,  3.4777e-01, -6.4897e-03,  2.0932e-02,  2.0471e-02,\n","        -2.2009e-02,  2.6752e-02, -4.1847e-02,  6.2082e-03, -3.7313e-02,\n","        -3.9273e-04,  2.1064e-02,  2.5925e-02,  9.5042e-03,  3.1333e-02,\n","         2.2061e-02, -1.1282e-02,  1.6810e-02,  5.3057e-02, -9.4329e-03,\n","         2.9291e-03,  7.9438e-03,  9.8559e-03, -9.2946e-02,  2.9761e-02,\n","        -3.3820e-03,  9.8083e-03,  6.0030e-03, -1.5150e-02, -4.3562e-03,\n","         2.6455e-02,  2.5353e-02,  1.8849e-02, -7.0244e-03,  6.8030e-03,\n","         3.1277e-02,  1.9667e-02,  1.6478e-02,  1.9452e-02, -9.6623e-04,\n","        -6.3059e-03, -8.1541e-03,  3.9795e-03,  4.2508e-02,  4.5595e-03,\n","         1.1091e-02,  5.9278e-02,  4.8465e-03,  1.7938e-02,  5.9207e-02,\n","        -1.1141e-02,  8.3145e-03, -8.4097e-03, -1.6956e-03, -8.7251e-03,\n","         2.3974e-02,  1.8378e-02, -1.9591e-02, -8.6058e-03, -7.4060e-03,\n","        -1.0198e-02, -1.4201e-01,  2.2461e-02,  1.0420e-02,  2.1097e-02,\n","        -9.0401e-03,  3.0010e-02,  1.8055e-02,  2.5954e-02,  5.0622e-03,\n","        -5.1361e-03,  2.4327e-03,  2.4640e-02,  3.8846e-03,  1.5082e-02,\n","         2.4333e-02,  1.6992e-02,  4.6226e-03, -1.0366e-02,  3.6624e-03,\n","        -1.2261e-03,  1.8952e-02,  4.2329e-02, -1.1133e-03,  1.9850e-03,\n","         2.4931e-02, -4.4305e-02,  1.8492e-02,  1.4927e-02,  4.4272e-02,\n","         3.2558e-02,  2.1321e-02,  5.7945e-03,  1.9714e-02,  2.3721e-02,\n","         3.6757e-02,  2.3772e-02,  8.9267e-02, -3.4410e-02, -1.9038e-02,\n","         1.2163e-02,  2.2508e-02, -3.1742e-02,  3.8067e-02,  4.1336e-02,\n","         8.7208e-03, -2.7214e-02, -1.6748e-02,  4.2466e-01,  4.8930e-02,\n","         4.1985e-02,  3.3497e-02,  8.5045e-03, -4.9738e-03, -9.1733e-03,\n","         4.3338e-02, -1.0397e-02,  2.6768e-02, -1.5669e-02,  5.8101e-02,\n","        -1.1133e-02, -3.6069e-02, -1.1497e-02, -8.8742e-03,  2.5798e-02,\n","         1.2805e-02, -1.4207e-03, -1.0385e-02, -1.2075e-01,  1.0254e-02,\n","         1.2827e-02,  2.5563e-02,  1.5510e-03, -8.7276e-03,  1.2874e-02,\n","        -5.4861e-04,  1.1237e-02,  1.1656e-02,  5.5663e-03,  5.1020e-04,\n","         2.5084e-03, -1.7832e-03,  1.9225e-02,  3.6974e-03, -1.1154e-02,\n","         3.0566e-02,  1.1319e-02,  1.4030e-02, -9.3461e-03,  1.1581e-02,\n","        -3.2451e-02,  2.8498e-02,  4.0561e-03,  3.2891e-02,  4.4055e-03,\n","         1.8884e-02, -1.5979e-02, -3.5495e-04,  2.1205e-02, -1.6530e-04,\n","         5.5217e-03,  3.0463e-02,  1.2026e-02,  1.6322e-02,  5.9938e-03,\n","        -1.1809e-02,  1.1143e-02, -7.4192e-03,  4.5199e-02, -3.7486e-02,\n","         2.0995e-02,  9.8705e-03,  1.9444e-02,  2.1260e-02,  4.9170e-02,\n","         2.3779e-03,  8.5347e-03,  5.5772e-02,  3.0698e-02,  2.0777e-02,\n","         8.1277e-03, -5.1169e-03, -1.7182e-01,  6.1315e-02,  2.6298e-02,\n","         1.2816e-02,  2.2403e-02,  1.2226e-02,  2.0092e-02, -1.8158e-02,\n","        -4.3574e-03,  3.9566e-02,  3.3679e-02, -1.0471e-02,  4.6560e-02,\n","         7.8568e-03, -4.3204e-02,  3.6972e-02,  2.3264e-02, -2.6250e-02,\n","         1.7062e-02, -2.1880e-02, -6.7740e-04,  9.3964e-03,  2.3374e-02,\n","         2.7628e-02, -1.0024e-02,  4.6221e-02,  2.8498e-02, -8.0936e-03,\n","        -6.5142e-03, -1.5308e-02, -4.2900e-03,  3.2943e-02,  4.0934e-02,\n","         3.2821e-01, -2.0933e-01, -6.1119e-03,  1.4123e-02,  8.8059e-03,\n","         1.7465e-03,  4.5657e-02, -2.3354e-02,  2.6175e-02,  1.7621e-02,\n","         3.1925e-02,  3.7570e-04,  1.8972e-02,  6.5024e-02, -1.0997e-02,\n","         1.9380e-02, -8.8907e-02,  8.0039e-02,  5.3407e-03, -1.4902e-02,\n","        -1.4937e-02,  6.0047e-03,  4.1865e-02, -1.4389e-02,  1.2933e-02,\n","         1.3835e-03,  4.2220e-02,  1.4794e-03,  1.9085e-03, -6.7496e-03,\n","         1.7700e-02, -1.3577e-02,  1.2299e-02,  3.3337e-02,  6.4963e-03,\n","         2.9347e-03,  6.8754e-03, -2.6927e-03, -1.9043e-03,  3.4128e-02,\n","        -2.7502e-02,  1.7844e-03,  1.3119e-02,  4.0508e-02, -1.0110e-03,\n","        -3.5489e-02,  1.1592e-01,  2.3252e-02,  1.3701e-02,  1.4698e-03,\n","        -1.5331e-02, -1.7127e-03,  1.4999e-02, -1.0101e-02,  1.0129e-02,\n","         3.0279e-02,  1.2507e-02,  1.5106e-02, -8.7786e-03,  2.4470e-02,\n","         1.5991e-02,  4.7043e-03, -7.9213e-04, -1.4661e-02, -6.4260e-03,\n","         3.4796e-02,  3.0444e-02,  3.8431e-02,  1.6288e-03,  1.9594e-02,\n","        -1.2043e-02,  3.0482e-02, -1.1165e-02,  2.9799e-02,  5.0296e-02,\n","        -1.2850e-02, -2.6389e-02,  4.3113e-03,  2.2689e-02,  2.2986e-02,\n","         2.4584e-03,  2.8011e-02,  2.2453e-02,  1.7214e-02, -1.2165e-02,\n","        -6.5908e-03,  8.6674e-03,  2.4143e-02,  3.3351e-02,  2.8083e-02,\n","         5.3764e-02,  2.6645e-02,  3.1699e-03, -1.3451e-02, -1.0193e-02,\n","        -1.9819e-02,  6.5050e-03, -8.3800e-03,  1.6086e-02,  2.2393e-02,\n","        -2.0060e-02,  1.1480e-02, -8.7650e-03,  2.9910e-02,  3.4620e-03,\n","        -3.6450e-02,  4.6979e-03, -2.2661e-02,  6.6594e-03,  7.5281e-03,\n","        -5.6028e-03,  1.7918e-02,  3.5254e-02, -1.3218e-02,  1.7821e-02,\n","        -5.3503e-03,  2.9257e-02, -4.6762e-03, -8.7403e-03,  1.2103e-02,\n","         2.6252e-02, -1.5761e-02,  4.5950e-02, -1.2852e-02, -3.8532e-02,\n","         3.5157e-02,  6.4261e-03,  3.6912e-02,  2.1826e-02,  1.2977e-02,\n","         1.8503e-02,  1.7160e-02,  1.4517e-02,  4.4673e-02, -2.5077e-02,\n","         2.5659e-02,  1.3455e-02,  3.7067e-02, -1.0420e-02,  1.3964e-03,\n","         4.6035e-02,  2.5316e-02,  3.8166e-02,  9.9031e-04,  2.1450e-02,\n","         4.6285e-03,  6.8337e-03,  3.4753e-02, -2.3968e-03,  4.7143e-02,\n","         9.1593e-03,  6.2969e-03,  1.0683e-02, -8.5284e-03,  2.2846e-02,\n","         2.9957e-02,  2.9813e-02,  8.2483e-03, -2.1761e-03, -1.0172e-02,\n","        -1.5678e-01, -2.7951e-03,  4.6728e-02,  1.8013e-02, -3.1996e-02,\n","        -1.6086e-02,  1.1882e-02, -2.0283e-02, -1.4534e-02,  1.0807e-03,\n","         1.9827e-02,  3.2595e-03, -4.7095e-02,  1.3696e-02,  1.2284e-02,\n","         3.0075e-02,  3.2230e-03, -2.7215e-02,  1.9513e-02, -2.7397e-02,\n","         5.1693e-03,  1.2862e-02, -6.3941e-04,  4.8048e-03, -3.8948e-03,\n","         1.6354e-02,  3.0418e-03,  1.8567e-02,  3.8866e-03,  4.1174e-02,\n","         1.0866e-02, -6.5944e-03,  3.1822e-02,  2.8469e-02, -5.7513e-03,\n","         8.1625e-03,  1.8507e-02,  3.9841e-03,  3.1920e-03, -4.8270e-02,\n","         5.8900e-03,  2.4513e-02, -4.0166e-02,  1.4448e-02,  5.1222e-03,\n","         3.2586e-02,  1.7786e-02,  7.6222e-02,  1.7708e-02,  4.9652e-02,\n","         7.5001e-03, -9.2199e-03,  1.0967e-03, -1.2194e-02,  6.4481e-03,\n","         1.5110e-02, -2.0136e-03, -4.0664e-03,  1.8472e-02, -3.1462e-02,\n","        -6.7375e-03,  1.7864e-02,  3.8919e-02, -5.4543e-02,  1.0494e-02,\n","         2.5426e-02, -2.8378e-02,  1.1150e-02, -1.9784e-03, -5.5754e-02,\n","        -3.4573e-02,  5.6036e-03,  2.6608e-02,  1.1461e-02, -1.2790e-02,\n","         3.3585e-02,  2.1926e-02, -2.0345e-02, -2.8081e-02,  3.8825e-03,\n","        -1.3853e-02, -3.6429e-02, -4.3683e-03,  6.1590e-02, -1.2015e-02,\n","         1.2267e-03, -2.7716e-02,  4.2425e-03,  2.3445e-03,  4.8923e-03,\n","        -6.1121e-03, -2.6611e-03,  1.8391e-03,  1.4922e-02,  2.6544e-02,\n","         7.0514e-03,  3.6240e-03,  3.5179e-03,  1.9159e-02,  2.9218e-02,\n","         4.6322e-02, -1.2064e-02,  6.4879e-03,  4.7135e-03,  1.1390e-02,\n","         9.5750e-02, -7.9921e-03,  2.5974e-02,  2.3404e-02,  3.1400e-02,\n","         6.4799e-03, -5.1150e-03, -1.6654e-02,  7.7214e-03,  3.5866e-02,\n","         3.9769e-03,  3.5815e-02,  2.1074e-02, -9.3381e-04,  2.1403e-02,\n","         3.0252e-02,  8.4771e-03, -2.3994e-02, -1.4937e-02,  9.9732e-03,\n","        -2.6557e-02,  4.1841e-03,  5.2969e-03], device='cuda:0',\n","       requires_grad=True)\n","blocks.11.attn.W_Q: torch.Size([12, 768, 64])\n","Parameter containing:\n","tensor([[[-0.2175,  0.0608, -0.0637,  ..., -0.0308,  0.0060,  0.0439],\n","         [ 0.0073, -0.1360, -0.0365,  ..., -0.0583,  0.1133,  0.0018],\n","         [ 0.1679, -0.1013,  0.0714,  ..., -0.0572,  0.0950, -0.0006],\n","         ...,\n","         [ 0.0365,  0.1295,  0.0607,  ..., -0.0190,  0.2121, -0.0290],\n","         [-0.1372,  0.1039,  0.0054,  ...,  0.0174, -0.0077, -0.0691],\n","         [ 0.1725,  0.0285, -0.0258,  ..., -0.0836,  0.0428,  0.0293]],\n","\n","        [[-0.0635, -0.1859, -0.0858,  ...,  0.0403, -0.0164,  0.0332],\n","         [-0.0061, -0.0573, -0.1372,  ..., -0.1988, -0.0209,  0.0757],\n","         [-0.0773, -0.0225, -0.1376,  ...,  0.1181,  0.0171, -0.0929],\n","         ...,\n","         [-0.0947, -0.0381, -0.0502,  ...,  0.0471,  0.1097,  0.2392],\n","         [-0.0954,  0.0795, -0.2401,  ..., -0.0271, -0.0144, -0.0380],\n","         [ 0.1071,  0.0074,  0.0344,  ...,  0.0031, -0.0134,  0.0598]],\n","\n","        [[-0.0663,  0.1041,  0.0488,  ...,  0.0282,  0.0492,  0.1491],\n","         [ 0.2246,  0.0010,  0.2452,  ..., -0.0952, -0.0487,  0.0399],\n","         [-0.0239, -0.1691, -0.0037,  ...,  0.2246,  0.0014, -0.0798],\n","         ...,\n","         [-0.0054,  0.0806, -0.3446,  ...,  0.1248,  0.1067,  0.1512],\n","         [ 0.0783, -0.0730,  0.1032,  ...,  0.0069, -0.0106,  0.0272],\n","         [ 0.0840, -0.0594,  0.1061,  ..., -0.0182,  0.2899,  0.0689]],\n","\n","        ...,\n","\n","        [[-0.0568, -0.0194,  0.0788,  ..., -0.0809, -0.1170,  0.0145],\n","         [-0.0015,  0.0697,  0.0097,  ..., -0.0901,  0.1247,  0.0442],\n","         [-0.0146,  0.1269, -0.1019,  ...,  0.1171, -0.1276,  0.1315],\n","         ...,\n","         [-0.1499,  0.0452, -0.0273,  ..., -0.0273,  0.0671,  0.2217],\n","         [ 0.0369,  0.0504,  0.0250,  ...,  0.1034, -0.0542,  0.0024],\n","         [-0.1735,  0.1978, -0.2612,  ..., -0.1656,  0.2712,  0.0097]],\n","\n","        [[ 0.0040, -0.0704,  0.1092,  ...,  0.0964, -0.0307,  0.1804],\n","         [-0.0937, -0.0598, -0.2397,  ..., -0.0536,  0.0093, -0.0346],\n","         [ 0.1385,  0.1015, -0.1898,  ...,  0.1018,  0.0754, -0.1852],\n","         ...,\n","         [-0.0890, -0.1347, -0.0189,  ..., -0.2230,  0.1421, -0.1236],\n","         [-0.0483,  0.0657, -0.0572,  ..., -0.2491,  0.0575,  0.1743],\n","         [ 0.0985,  0.0132, -0.0532,  ..., -0.0479, -0.2026, -0.0468]],\n","\n","        [[-0.1098, -0.0722,  0.1044,  ...,  0.0504,  0.0108, -0.1579],\n","         [ 0.1330, -0.0416, -0.1168,  ..., -0.0769, -0.0549,  0.0160],\n","         [-0.0110, -0.0511,  0.0014,  ..., -0.0349,  0.1284, -0.0867],\n","         ...,\n","         [-0.0173,  0.1699,  0.0711,  ..., -0.3092,  0.0138,  0.1783],\n","         [-0.2964,  0.0361, -0.0458,  ..., -0.2252, -0.0663,  0.0072],\n","         [ 0.0106, -0.0141, -0.0509,  ...,  0.1219, -0.0728, -0.0060]]],\n","       device='cuda:0', requires_grad=True)\n","blocks.11.attn.W_O: torch.Size([12, 64, 768])\n","Parameter containing:\n","tensor([[[ 1.1216e-01,  1.5094e-01,  6.9908e-02,  ...,  2.0310e-02,\n","          -1.6704e-01, -4.4227e-02],\n","         [-8.6594e-02, -7.0190e-02, -7.9596e-02,  ...,  2.7165e-01,\n","           5.1789e-02, -1.5401e-01],\n","         [-1.3391e-02, -2.8654e-02,  4.4232e-02,  ...,  6.3731e-02,\n","           3.7671e-02, -2.3575e-02],\n","         ...,\n","         [-1.3539e-03, -3.4393e-02, -3.6646e-05,  ...,  9.1483e-02,\n","          -1.6832e-02, -9.9999e-02],\n","         [-7.9261e-02,  2.6442e-02, -5.8073e-02,  ..., -3.4815e-02,\n","           7.2246e-02, -9.9509e-02],\n","         [ 5.8745e-03, -8.1756e-02,  3.7806e-02,  ...,  3.1403e-02,\n","          -9.4603e-02, -1.1366e-01]],\n","\n","        [[ 4.0931e-02,  1.3003e-01,  1.6298e-01,  ..., -1.0276e-01,\n","          -6.0167e-02, -1.2201e-01],\n","         [-2.7089e-01, -1.9263e-01,  1.5221e-01,  ..., -1.5538e-01,\n","           1.9973e-02,  1.6140e-02],\n","         [-7.5078e-02,  1.2379e-02, -4.2235e-03,  ..., -1.8051e-01,\n","          -1.8285e-01, -1.2090e-02],\n","         ...,\n","         [ 2.2786e-02, -1.3945e-01,  2.1970e-01,  ..., -1.9123e-01,\n","          -3.9002e-02,  1.1833e-01],\n","         [ 3.9997e-01, -2.5525e-01, -1.6223e-03,  ..., -1.4530e-01,\n","          -1.1068e-01,  1.2572e-01],\n","         [ 7.2454e-02, -3.1732e-01, -2.8480e-01,  ...,  3.0492e-02,\n","           1.3797e-01, -1.0879e-01]],\n","\n","        [[-1.9228e-02,  2.0428e-01,  1.7039e-02,  ..., -1.5586e-01,\n","           1.7199e-01,  1.7631e-01],\n","         [-1.9067e-01,  7.0027e-02, -1.7409e-01,  ...,  3.0228e-03,\n","           6.9245e-02, -5.9789e-03],\n","         [-1.4014e-03,  5.5206e-01,  7.3206e-02,  ..., -5.4928e-02,\n","          -1.3815e-01,  6.8598e-02],\n","         ...,\n","         [-4.5964e-02, -1.2454e-01, -1.8223e-01,  ..., -1.2626e-01,\n","          -2.5991e-01, -2.6627e-01],\n","         [-3.0952e-02,  1.5942e-02,  3.3495e-02,  ..., -9.5919e-02,\n","          -7.4537e-02, -6.5868e-02],\n","         [-1.1036e-01,  3.0428e-02, -3.3910e-01,  ..., -4.6538e-02,\n","          -1.2533e-02, -1.7256e-01]],\n","\n","        ...,\n","\n","        [[ 4.2260e-02,  7.6785e-02,  2.1761e-01,  ..., -4.9856e-02,\n","           2.3825e-01,  2.1325e-01],\n","         [ 1.7835e-02, -2.7509e-02, -7.8433e-02,  ..., -1.9613e-01,\n","           6.5151e-03, -1.7544e-01],\n","         [ 1.6792e-01,  4.3373e-01, -3.0781e-01,  ...,  1.7365e-01,\n","          -6.2292e-02,  1.0098e-01],\n","         ...,\n","         [ 1.5778e-01, -2.2454e-01, -9.2582e-02,  ..., -1.3701e-02,\n","           1.1386e-01,  2.7044e-01],\n","         [-2.4812e-01,  1.3564e-01, -1.0315e-01,  ...,  7.2639e-02,\n","          -2.1237e-01, -1.2514e-01],\n","         [ 1.4865e-01,  2.2826e-01, -1.2997e-01,  ...,  2.1460e-01,\n","          -3.3261e-01, -1.4875e-01]],\n","\n","        [[-7.0194e-02,  7.2981e-02,  1.4653e-01,  ..., -1.1165e-01,\n","          -2.2008e-02,  9.2253e-02],\n","         [ 6.8627e-02, -1.3338e-01, -8.9192e-02,  ...,  7.1086e-02,\n","           1.1327e-01, -2.2373e-01],\n","         [ 9.7607e-02, -4.8110e-02, -4.6906e-02,  ..., -2.2289e-01,\n","           2.1804e-01, -1.6109e-01],\n","         ...,\n","         [-1.6542e-01,  5.0414e-02, -1.6867e-01,  ..., -2.1013e-02,\n","           7.8524e-02, -4.4769e-01],\n","         [-1.8793e-01,  7.3126e-02,  1.2935e-01,  ...,  1.2884e-01,\n","          -1.1903e-01,  2.3106e-01],\n","         [ 1.8553e-02, -9.8469e-02,  1.9307e-02,  ...,  4.0572e-02,\n","           2.2969e-01, -1.4255e-01]],\n","\n","        [[ 6.1210e-02, -3.9854e-01, -1.5035e-01,  ...,  2.1287e-01,\n","          -1.3513e-01, -5.6134e-02],\n","         [ 2.3895e-02,  1.0871e-03,  9.7340e-02,  ...,  1.2699e-01,\n","          -4.6852e-02, -2.0346e-02],\n","         [-1.2749e-01, -1.0525e-01,  1.1721e-01,  ..., -2.9580e-01,\n","           9.1867e-02, -3.3036e-02],\n","         ...,\n","         [-4.3602e-02,  2.4208e-01,  1.0670e-03,  ..., -3.2157e-03,\n","           2.4506e-01,  1.2096e-01],\n","         [-1.5884e-01, -2.2799e-01,  7.2818e-02,  ...,  1.5906e-01,\n","           3.3795e-01, -1.4134e-01],\n","         [ 1.1283e-01, -2.1124e-01, -1.1039e-01,  ..., -1.9806e-02,\n","           9.2270e-02,  3.0145e-01]]], device='cuda:0', requires_grad=True)\n","blocks.11.attn.b_Q: torch.Size([12, 64])\n","Parameter containing:\n","tensor([[-2.2222e-01,  5.4906e-02,  3.3071e-02,  1.5805e-01,  3.0289e-02,\n","         -2.3497e-01, -3.0648e-01, -1.1610e-01,  1.1943e-01, -1.8294e-01,\n","          9.1356e-02,  1.7704e-01, -4.4169e-02, -2.3200e-01, -2.6596e-01,\n","         -6.4141e-02,  1.7822e-01,  2.3307e-01,  2.6206e-02, -1.0768e-01,\n","          2.8603e-02,  7.6642e-02, -1.8137e-01, -1.1824e-01, -3.8848e-02,\n","         -2.3406e-01, -1.0244e-01,  9.6169e-02,  1.3880e-02,  2.6460e-01,\n","          1.5880e-01,  6.0946e-02, -6.8381e-02, -1.2107e-01,  1.0946e-01,\n","         -1.4045e-02, -7.4478e-02, -5.7165e-02, -2.0175e-02,  1.8007e-02,\n","          1.3796e-01, -9.7650e-02, -2.9251e-02, -2.4638e-02, -3.7910e-02,\n","         -2.1374e-02,  9.2548e-02,  3.3767e-03,  2.6532e-01,  2.7109e-01,\n","          1.6453e-01, -1.5195e-01,  1.8583e-01, -2.4461e-01, -1.1437e-01,\n","          2.1341e-01,  1.3393e-01,  1.1492e-01, -3.5882e-03,  9.3312e-02,\n","          3.0719e-02, -1.2686e-02,  3.3930e-01, -4.5535e-02],\n","        [ 2.4397e-02, -4.5156e-02,  2.4305e-01, -5.8023e-01,  1.6919e-02,\n","          9.1323e-02, -9.5363e-02,  3.0690e-02, -1.8824e-01, -7.9207e-03,\n","          3.3017e-02,  8.5289e-02,  1.8738e-01, -1.1722e-01, -6.5017e-02,\n","          1.0617e-01, -2.0755e-01, -8.5182e-02,  2.5771e-02,  3.3479e-02,\n","         -4.5572e-02,  3.9989e-02,  1.0007e-01,  1.5401e-01,  4.8493e-02,\n","         -9.7793e-02, -1.4092e-02, -2.9058e-01,  9.5938e-02, -2.4239e-01,\n","         -1.0059e-01,  1.4022e-01,  1.7083e-01,  2.3030e-02, -9.2371e-02,\n","          1.2048e-01,  1.5061e-01,  5.9817e-02,  2.4829e-02, -1.2260e-01,\n","          4.9813e-01, -2.9362e-02, -6.9710e-02,  9.7355e-02, -1.4200e-01,\n","          1.9329e-01,  6.5002e-02, -2.7191e-01, -6.6362e-02,  2.1688e-01,\n","          1.4188e-01,  9.5196e-02, -3.7644e-02, -5.1035e-02, -9.0846e-02,\n","         -1.8777e-02,  6.5476e-02,  1.9709e-02,  8.2638e-03, -9.6475e-03,\n","         -1.6813e-02, -1.0795e-01, -3.7878e-02,  8.3275e-02],\n","        [-4.0371e-02,  1.4645e-01,  1.3978e-01, -1.1058e-01, -2.8148e-01,\n","         -2.7178e-01,  1.1905e-02, -1.9656e-01,  7.8388e-04, -1.1212e-01,\n","          9.5206e-02, -3.2944e-01,  1.9235e-01, -1.1848e-01,  1.5044e-01,\n","         -2.5125e-01,  4.5527e-02,  1.5891e-01, -3.8487e-01,  9.5693e-03,\n","          2.6705e-01, -1.8916e-01,  8.4798e-02,  5.0026e-02, -6.1098e-03,\n","         -1.4601e-02, -2.4129e-01, -2.0792e-01, -1.1677e-01, -5.9856e-01,\n","          2.7248e-01, -9.9534e-02,  7.6670e-02,  1.1575e-02,  2.8868e-01,\n","          1.0636e-02, -5.3687e-02,  1.1323e-01, -3.1367e-01,  1.7064e-01,\n","          2.8206e-01,  9.0633e-02,  2.4823e-01,  1.5168e-01,  2.2077e-01,\n","          3.4428e-01,  1.0559e-01, -2.4544e-01, -2.6355e-01, -1.3113e-01,\n","         -3.3851e-02,  2.2845e-01, -2.7150e-02,  4.2125e-01, -6.9739e-02,\n","          1.2751e-01,  8.1472e-02, -9.0482e-03,  1.9251e-02, -8.4821e-02,\n","         -1.7440e-01, -1.6647e-01,  8.9450e-02,  9.5539e-02],\n","        [ 4.0753e-02,  1.0202e-01, -2.1142e-01,  1.7552e-01,  1.8489e-01,\n","          2.7068e-01,  4.6609e-02, -1.1684e-01, -1.4969e-02, -1.1807e-01,\n","         -1.7775e-01,  9.1565e-02,  9.0573e-02, -3.1239e-02,  4.7489e-01,\n","          7.0859e-02, -1.7479e-01, -6.7714e-02, -1.1706e-01,  8.1897e-02,\n","         -2.3536e-02,  2.0306e-01, -5.5865e-02, -1.7194e-01, -9.3065e-02,\n","          7.3667e-03,  1.5035e-01, -2.3027e-02, -2.9991e-02,  2.0655e-02,\n","         -7.0763e-02,  1.6980e-01,  7.9264e-02,  6.9449e-02, -1.0074e-02,\n","          1.1714e-01, -1.4550e-01,  2.3472e-02, -3.6181e-01, -8.4105e-05,\n","         -1.1424e-01,  1.6806e-01,  1.8244e-01, -2.3113e-02, -7.3128e-01,\n","          3.8608e-02, -9.1521e-02, -2.9429e-05,  1.6148e-01, -1.1206e-01,\n","          2.7972e-02,  8.2478e-02, -9.8146e-02,  5.9921e-01,  4.2697e-02,\n","          2.6922e-01, -2.9771e-02,  3.5818e-02, -8.0460e-01, -6.8699e-02,\n","          2.1342e-02,  1.5300e-01, -4.6893e-01, -2.1019e-01],\n","        [-1.4475e-01,  1.0384e-02, -2.1260e-01, -1.9118e-01,  4.6335e-02,\n","          3.3471e-01,  1.1367e-01,  1.5222e-01, -1.8040e-01,  5.3034e-02,\n","          1.3044e-01,  9.1897e-03, -1.6146e-02,  2.3573e-01,  1.5870e-01,\n","          4.3869e-03,  4.9335e-01, -1.2162e-01,  5.7625e-02,  3.6344e-01,\n","         -6.0848e-02,  5.3018e-01,  3.5620e-01,  1.3396e-01,  5.0813e-02,\n","         -3.2271e-01, -1.0942e-01,  3.0319e-01,  3.7962e-01, -1.3014e-01,\n","          4.0265e-02,  1.1097e-01, -9.7932e-02, -2.7722e-01,  8.1672e-02,\n","         -1.9523e-01, -2.8140e-01,  6.0215e-02, -9.0830e-02, -4.2451e-01,\n","         -1.6642e-01, -2.3832e-03, -3.3357e-01, -2.4675e-01,  3.8656e-02,\n","         -3.8340e-01, -6.1960e-01, -1.7710e-03, -7.7042e-02, -6.4625e-02,\n","         -1.6675e-03,  4.8568e-01,  4.5084e-02, -3.7718e-01, -8.5890e-02,\n","          2.1210e-01,  1.7057e-01,  4.9288e-02,  2.0704e-01, -4.3852e-02,\n","          7.6254e-02, -6.0730e-02, -1.0272e-01,  1.4896e-01],\n","        [ 1.1390e-01, -3.5787e-02,  1.5527e-01, -4.3197e-01, -1.1882e-02,\n","          1.1518e-03,  1.3301e-01, -1.3234e-01,  2.6846e-01, -2.2130e-01,\n","         -1.0991e-01, -1.6941e-01,  2.1055e-01,  1.0744e-02, -1.3735e-01,\n","          1.1893e-01,  1.7798e-02,  3.6847e-02,  1.4308e-01, -2.6724e-01,\n","         -2.3095e-02, -2.3933e-01,  4.8161e-02, -3.9381e-02,  2.6412e-01,\n","          2.0335e-03, -1.4245e-02, -2.3611e-01,  2.4617e-01, -1.2672e-01,\n","          5.0979e-03,  1.0123e-01, -2.7358e-01, -1.1693e-01,  4.1555e-02,\n","         -2.7071e-01, -1.5432e-01,  5.8115e-01, -2.1575e-01, -7.2813e-02,\n","          7.5886e-03, -3.6905e-02,  6.6831e-02,  7.0179e-02,  2.0014e-01,\n","         -4.7344e-02, -6.4294e-02, -4.0000e-01,  7.8768e-02,  7.2465e-02,\n","         -2.6485e-01,  4.1316e-02,  1.0881e-01,  2.7210e-01,  1.6744e-01,\n","         -7.0022e-02,  2.9688e-01,  4.7160e-02, -4.7783e-02, -1.1584e-01,\n","         -6.6341e-01, -2.9759e-02,  2.5941e-01,  1.4036e-01],\n","        [ 2.3800e-01, -1.5318e-01,  2.6299e-01, -2.0758e-01, -1.9453e-03,\n","          2.7101e-01,  1.4292e-01, -4.5554e-01, -1.4688e-01, -3.5094e-01,\n","          2.0961e-01,  2.3468e-01, -1.0613e-01, -2.0221e-01, -2.3545e-01,\n","          1.5797e-01, -2.1824e-01, -3.2292e-01, -2.5469e-01, -3.2845e-01,\n","         -1.0782e-01, -2.3026e-01,  2.6250e-01, -1.5076e-01,  3.3046e-01,\n","          1.5827e-01, -1.2750e-01, -2.7852e-01,  2.5236e-02, -1.3169e-01,\n","          1.8342e-01,  1.2737e-01, -1.9910e-01,  9.2395e-02,  1.4016e-01,\n","          2.9001e-01,  1.1453e-01,  1.7253e-01, -4.5600e-02,  5.9137e-03,\n","          8.4622e-02, -3.3749e-01,  1.7828e-01, -7.1754e-02,  1.2968e-01,\n","          3.2643e-01,  2.2997e-01,  2.3997e-01,  1.6328e-01,  9.3666e-02,\n","         -2.6302e-01, -1.0412e-01,  1.6436e-01,  6.1016e-02,  1.6330e-01,\n","          4.3043e-02, -7.1146e-03,  2.2756e-01,  1.2085e-01,  9.0177e-02,\n","          1.8216e-01, -1.1225e-01, -2.2167e-01, -1.1596e-01],\n","        [-1.3216e-01, -1.0536e-02, -4.4064e-02,  5.1631e-02, -2.7826e-01,\n","         -1.9807e-01, -2.4242e-01, -7.1448e-02,  4.0477e-01,  1.4893e-01,\n","         -6.0161e-02,  5.6575e-02, -1.7166e-01, -3.3331e-02, -3.2660e-02,\n","         -2.5098e-01,  5.6007e-02,  5.3719e-01,  8.0455e-02, -2.1405e-01,\n","         -2.0154e-01,  4.1181e-02, -1.0843e-01, -1.6953e-01,  2.3170e-01,\n","         -3.1035e-02,  2.0299e-01, -7.9700e-02,  1.3231e-01,  6.4549e-02,\n","         -1.5605e-01, -1.0725e-01, -1.2074e-01, -1.6519e-01,  2.8294e-02,\n","          5.5149e-02,  8.1195e-02, -4.9663e-02,  1.8197e-02,  2.0371e-01,\n","         -1.4122e-01,  3.3642e-01, -4.9241e-02,  1.7357e-01,  1.0016e-01,\n","          6.2691e-03,  3.3311e-02, -9.6127e-03,  6.1170e-02,  1.1128e-01,\n","         -1.2564e-01,  8.6185e-02, -1.3428e-01, -1.2256e-01, -3.9080e-02,\n","          1.5844e-01,  4.6239e-01, -1.6234e-01,  1.3446e-01, -1.7469e-01,\n","          1.9572e-02,  8.7269e-03, -2.8085e-02,  3.9588e-01],\n","        [ 7.2364e-02, -7.9613e-03,  3.8798e-02,  9.3689e-02,  1.7367e-01,\n","         -7.4921e-02,  1.6460e-01, -1.9411e-01, -2.8017e-01,  3.7644e-01,\n","          1.0815e-01, -3.0740e-01,  2.7189e-01, -1.4843e-01, -7.2650e-02,\n","         -2.6491e-02, -1.8703e-01,  6.1051e-02, -2.2305e-01, -1.1350e-01,\n","          1.6093e-01,  1.3710e-01, -1.0988e-01,  2.3027e-01, -7.1552e-02,\n","         -1.6504e-01,  1.2068e-01, -3.8618e-02, -4.6633e-03,  1.0804e-02,\n","         -2.2275e-02,  9.3581e-02,  1.1431e-01,  3.5091e-01, -1.8273e-01,\n","         -1.0112e-01,  1.3931e-01,  8.2027e-02, -1.9914e-01, -8.7876e-03,\n","          1.5412e-01,  1.1592e-01, -1.9356e-01, -1.8761e-01, -7.2461e-02,\n","         -1.4155e-01, -2.5574e-01,  1.9370e-01,  1.4652e-02, -2.5305e-02,\n","          6.7868e-02,  1.2630e-01,  1.2303e-01, -1.5569e-01, -9.4138e-03,\n","         -2.4025e-01,  1.6667e-01, -1.4582e-01, -1.3141e-01,  1.5720e-01,\n","          2.0794e-02,  1.1820e-01,  4.8094e-03, -6.4629e-02],\n","        [-1.6050e-02,  2.4964e-01, -1.9314e-01,  1.5276e-01,  1.4907e-01,\n","         -1.8029e-01, -3.4905e-02,  1.3144e-01,  1.9405e-01,  4.8503e-01,\n","          8.0785e-02,  1.2556e-02, -2.8960e-01, -1.0557e-01, -1.0017e-01,\n","          7.6938e-02,  2.6695e-01, -1.2016e-02,  6.2367e-02, -6.4842e-02,\n","          7.5864e-03,  2.4133e-01, -5.5028e-02,  3.5044e-01, -2.5836e-02,\n","         -2.4152e-01, -1.2723e-01, -1.3349e-02,  1.3899e-01,  1.4648e-01,\n","          1.4640e-01,  1.6189e-01, -2.4546e-01,  1.0764e-01, -5.2811e-01,\n","         -8.9853e-03,  1.1926e-01, -5.8030e-01,  1.0420e-01, -1.9863e-01,\n","         -1.6014e-01,  6.0095e-02,  2.2367e-01, -1.3916e-01,  2.5295e-01,\n","          4.3943e-02, -6.2514e-02,  6.2648e-02, -6.3408e-02, -1.0169e-01,\n","         -4.0878e-01,  8.3009e-02,  2.3568e-01,  1.5782e-01, -6.6339e-02,\n","         -1.4552e-01,  1.9924e-01, -5.1823e-02, -2.3092e-01,  1.5730e-01,\n","          8.4872e-02, -6.5332e-02,  7.5058e-02,  1.7449e-01],\n","        [ 3.0531e-02,  8.7519e-02,  1.9080e-01,  5.3606e-01,  1.3917e-02,\n","         -1.4735e-01, -4.4103e-02, -3.7012e-02, -2.1161e-01, -7.3564e-02,\n","          1.0861e-01, -1.6523e-01, -1.1388e-01,  3.1773e-01,  1.0625e-01,\n","          5.3230e-02, -9.6852e-02, -2.3517e-01,  6.5025e-02,  3.6099e-02,\n","         -1.3305e-01, -6.3332e-02,  2.4605e-01, -4.1738e-02, -3.2873e-02,\n","          1.5844e-01,  1.3091e-01, -1.5021e-01,  8.5736e-02, -1.7654e-02,\n","         -1.6780e-01, -1.1544e-01, -1.1826e-01,  2.1930e-01,  1.3029e-01,\n","         -9.8581e-02,  3.4975e-02, -7.6634e-02,  1.1379e-01, -2.0794e-01,\n","          8.3357e-02,  8.8677e-02, -1.9582e-01, -1.3475e-01, -4.8995e-03,\n","          1.6952e-01, -1.0061e-02, -9.8593e-02, -1.5106e-01,  4.6955e-02,\n","         -1.6989e-02,  3.7248e-02, -8.8682e-02, -1.3782e-01,  4.3588e-02,\n","          2.7716e-02,  2.4254e-01,  1.2491e-01, -1.0780e-01, -4.6196e-02,\n","         -9.2368e-02,  1.7073e-01, -1.8006e-02, -9.8957e-02],\n","        [-6.1592e-02, -1.6367e-02,  1.4458e-01,  4.0924e-01,  3.8165e-02,\n","          9.9491e-02, -6.1939e-02,  3.2140e-01, -9.8379e-02,  2.7988e-01,\n","         -4.8016e-02,  8.1785e-02,  2.6063e-01,  1.2838e-01,  1.4901e-01,\n","         -4.9778e-02, -2.4597e-01,  7.0521e-02,  2.4314e-02, -2.1428e-01,\n","         -5.2159e-02,  1.9166e-01, -1.5807e-01, -1.1154e-01, -4.9180e-02,\n","         -4.5430e-02,  4.2110e-02,  8.5953e-02, -9.1021e-02,  1.6027e-01,\n","         -2.1604e-01,  1.4127e-01,  2.8717e-01, -2.0348e-01,  1.9828e-01,\n","         -9.8317e-02,  3.9058e-02, -3.9110e-01,  1.1897e-01, -7.7291e-02,\n","          1.7082e-01,  7.2201e-02,  2.5064e-01,  1.4083e-02,  6.1694e-02,\n","         -2.4499e-01, -1.9485e-01, -1.1492e-01,  2.7960e-03,  1.3363e-01,\n","          2.4018e-02, -2.3067e-01, -1.4330e-01, -4.3060e-01,  1.0450e-01,\n","         -9.5372e-02, -4.7957e-01, -2.8213e-01, -1.1129e-01, -3.4135e-03,\n","         -1.8323e-01,  1.5768e-02, -5.4081e-03,  2.0454e-01]], device='cuda:0',\n","       requires_grad=True)\n","blocks.11.attn.b_O: torch.Size([768])\n","Parameter containing:\n","tensor([ 4.4348e-03, -1.7544e-01, -2.9991e-01,  2.5262e-01,  3.9322e-01,\n","         7.6725e-02,  1.9360e-01,  1.2498e-01,  9.3535e-02,  8.4031e-02,\n","        -1.4863e-01,  6.5660e-02, -6.1264e-02, -1.3683e-02, -1.6177e-01,\n","         2.0264e-01, -7.4903e-02, -2.3057e-02,  4.8332e-01, -2.7169e-01,\n","         4.7717e-02, -2.0618e-01,  1.5867e-01, -3.5259e-02, -1.2451e-01,\n","        -1.5126e-01,  5.2641e-02,  1.9861e-01, -3.5941e-02,  1.8159e-01,\n","         6.3162e-02,  3.6674e-02,  1.0996e-01, -7.8093e-02, -1.7590e-01,\n","        -3.7443e-01,  2.8727e+00,  1.3430e-01,  1.7342e-01,  7.8760e-02,\n","        -1.2869e-01,  1.1872e-01,  2.0689e-01, -6.0169e-02, -2.0553e-01,\n","         1.7748e-03, -1.0017e-01, -9.6445e-02,  7.0061e-02,  1.9676e-01,\n","         2.0602e-01,  9.7302e-02, -1.2906e-01, -8.5798e-03,  6.2775e-02,\n","         2.2000e-01,  2.8550e-01, -1.4074e-01, -8.7610e-03,  2.2988e-01,\n","        -7.7560e-02,  2.9979e-01,  1.7073e-01,  1.4456e-01, -2.2162e+01,\n","        -1.6596e-01, -9.5361e-02,  1.0405e-01, -1.5062e-01,  1.4606e-01,\n","         2.3618e-01, -4.7923e-02, -2.2737e-01, -1.8901e-01, -1.1245e-02,\n","        -2.4316e-01,  2.5162e-01, -1.2548e-01,  5.1262e-03, -3.0293e-01,\n","        -2.1075e-01,  8.6904e-02,  2.0252e-01, -4.2383e-02, -3.6831e-01,\n","         9.4521e-03,  1.0527e-01, -2.3692e+01,  1.9185e-01, -5.2198e-02,\n","         7.0560e-02,  1.0676e-01, -5.5122e-02,  2.0729e-01, -6.0306e-02,\n","        -2.9235e-01,  5.9533e-01, -4.3656e-02, -1.2651e-01, -3.6622e-01,\n","         4.3192e-01,  2.5396e-02,  1.4642e-01,  1.5921e-01,  3.6419e-02,\n","         1.0986e-01,  3.4189e-02,  3.2631e-01,  2.7952e-02, -2.8402e-02,\n","         5.4201e-02,  4.3547e-02, -1.1434e-01, -6.3809e-02,  1.7533e-02,\n","         2.4055e-02, -1.3439e-01,  9.7305e-02, -1.2487e-01,  5.2715e-02,\n","        -2.3861e-02,  1.0448e-01,  2.8746e-01,  1.2040e-01,  4.1650e-01,\n","        -2.2425e-01,  5.5227e-02, -7.2814e-02, -2.8969e-01, -1.7415e-03,\n","        -2.6533e-01, -5.5982e-02,  5.6033e-03,  1.0659e-01,  3.3216e-01,\n","         2.1810e-02, -1.6790e-01, -7.3510e-02, -8.3883e+00, -4.4293e-02,\n","         3.1815e-01,  1.9613e-01, -5.8058e-02, -9.2110e-02, -9.2664e-02,\n","         3.7710e-01,  8.8418e-02,  2.0008e-01,  2.2693e-01, -7.2735e-02,\n","        -1.8209e-01,  1.7667e-01, -9.3755e-02,  1.7865e-01,  2.4700e-01,\n","        -6.3880e-02,  1.4776e-01, -2.3271e-01,  2.8461e-01,  1.3435e-01,\n","         2.4291e-01, -1.1523e-01,  1.0476e-01,  9.6353e-02,  1.7449e-01,\n","        -1.6407e-01, -4.7022e-02, -2.1637e-01, -4.3086e-01, -2.6947e-01,\n","         7.4766e-02,  2.2488e-02, -1.6748e-01,  5.7374e-03, -1.6533e-01,\n","         7.8959e-02, -1.1827e-01,  5.0204e-02,  1.7892e-01, -7.4476e-02,\n","        -2.4048e-01,  1.2588e-03, -3.0854e-02, -9.7965e-02, -1.6569e-01,\n","         2.4566e-01,  2.1689e-01, -3.4542e-03, -7.2940e-02,  1.8787e-02,\n","        -3.3737e-02, -9.4419e-02, -1.6105e-01,  1.7094e-01, -1.9307e-01,\n","        -3.2710e-01, -1.1712e-01, -2.4487e-01, -3.2459e-01, -8.5374e-02,\n","        -1.3373e-01,  6.1395e-02,  2.6882e-02,  4.1877e-02, -1.0463e-01,\n","        -1.2884e-02, -3.4108e-01,  6.0364e-02, -3.2932e-01,  1.9583e-02,\n","         1.1835e-01, -2.2206e-01, -1.7704e-01, -2.3444e-01, -5.3057e-01,\n","        -3.0122e-01, -5.1256e-02,  4.9393e-02, -2.0114e-01,  5.6651e-02,\n","         8.8214e-02,  7.1941e-02, -1.2550e-01,  5.7015e-02,  1.7033e-01,\n","         6.4099e-02,  2.9414e-01,  7.8616e-03, -1.0477e-01,  5.3239e-02,\n","        -2.2047e-01, -1.5334e-01,  2.1388e-01,  1.3150e-01,  7.9372e-03,\n","        -1.8930e-01,  4.9840e-02, -2.0512e-02, -1.9923e-02,  1.6225e-02,\n","        -3.6772e-02, -2.0433e-01, -7.3289e-02, -4.2087e-01, -2.1773e-01,\n","         8.4921e-02, -6.6003e-03, -1.2538e-01,  7.1527e-02,  7.6150e-02,\n","        -8.9501e-02, -8.2834e-02,  3.4875e-02,  1.4602e-01,  7.5062e-02,\n","         2.8337e-01, -6.3842e-02,  6.1896e-02,  3.2534e-01,  2.5178e-02,\n","         1.9070e-01,  7.5920e-02, -9.5689e-02,  2.4747e-02, -1.8087e-01,\n","         1.0735e-01, -2.1778e+01,  7.1400e-02,  9.8725e-02,  1.7137e-02,\n","         6.9341e-02,  1.1880e-01, -1.0403e-01,  3.1165e-01,  1.2038e-01,\n","         5.3144e-02,  4.3898e-02, -6.4743e-02, -4.0078e-02,  1.1493e-01,\n","         8.5067e-02,  2.4293e-02,  7.4511e-02, -1.0754e-01,  4.5427e-01,\n","         2.0140e-02, -4.0640e-02, -1.5770e-01,  1.0881e-01, -3.9901e-01,\n","        -6.6145e-02, -8.0251e-02, -1.2294e-01,  3.1588e-04,  3.4096e-02,\n","        -2.7208e-01, -5.5382e-02,  1.6729e-01,  4.7950e-02,  6.0704e-02,\n","         1.7919e-01, -2.4203e-01,  2.9589e-01, -1.4490e-01, -6.5785e-02,\n","        -1.9279e-01,  5.1668e-02,  1.5040e-01,  9.9130e-02, -9.8867e-02,\n","        -2.6161e-01, -3.4074e-01,  1.1328e-01,  3.7466e-02, -2.4579e-01,\n","        -7.0026e-03,  1.8685e-01, -1.3440e-01,  1.4098e-02,  2.9330e-01,\n","        -8.0389e-02, -5.2717e-02, -1.0645e-02, -2.6571e-01, -2.2775e-02,\n","         1.5450e-01,  2.9823e-01, -1.8683e-04,  1.5452e-01, -1.8892e-01,\n","         4.7775e-02,  2.5287e-01,  2.4208e-01, -2.1286e-02,  1.2904e-01,\n","        -2.7451e-01, -1.7871e-02, -9.5075e-02,  4.3503e-02,  9.8246e-02,\n","         6.9282e-02, -1.8301e-01,  9.0498e-02, -7.3825e-02,  1.1905e-01,\n","         1.7603e-01,  2.0709e-01, -1.1219e-01,  7.1145e-02,  2.1826e-02,\n","        -7.9057e-02,  4.1447e-02, -4.3550e-02, -1.9604e-02,  8.8787e-02,\n","         1.4321e-01, -1.1236e-01,  1.9294e-02, -1.1078e-01,  1.2460e-01,\n","         4.6088e-03, -7.2361e-02,  3.0902e-02, -6.9321e-02,  1.3985e-01,\n","        -5.0337e-01,  1.6321e-01,  1.3015e-01, -2.1935e-01,  2.1307e-01,\n","         1.7647e-03,  2.6987e-01, -1.0014e-01, -1.0797e+01, -1.8720e-01,\n","         9.2882e-03,  1.0535e-01,  5.6753e-02,  4.8629e-02,  2.9233e-01,\n","         7.2925e-02,  3.6509e-01, -1.9723e-01, -1.7298e-01,  3.1588e-02,\n","         4.5984e-01, -1.3370e-01, -2.1951e-01,  1.0637e-01, -5.7247e-01,\n","         8.2915e-02, -7.2365e-03,  2.6129e-01,  2.4579e-01, -1.7548e-01,\n","        -2.8275e-02, -8.6505e-02, -1.6479e-01,  1.2256e-01,  1.9862e-01,\n","         1.0119e-01,  3.1948e-01,  1.5037e-01,  1.4195e-01, -1.3542e-01,\n","         1.6471e-01,  2.0499e-02, -2.5437e-02,  2.2743e-01, -5.7386e-02,\n","        -2.8401e-01,  3.8424e-02,  3.8753e-02, -1.0407e-01,  3.1034e-03,\n","        -9.7348e-03,  2.2402e-02,  1.4373e-01, -1.5355e-01,  2.8223e-02,\n","        -1.2913e-01, -5.9315e-02, -2.1921e-01,  2.5038e-01,  4.1034e-02,\n","        -1.0517e-01, -1.5201e-01,  9.9128e-02, -2.2406e-01,  6.4655e-02,\n","         2.4837e+00, -3.3361e-01, -1.1039e-02, -1.2035e-01,  5.5085e-02,\n","         1.9761e-01, -1.3463e-01,  1.1871e-01,  1.7185e-01,  2.8630e-01,\n","         1.9292e-01, -4.7902e-02, -2.8671e-02, -2.1929e-01, -1.1782e-01,\n","         7.4289e-02, -2.2223e-02, -2.9747e+01, -1.7877e-01,  7.7040e-02,\n","        -6.0420e-02,  1.8646e-01,  6.0591e-02,  3.8517e-01,  1.8663e-01,\n","         3.4279e-01, -8.5412e-02,  1.8593e-01,  2.5248e-01, -3.1592e-01,\n","         7.1890e-02,  1.8161e-01,  5.9934e-02,  1.2122e-01, -4.1091e-01,\n","        -4.1755e-01,  9.1367e-02, -7.9606e-02, -1.5522e-01,  8.4895e-02,\n","        -2.7228e-01,  1.2048e-01, -1.5083e-03, -5.4313e-02,  5.9146e-02,\n","        -1.5712e-02,  1.9163e-01, -1.9856e-01, -8.6185e-02, -1.7978e-01,\n","        -2.2674e+01,  9.4186e+00,  1.5178e-02, -1.3586e-01, -6.3684e-02,\n","         2.7440e-01,  8.0252e-03, -4.3263e-02,  2.7800e-01, -3.3639e-02,\n","        -6.6075e-03, -7.3711e-02, -8.3195e-02,  1.0930e-02, -1.1563e-01,\n","         5.0784e-02,  1.1486e+01, -4.7667e-01,  1.5498e-01,  4.4303e-02,\n","         1.7757e-01, -1.8334e-02,  4.3352e-03, -5.2439e-01,  2.0015e-02,\n","        -1.9396e-01,  2.8807e-01,  1.8517e-01, -2.4223e-02,  3.0410e-02,\n","        -9.9194e-03, -2.9439e-01,  2.5950e-01,  3.7761e-02, -2.2989e-01,\n","        -5.9232e-02,  1.6292e-01,  6.7799e-02,  7.1130e-03,  4.3518e-02,\n","         1.5259e-01, -2.5969e-01,  1.0917e-01,  2.6665e-01,  1.7902e-02,\n","        -8.7034e-02, -6.6324e-01, -1.9188e-01,  7.9544e-02,  2.6789e-01,\n","         2.3983e-01, -2.6983e-02,  2.8129e-02,  7.1441e-02, -9.0379e-02,\n","        -8.9534e-02,  1.3097e-01,  4.3820e-03, -1.5707e-02, -2.1133e-01,\n","        -9.0938e-02,  7.5358e-02, -1.5564e-01, -2.5991e-01, -2.1163e-01,\n","        -6.4121e-02, -1.1927e-01, -2.6902e-02, -1.7708e-01, -1.6432e-01,\n","        -1.1734e-02,  8.3659e-02,  1.3377e-01, -1.2113e-01, -1.4255e-01,\n","        -1.4210e-01, -1.5675e-01,  1.4667e-01,  5.7180e-02, -2.6278e-01,\n","         2.6203e-02,  1.6265e-01,  1.1816e-01,  4.9487e-02,  9.9286e-02,\n","         1.9114e-01,  5.7199e-02, -4.2850e-01, -1.6217e-01,  8.1834e-02,\n","        -3.6468e-01, -1.6804e-01,  5.7756e-02, -2.5100e-01,  4.7479e-03,\n","        -9.6203e-02,  2.2407e-02,  1.3188e-01, -4.4792e-02,  4.2974e-02,\n","         3.7945e-01, -8.7370e-02, -4.4871e-02, -7.6464e-02,  7.7920e-02,\n","         2.3694e-01, -5.2171e-02,  1.9564e-02,  1.2920e-01,  1.4004e-01,\n","         1.5444e-01, -1.2711e-01,  3.1437e-01,  3.2328e-02,  1.1835e-01,\n","        -1.2052e-01, -1.3028e-01, -6.6265e-02, -2.7133e-03, -8.8563e-02,\n","        -2.6670e-01,  1.1904e-01, -1.5362e-01,  7.5020e-02, -6.8980e-02,\n","         3.5233e-01,  9.6533e-02, -4.9981e-02,  2.5297e-01,  2.3220e-01,\n","         6.8587e-02,  6.3495e-02, -2.2765e-01, -3.2295e-01, -1.7631e-01,\n","        -1.3520e-02,  1.2865e-01, -3.1404e-01, -3.4256e-02, -1.2522e-01,\n","        -4.3493e-01,  2.0294e-04,  1.3479e-01,  2.2648e-01, -8.0236e-02,\n","        -2.3081e-01, -1.1985e-01, -3.8702e-01,  2.3142e-01, -1.6629e-01,\n","        -1.8886e-02,  7.1811e-03,  6.3247e-02, -1.1719e-01,  1.8675e-01,\n","        -8.8768e-02, -1.1097e-01,  1.4269e-01, -4.0505e-02,  7.1935e-03,\n","         4.3456e-01,  1.8704e-01,  1.2998e-01, -2.5888e-01, -1.8889e-02,\n","        -9.6691e-02, -6.0281e-02,  1.2720e-01,  1.0895e-01, -1.4920e-01,\n","         1.5245e-01, -5.3598e-02,  1.7420e-01, -2.6338e-03,  5.9700e-02,\n","         1.7295e-01, -1.6809e-01, -3.0359e-02, -1.1979e-03,  3.1663e-01,\n","        -2.3863e-01, -8.2014e-02,  1.7486e-01, -1.3282e-01,  7.7157e-02,\n","         1.8438e-01, -3.0946e-02, -4.5993e-01, -2.6251e-01,  6.7444e-02,\n","         1.2525e-01, -1.6026e-01, -3.4740e-01,  1.3921e-01,  5.0597e-01,\n","         3.2286e-01, -1.2224e-01, -1.3558e-01,  6.6035e-02,  3.0056e-01,\n","        -1.3205e-01,  1.8924e-01,  8.4467e-02,  7.4175e-02, -3.0164e-01,\n","        -1.8642e-01,  1.0354e-01, -2.4960e-02,  1.7434e-01, -7.1759e-02,\n","        -2.3985e-01, -2.0917e-02, -1.4981e-01,  1.4006e-01, -1.9168e-01,\n","         2.6423e-01,  2.1803e-01,  1.2022e-01, -6.2412e-02,  1.2369e-01,\n","         8.4703e-02, -2.4296e-02, -1.0209e-01, -2.1797e-01, -8.2528e-02,\n","         1.3025e-01, -4.4362e-02,  1.7131e-01,  4.6962e-02,  3.8852e-02,\n","         1.7999e-01, -2.7564e-01, -1.8111e-01, -1.7206e-01, -1.4948e-01,\n","        -4.5911e-03, -5.1638e-02, -1.2205e-01,  6.3409e-02,  1.4814e-01,\n","         2.0000e-01,  1.2416e-01,  7.0638e-02,  8.8842e-02,  2.6086e-01,\n","         4.7354e-02,  7.1652e-02,  1.1915e-01,  7.6032e-02, -2.4815e-01,\n","        -3.3883e-02, -8.4975e-02, -1.8563e-01, -9.1577e-02,  1.1296e-01,\n","         6.9408e-02, -1.7945e-01, -9.7085e-02,  1.2425e-01, -1.7667e-01,\n","        -3.6145e-02,  1.7586e-01,  2.4824e-01, -6.8738e-03,  1.8545e-01,\n","        -3.2811e-01, -1.8163e-01,  1.0374e-01,  1.0976e-01,  2.3965e-02,\n","         9.4981e-02, -1.8337e-01,  8.3344e-02, -7.1032e-02,  5.9342e-02,\n","         6.6378e-03,  3.7421e-02,  3.3461e-02, -2.4677e-01, -2.9656e-03,\n","        -2.6877e-01,  4.3241e-02,  2.6029e-01,  9.4354e-02, -2.0040e-01,\n","         6.2573e-02,  1.6689e-01, -2.5017e-01], device='cuda:0',\n","       requires_grad=True)\n","blocks.11.attn.W_K: torch.Size([12, 768, 64])\n","Parameter containing:\n","tensor([[[ 0.0646, -0.3208,  0.2530,  ..., -0.0380, -0.0528,  0.0005],\n","         [-0.0126,  0.0477, -0.0613,  ...,  0.1235,  0.0564,  0.0877],\n","         [-0.0651,  0.0150, -0.0684,  ...,  0.0164, -0.1333,  0.1203],\n","         ...,\n","         [ 0.0506, -0.1385,  0.0351,  ..., -0.0656,  0.0689, -0.0538],\n","         [-0.0466,  0.0222, -0.0966,  ...,  0.0858, -0.2067, -0.1019],\n","         [ 0.1207,  0.2176,  0.0388,  ...,  0.0236, -0.0248, -0.0546]],\n","\n","        [[ 0.0876,  0.2437, -0.0340,  ..., -0.0538, -0.0564,  0.0494],\n","         [-0.0315, -0.0484, -0.0068,  ..., -0.0904, -0.0904, -0.0192],\n","         [ 0.1344,  0.2050, -0.1296,  ...,  0.0105, -0.0514,  0.0159],\n","         ...,\n","         [ 0.0472, -0.0580,  0.0006,  ..., -0.1309, -0.1495, -0.0877],\n","         [ 0.2119,  0.0657,  0.0647,  ..., -0.0871, -0.1653,  0.0425],\n","         [-0.1578,  0.0690,  0.0042,  ..., -0.0554, -0.0337, -0.0556]],\n","\n","        [[ 0.1248,  0.1355,  0.0339,  ..., -0.0462,  0.1083,  0.0322],\n","         [-0.0214, -0.1511,  0.2229,  ..., -0.1348,  0.2057, -0.0556],\n","         [-0.0050,  0.1462,  0.0374,  ...,  0.0300, -0.0197, -0.0779],\n","         ...,\n","         [ 0.0326,  0.0259, -0.0515,  ..., -0.0697,  0.1399,  0.1228],\n","         [ 0.0040, -0.1037,  0.0931,  ..., -0.0089, -0.2269, -0.1254],\n","         [-0.0638, -0.0499, -0.0784,  ...,  0.1343,  0.1497, -0.0484]],\n","\n","        ...,\n","\n","        [[-0.0240, -0.1042,  0.0346,  ...,  0.1247,  0.0510,  0.1104],\n","         [-0.1091,  0.0146, -0.0926,  ...,  0.2956,  0.0264, -0.2024],\n","         [ 0.0987,  0.0008, -0.0265,  ...,  0.1666, -0.0092, -0.0005],\n","         ...,\n","         [-0.0424,  0.0637,  0.0510,  ...,  0.0744, -0.0360, -0.0442],\n","         [-0.0919,  0.1274,  0.0927,  ...,  0.0992, -0.1206, -0.0988],\n","         [ 0.1649, -0.0227, -0.0594,  ...,  0.0164, -0.1395, -0.0190]],\n","\n","        [[-0.1545,  0.1338, -0.0787,  ..., -0.3306, -0.1673,  0.0234],\n","         [ 0.1003,  0.0406, -0.0339,  ..., -0.0108,  0.0475,  0.1075],\n","         [-0.0586, -0.0829, -0.1484,  ..., -0.0082, -0.0557, -0.0513],\n","         ...,\n","         [ 0.0289,  0.0905, -0.0049,  ..., -0.0652,  0.1651, -0.0604],\n","         [ 0.1852, -0.0633, -0.1053,  ..., -0.0289, -0.1641,  0.0616],\n","         [-0.0458,  0.1981, -0.1255,  ...,  0.0464, -0.2241,  0.0621]],\n","\n","        [[ 0.0079,  0.1676, -0.1486,  ..., -0.0187,  0.0225,  0.2313],\n","         [ 0.1002,  0.2535, -0.1204,  ..., -0.1808, -0.0107, -0.0907],\n","         [-0.0293,  0.0182, -0.1165,  ...,  0.0142, -0.1057,  0.1622],\n","         ...,\n","         [ 0.0518, -0.1147, -0.0888,  ...,  0.1206,  0.0300, -0.0229],\n","         [ 0.0100, -0.2300,  0.0940,  ..., -0.0233,  0.0305,  0.1952],\n","         [ 0.2179, -0.0017,  0.1560,  ..., -0.0836,  0.1493,  0.0920]]],\n","       device='cuda:0', requires_grad=True)\n","blocks.11.attn.W_V: torch.Size([12, 768, 64])\n","Parameter containing:\n","tensor([[[ 0.0967,  0.0217, -0.0475,  ..., -0.3533,  0.0375,  0.0337],\n","         [ 0.0723,  0.0807, -0.0477,  ..., -0.2299,  0.1371, -0.1578],\n","         [-0.0045, -0.0821,  0.1756,  ...,  0.0991,  0.1393,  0.0315],\n","         ...,\n","         [ 0.1628,  0.1085,  0.0325,  ...,  0.2540,  0.1668, -0.1200],\n","         [ 0.1399,  0.0197,  0.1489,  ...,  0.0664, -0.1860, -0.1727],\n","         [-0.2721, -0.1636, -0.2588,  ...,  0.1679, -0.0543, -0.1097]],\n","\n","        [[ 0.0802, -0.2423,  0.1068,  ..., -0.1324, -0.0921,  0.3835],\n","         [-0.0541, -0.1404, -0.0522,  ..., -0.0394, -0.3268, -0.1586],\n","         [ 0.0583,  0.2718, -0.0800,  ..., -0.1317, -0.0308, -0.3744],\n","         ...,\n","         [-0.1053, -0.1341,  0.1736,  ..., -0.0229, -0.3375,  0.1746],\n","         [-0.1272,  0.2208,  0.0223,  ...,  0.2228, -0.0831, -0.1259],\n","         [-0.1829, -0.0685, -0.1784,  ...,  0.3647,  0.0424, -0.4536]],\n","\n","        [[ 0.2690,  0.1527,  0.2379,  ...,  0.3040,  0.0463, -0.5385],\n","         [-0.0025, -0.0694,  0.0777,  ...,  0.0696,  0.0469,  0.0572],\n","         [ 0.1759,  0.0475,  0.0931,  ...,  0.0260,  0.0124, -0.1372],\n","         ...,\n","         [ 0.4181,  0.1854,  0.1611,  ..., -0.1253, -0.2926, -0.1479],\n","         [ 0.0508,  0.0774,  0.2403,  ..., -0.1157,  0.0935, -0.0632],\n","         [ 0.3333, -0.2066,  0.1295,  ..., -0.1170,  0.1219, -0.2901]],\n","\n","        ...,\n","\n","        [[-0.0282, -0.1285, -0.0501,  ...,  0.2180, -0.0367,  0.0564],\n","         [-0.3703, -0.1846,  0.0735,  ..., -0.1029, -0.0261, -0.0688],\n","         [-0.0967,  0.1445,  0.0170,  ...,  0.2523, -0.0606, -0.1392],\n","         ...,\n","         [ 0.0874,  0.0997, -0.0520,  ..., -0.0066, -0.0015, -0.0627],\n","         [ 0.2008, -0.1383,  0.0674,  ...,  0.1288, -0.0311, -0.2407],\n","         [-0.0267, -0.1436, -0.0392,  ..., -0.1328, -0.0836, -0.1224]],\n","\n","        [[-0.2531,  0.0788,  0.1198,  ..., -0.1444, -0.2019, -0.0206],\n","         [ 0.0852, -0.2279, -0.0993,  ...,  0.0921, -0.0451,  0.0106],\n","         [ 0.1777, -0.1541,  0.0306,  ..., -0.2027, -0.2207, -0.1956],\n","         ...,\n","         [-0.0413,  0.1215,  0.0064,  ...,  0.0178,  0.1008,  0.0343],\n","         [-0.0835, -0.0903,  0.0487,  ..., -0.0517, -0.1370,  0.1341],\n","         [ 0.0114, -0.2734, -0.2412,  ..., -0.1769, -0.0473, -0.0507]],\n","\n","        [[ 0.0588,  0.0198, -0.1870,  ...,  0.0919, -0.0784,  0.1461],\n","         [-0.3041, -0.0601, -0.2403,  ...,  0.1707, -0.1905, -0.3118],\n","         [-0.1910,  0.0432,  0.1344,  ...,  0.0021,  0.0143, -0.0613],\n","         ...,\n","         [ 0.2873,  0.0831, -0.4019,  ..., -0.1272,  0.1580, -0.0218],\n","         [ 0.0895, -0.0753,  0.2265,  ...,  0.0663,  0.3218,  0.0276],\n","         [-0.0740,  0.0698, -0.2318,  ...,  0.2647, -0.2513,  0.2650]]],\n","       device='cuda:0', requires_grad=True)\n","blocks.11.attn.b_K: torch.Size([12, 64])\n","Parameter containing:\n","tensor([[-3.4925e-02, -4.1395e-03, -5.1969e-02,  7.7581e-02, -9.8920e-02,\n","         -1.2892e-02, -8.4305e-02, -4.6174e-03, -4.9880e-02, -1.0015e-01,\n","         -3.8740e-02,  2.1259e-02,  1.6375e-02,  4.3721e-02,  7.7685e-02,\n","          1.6059e-01,  2.7598e-02, -7.8016e-02, -1.3344e-02,  7.0039e-02,\n","          6.9915e-02,  5.7902e-02, -1.1289e-02, -1.0574e-01, -3.6966e-02,\n","          3.3819e-02,  1.4668e-02, -4.7252e-02,  2.3821e-02,  5.4891e-02,\n","         -1.3334e-01,  4.7001e-03, -6.2327e-02, -3.8913e-02,  1.3126e-01,\n","          4.0423e-02, -1.0719e-01,  1.0132e-01,  3.2857e-02, -1.4819e-01,\n","          9.6694e-02,  6.0750e-02, -2.1170e-02, -5.1410e-03,  1.7762e-02,\n","          1.1751e-01,  6.7158e-02, -3.5233e-02, -9.2910e-02,  8.4722e-02,\n","         -9.4118e-02,  1.0166e-01, -3.2279e-02, -3.1577e-03,  5.1616e-02,\n","         -7.9856e-02, -3.5533e-02, -6.6280e-02,  7.9188e-02,  7.9776e-02,\n","         -2.6249e-02, -8.3371e-02, -2.9392e-02, -6.2771e-02],\n","        [ 4.1662e-02, -2.3767e-02,  6.6742e-02, -1.7644e-01,  3.7550e-02,\n","          1.1406e-01, -1.3459e-02, -5.6552e-02, -1.4406e-01,  1.0482e-01,\n","          4.5532e-02,  4.6322e-02,  8.5448e-03, -6.8413e-03, -1.0149e-01,\n","          6.7071e-02,  9.5786e-03, -6.0989e-02, -2.0106e-02, -4.2580e-02,\n","          8.7213e-03,  3.2136e-02,  3.0047e-02,  1.1215e-01,  4.5283e-02,\n","          2.9363e-02,  3.0147e-04,  3.5456e-03,  2.9573e-02,  1.5493e-02,\n","         -3.9160e-02,  8.2358e-02,  2.2662e-01, -4.7609e-02,  5.1834e-02,\n","          7.4437e-02, -5.9310e-02,  3.6095e-02, -9.9223e-03,  8.1895e-02,\n","          5.5551e-02, -3.5274e-03, -7.7766e-02,  9.3446e-02, -1.4313e-02,\n","          1.0295e-03,  2.7670e-02,  9.3626e-02,  1.0739e-01,  1.0629e-01,\n","          4.2536e-02, -4.3537e-02,  1.5815e-01, -4.2580e-02,  1.5247e-02,\n","         -9.5985e-02, -9.9096e-02,  7.9324e-02,  6.4971e-02,  9.7581e-03,\n","         -2.4403e-02, -4.0549e-02,  5.9653e-02, -1.5481e-02],\n","        [-4.9410e-02,  1.7664e-01,  1.7408e-02,  6.2497e-02, -9.3811e-02,\n","         -1.2936e-01, -3.9905e-02, -2.1122e-01,  1.8562e-01,  3.1557e-02,\n","         -6.8922e-02, -1.1826e-02,  4.9326e-02,  8.4561e-02,  9.7377e-02,\n","         -2.7590e-02, -1.1597e-01,  1.6486e-01, -2.0207e-01, -1.2688e-01,\n","          1.3333e-01,  9.1933e-02, -1.2901e-02,  2.2609e-02, -1.6418e-01,\n","         -1.9133e-02,  2.8205e-02, -9.3460e-02, -6.6214e-02,  8.6968e-02,\n","          1.8006e-01, -8.6205e-02,  4.4846e-02, -4.3062e-02,  5.5162e-02,\n","         -1.6449e-01,  1.2651e-02, -1.5352e-01, -6.6139e-02, -1.9481e-02,\n","          6.0030e-02,  6.9490e-02, -4.0641e-02, -4.9425e-02,  1.7378e-01,\n","          1.0274e-01,  7.2975e-02, -4.7539e-03, -5.8316e-02, -1.3758e-01,\n","          6.0444e-02,  2.1905e-01,  7.8999e-02, -6.3168e-02, -7.9253e-02,\n","         -4.3163e-03,  1.8632e-03,  5.1318e-02, -3.4252e-02,  6.3247e-02,\n","         -5.6919e-02,  6.3963e-02, -2.3533e-04,  2.7111e-02],\n","        [ 7.5792e-02,  2.3227e-02, -4.0356e-02,  1.2134e-01, -7.9101e-02,\n","          1.0738e-01, -2.2525e-01,  9.9724e-02, -1.6872e-02,  2.5554e-02,\n","          9.1324e-02,  2.9268e-02,  6.7546e-02, -1.5475e-01, -2.9306e-03,\n","          9.3797e-02,  5.0032e-02,  2.2546e-02,  1.8022e-02, -8.4144e-02,\n","          1.7324e-02,  6.4513e-03, -3.7854e-02, -3.4679e-02,  1.3832e-02,\n","         -1.4295e-02,  9.4451e-02,  5.5391e-03, -1.9514e-01, -7.9028e-02,\n","          2.0065e-01,  8.7198e-02, -1.7770e-01, -2.8410e-02,  6.5393e-02,\n","         -4.8524e-02, -9.8321e-02,  8.2870e-02,  1.1339e-01, -1.5621e-02,\n","          4.2865e-02,  4.8597e-02, -4.6214e-02, -1.0000e-01,  1.0781e-01,\n","          2.8847e-01, -9.3621e-02,  5.3504e-02,  9.5137e-02, -5.9160e-03,\n","         -8.5916e-02,  4.1702e-03,  8.7530e-02, -1.9936e-01, -1.2991e-02,\n","          4.6327e-02,  6.5211e-02,  7.1889e-02, -5.7108e-02, -2.5433e-02,\n","         -6.3828e-02, -6.0902e-02,  4.7099e-02, -1.5022e-01],\n","        [-5.6672e-02, -9.4107e-03, -5.4009e-02,  1.3949e-02, -4.2336e-02,\n","          1.1465e-01, -8.9999e-02,  7.3034e-02,  1.2216e-01, -2.2858e-02,\n","         -9.2206e-03,  3.4581e-02, -5.0708e-02,  1.1310e-01, -1.4410e-01,\n","         -6.0948e-02,  1.7256e-02, -2.3435e-02,  4.2458e-02,  1.2687e-03,\n","         -4.8981e-02, -2.7139e-01,  4.3370e-02, -6.4444e-02, -1.7733e-02,\n","          8.2654e-02,  1.3540e-02, -8.3017e-02, -7.5613e-02, -7.5459e-02,\n","         -5.4005e-02, -1.1520e-02,  4.0892e-02, -2.7897e-02, -7.9247e-02,\n","         -1.1093e-01,  3.2260e-02,  3.0686e-02,  4.1183e-02,  1.8613e-02,\n","         -6.0664e-02, -4.8165e-02, -1.6137e-02, -2.5046e-02, -5.9002e-02,\n","         -1.4122e-01,  4.1243e-02, -7.1040e-02,  1.3355e-01, -1.1016e-02,\n","         -8.1615e-02, -7.1921e-02, -1.2787e-01, -2.1314e-02,  6.3632e-02,\n","         -1.7774e-02, -1.1798e-02, -6.5546e-02, -1.6473e-01,  1.0515e-01,\n","          6.4347e-02,  5.0814e-02,  1.8586e-02,  8.8789e-02],\n","        [ 4.2540e-03, -1.4692e-01,  2.3269e-03, -2.2064e-02,  8.0339e-02,\n","          9.5447e-02,  4.0511e-03, -8.9050e-02, -1.5362e-02,  9.5985e-02,\n","         -5.9695e-02,  9.2547e-02,  5.1257e-02,  5.4549e-02,  1.0523e-01,\n","         -1.4291e-01,  9.7852e-02,  1.9540e-02,  6.1977e-03, -1.2511e-01,\n","         -1.1985e-01,  6.7255e-02, -1.1764e-01, -1.0192e-01,  1.4802e-02,\n","          4.5993e-02, -7.8487e-02,  4.0371e-02,  1.7726e-01, -1.2860e-01,\n","         -6.1773e-02,  7.4593e-02, -1.3637e-01, -4.9747e-02,  6.6499e-02,\n","         -1.5698e-02, -8.7760e-02,  6.4777e-02, -1.0728e-01,  5.5547e-02,\n","         -5.7427e-02,  3.3324e-04,  1.3511e-02,  8.7033e-02, -4.5900e-02,\n","         -3.9610e-02, -3.7723e-02,  7.7840e-04,  1.6777e-02,  1.2837e-02,\n","          1.3422e-02, -2.1753e-02, -1.5758e-01,  1.5278e-01,  3.4458e-02,\n","         -1.4084e-02,  9.2282e-02,  4.5491e-02, -3.5896e-03,  4.7241e-02,\n","         -3.4814e-01, -8.9951e-02,  6.7292e-02,  2.8780e-02],\n","        [-1.5716e-01,  9.6131e-02,  2.1417e-02,  6.6965e-02, -1.9525e-03,\n","          4.2091e-02,  9.3907e-02, -3.0395e-02,  1.6943e-01, -5.9534e-02,\n","         -4.7179e-02,  1.1982e-01, -6.1040e-02, -2.6638e-01, -1.5576e-01,\n","          7.6078e-02, -2.7790e-02,  2.4902e-02, -6.1403e-02,  1.7784e-02,\n","          2.9313e-02,  6.3808e-03,  4.9477e-02,  6.8439e-02,  1.7642e-03,\n","         -4.3001e-03,  2.9000e-02, -1.1365e-01,  4.2845e-02,  1.0106e-01,\n","          3.6124e-02, -5.0759e-02,  5.0088e-02,  1.1802e-01,  4.9407e-02,\n","          8.4094e-03,  1.0659e-01, -1.0312e-02,  1.9203e-01,  1.8948e-03,\n","          2.9512e-02,  5.5732e-02, -6.3971e-02,  6.0432e-02, -7.1568e-02,\n","          7.5998e-02, -1.9337e-01,  8.4099e-02,  6.6253e-02, -1.9971e-02,\n","          2.6290e-02, -3.0728e-02,  4.1648e-02, -1.9278e-01, -3.3572e-02,\n","         -6.1284e-02,  8.3365e-02,  6.4632e-03,  2.0484e-02,  5.6386e-02,\n","          1.4292e-02, -2.6456e-03, -1.4276e-01, -3.5396e-02],\n","        [ 1.3324e-02,  4.8044e-02, -3.2528e-02, -1.4990e-01,  4.0216e-03,\n","         -1.2576e-02, -9.5185e-02, -1.4494e-01,  2.1073e-01,  1.5033e-01,\n","         -6.3428e-02, -7.3325e-02,  2.7540e-02,  7.7706e-02,  1.6198e-02,\n","         -5.5812e-02, -8.7333e-02, -2.4315e-03, -4.8512e-02,  2.7651e-02,\n","         -7.9388e-02,  8.1647e-03, -5.2592e-02, -1.5184e-01, -3.5284e-02,\n","         -9.7185e-02,  2.4131e-01,  2.9722e-02, -4.6102e-02,  1.1861e-01,\n","         -1.2885e-01,  9.8187e-02, -9.1073e-02, -5.3507e-02, -1.8015e-02,\n","          6.7388e-02,  3.9957e-02,  1.2408e-02, -8.1893e-02,  5.1654e-02,\n","         -2.2783e-02,  1.2075e-01,  4.5627e-02,  1.0972e-01, -2.3331e-02,\n","          4.6911e-02, -7.7863e-02,  4.9465e-02, -1.2998e-01, -6.8112e-03,\n","         -7.1015e-03,  7.4631e-02, -1.3027e-01, -4.9998e-02,  1.2529e-01,\n","          7.4504e-02,  1.4202e-01, -1.2123e-01,  2.3324e-03, -7.7951e-03,\n","          6.8201e-02, -3.5523e-02,  7.9545e-02,  2.9789e-01],\n","        [ 1.7177e-01,  4.8788e-02, -1.1705e-01,  1.5289e-01,  4.2362e-02,\n","          4.8321e-02, -6.2399e-03,  5.2415e-03, -5.1583e-02, -5.5222e-03,\n","         -7.1545e-02, -1.3413e-01,  1.3319e-01,  1.0872e-01,  8.2287e-02,\n","         -1.9540e-01, -4.4955e-02,  3.5936e-02, -7.3260e-02,  1.0545e-01,\n","          9.4873e-02,  1.1060e-01,  4.4877e-02, -2.0594e-01, -4.7832e-02,\n","          2.7889e-02, -4.3081e-02,  1.5445e-01, -3.2559e-02, -5.4620e-02,\n","         -6.6609e-04,  4.8021e-02,  1.4056e-01,  3.2956e-01, -1.1172e-01,\n","         -1.0143e-01,  6.0131e-02,  2.7205e-02,  3.5987e-02,  1.1035e-02,\n","          8.3086e-02, -1.8114e-02, -1.6047e-01, -6.4928e-02, -1.1186e-01,\n","         -1.3723e-01, -7.5105e-02, -3.9224e-02, -1.4013e-02, -1.0567e-02,\n","          9.4517e-02, -8.1290e-02,  1.0463e-01, -7.6363e-02, -5.5163e-02,\n","          5.4853e-02,  3.0639e-04,  5.9269e-02, -7.5751e-02,  1.1138e-02,\n","          8.5855e-02,  6.5871e-02, -1.3015e-01,  8.4141e-02],\n","        [ 4.2302e-04,  5.0069e-02, -1.0288e-01, -5.6488e-02, -6.0041e-02,\n","         -4.4688e-02, -5.4836e-02,  2.9374e-02,  1.1999e-02,  4.8174e-02,\n","          1.4088e-01, -5.6328e-02,  3.9288e-02,  6.3071e-02,  3.0104e-02,\n","         -1.4605e-01,  1.9898e-01, -5.1936e-02,  3.5324e-02,  7.6649e-03,\n","         -1.4502e-02,  5.1694e-02,  3.6360e-02,  2.3969e-01, -1.2328e-01,\n","         -1.7565e-01, -1.6117e-01, -9.1870e-02,  7.3079e-02, -4.7673e-02,\n","          1.3044e-01,  1.1738e-01, -1.6794e-01, -6.5066e-02, -2.9664e-01,\n","         -1.7544e-02, -8.4912e-02, -1.1217e-01,  9.0615e-02,  7.6696e-02,\n","          5.8542e-02,  4.3466e-02,  7.1371e-02, -6.3170e-02,  2.3853e-02,\n","          8.2885e-02, -2.3806e-02, -5.1846e-02, -4.1475e-02, -6.5816e-02,\n","         -6.5062e-02,  1.6881e-01, -5.9623e-02,  6.9631e-02, -7.4488e-02,\n","         -7.3903e-02,  7.1661e-02,  2.9922e-02, -3.5927e-02, -5.6869e-02,\n","         -2.7214e-02, -1.4266e-01,  2.3972e-03,  8.3908e-02],\n","        [ 1.0071e-01, -2.6021e-02,  1.0496e-01, -7.6155e-02, -7.6778e-02,\n","         -2.2971e-02,  6.7423e-02,  7.4342e-02,  1.1832e-01, -4.1412e-02,\n","         -6.1501e-03, -9.4593e-03,  1.0446e-01,  8.5264e-02,  5.6454e-02,\n","         -1.7961e-02, -1.0345e-01,  1.1982e-02,  5.1144e-03, -6.4544e-02,\n","         -4.9173e-02,  1.2913e-01,  1.1096e-01,  4.1898e-02,  7.6243e-03,\n","          5.6852e-02, -1.0792e-02, -1.0637e-01, -2.5751e-02,  8.7401e-02,\n","         -3.5416e-02, -4.6896e-02,  1.0714e-01,  4.7705e-02,  8.0425e-03,\n","          1.7269e-01, -1.0580e-01, -1.5755e-02,  8.9356e-02, -5.7175e-02,\n","          1.2960e-02,  1.5589e-01,  6.2982e-02, -1.4887e-01,  9.5842e-03,\n","         -4.2767e-02,  1.5024e-02, -1.0790e-01, -6.7986e-02,  1.8776e-02,\n","          3.2230e-02, -2.5653e-02,  5.8469e-02, -5.0556e-02,  9.0267e-02,\n","          1.2837e-01,  1.4383e-02,  4.4212e-02, -8.6022e-04,  2.1627e-01,\n","         -6.1397e-02, -2.8534e-02,  1.2359e-02,  7.6024e-02],\n","        [-6.4958e-02,  4.7553e-02, -1.6368e-02,  2.9597e-01,  1.6988e-02,\n","         -9.5733e-02, -5.4772e-02,  6.9213e-02, -1.2808e-01, -2.8519e-02,\n","         -1.2311e-03, -5.5711e-03,  1.2730e-02,  5.3317e-02,  4.0722e-03,\n","         -4.3983e-02,  5.7787e-02, -2.8987e-03, -4.5938e-02,  1.2291e-02,\n","          6.1015e-02, -2.7502e-02, -8.2431e-02, -2.6548e-02,  4.3476e-02,\n","         -1.2353e-02, -4.5968e-02,  6.3462e-02,  2.1771e-02,  9.5048e-02,\n","         -9.3867e-02, -2.3326e-02,  1.4141e-01, -8.3217e-02, -6.0125e-02,\n","         -1.0153e-01, -8.2378e-02, -2.1715e-02,  1.0010e-01,  1.2629e-02,\n","          1.6579e-03, -2.2557e-02,  8.7386e-02,  1.9125e-01, -3.5704e-02,\n","         -2.0867e-02, -3.2185e-02, -1.1831e-01, -3.3682e-03,  1.3730e-01,\n","         -2.3809e-02, -1.1441e-01, -7.5423e-02, -6.8115e-02,  5.2433e-02,\n","          7.3030e-02, -7.7137e-03, -1.5035e-01,  6.4776e-02,  1.7436e-01,\n","         -7.7482e-02,  3.4990e-02,  2.8154e-02, -5.9081e-02]], device='cuda:0',\n","       requires_grad=True)\n","blocks.11.attn.b_V: torch.Size([12, 64])\n","Parameter containing:\n","tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n","       device='cuda:0', requires_grad=True)\n","blocks.11.mlp.W_in: torch.Size([768, 3072])\n","Parameter containing:\n","tensor([[-0.1440,  0.2177, -0.0821,  ...,  0.0604, -0.0454,  0.0257],\n","        [ 0.1404, -0.0434, -0.0759,  ..., -0.2034,  0.1176, -0.0198],\n","        [-0.0898, -0.1541,  0.0498,  ..., -0.0733,  0.0129, -0.2022],\n","        ...,\n","        [-0.2059,  0.0947,  0.0754,  ..., -0.0855,  0.0685,  0.2171],\n","        [ 0.0868, -0.0942,  0.1102,  ...,  0.0147, -0.0773, -0.0826],\n","        [ 0.0906, -0.1188,  0.0096,  ...,  0.0209,  0.1556,  0.0093]],\n","       device='cuda:0', requires_grad=True)\n","blocks.11.mlp.b_in: torch.Size([3072])\n","Parameter containing:\n","tensor([-0.0382, -0.1637,  0.2821,  ..., -0.0923, -0.1232, -0.0914],\n","       device='cuda:0', requires_grad=True)\n","blocks.11.mlp.W_out: torch.Size([3072, 768])\n","Parameter containing:\n","tensor([[ 0.0681,  0.0920, -0.0310,  ..., -0.0186,  0.0523,  0.0843],\n","        [ 0.1702,  0.0066,  0.1141,  ..., -0.2373,  0.0172, -0.1056],\n","        [-0.0283,  0.2363, -0.0688,  ...,  0.0324, -0.1550,  0.0332],\n","        ...,\n","        [ 0.1517,  0.1217,  0.0319,  ..., -0.1432, -0.2432, -0.1350],\n","        [ 0.0060, -0.0805,  0.0492,  ...,  0.1580, -0.0527,  0.0726],\n","        [ 0.0558,  0.1044, -0.1162,  ..., -0.2601,  0.1200,  0.0092]],\n","       device='cuda:0', requires_grad=True)\n","blocks.11.mlp.b_out: torch.Size([768])\n","Parameter containing:\n","tensor([ 1.0572e-01,  1.1879e-01,  6.7379e-03,  5.4252e-02, -2.0953e-02,\n","         7.7269e-03,  5.5386e-02,  5.1742e-02,  2.4586e-02,  5.6504e-02,\n","         7.2607e-02,  1.5076e-02,  7.1181e-02, -2.6223e-02, -4.7719e-03,\n","         1.3389e-01, -4.0425e-02, -9.6059e-02,  5.1433e-02, -7.7728e-02,\n","        -3.8933e-02, -1.1034e-02,  2.2768e-01, -5.1514e-02, -9.8916e-02,\n","         1.4074e-03, -4.1441e-02,  3.4522e-02, -9.6549e-03,  5.8057e-03,\n","         4.4663e-02, -4.7320e-02, -9.8542e-03,  1.7437e-02,  1.4408e-01,\n","        -1.2892e-01,  1.8401e-01, -1.7713e-02, -2.1363e-01,  6.4170e-02,\n","         7.3224e-02,  8.6715e-02,  7.6479e-02,  5.7796e-02, -9.9462e-02,\n","         1.0500e-02,  4.1930e-02,  4.2791e-02,  1.1134e-01,  1.4215e-01,\n","        -4.3593e-02,  1.7638e-01,  1.9844e-02, -5.7469e-02, -3.5152e-02,\n","         4.7848e-02, -5.1008e-02, -7.2841e-02, -6.4208e-02,  1.1923e-03,\n","         5.5512e-02,  4.6274e-02,  7.6309e-02, -3.2217e-02, -2.8233e-02,\n","         2.2415e-02,  2.8641e-01,  8.4060e-02, -1.0612e-01,  5.6944e-02,\n","        -9.0993e-02, -1.0579e-01,  1.6903e-02, -4.5003e-02, -3.9393e-02,\n","         4.2119e-04, -4.2567e-02, -1.9531e-01, -1.1876e-01, -1.1826e-01,\n","         2.3175e-02,  1.4658e-01, -1.1602e-02, -1.0424e-01, -3.7904e-02,\n","         5.6583e-02,  1.8228e-01, -2.5083e-01,  7.1082e-02, -2.0790e-02,\n","         1.5471e-01, -6.7578e-02, -3.6895e-02,  1.0317e-01, -9.9958e-02,\n","         1.1643e-01,  3.8131e-02,  3.4293e-02, -9.1408e-02, -5.7016e-02,\n","        -1.0627e-02, -9.8007e-02,  1.5857e-01,  1.7443e-01, -8.0009e-02,\n","         5.0136e-02,  7.6890e-02,  5.3975e-02,  4.0660e-02,  9.5955e-02,\n","        -3.0218e-02, -1.4983e-02,  1.9397e-02, -2.7931e-02, -2.7262e-01,\n","         9.8110e-03, -2.2446e-02, -6.4786e-02,  1.4062e-01, -7.4176e-02,\n","        -3.7756e-02, -1.5050e-01,  6.5330e-02,  1.4225e-01, -4.5734e-04,\n","        -9.3595e-02,  6.5302e-02, -1.1249e-01, -8.9142e-02, -2.3361e-01,\n","         2.2298e-01, -3.7233e-02, -1.2887e-01,  4.7280e-02,  1.2751e-01,\n","        -1.4881e-01,  1.8158e-02, -1.0750e-01,  1.2594e-01,  6.3952e-02,\n","        -1.8680e-01,  1.5195e-01, -5.8670e-02, -9.1480e-02, -1.9602e-01,\n","         1.2744e-02,  3.3053e-02,  1.6337e-02, -1.3293e-01,  6.1006e-04,\n","        -1.6633e-02,  9.7480e-02,  1.9665e-01,  8.1328e-02,  1.6761e-01,\n","         9.5780e-02,  6.1849e-02,  2.0257e-01,  6.6401e-02,  1.0221e-01,\n","        -5.5520e-02,  4.7802e-03,  1.1857e-01,  3.9364e-02,  1.3230e-01,\n","        -2.0744e-01, -1.7452e-02, -1.0337e-01,  2.6195e-01,  5.4406e-02,\n","        -6.4347e-02,  4.3047e-02, -7.9718e-02,  1.4043e-01, -8.5751e-02,\n","        -5.1306e-02, -1.5234e-01, -4.4695e-03, -5.6317e-02, -2.0362e-01,\n","        -3.8509e-02,  7.1817e-02, -1.6531e-02,  3.0568e-02,  4.7391e-02,\n","         3.0125e-02,  6.0942e-02, -9.1605e-02, -1.4780e-02,  8.2294e-02,\n","         1.3077e-01, -1.9461e-01, -7.7472e-03, -7.8554e-02, -1.9248e-02,\n","        -4.4688e-02, -7.3401e-02, -1.3075e-01, -7.4313e-02, -1.7099e-01,\n","         9.1723e-02, -5.7301e-02,  1.1888e-01, -1.9680e-02, -1.3036e-04,\n","         5.9940e-02, -7.7657e-02,  1.9796e-02, -7.7746e-02, -4.0898e-02,\n","         1.4334e-01, -5.9350e-02,  5.7266e-02,  6.8265e-02, -5.6205e-02,\n","        -2.0999e-01,  3.3929e-02,  2.7139e-02,  5.3058e-02,  5.2783e-02,\n","        -4.7506e-02, -9.2336e-02, -4.6216e-02,  3.3460e-02,  6.1667e-02,\n","        -6.1372e-02,  2.9460e-01,  1.2161e-01,  1.9840e-02,  1.3785e-02,\n","         9.2307e-02, -7.2099e-03,  1.0697e-01, -6.2160e-02,  1.8908e-01,\n","         1.0330e-01,  1.5134e-02, -1.0507e-01,  1.3786e-02,  1.5425e-01,\n","         6.2750e-02,  1.8912e-03,  2.5628e-02, -5.6894e-02, -1.8224e-01,\n","        -5.6574e-02,  2.1062e-01,  9.2668e-03, -1.9323e-01, -8.1908e-02,\n","        -1.7453e-01,  2.3179e-02,  6.9075e-02, -8.0734e-02,  5.3658e-02,\n","         1.5558e-01, -8.2802e-02,  1.0276e-01, -1.7344e-02, -6.9535e-02,\n","        -1.0493e-02,  1.4384e-01, -2.0758e-01, -1.2479e-01, -1.1120e-01,\n","        -1.3339e-01, -2.4917e-01,  2.0346e-01, -1.6052e-01,  8.5079e-02,\n","        -3.5181e-03,  5.0487e-02, -4.2942e-02,  7.9891e-03,  1.9121e-02,\n","        -2.0169e-01,  5.4721e-02, -1.6965e-01,  1.0441e-01, -5.5981e-03,\n","         1.1147e-01,  8.6738e-02,  1.5059e-01,  1.7929e-02,  3.5344e-02,\n","         9.2663e-02,  2.9168e-02, -5.0068e-02,  3.5208e-02, -5.0296e-02,\n","         1.4123e-02,  2.0188e-01, -1.5056e-01, -8.6907e-02, -7.4861e-02,\n","         1.1338e-01,  5.1165e-02,  2.5278e-03, -1.6773e-01, -3.7808e-03,\n","         1.8031e-01, -1.3222e-01, -2.5825e-01, -1.4690e-01, -5.2722e-02,\n","        -1.6529e-01, -6.2727e-02,  9.4581e-02, -1.2620e-02, -3.3709e-02,\n","        -2.5698e-01, -1.5856e-01,  1.1082e-01,  1.2593e-01, -8.2531e-02,\n","        -3.6449e-02,  2.2243e-01,  6.8903e-02, -5.1664e-02, -1.8017e-01,\n","        -2.6626e-02, -3.2147e-02, -1.3191e-03,  7.7325e-02, -5.0219e-03,\n","         5.2561e-02,  7.2620e-02,  9.7096e-02, -2.3107e-01,  6.9201e-02,\n","         1.2657e-01, -2.3266e-02, -1.3125e-01,  1.2131e-02,  1.4979e-02,\n","        -2.2421e-01,  4.0068e-02, -6.3698e-02, -1.4965e-01, -2.3132e-02,\n","        -7.2891e-02, -1.9409e-02,  1.7667e-01,  8.7174e-02, -1.5857e-02,\n","         1.2055e-01,  8.2296e-02,  6.3643e-03,  7.6144e-02,  4.3202e-02,\n","         9.5949e-02, -9.1608e-03, -5.0073e-02,  1.1223e-02,  1.2446e-01,\n","         1.0977e-01, -1.0122e-01,  1.1081e-01, -1.1549e-01,  1.5086e-01,\n","         4.6682e-02, -1.3020e-01,  6.5236e-02,  5.7370e-02,  2.3877e-02,\n","        -1.7285e-02,  2.3539e-01,  2.1465e-01, -8.1777e-02, -2.6992e-02,\n","        -2.6341e-01,  4.9678e-02, -8.6195e-02, -1.4439e-01, -1.6030e-01,\n","        -1.3839e-01, -3.9179e-02,  1.3730e-01, -8.1743e-02,  2.5222e-01,\n","         9.2870e-02,  1.8573e-02, -1.5000e-02,  3.1442e-03,  1.3097e-02,\n","         9.1505e-03,  3.7101e-02, -2.3007e-01,  8.7099e-02, -3.5230e-03,\n","         9.1063e-02, -4.3650e-02,  2.1710e-02,  4.0314e-02, -8.2574e-02,\n","        -9.5418e-03, -7.6777e-02, -1.3306e-01,  1.1965e-01, -2.0255e-02,\n","         5.7755e-02,  1.7457e-01, -2.5960e-02,  2.8210e-02, -1.1305e-01,\n","         1.5725e-02,  7.0588e-02, -7.3510e-02,  3.4142e-03,  1.9645e-01,\n","        -1.5030e-01,  2.6287e-02, -3.2753e-02,  1.0480e-01,  1.4720e-01,\n","         1.5684e-01, -1.1692e-02,  1.4269e-02,  2.3947e-02,  1.9866e-02,\n","        -1.8308e-01,  1.8304e-01, -1.3947e-01, -5.1109e-02, -1.4727e-01,\n","         8.8898e-02,  4.4508e-02, -1.8577e-02,  6.3682e-03, -6.6557e-02,\n","         3.6230e-01,  3.1461e-02, -3.0851e-02, -8.7272e-02,  5.7620e-02,\n","         1.7560e-01,  1.4485e-01,  1.1059e-01, -2.4380e-01, -1.2766e-01,\n","         1.1311e-01,  1.5620e-01,  3.0114e-02,  7.4779e-02, -8.2325e-03,\n","         1.1666e-01, -4.1148e-03,  1.6755e-01,  1.3345e-01,  1.5637e-01,\n","         1.6306e-01, -1.8500e-02, -1.2662e-01, -6.2124e-02,  8.6951e-02,\n","        -2.2274e-02, -5.8698e-02,  1.8022e-01,  1.9208e-02,  1.8095e-01,\n","        -1.0585e-01,  2.0035e-01, -1.5849e-03,  1.7373e-01,  3.3996e-01,\n","        -8.0917e-03,  7.3306e-03,  4.4030e-02,  1.5299e-01,  5.1435e-02,\n","        -1.9631e-01,  1.6560e-01, -1.5217e-01, -4.5821e-02, -8.6091e-02,\n","        -7.7387e-02, -1.5644e-02,  1.6115e-01, -1.1703e-01, -1.1466e-01,\n","        -3.8350e-01,  1.7597e-01,  1.3842e-01,  3.3484e-02, -1.0863e-01,\n","         5.6124e-02, -4.4190e-03,  1.9475e-01,  1.9959e-01,  2.0017e-03,\n","        -1.3468e-01, -1.2655e-01, -3.6448e-02,  1.4633e-01,  3.7585e-02,\n","         7.3768e-02,  4.3735e-01, -7.9439e-02,  2.8000e-02,  3.8989e-02,\n","         7.3716e-02,  1.8871e-02,  5.6248e-02, -2.1736e-01,  2.4100e-03,\n","        -9.0726e-03,  5.6102e-03,  2.0174e-01,  1.1162e-01,  6.3478e-02,\n","        -3.5721e-02, -1.1278e-01, -8.6482e-02,  1.4340e-01, -9.5219e-02,\n","        -7.4091e-02,  8.1779e-03, -6.7562e-02, -2.2984e-02,  8.3327e-02,\n","         1.4924e-02, -1.5129e-01,  4.5383e-02,  1.3640e-01,  1.3206e-02,\n","        -2.3577e-02,  2.8543e-03, -8.8803e-02, -9.9811e-02,  5.1691e-02,\n","         1.1250e-01,  1.1428e-01,  1.9531e-02, -1.4810e-01,  8.7839e-02,\n","        -3.1316e-01, -8.5429e-02,  3.3171e-02,  8.6071e-02, -5.1486e-02,\n","        -1.4495e-02,  4.1273e-02,  8.6265e-02, -4.3574e-02, -7.5190e-02,\n","        -2.9429e-02, -8.8570e-02,  7.8183e-02, -1.6987e-01, -1.1596e-01,\n","        -3.7403e-02,  1.2199e-01,  9.3386e-03, -2.5383e-02, -3.1777e-02,\n","         4.6747e-02, -8.4809e-03,  1.3684e-01, -7.8534e-03, -3.6620e-02,\n","        -1.3174e-03, -5.5213e-02,  7.2293e-02, -8.5691e-02, -3.5946e-02,\n","        -1.7964e-02, -6.0319e-02, -8.5489e-02, -1.9730e-01, -8.7556e-02,\n","        -4.4483e-02, -7.8376e-02,  1.2498e-01, -1.7656e-01, -1.0557e-01,\n","         5.6224e-03, -8.0780e-02, -6.8574e-02,  4.3504e-02,  2.4315e-01,\n","         4.7379e-02,  4.2447e-02,  8.2060e-02,  1.0923e-01,  6.2941e-03,\n","        -1.5769e-01, -1.3643e-01, -5.9392e-02,  9.0176e-02,  1.3574e-02,\n","        -1.7467e-01, -2.0946e-01,  9.9790e-02,  8.0118e-03,  3.2944e-02,\n","        -1.6904e-01, -6.7554e-02, -2.2980e-02, -1.4038e-01, -8.2827e-02,\n","        -1.4653e-01,  1.1138e-01, -1.1880e-01,  2.1451e-01, -6.6476e-02,\n","        -7.7930e-02,  5.7358e-02, -8.5525e-02,  3.8438e-02,  1.8681e-01,\n","        -1.8761e-01,  1.4060e-01, -6.8046e-02, -1.8404e-01, -1.0185e-01,\n","        -9.7167e-02, -5.3329e-03, -4.1926e-03, -4.0709e-02, -1.3587e-02,\n","         1.2239e-01, -6.3936e-02, -1.3515e-01, -4.4335e-03, -1.4297e-01,\n","        -1.3663e-01, -8.1266e-02, -1.5265e-01,  1.1475e-01, -1.3938e-01,\n","        -5.4311e-02, -7.3844e-02,  7.4162e-02,  5.3497e-02,  1.7059e-01,\n","        -3.5187e-02, -1.3852e-01,  9.8586e-02,  1.2629e-02, -3.8329e-02,\n","         1.0660e-01,  1.3036e-01, -1.0542e-01, -1.8507e-01, -3.5381e-02,\n","        -1.0341e-01, -9.2044e-02,  2.0749e-02, -2.5714e-03, -1.9062e-02,\n","         7.6535e-02,  3.0597e-02,  1.1857e-01, -1.1533e-01, -1.1641e-01,\n","        -8.4822e-03,  1.1227e-02, -6.1831e-02, -1.6218e-03,  9.2170e-02,\n","         6.7491e-02,  3.1028e-02,  1.2227e-02, -1.2369e-01,  2.1126e-02,\n","         2.3004e-01,  4.9124e-03,  1.0135e-02,  1.1690e-01,  2.3346e-01,\n","         5.6357e-03, -7.9665e-02, -2.1610e-02, -4.8720e-02,  5.6220e-02,\n","        -2.8325e-02,  2.2177e-01,  1.8658e-01,  1.7118e-01,  1.2180e-01,\n","        -7.9750e-02, -5.2540e-02,  1.1795e-02,  1.0606e-01, -2.2269e-01,\n","         4.2665e-02,  4.2882e-02, -1.3836e-01,  1.5606e-01,  7.1418e-02,\n","         8.9919e-02,  8.4956e-02, -1.3263e-01,  7.5401e-02, -1.3880e-01,\n","        -6.1631e-02, -1.0173e-01,  1.0787e-01, -6.5186e-03,  7.2937e-02,\n","         6.5807e-02, -8.5801e-03, -1.2480e-01, -1.1648e-01, -7.0237e-03,\n","         1.7039e-01, -2.2398e-01, -1.1090e-01, -9.5628e-02,  5.9916e-02,\n","         5.7450e-02, -2.5389e-02,  6.1323e-02, -5.6282e-02,  5.3920e-02,\n","         8.8330e-02,  3.3277e-03, -6.2501e-02,  1.9375e-01,  1.1044e-01,\n","        -4.9803e-03, -2.0570e-02, -2.1332e-02,  1.5818e-01,  1.3784e-01,\n","         9.6036e-02,  1.9995e-02,  2.3555e-02, -4.5321e-02, -1.7497e-01,\n","        -6.2306e-02, -1.3425e-01,  8.0241e-02, -6.4660e-02, -5.7260e-02,\n","        -1.6657e-01, -1.0838e-01,  4.4129e-04,  2.9783e-02, -2.1044e-01,\n","        -4.2904e-03,  8.5002e-02,  4.0066e-02, -8.7010e-02, -1.1930e-01,\n","        -1.1236e-01, -4.7993e-02,  5.8718e-02, -1.2858e-01, -1.1983e-01,\n","         1.0818e-01, -7.4752e-02,  8.8138e-02, -1.7099e-01, -8.2374e-02,\n","        -1.2052e-01,  2.0995e-01,  5.1958e-02,  2.6532e-02, -2.0338e-02,\n","         1.6600e-01,  1.5497e-01,  9.1099e-02,  1.2486e-02, -1.9829e-01,\n","        -3.7719e-02, -4.4782e-02, -3.2747e-02], device='cuda:0',\n","       requires_grad=True)\n","ln_final.w: torch.Size([768])\n","Parameter containing:\n","tensor([1.3971e+00, 1.3750e+00, 1.8870e+00, 1.1688e+00, 1.2724e+00, 1.2508e+00,\n","        9.4198e+00, 1.4371e+00, 1.4527e+00, 1.1856e+00, 1.3945e+00, 1.2796e+00,\n","        1.2071e+00, 1.2951e+00, 1.2776e+00, 1.3480e+00, 1.5088e+00, 1.3729e+00,\n","        1.3427e+00, 2.3761e+00, 1.1377e+00, 1.2909e+00, 1.3477e+00, 1.4775e+00,\n","        1.2540e+00, 1.1999e+00, 1.4932e+00, 1.1637e+00, 1.2590e+00, 1.2305e+00,\n","        1.1833e+00, 1.1914e+00, 1.2228e+00, 1.2792e+00, 1.3294e+00, 1.6213e+00,\n","        1.3804e+01, 1.1871e+00, 1.2235e+00, 1.4578e+00, 1.1687e+00, 1.3164e+00,\n","        1.1444e+00, 1.2628e+00, 1.4781e+00, 1.2426e+00, 1.1744e+00, 1.1602e+00,\n","        1.3637e+00, 2.1280e+00, 1.2371e+00, 1.2336e+00, 1.7410e+00, 1.1568e+00,\n","        1.3303e+00, 1.8593e+00, 1.2932e+00, 1.3320e+00, 1.2148e+00, 1.5415e+00,\n","        1.3781e+00, 1.2070e+00, 1.4030e+00, 1.5724e+00, 7.6159e-03, 1.1836e+00,\n","        1.2148e+00, 1.2604e+00, 1.8500e+00, 1.1540e+00, 1.2933e+00, 1.1572e+00,\n","        1.2341e+00, 1.1055e+00, 1.1680e+00, 1.3321e+00, 1.3856e+00, 3.6001e+00,\n","        1.6204e+00, 1.1333e+00, 1.4368e+00, 1.1365e+00, 1.2749e+00, 1.5402e+00,\n","        9.2773e-01, 1.5039e+00, 2.5029e+00, 4.4275e-03, 1.0613e+00, 1.3566e+00,\n","        1.2504e+00, 1.1983e+00, 1.4295e+00, 1.2386e+00, 1.1792e+00, 1.1883e+00,\n","        1.4453e+00, 1.4384e+00, 1.2305e+00, 1.3109e+00, 1.2305e+00, 1.1997e+00,\n","        3.1531e+00, 1.3615e+00, 1.1858e+00, 1.2148e+00, 1.2228e+00, 8.9936e+00,\n","        1.0824e+00, 1.2424e+00, 1.4070e+00, 1.2314e+00, 1.2359e+00, 1.2810e+00,\n","        1.3169e+00, 1.1992e+00, 1.4846e+00, 1.3867e+00, 1.2227e+00, 1.2774e+00,\n","        1.1955e+00, 1.2539e+00, 1.3414e+00, 1.2502e+00, 1.2220e+00, 1.2655e+00,\n","        1.1805e+00, 1.2932e+00, 1.6978e+00, 1.3635e+00, 1.2106e+00, 1.1450e+00,\n","        1.4414e+00, 1.0931e+00, 1.1859e+00, 1.2156e+00, 1.1804e+00, 1.5686e+00,\n","        8.6240e-02, 1.8252e+00, 1.1971e+00, 1.1500e+00, 3.3033e+00, 1.1137e+00,\n","        1.1841e+00, 1.8482e+00, 1.3211e+00, 1.1996e+00, 1.1784e+00, 1.4120e+00,\n","        1.2726e+00, 1.5131e+00, 1.4775e+00, 1.5084e+00, 1.4086e+00, 1.3018e+00,\n","        1.2469e+00, 1.2008e+00, 1.0666e+00, 1.0909e+00, 3.0489e+00, 1.2242e+00,\n","        1.2333e+00, 1.2970e+00, 1.2137e+00, 1.3484e+00, 1.2782e+00, 4.0765e+00,\n","        1.2149e+00, 1.3308e+00, 1.2631e+00, 1.1915e+00, 1.1758e+00, 1.4181e+00,\n","        1.4744e+00, 1.5844e+00, 2.1523e+00, 1.1229e+00, 1.4097e+00, 1.1849e+00,\n","        1.2051e+00, 1.2154e+00, 1.2320e+00, 1.3685e+00, 1.1289e+00, 1.2304e+00,\n","        1.1187e+00, 1.3789e+00, 1.2056e+00, 1.3168e+00, 1.2865e+00, 1.3707e+00,\n","        1.2933e+00, 1.2151e+00, 1.1296e+00, 1.8137e+00, 1.2315e+00, 1.2476e+00,\n","        1.2515e+00, 1.6609e+00, 1.4583e+00, 1.4180e+00, 1.2085e+00, 1.2292e+00,\n","        1.0586e+00, 1.2148e+00, 1.1842e+00, 1.0864e+00, 1.3871e+00, 1.2393e+00,\n","        1.2228e+00, 1.5026e+00, 1.3742e+00, 2.4785e+00, 1.2004e+00, 1.1891e+00,\n","        1.4659e+00, 1.1916e+00, 1.0978e+00, 1.2148e+00, 1.1180e+00, 1.1934e+00,\n","        1.1934e+00, 1.2339e+00, 1.6256e+00, 1.2190e+00, 1.2476e+00, 1.1685e+00,\n","        1.2186e+00, 1.2413e+00, 1.1367e+00, 1.3399e+00, 3.4147e+00, 1.0761e+00,\n","        1.1924e+00, 1.3913e+00, 1.1215e+00, 1.1398e+00, 1.3053e+00, 1.2300e+00,\n","        1.4287e+00, 1.5445e+00, 1.2461e+00, 1.1179e+00, 1.0352e+00, 1.2579e+00,\n","        1.1846e+00, 1.6518e+00, 1.2148e+00, 1.5199e+00, 2.3705e+00, 1.4342e+00,\n","        1.2745e+00, 1.4321e+00, 1.3017e+00, 1.5673e+00, 1.4878e+00, 1.1600e+00,\n","        1.2305e+00, 1.4492e+00, 1.2450e+00, 1.6015e+00, 1.2074e+00, 1.2931e+00,\n","        1.0899e+00, 1.2818e+00, 6.8271e-03, 1.3498e+00, 1.3882e+00, 1.6141e+00,\n","        2.2603e+00, 4.3566e+00, 1.2119e+00, 1.0664e+00, 1.5068e+00, 1.2935e+00,\n","        1.7190e+00, 1.2120e+00, 1.1749e+00, 1.2177e+00, 1.2027e+00, 1.1525e+00,\n","        1.4620e+00, 1.4274e+00, 1.0562e+00, 1.4126e+00, 1.3862e+00, 1.1511e+00,\n","        1.2874e+00, 2.0521e+00, 1.4653e+00, 1.2819e+00, 1.2038e+00, 1.1852e+00,\n","        1.4243e+00, 1.2345e+00, 1.0954e+00, 1.1217e+00, 1.1998e+00, 1.2631e+00,\n","        1.8584e+00, 1.1845e+00, 1.4605e+00, 1.2383e+00, 1.2808e+00, 1.0243e+00,\n","        1.2522e+00, 1.1446e+00, 3.1141e+00, 1.2562e+00, 1.1038e+00, 2.2026e+00,\n","        1.2352e+00, 1.2740e+00, 1.5308e+01, 1.3327e+00, 1.2991e+00, 1.2305e+00,\n","        1.2227e+00, 1.3008e+00, 2.4603e+00, 1.2306e+00, 1.1791e+00, 1.2395e+00,\n","        1.3017e+00, 1.2238e+00, 9.8373e-01, 1.1771e+00, 1.3761e+00, 1.1659e+00,\n","        1.1485e+00, 1.1823e+00, 1.2148e+00, 1.1784e+00, 1.0820e+00, 1.3048e+00,\n","        1.4846e+00, 1.1753e+00, 1.2101e+00, 1.3441e+00, 1.1446e+00, 1.1445e+00,\n","        1.1766e+00, 1.4649e+00, 1.4105e+00, 1.0483e+00, 1.2181e+00, 1.2429e+00,\n","        1.2293e+00, 1.2272e+00, 1.2309e+00, 1.9298e+00, 1.2051e+00, 1.3829e+00,\n","        1.2752e+00, 1.2049e+00, 1.9575e+00, 1.2054e+00, 1.0039e+00, 1.1939e+00,\n","        1.3718e+00, 2.8912e+00, 2.1898e+00, 1.1977e+00, 1.0975e+00, 3.9985e+00,\n","        1.2511e+00, 1.0346e+00, 1.1375e+00, 1.1822e+00, 1.4023e+00, 1.1227e+00,\n","        1.2915e+00, 3.5039e-02, 1.2217e+01, 1.4350e+00, 1.4025e+00, 2.3862e+00,\n","        8.5499e-01, 1.3179e+00, 1.2637e+00, 1.2388e+00, 1.0809e+00, 1.5234e+00,\n","        1.4024e+00, 1.2991e+00, 1.5354e+00, 1.1690e+00, 1.2194e+00, 2.6955e+00,\n","        1.2617e+00, 1.2485e+00, 1.3482e+00, 6.9770e-01, 1.4888e+00, 1.0986e+00,\n","        1.6696e+00, 1.1986e+00, 1.1655e+00, 1.1134e+00, 1.0508e+00, 1.2227e+00,\n","        2.3545e+00, 1.2345e+00, 1.0825e+00, 1.2153e+00, 1.2073e+00, 1.0666e+00,\n","        4.3418e+00, 1.1837e+00, 1.2441e+00, 1.2461e+00, 1.2586e+00, 1.2292e+00,\n","        1.4278e+00, 1.4742e+00, 1.2469e+00, 1.5043e+00, 1.4920e+00, 1.0824e+00,\n","        1.9560e+00, 1.4904e+00, 1.2004e+00, 1.1992e+00, 1.1798e+00, 1.0748e+00,\n","        1.1701e+00, 1.1871e+00, 1.2570e+00, 1.2104e+00, 1.6994e+01, 1.2695e+00,\n","        1.2397e+00, 1.2462e+00, 1.1837e+00, 1.4884e+00, 1.2487e+00, 1.2075e+00,\n","        1.4805e+00, 2.7156e+00, 1.2308e+00, 1.1758e+00, 1.2199e+01, 1.2564e+00,\n","        1.3756e+00, 1.2305e+00, 1.2151e+00, 3.5184e-02, 1.2539e+00, 1.2619e+00,\n","        1.3423e+00, 1.2802e+00, 1.1453e+00, 1.8877e+00, 1.3793e+00, 2.7507e+00,\n","        1.7741e+00, 1.3170e+00, 1.2972e+00, 1.6555e+00, 1.3009e+00, 1.3419e+00,\n","        1.1063e+00, 1.2773e+00, 9.6680e-01, 1.2736e+00, 1.2227e+00, 1.2159e+00,\n","        1.3187e+00, 1.1759e+00, 1.0922e+00, 1.1300e+00, 1.2853e+00, 1.2227e+00,\n","        1.1478e+00, 1.3477e+00, 1.0232e+00, 1.1962e+00, 1.1798e+00, 7.3442e+00,\n","        5.5998e-03, 4.2853e-02, 1.1763e+00, 1.2247e+00, 1.4425e+00, 1.2482e+00,\n","        1.1936e+00, 1.1623e+00, 1.5431e+00, 1.2553e+00, 1.2461e+00, 1.4025e+00,\n","        1.0510e+00, 1.1926e+00, 1.1642e+00, 1.1370e+00, 1.7419e+01, 1.7540e+00,\n","        1.2953e+00, 1.1212e+00, 1.2787e+00, 1.1915e+00, 1.4268e+00, 4.1753e+00,\n","        1.4481e+00, 1.1768e+00, 1.1994e+00, 1.2464e+00, 1.4068e+00, 1.2426e+00,\n","        1.0352e+00, 2.2258e+00, 1.7040e+00, 1.2463e+00, 1.3851e+00, 1.4013e+00,\n","        1.1661e+00, 1.3970e+00, 1.3403e+00, 1.2852e+00, 1.1684e+00, 1.2515e+00,\n","        1.2318e+00, 1.2731e+00, 1.1832e+00, 2.3393e+00, 2.0250e+00, 2.1031e+00,\n","        1.9473e+00, 1.0853e+00, 1.0114e+00, 1.2650e+00, 1.2014e+00, 1.0996e+00,\n","        1.2435e+00, 1.3647e+00, 1.1999e+00, 1.3419e+00, 1.4270e+00, 1.2332e+00,\n","        2.2816e+00, 1.2234e+00, 1.1839e+00, 2.4615e+00, 1.2603e+00, 1.3412e+00,\n","        1.2818e+00, 1.1999e+00, 1.4258e+00, 1.1138e+00, 1.1914e+00, 2.0622e+00,\n","        1.1712e+00, 1.3323e+00, 2.9923e+00, 1.2178e+00, 1.2220e+00, 1.2960e+00,\n","        1.2466e+00, 1.4102e+00, 1.3290e+00, 1.2458e+00, 1.1273e+00, 1.1836e+00,\n","        1.2652e+00, 1.2907e+00, 1.9197e+00, 1.1735e+00, 1.4725e+00, 1.4414e+00,\n","        1.1830e+00, 1.3088e+00, 1.1055e+00, 1.0831e+00, 1.2468e+00, 1.3466e+00,\n","        1.1992e+00, 1.2368e+00, 1.4933e+00, 1.1602e+00, 1.2542e+00, 1.3133e+00,\n","        1.4812e+00, 1.2707e+00, 1.2185e+00, 1.2779e+00, 1.2339e+00, 1.4316e+00,\n","        1.6659e+00, 1.2227e+00, 1.2312e+00, 1.2383e+00, 1.2305e+00, 1.4299e+00,\n","        1.0813e+00, 1.2005e+00, 1.2228e+00, 1.2314e+00, 1.2383e+00, 1.2539e+00,\n","        1.3949e+00, 1.3330e+00, 1.0798e+00, 1.2699e+00, 1.2942e+00, 1.2252e+00,\n","        1.3091e+00, 1.2312e+00, 1.8579e+00, 1.2031e+00, 1.3398e+00, 1.3956e+00,\n","        1.2026e+00, 1.1759e+00, 1.1842e+00, 1.1479e+00, 1.2016e+00, 1.2587e+00,\n","        1.1211e+00, 1.3564e+00, 1.0669e+00, 1.2955e+00, 1.5078e+00, 2.3227e+00,\n","        1.3065e+00, 1.1133e+00, 1.1542e+00, 6.1745e+00, 1.2328e+00, 1.2865e+00,\n","        1.2617e+00, 1.2497e+00, 1.1554e+00, 1.1533e+00, 1.2032e+00, 2.2578e+00,\n","        1.1680e+00, 1.0742e+00, 1.2881e+00, 1.2808e+00, 1.3027e+00, 1.1446e+00,\n","        1.2920e+00, 1.5471e+00, 1.4432e+00, 1.2617e+00, 1.1531e+00, 1.5527e+00,\n","        1.1369e+00, 1.5745e+00, 1.2476e+00, 1.4768e+00, 1.3202e+00, 1.2254e+00,\n","        1.2874e+00, 2.2262e+00, 1.2796e+00, 1.3802e+00, 1.1289e+00, 1.4846e+00,\n","        1.1908e+00, 1.3086e+00, 1.1986e+00, 1.1980e+00, 1.2156e+00, 1.6095e+00,\n","        1.3010e+00, 1.4810e+00, 2.0002e+00, 1.0530e+00, 2.1401e+00, 1.1956e+00,\n","        1.0898e+00, 1.1557e+00, 1.6530e+00, 1.1836e+00, 1.1818e+00, 1.1835e+00,\n","        1.3206e+00, 3.3972e+00, 1.3472e+00, 1.2540e+00, 1.2671e+00, 1.2726e+00,\n","        1.1836e+00, 1.4586e+00, 1.2540e+00, 1.1450e+00, 1.3078e+00, 1.1806e+00,\n","        1.2149e+00, 1.2552e+00, 1.1542e+00, 1.1541e+00, 1.2383e+00, 1.3058e+00,\n","        1.0963e+00, 1.1029e+00, 1.3066e+00, 1.7412e+00, 1.0508e+00, 1.5009e+00,\n","        1.3564e+00, 1.0530e+01, 1.1796e+00, 1.1801e+00, 1.8887e+00, 1.4579e+00,\n","        1.1528e+00, 6.6027e-01, 1.3696e+00, 1.0898e+00, 1.2464e+00, 1.2540e+00,\n","        1.1379e+00, 1.3102e+00, 1.1453e+00, 1.2852e+00, 1.8692e+00, 1.1606e+00,\n","        2.4319e+00, 1.4304e+00, 1.2322e+00, 1.2283e+00, 2.8226e+00, 1.3143e+00,\n","        1.5046e+00, 1.3252e+00, 1.3366e+00, 1.1009e+00, 1.2071e+00, 1.3483e+00,\n","        1.2312e+00, 1.3353e+00, 1.2706e+00, 1.2247e+00, 1.1510e+00, 1.1626e+00,\n","        1.4471e+00, 1.8308e+00, 1.3415e+00, 1.1664e+00, 1.4809e+00, 1.1465e+00,\n","        1.2681e+00, 2.1403e+00, 1.4574e+00, 1.1446e+00, 1.2617e+00, 1.4746e+00,\n","        1.2107e+00, 1.3090e+00, 1.0051e+00, 1.2245e+00, 1.2793e+00, 1.3636e+00,\n","        1.1871e+00, 1.3660e+00, 1.1758e+00, 1.4514e+00, 1.1525e+00, 1.1731e+00,\n","        4.2194e+00, 1.1660e+00, 1.1625e+00, 1.1034e+00, 1.0980e+00, 1.2070e+00],\n","       device='cuda:0', requires_grad=True)\n","ln_final.b: torch.Size([768])\n","Parameter containing:\n","tensor([ 1.0872e-03,  3.6529e-02, -6.7296e-02,  1.6416e-04, -6.7444e-02,\n","        -7.1351e-02,  5.0393e-01,  9.1723e-02, -4.9340e-02,  3.2622e-03,\n","         4.5723e-02, -6.8674e-03,  2.4039e-02, -2.3481e-02, -1.6724e-02,\n","        -1.7144e-02, -8.3718e-03, -3.1513e-02, -6.8601e-02, -2.3766e-01,\n","         3.6237e-02,  1.6346e-02, -9.8507e-02, -2.1232e-03,  1.1982e-02,\n","         2.8979e-02, -1.2852e-01, -1.5948e-02, -1.9886e-02, -5.3668e-02,\n","         6.9403e-03, -7.6807e-03, -1.0904e-01, -1.9977e-02,  9.6084e-03,\n","         1.0891e-01,  4.5043e+00, -2.6320e-02, -3.5563e-02,  6.8634e-02,\n","        -2.6733e-02,  4.5381e-03, -7.6494e-02, -1.8627e-02,  2.7786e-04,\n","         1.7049e-02,  1.5448e-02, -2.0069e-02, -9.4106e-02,  1.2935e-01,\n","        -2.8602e-02,  1.7971e-02, -1.2255e-01, -6.0040e-02, -2.7152e-02,\n","         2.0868e-01, -7.3314e-02, -1.8849e-02,  3.2550e-02, -1.0382e-01,\n","         3.3463e-02, -5.7886e-02,  2.7034e-02, -1.6745e-01, -1.0472e+00,\n","        -1.6542e-02, -5.1018e-02, -6.8653e-03, -2.1249e-01, -3.1209e-02,\n","        -6.0667e-02,  8.7675e-04,  2.8659e-02, -2.4280e-02, -7.4334e-03,\n","        -1.0984e-02, -9.6567e-02, -4.0275e-01,  3.5209e-02,  4.5582e-03,\n","        -7.4472e-03, -1.4675e-02,  1.0423e-02, -7.6423e-02,  1.5722e-02,\n","         2.2594e-02,  3.4847e-01, -9.9237e-01, -1.4573e-02,  4.1847e-02,\n","        -5.6549e-02, -6.4195e-02, -7.8837e-02, -8.6063e-02, -1.1810e-02,\n","         1.1617e-02, -4.3866e-03,  4.7045e-02,  1.4878e-02,  1.5424e-01,\n","        -1.9613e-02, -1.0770e-01,  1.1270e-01, -6.4523e-03,  4.0445e-02,\n","        -2.7771e-02, -1.7304e-02,  7.3762e-01, -2.5960e-02, -2.7389e-02,\n","        -3.1064e-02,  1.5734e-02, -5.2281e-02,  4.1252e-02, -1.3316e-02,\n","        -4.5049e-02, -1.8180e-03,  7.2320e-03,  1.3693e-02, -3.9412e-02,\n","        -3.4724e-02,  5.1059e-02, -2.0570e-02, -2.1606e-02, -1.3500e-01,\n","         5.4560e-02, -3.6672e-02,  2.2630e-02, -1.0954e-01, -1.3664e-02,\n","         5.5158e-02,  2.8813e-02,  2.7308e-02, -5.6942e-02, -7.8654e-02,\n","         2.3580e-03,  2.0007e-02, -5.7116e-02,  6.4764e-01,  1.0185e-01,\n","        -6.1624e-02, -3.7634e-02, -3.9838e-01,  2.1430e-02, -1.8644e-02,\n","         1.9693e-01,  2.2677e-02, -6.5989e-02, -4.3632e-02,  9.9600e-03,\n","         2.4032e-02, -1.0095e-01, -4.6580e-02,  2.9137e-02, -5.9029e-02,\n","        -3.2612e-02, -1.9738e-03,  2.4192e-03, -3.7447e-02, -3.0108e-02,\n","        -6.3761e-02,  3.3632e-02, -1.8530e-02,  2.2146e-02, -6.4106e-02,\n","         7.4832e-02, -9.5605e-02, -3.6251e-01, -3.0068e-02, -1.1445e-01,\n","        -4.1705e-02, -7.9181e-02,  4.7085e-04,  8.2493e-02, -5.6607e-02,\n","        -3.3807e-02, -2.8627e-01, -4.7230e-02, -1.1380e-01, -4.0840e-02,\n","         5.7112e-03, -2.5453e-02,  6.4612e-02,  3.4492e-02,  2.0566e-02,\n","        -4.5267e-02, -3.4678e-02, -7.2612e-03, -1.8908e-02,  5.7890e-02,\n","        -4.2166e-02, -6.7557e-02,  5.6523e-02, -2.8467e-02,  3.5454e-02,\n","         1.5290e-02,  1.2768e-02, -2.8542e-02,  2.3154e-02, -2.0937e-01,\n","         4.4651e-02, -9.4332e-03, -1.6042e-02,  1.3285e-02, -1.3079e-02,\n","         5.2382e-04,  1.3041e-02, -2.7098e-02,  4.4549e-02, -8.7790e-03,\n","        -1.4647e-02,  9.1764e-02, -3.1280e-02,  2.3198e-01,  4.4123e-02,\n","         1.4304e-02, -5.7298e-02,  7.8618e-03, -1.0237e-03,  2.8485e-02,\n","         1.3268e-02, -9.5455e-03, -2.3109e-04, -2.0369e-02,  8.3394e-02,\n","        -7.1135e-02, -6.4807e-02, -6.1181e-03,  4.6791e-02, -9.2088e-03,\n","         3.4884e-02, -4.5029e-02,  2.7879e-01, -3.7818e-02, -5.4034e-02,\n","        -6.1790e-02, -3.8778e-02,  4.9349e-03,  2.4378e-02,  8.9025e-03,\n","        -3.5052e-03,  1.6581e-01,  5.8664e-02, -3.1299e-03,  2.7989e-02,\n","         2.5872e-02, -1.1119e-02,  7.6097e-02, -2.2228e-02, -1.9689e-02,\n","        -1.3784e-01, -6.6437e-02, -5.2913e-03,  1.7010e-03, -2.6449e-02,\n","         1.1717e-01, -1.1523e-01,  7.0097e-02, -8.2283e-02,  6.1100e-02,\n","        -1.2160e-02,  9.0952e-02,  7.5562e-03,  3.8820e-02,  1.9466e-02,\n","        -6.4488e-02, -9.7399e-01,  1.0671e-03, -7.2186e-03,  8.7493e-02,\n","        -1.1547e-01,  4.3738e-01,  5.4697e-03, -1.5715e-02,  2.8925e-02,\n","        -3.3470e-02, -4.2125e-02,  1.2895e-02, -2.9777e-02, -1.7015e-02,\n","        -2.2735e-02,  1.7061e-02,  4.9545e-02,  1.1104e-01, -5.8314e-03,\n","         5.7407e-02, -2.2805e-02,  2.0941e-02, -3.5016e-01, -2.1634e-02,\n","        -5.8145e-02, -2.1873e-02, -1.3668e-02,  1.2862e-02,  3.6718e-02,\n","         5.1902e-03,  1.0907e-02, -7.8232e-03, -4.5908e-02, -1.7366e-02,\n","        -2.8400e-02,  4.1859e-02, -1.0367e-01,  2.9875e-02, -4.3200e-02,\n","        -2.7472e-02,  7.6173e-03, -7.8905e-03, -4.4235e-01, -2.4563e-02,\n","        -1.7634e-02,  1.2442e-01,  3.7981e-02, -7.6377e-03, -4.1918e+00,\n","        -5.0516e-02,  2.9369e-02, -9.7174e-03,  7.4856e-05,  3.8322e-02,\n","        -2.1775e-01, -1.3928e-03, -4.3413e-02, -4.7812e-02,  1.0623e-02,\n","        -5.4639e-02, -5.3187e-01, -2.2528e-02,  1.0735e-02,  7.7141e-03,\n","        -1.1821e-03, -7.1923e-02, -6.6898e-02, -9.4570e-02,  1.8275e-02,\n","        -5.6802e-03,  3.3925e-02, -6.8035e-03, -2.1191e-02, -3.3668e-02,\n","        -4.5747e-02, -1.7164e-02, -6.4126e-02, -5.9322e-02,  6.6308e-03,\n","        -5.7392e-02, -2.9224e-02, -1.0237e-01, -2.1006e-02,  3.7682e-02,\n","        -8.3238e-03,  1.8629e-01, -3.0289e-02, -8.6108e-02, -3.3981e-02,\n","        -1.6380e-03,  9.5645e-05,  1.8391e-02,  6.6154e-03, -2.5787e-02,\n","        -5.4965e-02,  3.3532e-02,  7.6414e-02, -3.5418e-02,  1.5757e-04,\n","        -4.9215e-01, -1.7935e-02, -4.2474e-02, -3.6654e-02,  3.7187e-03,\n","         8.3721e-02, -7.3905e-02,  1.3349e-02, -8.1251e-01, -2.2964e+00,\n","        -2.3672e-02, -8.1334e-02,  1.5086e-01, -7.6905e-02, -3.1052e-02,\n","         2.1425e-02, -4.8389e-02, -1.4152e-02, -4.3935e-02, -3.7510e-02,\n","        -1.1541e-01,  6.2883e-02, -1.7672e-02,  1.0962e-02, -2.6148e-01,\n","         5.8860e-02,  4.1171e-02, -5.2769e-02, -5.3264e-01, -7.3070e-02,\n","        -3.0272e-02, -3.3503e-02, -2.3348e-02,  1.6839e-02,  1.3835e-02,\n","        -3.1535e-02, -1.2930e-01,  8.2034e-02, -1.7669e-02, -3.7012e-02,\n","        -5.3559e-02, -8.0793e-02, -4.5030e-02,  5.8326e-01, -2.8019e-02,\n","        -2.2854e-02, -2.9491e-02, -1.2646e-02, -1.9085e-02,  7.2778e-02,\n","        -2.9988e-02, -4.3035e-03, -2.3171e-02, -2.9115e-02,  2.8318e-03,\n","        -1.9056e-01, -3.6604e-02,  1.4934e-02, -7.2772e-02,  1.7382e-02,\n","         1.3184e-02,  3.3194e-02,  1.2090e-02, -6.7826e-02, -4.2046e-02,\n","         4.5765e+00,  3.8094e-02, -5.8475e-03, -3.3060e-02, -2.4420e-03,\n","         7.0572e-02, -8.5184e-03, -4.7140e-02, -3.5492e-02,  1.3906e-01,\n","         9.6806e-03,  3.7759e-03,  1.5214e+00,  1.5772e-02, -2.0146e-03,\n","         1.9806e-04, -2.5916e-02,  7.4553e-01,  2.2555e-02,  3.9150e-02,\n","        -4.0612e-02, -6.6488e-02, -1.4694e-02, -1.8814e-01, -2.5680e-02,\n","         2.7539e-01, -8.6698e-02, -5.4068e-02, -3.7796e-02,  1.7496e-01,\n","         1.0016e-01,  1.8288e-02,  1.9015e-02, -4.9247e-02, -1.1344e-01,\n","         3.2417e-03,  1.5069e-02, -2.3991e-02,  1.1169e-02,  5.5201e-02,\n","         6.8813e-02,  1.5437e-02,  1.4457e-02,  3.6382e-02,  3.3006e-02,\n","         1.6601e-03,  3.5841e-02,  2.3049e-02, -3.7833e-02, -8.8917e-01,\n","        -8.5626e-01,  7.6501e-01, -1.6650e-02,  5.3425e-03, -2.0975e-02,\n","        -2.0985e-02, -2.5421e-02,  1.1607e-03, -2.5669e-02,  1.1613e-04,\n","        -2.6443e-02, -1.2821e-02, -1.1060e-02, -6.4586e-02, -1.6700e-03,\n","         6.0491e-02,  7.3683e+00, -6.0230e-02, -2.9137e-02, -1.2580e-02,\n","        -5.3060e-02, -1.8582e-02, -1.7887e-02, -2.9617e-01,  8.0085e-02,\n","         5.4053e-02, -2.8139e-02, -8.7857e-03,  1.0940e-02, -1.9958e-02,\n","        -3.9983e-02, -2.5002e-01,  9.0808e-02, -2.3754e-03,  4.6434e-03,\n","        -6.0453e-02,  6.9979e-03, -3.8280e-02, -5.8416e-02, -1.8324e-02,\n","        -2.6310e-02,  8.2354e-02,  8.0878e-03, -6.1616e-02, -4.6368e-02,\n","        -1.1206e-01,  2.2739e-01, -1.9157e-01, -2.8906e-02,  3.9452e-03,\n","         1.5285e-02, -8.9685e-03, -4.1765e-02,  2.6316e-02, -4.1366e-02,\n","        -6.1208e-03, -1.0726e-02, -5.3724e-02, -1.1064e-02,  5.4608e-02,\n","         1.2026e-01, -5.9791e-02, -1.1439e-02, -3.0206e-01, -6.6082e-03,\n","         7.5021e-02,  3.3470e-02,  3.1955e-02, -8.9656e-03, -2.4131e-02,\n","         2.0099e-02,  1.7902e-01, -4.7128e-02,  3.5336e-02, -5.9965e-02,\n","        -1.0729e-02,  2.5535e-02, -3.2598e-02, -1.1571e-02,  3.9279e-03,\n","        -4.6097e-02, -1.0125e-02, -2.5468e-02, -5.3132e-02,  1.0430e-03,\n","        -5.7897e-02,  1.1562e-01,  1.6695e-02, -9.3858e-03, -1.0967e-01,\n","         1.1385e-01, -1.2587e-02, -2.9855e-02,  6.6515e-03,  1.1277e-03,\n","        -8.8445e-02,  3.5600e-02, -4.7699e-02, -6.5989e-03, -2.5376e-02,\n","        -5.9169e-02, -2.6125e-02,  3.5664e-02,  4.2330e-02, -2.8365e-02,\n","        -1.1422e-01, -1.2717e-02, -5.4891e-02,  2.6614e-02, -2.0510e-02,\n","        -4.0455e-02,  2.5847e-02,  1.8912e-02,  3.9873e-03,  1.2472e-02,\n","        -1.5778e-02, -4.3945e-02, -3.9807e-02,  4.9368e-02, -3.4811e-02,\n","        -3.6738e-02,  6.0444e-02, -3.1983e-02,  2.1002e-02,  5.9787e-02,\n","        -5.9418e-02, -5.6518e-02, -1.9562e-02, -1.0192e-01, -7.3266e-02,\n","         6.0253e-03, -1.2703e-03, -1.7658e-02, -1.7046e-04, -2.2049e-02,\n","        -4.4822e-02, -3.0320e-02,  6.1333e-03, -7.3983e-02, -3.9071e-02,\n","         7.1127e-02, -1.9383e-02,  8.1372e-02, -3.7656e-02, -3.9241e-02,\n","         1.1307e-02,  1.9240e-02, -5.2134e-01, -5.7102e-02,  1.2872e-02,\n","         2.6437e-02, -2.4696e-02, -9.5752e-04, -2.9517e-03, -4.0031e-02,\n","        -2.6403e-01, -1.8459e-02, -4.3772e-02, -6.4264e-02,  6.2169e-04,\n","        -4.2976e-01, -5.2110e-02, -2.7672e-02, -1.3235e-01, -2.0824e-02,\n","        -2.6675e-02, -2.9728e-02,  4.1735e-02,  1.0057e-02,  5.2260e-02,\n","        -7.4459e-02, -2.1856e-02, -1.4217e-02, -6.5240e-02, -2.2235e-02,\n","         1.6941e-01, -9.0145e-03,  2.4160e-02, -2.9787e-02,  1.4448e-01,\n","         1.9557e-02, -5.5833e-03, -5.0508e-02,  3.8701e-02, -2.9668e-02,\n","         3.1690e-02, -6.8745e-03, -1.9214e-02,  2.6903e-01, -7.6019e-03,\n","        -1.5625e-01, -2.6517e-02, -4.4908e-03, -3.7796e-02, -2.0304e-01,\n","        -4.0343e-02, -2.9758e-02,  3.2639e-02,  6.7867e-02,  2.9190e-02,\n","        -8.3563e-02, -7.6448e-02, -7.0672e-02,  9.8573e-03,  3.5905e-02,\n","         4.4131e-02, -5.1119e-03, -1.0302e-02,  1.4177e-02,  1.2777e-02,\n","         4.4026e-02,  2.6884e-02,  5.4663e-02, -5.9550e-02,  2.1386e-03,\n","        -6.3401e-02, -4.6159e-02,  1.7755e-02,  9.3017e-03, -1.3974e-02,\n","        -2.5991e-02,  6.9902e-02, -2.0447e-02, -8.0996e-01, -7.3992e-03,\n","        -6.9028e-02, -2.3947e-01, -1.0159e-01, -3.5832e-02, -1.9236e-01,\n","        -4.7394e-02, -1.6717e-03,  5.3983e-02,  1.0544e-02,  1.4304e-02,\n","        -4.8561e-02, -4.2476e-02, -8.7717e-04,  1.4124e-01,  9.4687e-04,\n","        -4.8157e-02, -1.1013e-01, -4.4088e-02, -4.0713e-02, -5.9785e-02,\n","        -1.6111e-02,  8.9078e-02, -4.9754e-02, -6.3769e-02,  1.4608e-02,\n","        -4.4700e-02,  1.0339e-02,  3.8344e-02,  5.5821e-02, -4.3954e-02,\n","         4.0682e-02,  1.2429e-02,  1.1265e-03, -9.7955e-02, -3.3169e-02,\n","        -5.4159e-02, -6.5162e-02, -6.4554e-02,  3.4367e-02, -5.5316e-02,\n","         1.6239e-01, -9.1327e-03,  2.1942e-02,  1.7757e-03, -7.4256e-02,\n","         2.2889e-02, -9.6414e-02, -2.9426e-02,  2.1863e-02, -2.4523e-02,\n","         5.9060e-02,  2.9360e-01,  6.2494e-02,  3.8487e-04,  9.1539e-02,\n","         3.1131e-02,  3.3019e-03,  4.5760e-01, -5.7599e-02,  3.4124e-02,\n","        -1.0095e-02, -2.5538e-02,  3.4450e-02], device='cuda:0',\n","       requires_grad=True)\n","unembed.W_U: torch.Size([768, 50257])\n","Parameter containing:\n","tensor([[-0.1101,  0.0403, -0.1275,  ..., -0.0445,  0.1860,  0.0514],\n","        [-0.0393, -0.0486,  0.0479,  ..., -0.0548,  0.0167, -0.0277],\n","        [ 0.0331,  0.0462,  0.1841,  ...,  0.0123,  0.0461,  0.0499],\n","        ...,\n","        [-0.1364,  0.0861,  0.0899,  ...,  0.1044, -0.0963,  0.0070],\n","        [ 0.0151,  0.0025, -0.1297,  ...,  0.0978,  0.0785,  0.1552],\n","        [ 0.0453,  0.0432, -0.0879,  ..., -0.0695, -0.0225,  0.1207]],\n","       device='cuda:0', requires_grad=True)\n","unembed.b_U: torch.Size([50257])\n","Parameter containing:\n","tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)\n","Output shape (our layer): torch.Size([1, 35, 50257])\n","Reference output shape (GPT-2): torch.Size([1, 35, 50257]) \n","\n","100.00% of the values are correct\n","\n","=== Example Differences (First 10 Elements) ===\n","tensor([0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n","        0.0002], device='cuda:0', grad_fn=<SliceBackward0>)\n"]}]},{"cell_type":"code","execution_count":21,"metadata":{"id":"RcNrSDzgVjQg","executionInfo":{"status":"ok","timestamp":1726690334507,"user_tz":-180,"elapsed":1913,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}}},"outputs":[],"source":["demo_gpt2 = DemoTransformer(Config(debug=False)).to(device)\n","demo_gpt2.load_state_dict(reference_gpt2.state_dict(), strict=False)\n","\n","demo_logits = demo_gpt2(tokens)"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rb2_gL9uVmPj","outputId":"f7ab1fd2-8232-4641-809b-d49241d080a8","executionInfo":{"status":"ok","timestamp":1726690336156,"user_tz":-180,"elapsed":6,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["DemoTransformer(\n","  (embed): Embed()\n","  (pos_embed): PosEmbed()\n","  (blocks): ModuleList(\n","    (0-11): 12 x TransformerBlock(\n","      (ln1): LayerNorm()\n","      (attn): Attention()\n","      (ln2): LayerNorm()\n","      (mlp): MLP()\n","    )\n","  )\n","  (ln_final): LayerNorm()\n","  (unembed): Unembed()\n",")"]},"metadata":{},"execution_count":22}],"source":["demo_gpt2"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fkrsjh5SVpl3","outputId":"3f5bb476-bc1f-41f7-b2d5-b1ab6d6259db","executionInfo":{"status":"ok","timestamp":1726690338239,"user_tz":-180,"elapsed":4,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["HookedTransformer(\n","  (embed): Embed()\n","  (hook_embed): HookPoint()\n","  (pos_embed): PosEmbed()\n","  (hook_pos_embed): HookPoint()\n","  (blocks): ModuleList(\n","    (0-11): 12 x TransformerBlock(\n","      (ln1): LayerNorm(\n","        (hook_scale): HookPoint()\n","        (hook_normalized): HookPoint()\n","      )\n","      (ln2): LayerNorm(\n","        (hook_scale): HookPoint()\n","        (hook_normalized): HookPoint()\n","      )\n","      (attn): Attention(\n","        (hook_k): HookPoint()\n","        (hook_q): HookPoint()\n","        (hook_v): HookPoint()\n","        (hook_z): HookPoint()\n","        (hook_attn_scores): HookPoint()\n","        (hook_pattern): HookPoint()\n","        (hook_result): HookPoint()\n","      )\n","      (mlp): MLP(\n","        (hook_pre): HookPoint()\n","        (hook_post): HookPoint()\n","      )\n","      (hook_attn_in): HookPoint()\n","      (hook_q_input): HookPoint()\n","      (hook_k_input): HookPoint()\n","      (hook_v_input): HookPoint()\n","      (hook_mlp_in): HookPoint()\n","      (hook_attn_out): HookPoint()\n","      (hook_mlp_out): HookPoint()\n","      (hook_resid_pre): HookPoint()\n","      (hook_resid_mid): HookPoint()\n","      (hook_resid_post): HookPoint()\n","    )\n","  )\n","  (ln_final): LayerNorm(\n","    (hook_scale): HookPoint()\n","    (hook_normalized): HookPoint()\n","  )\n","  (unembed): Unembed()\n",")"]},"metadata":{},"execution_count":23}],"source":["reference_gpt2"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dyiHpWcvV2mn","outputId":"facf3f61-247e-4831-d54b-b403b78d6e3c","executionInfo":{"status":"ok","timestamp":1726690346223,"user_tz":-180,"elapsed":1057,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Avg cross entropy loss: 4.5647\n","Avg cross entropy loss for uniform distribution: 10.824905\n","Avg probability assigned to correct token: 0.087902\n"]}],"source":["def get_log_probs(\n","    logits: Float[Tensor, \"batch posn d_vocab\"],\n","    tokens: Int[Tensor, \"batch posn\"]\n",") -> Float[Tensor, \"batch posn-1\"]:\n","\n","    log_probs = logits.log_softmax(dim=-1)\n","    # Get logprobs the first seq_len-1 predictions (so we can compare them with the actual next tokens)\n","    log_probs_for_tokens = log_probs[:, :-1].gather(dim=-1, index=tokens[:, 1:].unsqueeze(-1)).squeeze(-1)\n","\n","    return log_probs_for_tokens\n","\n","\n","pred_log_probs = get_log_probs(demo_logits, tokens)\n","print(f\"Avg cross entropy loss: {-pred_log_probs.mean():.4f}\")\n","print(f\"Avg cross entropy loss for uniform distribution: {math.log(demo_gpt2.cfg.d_vocab):4f}\")\n","print(f\"Avg probability assigned to correct token: {pred_log_probs.exp().mean():4f}\")"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":87,"referenced_widgets":["f4f8cad9ecad43f9b70c95cd50389a1c","f331e3d29cb44929b3415228e7d74a6e","297d6a1b2b2c423d82b5d55be1618bb0","fd8feecfbadf44ea9f85f6c407dc3d06","fbd8f1c95a8a44dca01830d15498b5ae","225ef4d875d543348fea6691951ba1ec","6bf1bcb526204b039218022b27b508d0","35b4ab69177e480c92a944fbe62ed71f","404fcf3b39504f958eef710df2abe503","4c35e9ae6dcc466e9d9aa39c45f37115","80c97cc99669486ca17deaf79c28f857"]},"id":"jFqu7OlPV685","outputId":"ab44b630-891c-4ddc-93d7-62a7974c1637","executionInfo":{"status":"ok","timestamp":1726690352002,"user_tz":-180,"elapsed":2456,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4f8cad9ecad43f9b70c95cd50389a1c"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["The Total Perspective Vortex derives its picture of the whole Universe on the principle of the total perspective. The total perspective is the view of the whole Universe from the point of view of the observer. The total perspective is the view of the whole Universe from the point of view of the observer. The total perspective is the view of the whole Universe from the point of view of the observer. The total perspective is the view of the whole Universe from the point of view of the observer. The total perspective is the view of the whole Universe from the point of view of the observer. The\n"]}],"source":["test_string = '''The Total Perspective Vortex derives its picture of the whole Universe on the principle of'''\n","for i in tqdm(range(100)):\n","    test_tokens = reference_gpt2.to_tokens(test_string).to(device)\n","    demo_logits = demo_gpt2(test_tokens)\n","    test_string += reference_gpt2.tokenizer.decode(demo_logits[-1, -1].argmax())\n","\n","print(test_string)"]},{"cell_type":"markdown","metadata":{"id":"wG0zGo4iJFMa"},"source":["# Сэмплирование - 10 баллов\n","Теперь разберем различные техники сэмплирования. За каждую из функций `apply_temperature`, `apply_frequency_penalty`, `sample_basic`, `sample_top_k`, `sample_top_p` по 2 балла."]},{"cell_type":"markdown","metadata":{"id":"dK5fbWLLWwSS"},"source":["\n","1. **Temperature Sampling**:\n","   - Применяется первым, поскольку изменение температуры изменяет масштабы логитов перед дальнейшими операциями.\n","\n","2. **Frequency Penalty**:\n","   - Применяется следующим, чтобы учесть частоты токенов до того, как логиты будут обрезаны методами top-k или top-p.\n","\n","3. **Top-k Sampling**:\n","   - Применяется после temperature sampling и frequency penalty, так как он отбирает фиксированное количество наиболее вероятных токенов.\n","\n","4. **Top-p (Nucleus Sampling)**:\n","   - Применяется после top-k sampling, чтобы отфильтровать токены на основе совокупной вероятности."]},{"cell_type":"markdown","metadata":{"id":"TgdKJfPfbR-J"},"source":["Обозначим размер словаря для удобства $\\Sigma = vocab\\_size$\n","\n","Пусть $ \\text{logits} \\in \\mathbb{R}^{\\text{seq} \\times \\Sigma} $:\n","\n","1. **Temperature Sampling**:\n","   $$\n","   \\text{logits}'_{i,j} = \\frac{\\text{logits}_{i,j}}{T} \\quad \\forall \\ i \\in [1, \\text{seq}], \\ j \\in [1, |vocab_size|]\n","   $$\n","\n","2. **Frequency Penalty**:\n","   $$\n","   \\text{penalty}(t_j) = 1 + \\alpha \\cdot f(t_j) \\\\\n","   \\text{logits}''_{i,j} = \\frac{\\text{logits}'_{i,j}}{\\text{penalty}(t_j)} \\quad \\forall \\ i \\in [1, \\text{seq}], \\ j \\in [1, \\Sigma]\n","   $$\n","\n","3. **Top-k Sampling**:\n","   $$\n","   top\\_k\\_indices_i = \\text{argtop-k}(\\text{logits}''_i, k) \\quad \\forall \\ i \\in [1, \\text{seq}] \\\\\n","   \\text{mask}_{i,j} =\n","   \\begin{cases}\n","   1 & \\text{если} \\ j \\in top\\_k\\_indices_i \\\\\n","   0 & \\text{иначе}\n","   \\end{cases} \\\\\n","   \\text{logits}'''_{i,j} = \\text{logits}''_{i,j} \\cdot \\text{mask}_{i,j} \\quad \\forall \\ i \\in [1, \\text{seq}], \\ j \\in [1, \\Sigma]\n","   $$\n","\n","4. **Top-p (Nucleus Sampling)**:\n","   $$\n","   sorted\\_logits_i, sorted\\_indices_i = \\text{sort}(\\text{logits}'''_i, \\text{descending=True}) \\quad ∀ \\ i \\in [1, \\text{seq}] \\\\\n","   probs_i = softmax(sorted\\_logits_i) \\quad \\\\\n","    cumulative\\_probs_{i,j} = \\sum_{k=1}^{j} \\text{probs}_{i,k} \\quad \\forall \\ i \\in [1, \\text{seq}], \\ j \\in [1, \\Sigma\n","    \\quad \\forall \\ i \\in [1, \\text{seq}] \\\\\n","   top\\_p\\_mask_{i,j} =\n","   \\begin{cases}\n","   1, & cumulative\\_probs_{i,j} \\leq p \\\\\n","   0 &\n","   \\end{cases} \\\\\n","   \\text{logits}^{\\text{final}}_{i,j} = sorted\\_logits_{i,j} \\cdot top\\_p\\_mask_{i,j} \\quad \\forall \\ i \\in [1, \\text{seq}], \\ j \\in [1, \\Sigma]\n","   $$\n","\n","5. **Softmax**:\n","   $$\n","   \\mathbf{probs}_{i,j} = \\text{softmax}(\\text{logits}^{\\text{final}}_{i,j}) \\quad \\forall \\ i \\in [1, \\text{seq}], \\ j \\in [1, |\\Sigma|]\n","\\\\\n","   \\mathbf{probs}_{i,j} = \\frac{e^{\\text{logits}^{\\text{final}}_{i,j}}}{\\sum_{k=1}^{|\\Sigma|} e^{\\text{logits}^{\\text{final}}_{i,k}}}\n","   $$"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"KhLvuGw5UpOh","executionInfo":{"status":"ok","timestamp":1726690368559,"user_tz":-180,"elapsed":1973,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}}},"outputs":[],"source":["model_cfg = Config()\n","model = DemoTransformer(model_cfg).to(device)\n","model.load_state_dict(reference_gpt2.state_dict(), strict=False) # загружаем веса gpt2\n","\n","tokenizer = reference_gpt2.tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"opp-1FmGWgGn"},"outputs":[],"source":["\"\"\"\n","class TransformerSampler:\n","\n","    def __init__(self, model: DemoTransformer, tokenizer: GPT2TokenizerFast):\n","        self.model = model\n","        self.cfg = model.cfg\n","        self.tokenizer = tokenizer\n","\n","    @t.inference_mode()\n","    def sample(self, prompt: str, max_tokens_generated=100, verbose=False, **kwargs):\n","        '''\n","        Возвращаем сгенерированную строку, включая промпт.\n","        Генерация заканчивается после max_tokens_generated токенов или по генерации EOS.\n","\n","        kwargs передаются в sample_next_token\n","        '''\n","        pass\n","\n","\n","\n","    @staticmethod\n","    def sample_next_token(\n","        input_ids: Int[Tensor, \"seq_len\"],\n","        logits: Float[Tensor, \"d_vocab\"],\n","        temperature=1.0,\n","        top_k=0,\n","        top_p=0.0,\n","        frequency_penalty=0.0,\n","        seed=None\n","    ):\n","        assert input_ids.ndim == 1, \"input_ids should be a 1D sequence of token ids\"\n","        assert temperature >= 0, \"Temperature should be non-negative\"\n","        assert 0 <= top_p <= 1.0, \"Top-p must be a probability\"\n","        assert 0 <= top_k, \"Top-k must be non-negative\"\n","        assert not (top_p != 0 and top_k != 0), \"At most one of top-p and top-k supported\"\n","\n","        # Set random seeds for reproducibility\n","        if seed is not None:\n","            t.manual_seed(seed)\n","            np.random.seed(seed)\n","\n","        # Apply all the specialized sampling methods\n","        if temperature == 0:\n","            return TransformerSampler.greedy_search(logits)\n","        elif temperature != 1.0:\n","            logits = TransformerSampler.apply_temperature(logits, temperature)\n","        if frequency_penalty != 0.0:\n","            logits = TransformerSampler.apply_frequency_penalty(input_ids, logits, frequency_penalty)\n","        if top_k > 0:\n","            return TransformerSampler.sample_top_k(logits, top_k)\n","        if top_p > 0.0:\n","            return TransformerSampler.sample_top_p(logits, top_p)\n","        return TransformerSampler.sample_basic(logits)\n","\n","\n","    @staticmethod\n","    def greedy_search(logits: Float[Tensor, \"d_vocab\"]) -> int:\n","        '''\n","        Возвращаем самый вероятный токен жадно\n","        '''\n","        out = logits.argmax().item()\n","        return out\n","\n","\n","    @staticmethod\n","    def apply_temperature(logits: Float[Tensor, \"d_vocab\"], temperature: float) -> Float[Tensor, \"d_vocab\"]:\n","        '''\n","        Применяем температуру к логитам\n","        '''\n","        pass\n","\n","\n","    @staticmethod\n","    def apply_frequency_penalty(input_ids: Int[Tensor, \"seq_len\"], logits: Float[Tensor, \"d_vocab\"], freq_penalty: float) -> Float[Tensor, \"d_vocab\"]:\n","        '''\n","        Применяем frequency penalty к логитам\n","        '''\n","        pass\n","\n","\n","    @staticmethod\n","    def sample_basic(logits: Float[Tensor, \"d_vocab\"]) -> int:\n","        '''\n","        Простое сэмплирование! Тут нам поможет torch.multinomial\n","        '''\n","        pass\n","\n","\n","    @staticmethod\n","    def sample_top_k(logits: Float[Tensor, \"d_vocab\"], k: int) -> int:\n","        '''\n","        top-k сэмплирование\n","        '''\n","        pass\n","\n","\n","    @staticmethod\n","    def sample_top_p(logits: Float[Tensor, \"d_vocab\"], top_p: float, min_tokens_to_keep: int = 1) -> int:\n","        '''\n","        top_p сэмплирование\n","        '''\n","        pass\n","\n","\"\"\""]},{"cell_type":"code","source":["class TransformerSampler:\n","\n","    def __init__(self, model: DemoTransformer, tokenizer: GPT2TokenizerFast):\n","        self.model = model\n","        self.cfg = model.cfg\n","        self.tokenizer = tokenizer\n","        self.model = model.to(model.device)  # Переносим модель на нужное устройство\n","\n","    @t.inference_mode()\n","    def sample(self, prompt: str, max_tokens_generated=100, verbose=False, **kwargs):\n","        '''\n","        Возвращаем сгенерированную строку, включая промпт.\n","        Генерация заканчивается после max_tokens_generated токенов или по генерации EOS.\n","\n","        kwargs передаются в sample_next_token\n","        '''\n","        input_ids = self.tokenizer(prompt, return_tensors='pt').input_ids.to(self.model.device)\n","\n","        for _ in range(max_tokens_generated):\n","            # Прогоняем через модель, получаем логиты\n","            logits = self.model(input_ids)[0, -1, :]\n","\n","            # Выбираем следующий токен с помощью sample_next_token\n","            next_token_id = self.sample_next_token(input_ids[0], logits, **kwargs)\n","\n","            # Преобразуем токен в тензор\n","            next_token_tensor = torch.tensor([next_token_id], device=input_ids.device)\n","\n","            # Если сгенерирован токен конца предложения (EOS), останавливаем генерацию\n","            if next_token_id == self.tokenizer.eos_token_id:\n","                break\n","\n","            # Добавляем новый токен к последовательности\n","            input_ids = torch.cat([input_ids, next_token_tensor.unsqueeze(0)], dim=1)\n","\n","        # Преобразуем в текст\n","        return self.tokenizer.decode(input_ids[0], skip_special_tokens=True)\n","\n","\n","    @staticmethod\n","    def sample_next_token(\n","        input_ids: Int[Tensor, \"seq_len\"],\n","        logits: Float[Tensor, \"d_vocab\"],\n","        temperature=1.0,\n","        top_k=0,\n","        top_p=0.0,\n","        frequency_penalty=0.0,\n","        seed=None\n","    ):\n","        assert input_ids.ndim == 1, \"input_ids should be a 1D sequence of token ids\"\n","        assert temperature >= 0, \"Temperature should be non-negative\"\n","        assert 0 <= top_p <= 1.0, \"Top-p must be a probability\"\n","        assert 0 <= top_k, \"Top-k must be non-negative\"\n","        assert not (top_p != 0 and top_k != 0), \"At most one of top-p and top-k supported\"\n","\n","        # Set random seeds for reproducibility\n","        if seed is not None:\n","            t.manual_seed(seed)\n","            np.random.seed(seed)\n","\n","        # Apply all the specialized sampling methods\n","        if temperature == 0:\n","            return TransformerSampler.greedy_search(logits)\n","        elif temperature != 1.0:\n","            logits = TransformerSampler.apply_temperature(logits, temperature)\n","        if frequency_penalty != 0.0:\n","            logits = TransformerSampler.apply_frequency_penalty(input_ids, logits, frequency_penalty)\n","        if top_k > 0:\n","            return TransformerSampler.sample_top_k(logits, top_k)\n","        if top_p > 0.0:\n","            return TransformerSampler.sample_top_p(logits, top_p)\n","        return TransformerSampler.sample_basic(logits)\n","\n","    @staticmethod\n","    def greedy_search(logits: Float[Tensor, \"d_vocab\"]) -> int:\n","        '''\n","        Возвращаем самый вероятный токен жадно\n","        '''\n","        out = logits.argmax().item()\n","        return out\n","\n","    @staticmethod\n","    def apply_temperature(logits: Float[Tensor, \"d_vocab\"], temperature: float) -> Float[Tensor, \"d_vocab\"]:\n","        \"\"\"\n","        Применяет температуру к логитам, масштабируя их.\n","        Чем ниже температура, тем острее распределение вероятностей,\n","        что делает выбор токенов более уверенным.\n","\n","        :param logits: Тензор логитов с вероятностями для каждого токена\n","        :param temperature: Параметр температуры (должен быть больше 0)\n","        :return: Логиты после применения температуры\n","        \"\"\"\n","        if temperature == 0:\n","            raise ValueError(\"Temperature should be greater than zero.\")\n","        return logits / temperature\n","\n","    @staticmethod\n","    def sample_next_token(\n","        input_ids: Int[Tensor, \"seq_len\"],\n","        logits: Float[Tensor, \"d_vocab\"],\n","        temperature=1.0,\n","        top_k=0,\n","        top_p=0.0,\n","        frequency_penalty=0.0,\n","        seed=None\n","    ):\n","        assert input_ids.ndim == 1, \"input_ids should be a 1D sequence of token ids\"\n","        assert temperature >= 0, \"Temperature should be non-negative\"\n","        assert 0 <= top_p <= 1.0, \"Top-p must be a probability\"\n","        assert 0 <= top_k, \"Top-k must be non-negative\"\n","        assert not (top_p != 0 and top_k != 0), \"At most one of top-p and top-k supported\"\n","\n","        # Set random seeds for reproducibility\n","        if seed is not None:\n","            t.manual_seed(seed)\n","            np.random.seed(seed)\n","\n","        # Apply all the specialized sampling methods\n","        if temperature == 0:\n","            return TransformerSampler.greedy_search(logits)  # Применяем жадный поиск\n","        elif temperature != 1.0:\n","            logits = TransformerSampler.apply_temperature(logits, temperature)\n","        if frequency_penalty != 0.0:\n","            logits = TransformerSampler.apply_frequency_penalty(input_ids, logits, frequency_penalty)\n","        if top_k > 0:\n","            return TransformerSampler.sample_top_k(logits, top_k)\n","        if top_p > 0.0:\n","            return TransformerSampler.sample_top_p(logits, top_p)\n","        return TransformerSampler.sample_basic(logits)\n","\n","\n","    @staticmethod\n","    def apply_frequency_penalty(input_ids: Int[Tensor, \"seq_len\"], logits: Float[Tensor, \"d_vocab\"], freq_penalty: float) -> Float[Tensor, \"d_vocab\"]:\n","        '''\n","        Применяем frequency penalty к логитам.\n","        Часто встречающиеся токены получают штраф, уменьшая вероятность их повторного выбора.\n","        '''\n","        # Создаем тензор для хранения частоты встречаемости каждого токена в последовательности\n","        token_counts = torch.bincount(input_ids, minlength=logits.size(-1)).float()\n","\n","        # Применяем штраф к логитам на основе частоты токенов\n","        logits = logits - freq_penalty * token_counts\n","\n","        return logits\n","\n","    @staticmethod\n","    def sample_basic(logits: Float[Tensor, \"d_vocab\"]) -> int:\n","        '''\n","        Простое сэмплирование! Тут нам поможет torch.multinomial.\n","        '''\n","        # Применяем softmax к логитам для получения распределения вероятностей\n","        probs = torch.softmax(logits, dim=-1)\n","\n","        # Используем multinomial для сэмплирования токена\n","        sampled_token = torch.multinomial(probs, num_samples=1).item()\n","\n","        return sampled_token\n","\n","    @staticmethod\n","    def sample_top_k(logits: Float[Tensor, \"d_vocab\"], k: int) -> int:\n","        '''\n","        top-k сэмплирование\n","        '''\n","        # Обрезаем логиты, оставляя только k наибольших значений\n","        top_k_logits, _ = torch.topk(logits, k)\n","\n","        # Создаем маску для обнуления всех логитов, кроме top-k\n","        mask = logits < top_k_logits[..., -1, None]\n","        logits[mask] = -float('inf')\n","\n","        # Применяем softmax к обрезанным логитам\n","        probs = torch.softmax(logits, dim=-1)\n","\n","        # Сэмплируем токен с помощью multinomial\n","        sampled_token = torch.multinomial(probs, num_samples=1).item()\n","\n","        return sampled_token\n","\n","\n","    @staticmethod\n","    def sample_top_p(logits: Float[Tensor, \"d_vocab\"], top_p: float, min_tokens_to_keep: int = 1) -> int:\n","        '''\n","        top-p сэмплирование\n","        '''\n","        # Применяем softmax для получения вероятностей\n","        probs = torch.softmax(logits, dim=-1)\n","\n","        # Сортируем вероятности и логиты по убыванию вероятности\n","        sorted_probs, sorted_indices = torch.sort(probs, descending=True)\n","\n","        # Вычисляем кумулятивную сумму вероятностей\n","        cumulative_probs = torch.cumsum(sorted_probs, dim=-1)\n","\n","        # Находим индекс, где cumulative_probs превышает top_p\n","        cutoff_idx = torch.searchsorted(cumulative_probs, top_p)\n","\n","        # Обрезаем все логиты, которые идут после порогового значения\n","        cutoff_idx = max(cutoff_idx.item(), min_tokens_to_keep)\n","        logits[sorted_indices[cutoff_idx:]] = -float('inf')\n","\n","        # Применяем softmax к обрезанным логитам\n","        probs = torch.softmax(logits, dim=-1)\n","\n","        # Сэмплируем токен\n","        sampled_token = torch.multinomial(probs, num_samples=1).item()\n","\n","        return sampled_token\n"],"metadata":{"id":"8LW7vWfu4mf_","executionInfo":{"status":"ok","timestamp":1726690377035,"user_tz":-180,"elapsed":1011,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tear0Nn0WjZY","outputId":"549017d6-71e1-4da7-b13b-4f694fb33a2d","executionInfo":{"status":"ok","timestamp":1726690385596,"user_tz":-180,"elapsed":481,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Greedy decoding with prompt: 'Jingle bells, jingle bells, jingle all the way'\n","\n","Your model said: 'Jingle bells, jingle bells, jingle all the way up to the top of the mountain.'\n","\n","Tests passed!\n"]}],"source":["sampler = TransformerSampler(model, tokenizer)\n","\n","prompt = \"Jingle bells, jingle bells, jingle all the way\"\n","print(f\"Greedy decoding with prompt: {prompt!r}\\n\")\n","\n","output = sampler.sample(prompt, max_tokens_generated=8, temperature=0.0)\n","print(f\"Your model said: {output!r}\\n\")\n","\n","expected = \"Jingle bells, jingle bells, jingle all the way up to the top of the mountain.\"\n","assert output == expected\n","\n","print(\"Tests passed!\")"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E3VYdChTdNLc","outputId":"a7092e19-432f-45b2-ca40-0ce2b1cd7d4c","executionInfo":{"status":"ok","timestamp":1726690389197,"user_tz":-180,"elapsed":516,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["A low temperature \"sharpens\" or \"peaks\" the distribution:  tensor([  0.0000, 693.1472])\n","A high temperature flattens the distribution:  tensor([0.0000, 0.0007])\n","Tests passed!\n"]}],"source":["logits = t.tensor([1, 2]).log()\n","\n","cold_logits = TransformerSampler.apply_temperature(logits, temperature=0.001)\n","print('A low temperature \"sharpens\" or \"peaks\" the distribution: ', cold_logits)\n","t.testing.assert_close(cold_logits, 1000.0 * logits)\n","\n","hot_logits = TransformerSampler.apply_temperature(logits, temperature=1000.0)\n","print(\"A high temperature flattens the distribution: \", hot_logits)\n","t.testing.assert_close(hot_logits, 0.001 * logits)\n","\n","print(\"Tests passed!\")"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J0no5kj-dTos","outputId":"db54b57b-0f43-45ce-aeeb-9e9193d21c48","executionInfo":{"status":"ok","timestamp":1726690391234,"user_tz":-180,"elapsed":4,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Tests passed!\n"]}],"source":["bieber_prompt = \"And I was like Baby, baby, baby, oh Like, Baby, baby, baby, no Like, Baby, baby, baby, oh I thought you'd always be mine, mine\"\n","input_ids = tokenizer.encode(bieber_prompt, return_tensors=\"pt\")\n","logits = t.ones(tokenizer.vocab_size)\n","penalized_logits = TransformerSampler.apply_frequency_penalty(input_ids.squeeze(), logits, 2.0)\n","\n","assert penalized_logits[5156].item() == -11, \"Expected 6 occurrences of ' baby' with leading space, 1-2*6=-11\"\n","assert penalized_logits[14801].item() == -5, \"Expected 3 occurrences of ' Baby' with leading space, 1-2*3=-5\"\n","\n","print(\"Tests passed!\")"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":86,"referenced_widgets":["96efcb1fa583440cbef05d4aa4de7dc8","312f6c82b0644746b51aafb8f0d6e66d","aa539d9ddf414ad2bd8ec8725afba3b1","e0c2f547697a49138dac8d61c3f7c4b2","a002a7f1aea641f38f5b77aad81092c8","530526a7fb4d4ebcb91a20feba0e7f39","a81c71e60d584752a17533b6eaac68f2","65b3fdc7757f4126b2e0c261fd99f59d","d95d9d037409404d8dcca81d5580b2d0","23184f4f5bae48acbb07029e5925ea7a","68a47d916535453dbc96c31b07585f1c"]},"id":"AjQi5zDMWtTJ","outputId":"df1b8abf-6d17-48b8-bbc2-68544d31c8b1","executionInfo":{"status":"ok","timestamp":1726690590815,"user_tz":-180,"elapsed":7445,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/10000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96efcb1fa583440cbef05d4aa4de7dc8"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Word: ' church'. Expected freq 0.6384, observed freq 1.0000\n","Word: ' house' . Expected freq 0.3616, observed freq 0.0000\n"]}],"source":["prompt = \"John and Mary went to the\"\n","input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n","logits = model(input_ids)[0, -1]\n","\n","expected_top_10pct = {\n","    \" church\": 0.0648,\n","    \" house\": 0.0367, # These are the two most likely tokens, and add up to >10%\n","}\n","top_10pct_sum = sum(expected_top_10pct.values())\n","\n","observed_freqs = defaultdict(int)\n","\n","N = 10000\n","for _ in tqdm(range(N)):\n","    token = TransformerSampler.sample_next_token(input_ids.squeeze(), logits, top_p=0.1)\n","    observed_freqs[tokenizer.decode(token)] += 1\n","\n","for word in expected_top_10pct:\n","    expected_freq = expected_top_10pct[word] / top_10pct_sum\n","    observed_freq = observed_freqs[word] / N\n","    print(f\"Word: {word!r:<9}. Expected freq {expected_freq:.4f}, observed freq {observed_freq:.4f}\")\n","    assert abs(observed_freq - expected_freq) < 0.4, \"Try increasing N if this fails by a small amount.\""]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":86,"referenced_widgets":["bad1b429679f45a8a9880fea33172aaa","0e0d078a9d214fe9a3a27b4a1122c2c1","aea052813b2746ff88d21fdc50f37d16","930cac735865401285c284e6e4e8094f","880058612c16466da37f87ca4dfef897","376b93ca857c4f0b8336512598c7dc60","21b6130c332f42599c68324ef8bf16fc","c378b0b15d09491ba00fe0fe9027af39","4750f63552a94812a5e08ab1b88bd934","94e0ab5c97754afc988235919f07f085","25ff5eca46a1407b9d57ade8aa9f22a0"]},"id":"VndvR_GzczQ2","outputId":"21d1773b-4e6f-4dd2-a298-3adb82ce263f","executionInfo":{"status":"ok","timestamp":1726690560248,"user_tz":-180,"elapsed":7388,"user":{"displayName":"Mikhail Puzitskiy","userId":"03381470082687778890"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/10000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bad1b429679f45a8a9880fea33172aaa"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Word: ' church'. Expected freq 0.6384, observed freq 1.0000\n","Word: ' house' . Expected freq 0.3616, observed freq 0.0000\n"]}],"source":["prompt = \"John and Mary went to the\"\n","input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n","logits = model(input_ids)[0, -1]\n","\n","expected_top_10pct = {\n","    \" church\": 0.0648,\n","    \" house\": 0.0367, # These are the two most likely tokens, and add up to >10%\n","}\n","top_10pct_sum = sum(expected_top_10pct.values())\n","\n","observed_freqs = defaultdict(int)\n","\n","N = 10000\n","for _ in tqdm(range(N)):\n","    token = TransformerSampler.sample_next_token(input_ids.squeeze(), logits, top_p=0.1)\n","    observed_freqs[tokenizer.decode(token)] += 1\n","\n","for word in expected_top_10pct:\n","    expected_freq = expected_top_10pct[word] / top_10pct_sum\n","    observed_freq = observed_freqs[word] / N\n","    print(f\"Word: {word!r:<9}. Expected freq {expected_freq:.4f}, observed freq {observed_freq:.4f}\")\n","    assert abs(observed_freq - expected_freq) < 0.4, \"Try increasing N if this fails by a small amount.\""]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"},"widgets":{"application/vnd.jupyter.widget-state+json":{"3bcf60ec028745ddb63a00c1601d3f03":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f3f8a061202f420daaeb36265387fbb6","IPY_MODEL_b5f5d07f7f90434abad654888d032007","IPY_MODEL_c82625f2ec57472eb315b4abb4de2676"],"layout":"IPY_MODEL_2af8bb81e7f14a7e9d8b0a23ebdc1306"}},"f3f8a061202f420daaeb36265387fbb6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_742e1d25c19548f7834f8697241fa8bd","placeholder":"​","style":"IPY_MODEL_ca2d2e52bce1446ca56c37c5196dd4f7","value":"config.json: 100%"}},"b5f5d07f7f90434abad654888d032007":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f46343a83fa4398ad9148d968874a4c","max":665,"min":0,"orientation":"horizontal","style":"IPY_MODEL_df77d574e4a8403bbe28c03f955fbf0d","value":665}},"c82625f2ec57472eb315b4abb4de2676":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_24c6c44c34b742eba9b7192393c49c21","placeholder":"​","style":"IPY_MODEL_3c82ae1e83d94c3eb4dbd751fc6e2bd8","value":" 665/665 [00:00&lt;00:00, 14.3kB/s]"}},"2af8bb81e7f14a7e9d8b0a23ebdc1306":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"742e1d25c19548f7834f8697241fa8bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ca2d2e52bce1446ca56c37c5196dd4f7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4f46343a83fa4398ad9148d968874a4c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df77d574e4a8403bbe28c03f955fbf0d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"24c6c44c34b742eba9b7192393c49c21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c82ae1e83d94c3eb4dbd751fc6e2bd8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"32fba32fcdcd42f29b7dd3fffc4bed89":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5abe8076318d47e1ac751b608014645e","IPY_MODEL_6497fc31b7dd4e71a2df915a444dc55c","IPY_MODEL_63a4c3fdf04d4ef8a9fca149e7d62f98"],"layout":"IPY_MODEL_449a5ad462f144c1b3a57f4e73a436b3"}},"5abe8076318d47e1ac751b608014645e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb4afd36146e4442b8407331642a6b6e","placeholder":"​","style":"IPY_MODEL_7509bff3efca4f509f06ae767475547b","value":"model.safetensors: 100%"}},"6497fc31b7dd4e71a2df915a444dc55c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_aef809e06b464861b6c85ea9c08c78b8","max":548105171,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7cd4f44a777f4ee082111f6fe7125cdd","value":548105171}},"63a4c3fdf04d4ef8a9fca149e7d62f98":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_27542a45f7b7406cb1c0cce26bef3a10","placeholder":"​","style":"IPY_MODEL_e12f3a13c30c43cf995be53227942a37","value":" 548M/548M [00:04&lt;00:00, 141MB/s]"}},"449a5ad462f144c1b3a57f4e73a436b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb4afd36146e4442b8407331642a6b6e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7509bff3efca4f509f06ae767475547b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aef809e06b464861b6c85ea9c08c78b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7cd4f44a777f4ee082111f6fe7125cdd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"27542a45f7b7406cb1c0cce26bef3a10":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e12f3a13c30c43cf995be53227942a37":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f03229988a9644e389dbd2d3e8045ce5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3b9a9cd5365f47c2b3fd918881cd86ba","IPY_MODEL_d650b681deee447c875ca49d6427577f","IPY_MODEL_a14d1b0351e447ee96de26ad9724cac0"],"layout":"IPY_MODEL_99fa4debe96346e896359ccc92038028"}},"3b9a9cd5365f47c2b3fd918881cd86ba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2335b5a05d534c3998cc77ce1c28cc8a","placeholder":"​","style":"IPY_MODEL_3cf234110b9846d7a73b5e0952722cbe","value":"generation_config.json: 100%"}},"d650b681deee447c875ca49d6427577f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e500dac50f604837814510bfb8d1915d","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8299b8be7d4545f4813eb1e018a2a9a7","value":124}},"a14d1b0351e447ee96de26ad9724cac0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f80c86aa9ec44596ac38aa79a13dcfbd","placeholder":"​","style":"IPY_MODEL_6539743063bb47c4aeaab67b2dfef072","value":" 124/124 [00:00&lt;00:00, 2.42kB/s]"}},"99fa4debe96346e896359ccc92038028":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2335b5a05d534c3998cc77ce1c28cc8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3cf234110b9846d7a73b5e0952722cbe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e500dac50f604837814510bfb8d1915d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8299b8be7d4545f4813eb1e018a2a9a7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f80c86aa9ec44596ac38aa79a13dcfbd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6539743063bb47c4aeaab67b2dfef072":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c3e702e9a0b4474ba968b1a04fcf4730":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_792dea46bcf945f6993b3902e2250ab6","IPY_MODEL_ebcf0a50088f404c9675d5c2d64513c9","IPY_MODEL_a259bf6d873a4871b6bd29dfe613319c"],"layout":"IPY_MODEL_50ac5311da0e4c0c958ef61d444ded71"}},"792dea46bcf945f6993b3902e2250ab6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_99504e4831cf4a8ea9b88574eb54725c","placeholder":"​","style":"IPY_MODEL_7412b986cd904188a017bd51a135a1d8","value":"tokenizer_config.json: 100%"}},"ebcf0a50088f404c9675d5c2d64513c9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a2fa306457b4634a700589581a5adc4","max":26,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b3310d58ed404c3fb0fb012cdd80b2fd","value":26}},"a259bf6d873a4871b6bd29dfe613319c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_29b37ce9d2c84b79857bd8f95ccd6cf3","placeholder":"​","style":"IPY_MODEL_b7a4e36bfd73454787df7c411f4c7b09","value":" 26.0/26.0 [00:00&lt;00:00, 343B/s]"}},"50ac5311da0e4c0c958ef61d444ded71":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99504e4831cf4a8ea9b88574eb54725c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7412b986cd904188a017bd51a135a1d8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9a2fa306457b4634a700589581a5adc4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3310d58ed404c3fb0fb012cdd80b2fd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"29b37ce9d2c84b79857bd8f95ccd6cf3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7a4e36bfd73454787df7c411f4c7b09":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"373a12455c92462e945dfd9b9ffe23e4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fd71311e804a4a93b7510db9e5a41037","IPY_MODEL_5e4b3431f26941349c4af71055ae5e42","IPY_MODEL_2e9829ac1e1040bd8c075e467c95da13"],"layout":"IPY_MODEL_ed64b016f33b4d498e867c51b834b47c"}},"fd71311e804a4a93b7510db9e5a41037":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_853987c846c847449acb075dca984620","placeholder":"​","style":"IPY_MODEL_b726612a5c8b47acbc8b74d00e9497e6","value":"vocab.json: 100%"}},"5e4b3431f26941349c4af71055ae5e42":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e2690e8bf2d40919b4e5adb39257d33","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b65c9e49fedf4aa9b6bd8e0bedd9b68b","value":1042301}},"2e9829ac1e1040bd8c075e467c95da13":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_893f8ffd0b5e440ab828a0076c661db1","placeholder":"​","style":"IPY_MODEL_b400f08aaacf4cc79bd2c25ce39d4ef0","value":" 1.04M/1.04M [00:00&lt;00:00, 1.39MB/s]"}},"ed64b016f33b4d498e867c51b834b47c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"853987c846c847449acb075dca984620":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b726612a5c8b47acbc8b74d00e9497e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5e2690e8bf2d40919b4e5adb39257d33":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b65c9e49fedf4aa9b6bd8e0bedd9b68b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"893f8ffd0b5e440ab828a0076c661db1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b400f08aaacf4cc79bd2c25ce39d4ef0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8d9a25de868744eaaad81fa5c5104807":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e0ac2dece79e436bbd3c91c857c1e3a8","IPY_MODEL_554d1f9abf4145c585623e025eda655b","IPY_MODEL_299cbacc02e74561b5de6b88f228e286"],"layout":"IPY_MODEL_f76b9221a90c48cf95360e8e3704efe4"}},"e0ac2dece79e436bbd3c91c857c1e3a8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c12d583ab994ffca0021ece5d2f2920","placeholder":"​","style":"IPY_MODEL_a8a2c618f3c94d98b0836deda86855a3","value":"merges.txt: 100%"}},"554d1f9abf4145c585623e025eda655b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b3aa81cf46745b9a24756ebc1eeec3a","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_97dbe9a640f64ac29cf5e6ffff54430c","value":456318}},"299cbacc02e74561b5de6b88f228e286":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e302a8bb2ec4a92b8507c10ce3e5ec6","placeholder":"​","style":"IPY_MODEL_05a7d4fe95ef4a22b120bdc30417bcde","value":" 456k/456k [00:00&lt;00:00, 924kB/s]"}},"f76b9221a90c48cf95360e8e3704efe4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c12d583ab994ffca0021ece5d2f2920":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8a2c618f3c94d98b0836deda86855a3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6b3aa81cf46745b9a24756ebc1eeec3a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97dbe9a640f64ac29cf5e6ffff54430c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9e302a8bb2ec4a92b8507c10ce3e5ec6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"05a7d4fe95ef4a22b120bdc30417bcde":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a3ad01b612a94e96bf9a0b51cb9376ba":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b4ec44d9a60b4a37942e6e076027430b","IPY_MODEL_289bbb88f68242f3861def71b15b0375","IPY_MODEL_71c0d1f4a4554278909d20cfac6a1df9"],"layout":"IPY_MODEL_966a95b868e84f02849ea9ff65d5a3ce"}},"b4ec44d9a60b4a37942e6e076027430b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e528e6f43eae48dfa1311640237b8590","placeholder":"​","style":"IPY_MODEL_389359b93d06464db2c47fdcef209a12","value":"tokenizer.json: 100%"}},"289bbb88f68242f3861def71b15b0375":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_df37ba4e523b4313adcd04c7ba4c2864","max":1355256,"min":0,"orientation":"horizontal","style":"IPY_MODEL_43bd78b6b7484550adfd11882dc3eb37","value":1355256}},"71c0d1f4a4554278909d20cfac6a1df9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a045cbdd7b4d452585978b0babbb1244","placeholder":"​","style":"IPY_MODEL_f74df40d30a94c6890ad148d28f32de2","value":" 1.36M/1.36M [00:00&lt;00:00, 14.0MB/s]"}},"966a95b868e84f02849ea9ff65d5a3ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e528e6f43eae48dfa1311640237b8590":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"389359b93d06464db2c47fdcef209a12":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"df37ba4e523b4313adcd04c7ba4c2864":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43bd78b6b7484550adfd11882dc3eb37":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a045cbdd7b4d452585978b0babbb1244":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f74df40d30a94c6890ad148d28f32de2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f4f8cad9ecad43f9b70c95cd50389a1c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f331e3d29cb44929b3415228e7d74a6e","IPY_MODEL_297d6a1b2b2c423d82b5d55be1618bb0","IPY_MODEL_fd8feecfbadf44ea9f85f6c407dc3d06"],"layout":"IPY_MODEL_fbd8f1c95a8a44dca01830d15498b5ae"}},"f331e3d29cb44929b3415228e7d74a6e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_225ef4d875d543348fea6691951ba1ec","placeholder":"​","style":"IPY_MODEL_6bf1bcb526204b039218022b27b508d0","value":"100%"}},"297d6a1b2b2c423d82b5d55be1618bb0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_35b4ab69177e480c92a944fbe62ed71f","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_404fcf3b39504f958eef710df2abe503","value":100}},"fd8feecfbadf44ea9f85f6c407dc3d06":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c35e9ae6dcc466e9d9aa39c45f37115","placeholder":"​","style":"IPY_MODEL_80c97cc99669486ca17deaf79c28f857","value":" 100/100 [00:02&lt;00:00, 45.68it/s]"}},"fbd8f1c95a8a44dca01830d15498b5ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"225ef4d875d543348fea6691951ba1ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6bf1bcb526204b039218022b27b508d0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"35b4ab69177e480c92a944fbe62ed71f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"404fcf3b39504f958eef710df2abe503":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4c35e9ae6dcc466e9d9aa39c45f37115":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80c97cc99669486ca17deaf79c28f857":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"96efcb1fa583440cbef05d4aa4de7dc8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_312f6c82b0644746b51aafb8f0d6e66d","IPY_MODEL_aa539d9ddf414ad2bd8ec8725afba3b1","IPY_MODEL_e0c2f547697a49138dac8d61c3f7c4b2"],"layout":"IPY_MODEL_a002a7f1aea641f38f5b77aad81092c8"}},"312f6c82b0644746b51aafb8f0d6e66d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_530526a7fb4d4ebcb91a20feba0e7f39","placeholder":"​","style":"IPY_MODEL_a81c71e60d584752a17533b6eaac68f2","value":"100%"}},"aa539d9ddf414ad2bd8ec8725afba3b1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_65b3fdc7757f4126b2e0c261fd99f59d","max":10000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d95d9d037409404d8dcca81d5580b2d0","value":10000}},"e0c2f547697a49138dac8d61c3f7c4b2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_23184f4f5bae48acbb07029e5925ea7a","placeholder":"​","style":"IPY_MODEL_68a47d916535453dbc96c31b07585f1c","value":" 10000/10000 [00:06&lt;00:00, 1684.24it/s]"}},"a002a7f1aea641f38f5b77aad81092c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"530526a7fb4d4ebcb91a20feba0e7f39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a81c71e60d584752a17533b6eaac68f2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"65b3fdc7757f4126b2e0c261fd99f59d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d95d9d037409404d8dcca81d5580b2d0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"23184f4f5bae48acbb07029e5925ea7a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68a47d916535453dbc96c31b07585f1c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bad1b429679f45a8a9880fea33172aaa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0e0d078a9d214fe9a3a27b4a1122c2c1","IPY_MODEL_aea052813b2746ff88d21fdc50f37d16","IPY_MODEL_930cac735865401285c284e6e4e8094f"],"layout":"IPY_MODEL_880058612c16466da37f87ca4dfef897"}},"0e0d078a9d214fe9a3a27b4a1122c2c1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_376b93ca857c4f0b8336512598c7dc60","placeholder":"​","style":"IPY_MODEL_21b6130c332f42599c68324ef8bf16fc","value":"100%"}},"aea052813b2746ff88d21fdc50f37d16":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c378b0b15d09491ba00fe0fe9027af39","max":10000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4750f63552a94812a5e08ab1b88bd934","value":10000}},"930cac735865401285c284e6e4e8094f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_94e0ab5c97754afc988235919f07f085","placeholder":"​","style":"IPY_MODEL_25ff5eca46a1407b9d57ade8aa9f22a0","value":" 10000/10000 [00:06&lt;00:00, 1727.14it/s]"}},"880058612c16466da37f87ca4dfef897":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"376b93ca857c4f0b8336512598c7dc60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21b6130c332f42599c68324ef8bf16fc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c378b0b15d09491ba00fe0fe9027af39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4750f63552a94812a5e08ab1b88bd934":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"94e0ab5c97754afc988235919f07f085":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25ff5eca46a1407b9d57ade8aa9f22a0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}